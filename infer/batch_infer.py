# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#!/usr/bin/env python3
"""
æ‰¹é‡æ¨ç†è„šæœ¬ - å¯¹ReportBenchæ•°æ®è¿›è¡Œå¤šæ¨¡å‹æ¨ç†ï¼ˆå¹¶è¡Œç‰ˆæœ¬ï¼‰

æ”¯æŒåŠŸèƒ½ï¼š
1. è¯»å–ReportBench_v0.7_sample_150_sheet1.csvæ–‡ä»¶
2. ä½¿ç”¨å››ä¸ªæ¨¡å‹è¿›è¡Œæ‰¹é‡æ¨ç†ï¼ˆæ”¯æŒå¹¶è¡ŒåŠ é€Ÿï¼‰
3. è¾“å‡ºç»“æœä¸ºjsonlæ ¼å¼
4. æ”¯æŒè¿›åº¦æ˜¾ç¤ºå’Œé”™è¯¯æ¢å¤
5. çº¿ç¨‹å®‰å…¨çš„å¹¶è¡Œå¤„ç†å’Œè¿›åº¦æ›´æ–°
6. æ”¯æŒæ¨¡æ¿å˜é‡æ˜ å°„å’Œå¤šåˆ—æ•°æ®ç»„è£…
"""

import pandas as pd
import json
import time
import argparse
import threading
import random
import re
from pathlib import Path
from typing import Dict, List, Any, Tuple
from datetime import datetime
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed

from utils import build_test_model
from langchain.schema import HumanMessage

# å››ä¸ªå¯ç”¨æ¨¡å‹
MODELS = [
    "o3-2025-04-16",
    "o4-mini-2025-04-16", 
    "gemini-2.5-pro-preview-05-06",
    "gcp-claude4-opus"
]

# å¯ç”¨çš„promptåˆ—
PROMPT_COLUMNS = [
    "ä¸­æ–‡prompt",
    "sentence", 
    "paragraph",
    "detail"
]

# çº¿ç¨‹é”ç”¨äºæ–‡ä»¶å†™å…¥å’Œè¿›åº¦æ›´æ–°
file_lock = threading.Lock()

def extract_template_variables(template: str) -> List[str]:
    """ä»æ¨¡æ¿ä¸­æå–æ‰€æœ‰å˜é‡å"""
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… {å˜é‡å} æ¨¡å¼
    pattern = r'\{([^}]+)\}'
    variables = re.findall(pattern, template)
    unique_variables = list(set(variables))  # å»é‡
    print(f"ğŸ“‹ æå–åˆ°æ¨¡æ¿å˜é‡: {unique_variables}")
    return unique_variables

def build_column_mapping(variables: List[str], csv_columns: List[str]) -> Dict[str, str]:
    """å»ºç«‹æ¨¡æ¿å˜é‡å’ŒCSVåˆ—çš„æ˜ å°„å…³ç³»"""
    print(f"ğŸ”— å»ºç«‹å˜é‡æ˜ å°„å…³ç³»...")
    mapping = {}
    
    for var in variables:
        # é¦–å…ˆå°è¯•æ‰¾åŒååˆ—
        if var in csv_columns:
            mapping[var] = var
            print(f"  âœ… {var} -> {var} (åŒååˆ—)")
        else:
            # æ‰¾ä¸åˆ°åŒååˆ—ï¼Œæ˜¾ç¤ºæ‰€æœ‰å¯ç”¨åˆ—å¹¶è¯·æ±‚ç”¨æˆ·è¾“å…¥
            print(f"\nâŒ æ‰¾ä¸åˆ°å˜é‡ '{var}' å¯¹åº”çš„åŒååˆ—")
            print(f"ğŸ“Š å¯ç”¨çš„CSVåˆ—:")
            for i, col in enumerate(csv_columns, 1):
                print(f"  {i:2d}. {col}")
            
            while True:
                user_input = input(f"\nè¯·ä¸ºå˜é‡ '{var}' é€‰æ‹©å¯¹åº”çš„åˆ—ï¼ˆè¾“å…¥åˆ—åæˆ–åºå·ï¼‰: ").strip()
                
                if not user_input:
                    print("âŒ è¾“å…¥ä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥")
                    continue
                
                # å°è¯•æŒ‰åºå·è§£æ
                if user_input.isdigit():
                    col_index = int(user_input) - 1
                    if 0 <= col_index < len(csv_columns):
                        column_name = csv_columns[col_index]
                        mapping[var] = column_name
                        print(f"  âœ… {var} -> {column_name} (ç”¨æˆ·é€‰æ‹©)")
                        break
                    else:
                        print(f"âŒ åºå· {user_input} è¶…å‡ºèŒƒå›´ï¼Œè¯·è¾“å…¥1-{len(csv_columns)}ä¹‹é—´çš„æ•°å­—")
                        continue
                
                # å°è¯•æŒ‰åˆ—åè§£æ
                if user_input in csv_columns:
                    mapping[var] = user_input
                    print(f"  âœ… {var} -> {user_input} (ç”¨æˆ·é€‰æ‹©)")
                    break
                else:
                    print(f"âŒ åˆ—å '{user_input}' ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°è¾“å…¥")
                    continue
    
    print(f"\nğŸ¯ æœ€ç»ˆæ˜ å°„å…³ç³»:")
    for var, col in mapping.items():
        print(f"  {var} -> {col}")
    
    return mapping

def apply_template_with_mapping(template: str, mapping: Dict[str, str], row: pd.Series) -> str:
    """ä½¿ç”¨æ˜ å°„å…³ç³»å°†è¡Œæ•°æ®å¡«å…¥æ¨¡æ¿"""
    try:
        # å‡†å¤‡å˜é‡å€¼å­—å…¸
        template_values = {}
        for var, col in mapping.items():
            value = row.get(col, '')
            if pd.isna(value):
                value = ''
            template_values[var] = str(value).strip()
        
        # ä½¿ç”¨formatæ–¹æ³•å¡«å……æ¨¡æ¿
        formatted_prompt = template.format(**template_values)
        return formatted_prompt
    except Exception as e:
        print(f"âŒ æ¨¡æ¿åº”ç”¨å¤±è´¥: {e}")
        # å¦‚æœæ¨¡æ¿åº”ç”¨å¤±è´¥ï¼Œè¿”å›åŸå§‹æ¨¡æ¿
        return template

def is_rate_limit_error(error_message: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºé™æµé”™è¯¯"""
    rate_limit_indicators = [
        "rate limit", "rate_limit", "ratelimit",
        "429", "too many requests", "quota exceeded",
        "throttled", "throttling", "é™æµ", "é¢‘ç‡é™åˆ¶",
        "exceed", "maximum", "limit exceeded",
        "retry after", "retry-after", "è¯·æ±‚è¿‡äºé¢‘ç¹",
        "concurrent requests", "è¯·ç¨åé‡è¯•"
    ]
    
    error_lower = error_message.lower()
    return any(indicator in error_lower for indicator in rate_limit_indicators)

def exponential_backoff(attempt: int, base_delay: float = 1.0, max_delay: float = 60.0) -> float:
    """æŒ‡æ•°é€€é¿ç®—æ³•è®¡ç®—å»¶è¿Ÿæ—¶é—´"""
    # åŸºç¡€å»¶è¿Ÿ * 2^é‡è¯•æ¬¡æ•° + éšæœºæŠ–åŠ¨
    delay = min(base_delay * (2 ** attempt), max_delay)
    # æ·»åŠ 10%çš„éšæœºæŠ–åŠ¨ï¼Œé¿å…æ‰€æœ‰çº¿ç¨‹åŒæ—¶é‡è¯•
    jitter = delay * 0.1 * random.random()
    return delay + jitter

def load_data(csv_path: str) -> pd.DataFrame:
    """åŠ è½½CSVæ•°æ®"""
    print(f"ğŸ“– åŠ è½½æ•°æ®æ–‡ä»¶: {csv_path}")
    df = pd.read_csv(csv_path)
    print(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡æ•°æ®")
    return df

def build_models(model_list: List[str]) -> Dict[str, Any]:
    """æ„å»ºæŒ‡å®šçš„æ¨¡å‹"""
    print(f"ğŸ”§ æ„å»ºæ¨¡å‹...")
    models = {}
    
    for model_name in model_list:
        try:
            print(f"  æ„å»ºæ¨¡å‹: {model_name}")
            model = build_test_model(model_name)
            models[model_name] = model
            print(f"  âœ… {model_name} æ„å»ºæˆåŠŸ")
        except Exception as e:
            print(f"  âŒ {model_name} æ„å»ºå¤±è´¥: {e}")
            models[model_name] = None
    
    successful_models = [name for name, model in models.items() if model is not None]
    print(f"âœ… æˆåŠŸæ„å»º {len(successful_models)}/{len(model_list)} ä¸ªæ¨¡å‹")
    
    if not successful_models:
        raise RuntimeError("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ï¼")
    
    return models

def infer_single_with_retry(model, prompt: str, model_name: str, max_retries: int = 3, 
                           timeout: int = 60) -> Dict[str, Any]:
    """å¸¦é‡è¯•æœºåˆ¶çš„å•æ¬¡æ¨ç†"""
    start_time = time.time()
    attempt = 0
    total_retry_delay = 0
    
    while True:
        try:
            attempt_start = time.time()
            response = model.invoke([HumanMessage(content=prompt)])
            attempt_end = time.time()
            
            # æˆåŠŸæ‰§è¡Œ
            total_time = time.time() - start_time
            return {
                "success": True,
                "response": response.content,
                "model_name": model_name,
                "response_time": round(total_time, 2),
                "timestamp": datetime.now().isoformat(),
                "error": None,
                "retry_count": attempt,
                "retry_delay": total_retry_delay
            }
            
        except Exception as e:
            error_msg = str(e)
            is_rate_limit = is_rate_limit_error(error_msg)
            
            # åˆ¤æ–­æ˜¯å¦éœ€è¦é‡è¯•
            should_retry = False
            if is_rate_limit:
                # é™æµé”™è¯¯ï¼šæ— é™é‡è¯•
                should_retry = True
                retry_reason = "rate_limit"
            elif attempt < max_retries:
                # å…¶ä»–é”™è¯¯ï¼šæœ‰é™é‡è¯•
                should_retry = True
                retry_reason = "other_error"
            
            if should_retry:
                attempt += 1
                
                # è®¡ç®—é€€é¿å»¶è¿Ÿ
                if is_rate_limit:
                    # é™æµé”™è¯¯ï¼šè¾ƒé•¿çš„é€€é¿æ—¶é—´
                    base_delay = 2.0
                    max_delay = 120.0
                else:
                    # å…¶ä»–é”™è¯¯ï¼šè¾ƒçŸ­çš„é€€é¿æ—¶é—´
                    base_delay = 1.0
                    max_delay = 30.0
                
                delay = exponential_backoff(attempt - 1, base_delay, max_delay)
                total_retry_delay += delay
                
                # ç­‰å¾…åé‡è¯•
                time.sleep(delay)
                continue
            
            # ä¸å†é‡è¯•ï¼Œè¿”å›å¤±è´¥ç»“æœ
            total_time = time.time() - start_time
            return {
                "success": False,
                "response": None,
                "model_name": model_name,
                "response_time": round(total_time, 2),
                "timestamp": datetime.now().isoformat(),
                "error": error_msg,
                "retry_count": attempt,
                "retry_delay": total_retry_delay,
                "is_rate_limit": is_rate_limit
            }

def process_single_task(task_data: Tuple[int, str, str, Dict[str, Any], Any, str, int]) -> Dict[str, Any]:
    """å¤„ç†å•ä¸ªæ¨ç†ä»»åŠ¡"""
    row_idx, model_name, prompt, base_data, model, delay, max_retries = task_data
    
    # æ‰§è¡Œæ¨ç†ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
    result = infer_single_with_retry(model, prompt, model_name, max_retries)
    
    # åˆå¹¶ç»“æœ
    output_data = {**base_data, **result}
    
    # æ·»åŠ çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…APIé™æµ
    if delay > 0:
        time.sleep(delay)
    
    return output_data

def write_result_to_file(result: Dict[str, Any], file_handle, pbar: tqdm) -> None:
    """çº¿ç¨‹å®‰å…¨åœ°å†™å…¥ç»“æœåˆ°æ–‡ä»¶å¹¶æ›´æ–°è¿›åº¦æ¡"""
    with file_lock:
        file_handle.write(json.dumps(result, ensure_ascii=False) + '\n')
        file_handle.flush()
        
        # æ›´æ–°è¿›åº¦æ¡
        retry_count = result.get('retry_count', 0)
        retry_delay = result.get('retry_delay', 0)
        
        if result['success']:
            retry_info = f"R{retry_count}" if retry_count > 0 else ""
            pbar.set_postfix(status="âœ…", time=f"{result['response_time']}s", 
                           model=result['model_name'][:8], retry=retry_info)
        else:
            is_rate_limit = result.get('is_rate_limit', False)
            error_type = "é™æµ" if is_rate_limit else "é”™è¯¯"
            retry_info = f"R{retry_count}" if retry_count > 0 else ""
            pbar.set_postfix(status="âŒ", type=error_type,
                           model=result['model_name'][:8], retry=retry_info)
        pbar.update(1)

def load_template(template_path: str) -> str:
    """åŠ è½½æ¨¡æ¿æ–‡ä»¶"""
    try:
        with open(template_path, 'r', encoding='utf-8') as f:
            template = f.read().strip()
        print(f"ğŸ“„ åŠ è½½æ¨¡æ¿: {template_path}")
        print(f"ğŸ“ æ¨¡æ¿å†…å®¹é¢„è§ˆ: {template[:100]}...")
        return template
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡æ¿å¤±è´¥: {e}")
        raise

def apply_template(original_prompt: str, template: str) -> str:
    """åº”ç”¨æ¨¡æ¿åˆ°åŸå§‹prompt"""
    try:
        # ä½¿ç”¨formatæ–¹æ³•å°†åŸå§‹promptå¡«å…¥æ¨¡æ¿
        formatted_prompt = template.format(prompt=original_prompt)
        return formatted_prompt
    except Exception as e:
        print(f"âŒ æ¨¡æ¿åº”ç”¨å¤±è´¥: {e}")
        # å¦‚æœæ¨¡æ¿åº”ç”¨å¤±è´¥ï¼Œè¿”å›åŸå§‹prompt
        return original_prompt

def batch_infer_parallel(df: pd.DataFrame, models: Dict[str, Any], prompt_column: str, 
                        output_path: str, start_idx: int = 0, max_workers: int = 8,
                        delay_between_requests: float = 0.1, max_retries: int = 3,
                        template_path: str = None) -> None:
    """å¹¶è¡Œæ‰¹é‡æ¨ç†"""
    print(f"ğŸš€ å¼€å§‹å¹¶è¡Œæ‰¹é‡æ¨ç†")
    print(f"ğŸ“Š æ•°æ®é‡: {len(df)} æ¡")
    print(f"ğŸ¤– æ¨¡å‹æ•°: {len([m for m in models.values() if m is not None])} ä¸ª")
    print(f"ğŸ“ Promptåˆ—: {prompt_column}")
    print(f"ğŸ’¾ è¾“å‡ºæ–‡ä»¶: {output_path}")
    print(f"ğŸ“ å¼€å§‹ä½ç½®: {start_idx}")
    print(f"ğŸ”§ æœ€å¤§å¹¶å‘æ•°: {max_workers}")
    print(f"â±ï¸  è¯·æ±‚é—´éš”: {delay_between_requests}ç§’")
    print(f"ğŸ”„ æœ€å¤§é‡è¯•æ¬¡æ•°: {max_retries} (é™æµé”™è¯¯æ— é™é‡è¯•)")
    
    # åŠ è½½æ¨¡æ¿å’Œå»ºç«‹æ˜ å°„å…³ç³»ï¼ˆå¦‚æœæä¾›ï¼‰
    template = None
    column_mapping = {}
    if template_path:
        template = load_template(template_path)
        
        # æå–æ¨¡æ¿å˜é‡
        variables = extract_template_variables(template)
        
        if variables:
            # å»ºç«‹åˆ—æ˜ å°„å…³ç³»
            csv_columns = list(df.columns)
            column_mapping = build_column_mapping(variables, csv_columns)
            print(f"ğŸ“„ ä½¿ç”¨æ¨¡æ¿: å·²å¯ç”¨ï¼Œæ˜ å°„ {len(variables)} ä¸ªå˜é‡")
        else:
            print(f"ğŸ“„ ä½¿ç”¨æ¨¡æ¿: å·²å¯ç”¨ï¼Œæ— éœ€å˜é‡æ˜ å°„")
    else:
        print(f"ğŸ“„ ä½¿ç”¨æ¨¡æ¿: æ— ")
    
    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    # å¦‚æœæ˜¯ç»­ä¼ ï¼Œå…ˆè¯»å–å·²æœ‰ç»“æœ
    processed_items = set()
    if output_file.exists() and start_idx > 0:
        print(f"ğŸ“– æ£€æµ‹åˆ°ç°æœ‰è¾“å‡ºæ–‡ä»¶ï¼ŒåŠ è½½å·²å¤„ç†é¡¹ç›®...")
        with open(output_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    data = json.loads(line)
                    processed_items.add((data['row_index'], data['model_name']))
        print(f"âœ… å‘ç° {len(processed_items)} ä¸ªå·²å¤„ç†é¡¹ç›®")
    
    # å‡†å¤‡æ‰€æœ‰ä»»åŠ¡
    tasks = []
    available_models = [(name, model) for name, model in models.items() if model is not None]
    
    for idx, row in df.iterrows():
        if idx < start_idx:
            continue
            
        # è·å–prompt
        prompt = row[prompt_column]
        if pd.isna(prompt) or not str(prompt).strip():
            print(f"âš ï¸  ç¬¬{idx}è¡Œpromptä¸ºç©ºï¼Œè·³è¿‡")
            continue
        
        prompt = str(prompt).strip()
        
        # åº”ç”¨æ¨¡æ¿ï¼ˆå¦‚æœæä¾›ï¼‰
        original_prompt = prompt
        if template and column_mapping:
            # ä½¿ç”¨æ˜ å°„å…³ç³»åº”ç”¨æ¨¡æ¿
            prompt = apply_template_with_mapping(template, column_mapping, row)
        elif template:
            # å…¼å®¹æ—§ç‰ˆæœ¬ï¼Œåªæœ‰promptå˜é‡çš„æƒ…å†µ
            prompt = apply_template(original_prompt, template)
        
        # å‡†å¤‡åŸºç¡€æ•°æ®
        base_data = {
            "row_index": idx,
            "arxiv_id": row.get('arxiv_id', ''),
            "title": row.get('title', ''),
            "prompt_column": prompt_column,
            "original_prompt": original_prompt,
            "prompt": prompt,
            "prompt_length": len(prompt),
            "template_used": template_path is not None,
            "template_variables": list(column_mapping.keys()) if column_mapping else []
        }
        
        # ä¸ºæ¯ä¸ªæ¨¡å‹åˆ›å»ºä»»åŠ¡
        for model_name, model in available_models:
            # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡
            if (idx, model_name) in processed_items:
                continue
                
            task_data = (idx, model_name, prompt, base_data, model, delay_between_requests, max_retries)
            tasks.append(task_data)
    
    if not tasks:
        print("âœ… æ‰€æœ‰ä»»åŠ¡éƒ½å·²å®Œæˆï¼Œæ— éœ€å¤„ç†")
        return
    
    print(f"ğŸ“‹ å‡†å¤‡å¤„ç† {len(tasks)} ä¸ªä»»åŠ¡")
    
    # æ‰“å¼€è¾“å‡ºæ–‡ä»¶ï¼ˆè¿½åŠ æ¨¡å¼ï¼‰
    mode = 'a' if start_idx > 0 else 'w'
    with open(output_file, mode, encoding='utf-8') as f:
        
        # åˆ›å»ºè¿›åº¦æ¡
        pbar = tqdm(total=len(tasks), desc="å¹¶è¡Œæ¨ç†è¿›åº¦", 
                   initial=0, ncols=120)
        
        # ä½¿ç”¨ThreadPoolExecutorè¿›è¡Œå¹¶è¡Œå¤„ç†
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_task = {executor.submit(process_single_task, task): task for task in tasks}
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_task):
                try:
                    result = future.result()
                    write_result_to_file(result, f, pbar)
                    
                except Exception as e:
                    # å¤„ç†ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸
                    task_data = future_to_task[future]
                    row_idx, model_name = task_data[0], task_data[1]
                    
                    error_result = {
                        "row_index": row_idx,
                        "model_name": model_name,
                        "success": False,
                        "response": None,
                        "response_time": 0,
                        "timestamp": datetime.now().isoformat(),
                        "error": f"Task execution failed: {str(e)}"
                    }
                    
                    with file_lock:
                        pbar.set_postfix(status="âŒ", error=str(e)[:20], model=model_name[:10])
                        pbar.update(1)
                    
                    print(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥ [ç¬¬{row_idx}è¡Œ, {model_name}]: {e}")
        
        pbar.close()
    
    print(f"ğŸ‰ å¹¶è¡Œæ‰¹é‡æ¨ç†å®Œæˆï¼")
    print(f"ğŸ“Š æ€»ä»»åŠ¡æ•°: {len(tasks)}")
    print(f"ğŸ’¾ ç»“æœä¿å­˜è‡³: {output_path}")

def show_summary(output_path: str) -> None:
    """æ˜¾ç¤ºæ¨ç†ç»“æœç»Ÿè®¡"""
    print(f"\nğŸ“ˆ æ¨ç†ç»“æœç»Ÿè®¡")
    print("=" * 50)
    
    if not Path(output_path).exists():
        print("âŒ è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    results = []
    with open(output_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                results.append(json.loads(line))
    
    if not results:
        print("âŒ æ²¡æœ‰ç»“æœæ•°æ®")
        return
    
    # æŒ‰æ¨¡å‹ç»Ÿè®¡
    model_stats = {}
    total_time = 0
    total_retries = 0
    rate_limit_errors = 0
    
    for result in results:
        model_name = result['model_name']
        if model_name not in model_stats:
            model_stats[model_name] = {
                'total': 0,
                'success': 0,
                'failed': 0,
                'total_time': 0,
                'avg_time': 0,
                'total_retries': 0,
                'rate_limit_errors': 0
            }
        
        stats = model_stats[model_name]
        stats['total'] += 1
        total_time += result['response_time']
        stats['total_time'] += result['response_time']
        
        # ç»Ÿè®¡é‡è¯•æ¬¡æ•°
        retry_count = result.get('retry_count', 0)
        stats['total_retries'] += retry_count
        total_retries += retry_count
        
        # ç»Ÿè®¡é™æµé”™è¯¯
        if result.get('is_rate_limit', False):
            stats['rate_limit_errors'] += 1
            rate_limit_errors += 1
        
        if result['success']:
            stats['success'] += 1
        else:
            stats['failed'] += 1
    
    # è®¡ç®—å¹³å‡æ—¶é—´
    for model_name, stats in model_stats.items():
        if stats['total'] > 0:
            stats['avg_time'] = round(stats['total_time'] / stats['total'], 2)
    
    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†æ¨¡æ¿
    template_used_count = sum(1 for result in results if result.get('template_used', False))
    template_usage = template_used_count > 0
    
    # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
    print(f"æ€»ç»“æœæ•°: {len(results)}")
    print(f"æ€»è€—æ—¶: {round(total_time, 2)}ç§’")
    print(f"æ€»é‡è¯•æ¬¡æ•°: {total_retries}")
    print(f"é™æµé”™è¯¯æ•°: {rate_limit_errors}")
    if template_usage:
        print(f"ä½¿ç”¨æ¨¡æ¿: âœ… ({template_used_count}/{len(results)} æ¡)")
    else:
        print(f"ä½¿ç”¨æ¨¡æ¿: âŒ")
    print()
    
    for model_name, stats in model_stats.items():
        success_rate = round(stats['success'] / stats['total'] * 100, 1) if stats['total'] > 0 else 0
        avg_retries = round(stats['total_retries'] / stats['total'], 1) if stats['total'] > 0 else 0
        print(f"ğŸ¤– {model_name}:")
        print(f"  æ€»æ•°: {stats['total']}")
        print(f"  æˆåŠŸ: {stats['success']} ({success_rate}%)")
        print(f"  å¤±è´¥: {stats['failed']}")
        print(f"  å¹³å‡è€—æ—¶: {stats['avg_time']}ç§’")
        print(f"  æ€»é‡è¯•: {stats['total_retries']} (å¹³å‡{avg_retries}æ¬¡)")
        print(f"  é™æµé”™è¯¯: {stats['rate_limit_errors']}")
        print()

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å¹¶è¡Œæ‰¹é‡æ¨ç†è„šæœ¬")
    parser.add_argument("--csv", default="ReportBench_v0.7_sample_150_sheet1.csv", 
                       help="è¾“å…¥CSVæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--prompt-column", choices=PROMPT_COLUMNS, default="è‹±æ–‡prompt",
                       help="ä½¿ç”¨çš„promptåˆ—å")
    parser.add_argument("--output", help="è¾“å‡ºjsonlæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰")
    parser.add_argument("--start-idx", type=int, default=0,
                       help="å¼€å§‹çš„è¡Œç´¢å¼•ï¼ˆç”¨äºç»­ä¼ ï¼‰")
    parser.add_argument("--models", nargs="+", choices=MODELS, default=MODELS,
                       help="è¦ä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨")
    parser.add_argument("--max-workers", type=int, default=8,
                       help="æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°ï¼ˆé»˜è®¤8ï¼‰")
    parser.add_argument("--delay", type=float, default=0.1,
                       help="è¯·æ±‚é—´éš”æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤0.1ï¼‰")
    parser.add_argument("--max-retries", type=int, default=3,
                       help="éé™æµé”™è¯¯çš„æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤3ï¼Œé™æµé”™è¯¯æ— é™é‡è¯•ï¼‰")
    parser.add_argument("--template", type=str, default=None,
                       help="æ¨¡æ¿æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚eval.txtï¼‰ï¼Œç”¨äºå¯¹åŸå§‹promptè¿›è¡Œæ¨¡æ¿åŒ–å¤„ç†")
    
    args = parser.parse_args()
    
    # ç”Ÿæˆé»˜è®¤è¾“å‡ºæ–‡ä»¶å
    if not args.output:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        column_name = args.prompt_column.replace("æ–‡", "").replace("prompt", "")
        args.output = f"batch_infer_results_{column_name}_{timestamp}.jsonl"
    
    try:
        # åŠ è½½æ•°æ®
        df = load_data(args.csv)
        
        # æ£€æŸ¥promptåˆ—æ˜¯å¦å­˜åœ¨
        if args.prompt_column not in df.columns:
            print(f"âŒ åˆ— '{args.prompt_column}' ä¸å­˜åœ¨")
            print(f"å¯ç”¨åˆ—: {list(df.columns)}")
            return
        
        # è¿‡æ»¤è¦ä½¿ç”¨çš„æ¨¡å‹
        selected_models = [m for m in MODELS if m in args.models]
        
        # æ„å»ºæ¨¡å‹
        models = build_models(selected_models)
        
        # æ‰§è¡Œå¹¶è¡Œæ‰¹é‡æ¨ç†
        batch_infer_parallel(df, models, args.prompt_column, args.output, 
                           args.start_idx, args.max_workers, args.delay, args.max_retries,
                           args.template)
        
        # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
        show_summary(args.output)
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        print(f"ğŸ’¡ å¯ä»¥ä½¿ç”¨ --start-idx å‚æ•°ç»­ä¼ ")
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        raise

if __name__ == "__main__":
    main() 