{"bib_id":"AIinfinance","title":"Artificial intelligence and machine learning in finance: Identifying foundations, themes, and research clusters from bibliometric analysis","author":"Goodell, John and Kumar, Satish and Lim, Weng Marc and Pattnaik, Debidutta","meta_info":{"doi":"10.1016\/j.jbef.2021.100577","journal":"Journal of Behavioral and Experimental Finance","volume":"32","pages":"","month":"08","year":"2021"}}
{"bib_id":"Zhang_2020","title":"Deep Learning for Portfolio Optimization","author":"Zihao Zhang and Stefan Zohren and Stephen Roberts","meta_info":{"journal":"The Journal of Financial Data Science","pages":"8--20","number":"4","volume":"2","publisher":"Pageant Media US","month":"aug","year":"2020","url":"https:\/\/doi.org\/10.3905%2Fjfds.2020.1.042","doi":"10.3905\/jfds.2020.1.042"}}
{"bib_id":"9249416","title":"Machine Learning for Financial Risk Management: A Survey","author":"Mashrur, Akib and Luo, Wei and Zaidi, Nayyar A. and Robles-Kelly, Antonio","meta_info":{"doi":"10.1109\/ACCESS.2020.3036322","pages":"203203-203223","number":"","volume":"8","year":"2020","journal":"IEEE Access"}}
{"bib_id":"wang2019dynamic","title":"Dynamic Portfolio Management with Reinforcement Learning","author":"Junhao Wang and Yinheng Li and Yijie Cao","meta_info":{"primaryclass":"q-fin.PM","archiveprefix":"arXiv","eprint":"1911.11880","year":"2019"}}
{"bib_id":"10.1145\/3490354.3494388","title":"Investor Behavior Modeling by Analyzing Financial Advisor Notes: A Machine Learning Perspective","author":"Pagliaro, Cynthia and Mehta, Dhagash and Shiao, Han-Tai and Wang, Shaofei and Xiong, Luwei","meta_info":{"series":"ICAIF '21","location":"Virtual Event","keywords":"financial advice, investor's modeling, machine learning, natural language processing","numpages":"8","articleno":"23","booktitle":"Proceedings of the Second ACM International Conference on AI in Finance","abstract":"Modeling investor behavior is crucial to identifying behavioral coaching opportunities for financial advisors. With the help of natural language processing (NLP) we analyze an unstructured (textual) dataset of financial advisors' summary notes, taken after every investor conversation, to gain first ever insights into advisor-investor interactions. These insights are used to predict investor needs during adverse market conditions; thus allowing advisors to coach investors and help avoid inappropriate financial decision-making. First, we perform topic modeling to gain insight into the emerging topics and trends. Based on this insight, we construct a supervised classification model to predict the probability that an advised investor will move assets to cash during volatile market periods. To the best of our knowledge, ours is the first work on exploring the advisor-investor relationship using unstructured data. This work may have far-reaching implications for both traditional and emerging financial advisory service models like robo-advising.","doi":"10.1145\/3490354.3494388","url":"https:\/\/doi.org\/10.1145\/3490354.3494388","address":"New York, NY, USA","publisher":"Association for Computing Machinery","isbn":"9781450391481","year":"2022"}}
{"bib_id":"fintextmining","title":"Comprehensive review of text-mining applications in finance","author":"Gupta, Aaryan and Dengre, Vinya and Kheruwala, Hamza and Shah, Manan","meta_info":{"doi":"10.1186\/s40854-020-00205-1","journal":"Journal of Financial Innovation","volume":"6","pages":"","month":"11","year":"2020"}}
{"bib_id":"Shah_Raj_Kumar_P_H","title":"FinAID, A Financial Advisor Application using AI","author":"Shah, Ashish and Raj, Pratik and Kumar, Pushpam and P, Supriya and H V, Asha","meta_info":{"pages":"2282–2286","month":"May","year":"2020","publisher":"Blue Eyes Intelligence Engineering and Sciences Engineering and Sciences Publication - BEIESP","journal":"International Journal of Recent Technology and Engineering (IJRTE)","number":"1","abstractnote":"<jats:p>The need for skilled financial advisors is more than ever in the current scenario when there are in-numerous money-making strategies and at the same time, the global economy might be on the verge of collapse. Also there is a pure lack of good financial advisors and even if you find one, you will end up paying a hefty amount. The current proposed application fulfils the above-stated demand in a cost-effective and reliable way. The proposed system automates the job of a financial advisor using Artificial Intelligence. It provides the user with a simple and easy to use interface where every individual will have their own account handled by Google’s firebase platform. The application uses “Plaid” API which allows app to send a request to the corresponding bank server and fetch the account details of an individual. Logged in user is shown a very comprehensive representation of their account details which also includes category-wise expenditure, their investment, and the savings. One of the unique parts of this project is a Chatbot which is ever ready to answer the queries of the user related to their accounts and finance. Dialogflow will help in the functionality of Chatbot incorporating Google’s machine learning expertise. The proposed application will help provide every needy individual a very reliable, easy to use, and cost-efficient solution to their problem of having a personal financial advisor.<\/jats:p>","doi":"10.35940\/ijrte.a2951.059120","url":"http:\/\/dx.doi.org\/10.35940\/ijrte.A2951.059120","volume":"9"}}
{"bib_id":"raffel2020exploring","title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer","author":"Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu","meta_info":{"primaryclass":"cs.LG","archiveprefix":"arXiv","eprint":"1910.10683","year":"2020"}}
{"bib_id":"graves2014generating","title":"Generating Sequences With Recurrent Neural Networks","author":"Alex Graves","meta_info":{"primaryclass":"cs.NE","archiveprefix":"arXiv","eprint":"1308.0850","year":"2014"}}
{"bib_id":"cho2014learning","title":"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation","author":"Kyunghyun Cho and Bart van Merrienboer and Caglar Gulcehre and Dzmitry Bahdanau and Fethi Bougares and Holger Schwenk and Yoshua Bengio","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"1406.1078","year":"2014"}}
{"bib_id":"vaswani2017attention","title":"Attention Is All You Need","author":"Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"1706.03762","year":"2017"}}
{"bib_id":"devlin2019bert","title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding","author":"Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"1810.04805","year":"2019"}}
{"bib_id":"brown2020language","title":"Language Models are Few-Shot Learners","author":"Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2005.14165","year":"2020"}}
{"bib_id":"deeplearning_fraud_detection","title":"Deep learning detecting fraud in credit card transactions","author":"Roy, Abhimanyu and Sun, Jingyi and Mahoney, Robert and Alonzi, Loreto and Adams, Stephen and Beling, Peter","meta_info":{"doi":"10.1109\/SIEDS.2018.8374722","pages":"129-134","number":"","volume":"","year":"2018","booktitle":"2018 Systems and Information Engineering Design Symposium (SIEDS)"}}
{"bib_id":"creditscoring_deeplearning","title":"A deep learning approach for credit scoring using credit default swaps","author":"Cuicui Luo and Desheng Wu and Dexiang Wu","meta_info":{"abstract":"After 2007–2008 crisis, it is clear that corporate credit scoring is becoming a key role in credit risk management. In this paper, we investigate the performances of credit scoring models applied to CDS data sets. The classification performance of deep learning algorithm such as deep belief networks with Restricted Boltzmann Machines are evaluated and compared with some popular credit scoring models such as logistic regression, multi-layer perceptron and support vector machine. The performance is assessed using the classification accuracy and the area under the receiver operating characteristic curve. It is found that DBN yields the best performance.","keywords":"Deep learning, CDS, Credit scoring, Machine learning","url":"https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0952197616302299","doi":"https:\/\/doi.org\/10.1016\/j.engappai.2016.12.002","issn":"0952-1976","year":"2017","pages":"465-470","volume":"65","journal":"Engineering Applications of Artificial Intelligence"}}
{"bib_id":"bankruptcyprediction","title":"Bankruptcy prediction in firms with statistical and intelligent techniques and a comparison of evolutionary computation approaches","author":"Mu-Yen Chen","meta_info":{"abstract":"In this paper, we compare some traditional statistical methods for predicting financial distress to some more “unconventional” methods, such as decision tree classification, neural networks, and evolutionary computation techniques, using data collected from 200 Taiwan Stock Exchange Corporation (TSEC) listed companies. Empirical experiments were conducted using a total of 42 ratios including 33 financial, 8 non-financial and 1 combined macroeconomic index, using principle component analysis (PCA) to extract suitable variables. This paper makes four critical contributions: (1) with nearly 80% fewer financial ratios by the PCA method, the prediction performance is still able to provide highly-accurate forecasts of financial bankruptcy; (2) we show that traditional statistical methods are better able to handle large datasets without sacrificing prediction performance, while intelligent techniques achieve better performance with smaller datasets and would be adversely affected by huge datasets; (3) empirical results show that C5.0 and CART provide the best prediction performance for imminent bankruptcies; and (4) Support Vector Machines (SVMs) with evolutionary computation provide a good balance of high-accuracy short- and long-term performance predictions for healthy and distressed firms. Therefore, the experimental results show that the Particle Swarm Optimization (PSO) integrated with SVM (PSO–SVM) approach could be considered for predicting potential financial distress.","keywords":"Decision tree classification, Support vector machine, Financial bankruptcy prediction","url":"https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0898122111008947","doi":"https:\/\/doi.org\/10.1016\/j.camwa.2011.10.030","issn":"0898-1221","year":"2011","pages":"4514-4524","number":"12","volume":"62","journal":"Computers & Mathematics with Applications"}}
{"bib_id":"creditscorenn","title":"Neural network credit scoring models","author":"David West","meta_info":{"abstract":"This paper investigates the credit scoring accuracy of five neural network models: multilayer perceptron, mixture-of-experts, radial basis function, learning vector quantization, and fuzzy adaptive resonance. The neural network credit scoring models are tested using 10-fold crossvalidation with two real world data sets. Results are benchmarked against more traditional methods under consideration for commercial applications including linear discriminant analysis, logistic regression, k nearest neighbor, kernel density estimation, and decision trees. Results demonstrate that the multilayer perceptron may not be the most accurate neural network model, and that both the mixture-of-experts and radial basis function neural network models should be considered for credit scoring applications. Logistic regression is found to be the most accurate of the traditional methods.\nScope and purpose\nIn the last few decades quantitative methods known as credit scoring models have been developed for the credit granting decision. The objective of quantitative credit scoring models is to assign credit applicants to one of two groups: a “good credit” group that is likely to repay the financial obligation, or a “bad credit” group that should be denied credit because of a high likelihood of defaulting on the financial obligation. The first model employed for credit scoring, and a commonly used method today, is linear discriminant analysis, a simple parametric statistical method. With the growth of the credit industry and the large loan portfolios under management today, the industry is actively developing more accurate credit scoring models. Even a fraction of a percent increase in credit scoring accuracy is a significant accomplishment. This effort is leading to the investigation of nonparametric statistical methods, classification trees, and neural network technology for credit scoring applications. The purpose of this research is to investigate the accuracy of five neural network architectures for the credit scoring applications and to benchmark their performance against the models currently under investigation today.","keywords":"Credit scoring, Neural networks, Multilayer perceptron, Radial basis function, Mixture-of-experts","url":"https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0305054899001495","doi":"https:\/\/doi.org\/10.1016\/S0305-0548(99)00149-5","issn":"0305-0548","year":"2000","pages":"1131-1152","number":"11","volume":"27","journal":"Computers & Operations Research"}}
{"bib_id":"deeplearninginfinancesurvcey","title":"Deep Learning for Financial Applications : A Survey","author":"Ahmet Murat Ozbayoglu and Mehmet Ugur Gudelek and Omer Berat Sezer","meta_info":{"primaryclass":"q-fin.ST","archiveprefix":"arXiv","eprint":"2002.05786","year":"2020"}}
{"bib_id":"trading_Sentiment","title":"Using Financial News Sentiment for Stock Price Direction Prediction","author":"Fazlija, Bledar and Harder, Pedro","meta_info":{"doi":"10.3390\/math10132156","issn":"2227-7390","url":"https:\/\/www.mdpi.com\/2227-7390\/10\/13\/2156","article-number":"2156","number":"13","year":"2022","volume":"10","journal":"Mathematics"}}
{"bib_id":"chatbot","title":"Chatbots in customer service: Their relevance and impact on service quality","author":"Chiara Valentina Misischia and Flora Poecze and Christine Strauss","meta_info":{"abstract":"Chatbots are increasingly finding their way into e-commerce and e-services, as their implementation opens up promising opportunities to improve customer service. The present paper examines chatbots in this context, elaborating on their functional aspects that are rapidly leading to significant improvements in service quality. First, based on a literature review of recent publications in this field, an overview of their key features and functionalities underlining the relevance of chatbots for customer service is provided. Second, a further contribution is made by introducing two categories of chatbots’ objectives based on their functional dedication, i.e. “improvement of service performance” and “fulfillment of customer’s expectations”. The considered chatbots’ customer-related functions are interaction, entertainment, problem-solving, trendiness, and customization. The chatbot categories are discussed in detail. Their positive influence on service quality, constituting the chatbots’ functional goal, as well as the potential of chatbots in customer service are pointed out.","keywords":"chatbot, e-service agents, customer service, service quality, e-services, e-commerce, artificial intelligence","url":"https:\/\/www.sciencedirect.com\/science\/article\/pii\/S1877050922004689","doi":"https:\/\/doi.org\/10.1016\/j.procs.2022.03.055","issn":"1877-0509","note":"The 13th International Conference on Ambient Systems, Networks and Technologies (ANT) \/ The 5th International Conference on Emerging Data and Industry 4.0 (EDI40)","year":"2022","pages":"421-428","volume":"201","journal":"Procedia Computer Science"}}
{"bib_id":"zeroshot","title":"A Practical Survey on Zero-shot Prompt Design for In-context Learning","author":"Li, Yinheng","meta_info":{"pages":"","publisher":"International Conference Recent Advances in Natural Language Processing ","month":"07","year":"2023"}}
{"bib_id":"zhang2023sentiment","title":"Sentiment Analysis in the Era of Large Language Models: A Reality Check","author":"Wenxuan Zhang and Yue Deng and Bing Liu and Sinno Jialin Pan and Lidong Bing","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2305.15005","year":"2023"}}
{"bib_id":"gpt3","title":"Language Models are Few-Shot Learners","author":"Tom B. Brown and\nBenjamin Mann and\nNick Ryder and\nMelanie Subbiah and\nJared Kaplan and\nPrafulla Dhariwal and\nArvind Neelakantan and\nPranav Shyam and\nGirish Sastry and\nAmanda Askell and\nSandhini Agarwal and\nAriel Herbert-Voss and\nGretchen Krueger and\nTom Henighan and\nRewon Child and\nAditya Ramesh and\nDaniel M. Ziegler and\nJeffrey Wu and\nClemens Winter and\nChristopher Hesse and\nMark Chen and\nEric Sigler and\nMateusz Litwin and\nScott Gray and\nBenjamin Chess and\nJack Clark and\nChristopher Berner and\nSam McCandlish and\nAlec Radford and\nIlya Sutskever and\nDario Amodei","meta_info":{"bibsource":"dblp computer science bibliography, https:\/\/dblp.org","biburl":"https:\/\/dblp.org\/rec\/journals\/corr\/abs-2005-14165.bib","timestamp":"Thu, 25 May 2023 10:38:31 +0200","eprint":"2005.14165","eprinttype":"arXiv","url":"https:\/\/arxiv.org\/abs\/2005.14165","year":"2020","volume":"abs\/2005.14165","journal":"CoRR"}}
{"bib_id":"yang2023fingpt","title":"FinGPT: Open-Source Financial Large Language Models","author":"Hongyang Yang and Xiao-Yang Liu and Christina Dan Wang","meta_info":{"primaryclass":"q-fin.ST","archiveprefix":"arXiv","eprint":"2306.06031","year":"2023"}}
{"bib_id":"semantic_kernel","title":"Semantic Kernel","author":"Microsoft","meta_info":{"commit":"5ae044f53db4af1b8a54ef8c7e2afb17e67568b9","howpublished":"r̆lhttps:\/\/github.com\/microsoft\/semantic-kernel","journal":"GitHub repository","publisher":"GitHub","year":"2023"}}
{"bib_id":"AutoGPTforfinance","title":"Auto-GPT for finance - an exploratory guide - algotrading101 blog","author":"Radovanovic, Igor","meta_info":{"month":"May","year":"2023","journal":"Quantitative Trading Ideas and Guides - AlgoTrading101 Blog","url":"https:\/\/algotrading101.com\/learn\/auto-gpt-finance-guide\/"}}
{"bib_id":"yang2023harnessing","title":"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond","author":"Jingfeng Yang and Hongye Jin and Ruixiang Tang and Xiaotian Han and Qizhang Feng and Haoming Jiang and Bing Yin and Xia Hu","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2304.13712","year":"2023"}}
{"bib_id":"wei2022emergent","title":"Emergent Abilities of Large Language Models","author":"Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2206.07682","year":"2022"}}
{"bib_id":"openai2023gpt4","title":"GPT-4 Technical Report","author":"OpenAI","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2303.08774","year":"2023"}}
{"bib_id":"mlq-ai","title":"GPT-4 for Financial Statements: Building an AI Analyst","author":"Foy, Peter","meta_info":{"url":"https:\/\/www.mlq.ai\/gpt-4-financial-statements-ai-analyst\/","year":"2023","month":"May","howpublished":"MLQ AI"}}
{"bib_id":"nlpfinance","title":"Natural language based financial forecasting: a survey","author":"Xing, Frank and Cambria, Erik and Welsch, Roy","meta_info":{"doi":"10.1007\/s10462-017-9588-9","journal":"Artificial Intelligence Review","volume":"50","pages":"","month":"06","year":"2018"}}
{"bib_id":"liang2022holistic","title":"Holistic Evaluation of Language Models","author":"Percy Liang and Rishi Bommasani and Tony Lee and Dimitris Tsipras and Dilara Soylu and Michihiro Yasunaga and Yian Zhang and Deepak Narayanan and Yuhuai Wu and Ananya Kumar and Benjamin Newman and Binhang Yuan and Bobby Yan and Ce Zhang and Christian Cosgrove and Christopher D. Manning and Christopher Ré and Diana Acosta-Navas and Drew A. Hudson and Eric Zelikman and Esin Durmus and Faisal Ladhak and Frieda Rong and Hongyu Ren and Huaxiu Yao and Jue Wang and Keshav Santhanam and Laurel Orr and Lucia Zheng and Mert Yuksekgonul and Mirac Suzgun and Nathan Kim and Neel Guha and Niladri Chatterji and Omar Khattab and Peter Henderson and Qian Huang and Ryan Chi and Sang Michael Xie and Shibani Santurkar and Surya Ganguli and Tatsunori Hashimoto and Thomas Icard and Tianyi Zhang and Vishrav Chaudhary and William Wang and Xuechen Li and Yifan Mai and Yuhui Zhang and Yuta Koreeda","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2211.09110","year":"2022"}}
{"bib_id":"tamkin2021understanding","title":"Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models","author":"Alex Tamkin and Miles Brundage and Jack Clark and Deep Ganguli","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2102.02503","year":"2021"}}
{"bib_id":"jpmorgan","title":"JPMorgan is developing a CHATGPT-like A.I. service that gives investment advice","author":"Hugh Son","meta_info":{"month":"May","year":"2023","publisher":"CNBC","journal":"CNBC","url":"https:\/\/www.cnbc.com\/2023\/05\/25\/jpmorgan-develops-ai-investment-advisor.html"}}
{"bib_id":"KIM2003307","title":"Financial time series forecasting using support vector machines","author":"Kyoung-jae Kim","meta_info":{"abstract":"Support vector machines (SVMs) are promising methods for the prediction of financial time-series because they use a risk function consisting of the empirical error and a regularized term which is derived from the structural risk minimization principle. This study applies SVM to predicting the stock price index. In addition, this study examines the feasibility of applying SVM in financial forecasting by comparing it with back-propagation neural networks and case-based reasoning. The experimental results show that SVM provides a promising alternative to stock market prediction.","keywords":"Support vector machines, Back-propagation neural networks, Case-based reasoning, Financial time series","url":"https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0925231203003722","doi":"https:\/\/doi.org\/10.1016\/S0925-2312(03)00372-2","issn":"0925-2312","note":"Support Vector Machines","year":"2003","pages":"307-319","number":"1","volume":"55","journal":"Neurocomputing"}}
{"bib_id":"bengio2000neural","title":"A neural probabilistic language model","author":"Bengio, Yoshua and Ducharme, Réjean and Vincent, Pascal","meta_info":{"year":"2000","volume":"13","journal":"Advances in neural information processing systems"}}
{"bib_id":"zolotareva2021aiding","title":"Aiding Long-Term Investment Decisions with XGBoost Machine Learning Model","author":"Ekaterina Zolotareva","meta_info":{"primaryclass":"q-fin.CP","archiveprefix":"arXiv","eprint":"2104.09341","year":"2021"}}
{"bib_id":"deepnntrading","title":"A Deep Neural-Network Based Stock Trading System Based on Evolutionary Optimized Technical Analysis Parameters","author":"Omer Berat Sezer and Murat Ozbayoglu and Erdogan Dogdu","meta_info":{"abstract":"In this study, we propose a stock trading system based on optimized technical analysis parameters for creating buy-sell points using genetic algorithms. The model is developed utilizing Apache Spark big data platform. The optimized parameters are then passed to a deep MLP neural network for buy-sell-hold predictions. Dow 30 stocks are chosen for model validation. Each Dow stock is trained separately using daily close prices between 1996-2016 and tested between 2007-2016. The results indicate that optimizing the technical indicator parameters not only enhances the stock trading performance but also provides a model that might be used as an alternative to Buy and Hold and other standard technical analysis models.","keywords":"Stock Trading, Stock Market, Deep Neural-Network, Evolutionary Algorithms, Technical Analysis","url":"https:\/\/www.sciencedirect.com\/science\/article\/pii\/S1877050917318252","doi":"https:\/\/doi.org\/10.1016\/j.procs.2017.09.031","issn":"1877-0509","note":"Complex Adaptive Systems Conference with Theme: Engineering Cyber Physical Systems, CAS October 30 – November 1, 2017, Chicago, Illinois, USA","year":"2017","pages":"473-480","volume":"114","journal":"Procedia Computer Science"}}
{"bib_id":"wen2023transformers","title":"Transformers in Time Series: A Survey","author":"Qingsong Wen and Tian Zhou and Chaoli Zhang and Weiqi Chen and Ziqing Ma and Junchi Yan and Liang Sun","meta_info":{"primaryclass":"cs.LG","archiveprefix":"arXiv","eprint":"2202.07125","year":"2023"}}
{"bib_id":"almutiri2022markov","title":"Markov models applications in natural language processing: a survey","author":"Almutiri, Talal and Nadeem, Farrukh","meta_info":{"year":"2022","pages":"1--16","volume":"2","journal":"Int. J. Inf. Technol. Comput. Sci"}}
{"bib_id":"hu2021lora","title":"LoRA: Low-Rank Adaptation of Large Language Models","author":"Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2106.09685","year":"2021"}}
{"bib_id":"chung2022scaling","title":"Scaling Instruction-Finetuned Language Models","author":"Hyung Won Chung and Le Hou and Shayne Longpre and Barret Zoph and Yi Tay and William Fedus and Yunxuan Li and Xuezhi Wang and Mostafa Dehghani and Siddhartha Brahma and Albert Webson and Shixiang Shane Gu and Zhuyun Dai and Mirac Suzgun and Xinyun Chen and Aakanksha Chowdhery and Alex Castro-Ros and Marie Pellat and Kevin Robinson and Dasha Valter and Sharan Narang and Gaurav Mishra and Adams Yu and Vincent Zhao and Yanping Huang and Andrew Dai and Hongkun Yu and Slav Petrov and Ed H. Chi and Jeff Dean and Jacob Devlin and Adam Roberts and Denny Zhou and Quoc V. Le and Jason Wei","meta_info":{"primaryclass":"cs.LG","archiveprefix":"arXiv","eprint":"2210.11416","year":"2022"}}
{"bib_id":"workshop2023bloom","title":"BLOOM: A 176B-Parameter Open-Access Multilingual Language Model","author":"BigScience Workshop and : and Teven Le Scao and Angela Fan and Christopher Akiki and Ellie Pavlick and Suzana Ilić and Daniel Hesslow and Roman Castagné and Alexandra Sasha Luccioni and François Yvon and Matthias Gallé and Jonathan Tow and Alexander M. Rush and Stella Biderman and Albert Webson and Pawan Sasanka Ammanamanchi and Thomas Wang and Benoît Sagot and Niklas Muennighoff and Albert Villanova del Moral and Olatunji Ruwase and Rachel Bawden and Stas Bekman and Angelina McMillan-Major and Iz Beltagy and Huu Nguyen and Lucile Saulnier and Samson Tan and Pedro Ortiz Suarez and Victor Sanh and Hugo Laurençon and Yacine Jernite and Julien Launay and Margaret Mitchell and Colin Raffel and Aaron Gokaslan and Adi Simhi and Aitor Soroa and Alham Fikri Aji and Amit Alfassy and Anna Rogers and Ariel Kreisberg Nitzav and Canwen Xu and Chenghao Mou and Chris Emezue and Christopher Klamm and Colin Leong and Daniel van Strien and David Ifeoluwa Adelani and Dragomir Radev and Eduardo González Ponferrada and Efrat Levkovizh and Ethan Kim and Eyal Bar Natan and Francesco De Toni and Gérard Dupont and Germán Kruszewski and Giada Pistilli and Hady Elsahar and Hamza Benyamina and Hieu Tran and Ian Yu and Idris Abdulmumin and Isaac Johnson and Itziar Gonzalez-Dios and Javier de la Rosa and Jenny Chim and Jesse Dodge and Jian Zhu and Jonathan Chang and Jörg Frohberg and Joseph Tobing and Joydeep Bhattacharjee and Khalid Almubarak and Kimbo Chen and Kyle Lo and Leandro Von Werra and Leon Weber and Long Phan and Loubna Ben allal and Ludovic Tanguy and Manan Dey and Manuel Romero Muñoz and Maraim Masoud and María Grandury and Mario Šaško and Max Huang and Maximin Coavoux and Mayank Singh and Mike Tian-Jian Jiang and Minh Chien Vu and Mohammad A. Jauhar and Mustafa Ghaleb and Nishant Subramani and Nora Kassner and Nurulaqilla Khamis and Olivier Nguyen and Omar Espejel and Ona de Gibert and Paulo Villegas and Peter Henderson and Pierre Colombo and Priscilla Amuok and Quentin Lhoest and Rheza Harliman and Rishi Bommasani and Roberto Luis López and Rui Ribeiro and Salomey Osei and Sampo Pyysalo and Sebastian Nagel and Shamik Bose and Shamsuddeen Hassan Muhammad and Shanya Sharma and Shayne Longpre and Somaieh Nikpoor and Stanislav Silberberg and Suhas Pai and Sydney Zink and Tiago Timponi Torrent and Timo Schick and Tristan Thrush and Valentin Danchev and Vassilina Nikoulina and Veronika Laippala and Violette Lepercq and Vrinda Prabhu and Zaid Alyafeai and Zeerak Talat and Arun Raja and Benjamin Heinzerling and Chenglei Si and Davut Emre Taşar and Elizabeth Salesky and Sabrina J. Mielke and Wilson Y. Lee and Abheesht Sharma and Andrea Santilli and Antoine Chaffin and Arnaud Stiegler and Debajyoti Datta and Eliza Szczechla and Gunjan Chhablani and Han Wang and Harshit Pandey and Hendrik Strobelt and Jason Alan Fries and Jos Rozen and Leo Gao and Lintang Sutawika and M Saiful Bari and Maged S. Al-shaibani and Matteo Manica and Nihal Nayak and Ryan Teehan and Samuel Albanie and Sheng Shen and Srulik Ben-David and Stephen H. Bach and Taewoon Kim and Tali Bers and Thibault Fevry and Trishala Neeraj and Urmish Thakker and Vikas Raunak and Xiangru Tang and Zheng-Xin Yong and Zhiqing Sun and Shaked Brody and Yallow Uri and Hadar Tojarieh and Adam Roberts and Hyung Won Chung and Jaesung Tae and Jason Phang and Ofir Press and Conglong Li and Deepak Narayanan and Hatim Bourfoune and Jared Casper and Jeff Rasley and Max Ryabinin and Mayank Mishra and Minjia Zhang and Mohammad Shoeybi and Myriam Peyrounette and Nicolas Patry and Nouamane Tazi and Omar Sanseviero and Patrick von Platen and Pierre Cornette and Pierre François Lavallée and Rémi Lacroix and Samyam Rajbhandari and Sanchit Gandhi and Shaden Smith and Stéphane Requena and Suraj Patil and Tim Dettmers and Ahmed Baruwa and Amanpreet Singh and Anastasia Cheveleva and Anne-Laure Ligozat and Arjun Subramonian and Aurélie Névéol and Charles Lovering and Dan Garrette and Deepak Tunuguntla and Ehud Reiter and Ekaterina Taktasheva and Ekaterina Voloshina and Eli Bogdanov and Genta Indra Winata and Hailey Schoelkopf and Jan-Christoph Kalo and Jekaterina Novikova and Jessica Zosa Forde and Jordan Clive and Jungo Kasai and Ken Kawamura and Liam Hazan and Marine Carpuat and Miruna Clinciu and Najoung Kim and Newton Cheng and Oleg Serikov and Omer Antverg and Oskar van der Wal and Rui Zhang and Ruochen Zhang and Sebastian Gehrmann and Shachar Mirkin and Shani Pais and Tatiana Shavrina and Thomas Scialom and Tian Yun and Tomasz Limisiewicz and Verena Rieser and Vitaly Protasov and Vladislav Mikhailov and Yada Pruksachatkun and Yonatan Belinkov and Zachary Bamberger and Zdeněk Kasner and Alice Rueda and Amanda Pestana and Amir Feizpour and Ammar Khan and Amy Faranak and Ana Santos and Anthony Hevia and Antigona Unldreaj and Arash Aghagol and Arezoo Abdollahi and Aycha Tammour and Azadeh HajiHosseini and Bahareh Behroozi and Benjamin Ajibade and Bharat Saxena and Carlos Muñoz Ferrandis and Daniel McDuff and Danish Contractor and David Lansky and Davis David and Douwe Kiela and Duong A. Nguyen and Edward Tan and Emi Baylor and Ezinwanne Ozoani and Fatima Mirza and Frankline Ononiwu and Habib Rezanejad and Hessie Jones and Indrani Bhattacharya and Irene Solaiman and Irina Sedenko and Isar Nejadgholi and Jesse Passmore and Josh Seltzer and Julio Bonis Sanz and Livia Dutra and Mairon Samagaio and Maraim Elbadri and Margot Mieskes and Marissa Gerchick and Martha Akinlolu and Michael McKenna and Mike Qiu and Muhammed Ghauri and Mykola Burynok and Nafis Abrar and Nazneen Rajani and Nour Elkott and Nour Fahmy and Olanrewaju Samuel and Ran An and Rasmus Kromann and Ryan Hao and Samira Alizadeh and Sarmad Shubber and Silas Wang and Sourav Roy and Sylvain Viguier and Thanh Le and Tobi Oyebade and Trieu Le and Yoyo Yang and Zach Nguyen and Abhinav Ramesh Kashyap and Alfredo Palasciano and Alison Callahan and Anima Shukla and Antonio Miranda-Escalada and Ayush Singh and Benjamin Beilharz and Bo Wang and Caio Brito and Chenxi Zhou and Chirag Jain and Chuxin Xu and Clémentine Fourrier and Daniel León Periñán and Daniel Molano and Dian Yu and Enrique Manjavacas and Fabio Barth and Florian Fuhrimann and Gabriel Altay and Giyaseddin Bayrak and Gully Burns and Helena U. Vrabec and Imane Bello and Ishani Dash and Jihyun Kang and John Giorgi and Jonas Golde and Jose David Posada and Karthik Rangasai Sivaraman and Lokesh Bulchandani and Lu Liu and Luisa Shinzato and Madeleine Hahn de Bykhovetz and Maiko Takeuchi and Marc Pàmies and Maria A Castillo and Marianna Nezhurina and Mario Sänger and Matthias Samwald and Michael Cullan and Michael Weinberg and Michiel De Wolf and Mina Mihaljcic and Minna Liu and Moritz Freidank and Myungsun Kang and Natasha Seelam and Nathan Dahlberg and Nicholas Michio Broad and Nikolaus Muellner and Pascale Fung and Patrick Haller and Ramya Chandrasekhar and Renata Eisenberg and Robert Martin and Rodrigo Canalli and Rosaline Su and Ruisi Su and Samuel Cahyawijaya and Samuele Garda and Shlok S Deshmukh and Shubhanshu Mishra and Sid Kiblawi and Simon Ott and Sinee Sang-aroonsiri and Srishti Kumar and Stefan Schweter and Sushil Bharati and Tanmay Laud and Théo Gigant and Tomoya Kainuma and Wojciech Kusa and Yanis Labrak and Yash Shailesh Bajaj and Yash Venkatraman and Yifan Xu and Yingxin Xu and Yu Xu and Zhe Tan and Zhongli Xie and Zifan Ye and Mathilde Bras and Younes Belkada and Thomas Wolf","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2211.05100","year":"2023"}}
{"bib_id":"gholami2021survey","title":"A Survey of Quantization Methods for Efficient Neural Network Inference","author":"Amir Gholami and Sehoon Kim and Zhen Dong and Zhewei Yao and Michael W. Mahoney and Kurt Keutzer","meta_info":{"primaryclass":"cs.CV","archiveprefix":"arXiv","eprint":"2103.13630","year":"2021"}}
{"bib_id":"wang2020generalizing","title":"Generalizing from a Few Examples: A Survey on Few-Shot Learning","author":"Yaqing Wang and Quanming Yao and James Kwok and Lionel M. Ni","meta_info":{"primaryclass":"cs.LG","archiveprefix":"arXiv","eprint":"1904.05046","year":"2020"}}
{"bib_id":"instruct","title":"Training language models to follow instructions with human feedback","author":"Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2203.02155","year":"2022"}}
{"bib_id":"kalamkar2019study","title":"A Study of BFLOAT16 for Deep Learning Training","author":"Dhiraj Kalamkar and Dheevatsa Mudigere and Naveen Mellempudi and Dipankar Das and Kunal Banerjee and Sasikanth Avancha and Dharma Teja Vooturi and Nataraj Jammalamadaka and Jianyu Huang and Hector Yuen and Jiyan Yang and Jongsoo Park and Alexander Heinecke and Evangelos Georganas and Sudarshan Srinivasan and Abhisek Kundu and Misha Smelyanskiy and Bharat Kaul and Pradeep Dubey","meta_info":{"primaryclass":"cs.LG","archiveprefix":"arXiv","eprint":"1905.12322","year":"2019"}}
{"bib_id":"xie2023pixiu","title":"PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark for Finance","author":"Qianqian Xie and Weiguang Han and Xiao Zhang and Yanzhao Lai and Min Peng and Alejandro Lopez-Lira and Jimin Huang","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2306.05443","year":"2023"}}
{"bib_id":"zhang2023instructfingpt","title":"Instruct-FinGPT: Financial Sentiment Analysis by Instruction Tuning of General-Purpose Large Language Models","author":"Boyu Zhang and Hongyang Yang and Xiao-Yang Liu","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2306.12659","year":"2023"}}
{"bib_id":"wu2023bloomberggpt","title":"BloombergGPT: A Large Language Model for Finance","author":"Shijie Wu and Ozan Irsoy and Steven Lu and Vadim Dabravolski and Mark Dredze and Sebastian Gehrmann and Prabhanjan Kambadur and David Rosenberg and Gideon Mann","meta_info":{"primaryclass":"cs.LG","archiveprefix":"arXiv","eprint":"2303.17564","year":"2023"}}
{"bib_id":"zhang2022opt","title":"OPT: Open Pre-trained Transformer Language Models","author":"Susan Zhang and Stephen Roller and Naman Goyal and Mikel Artetxe and Moya Chen and Shuohui Chen and Christopher Dewan and Mona Diab and Xian Li and Xi Victoria Lin and Todor Mihaylov and Myle Ott and Sam Shleifer and Kurt Shuster and Daniel Simig and Punit Singh Koura and Anjali Sridhar and Tianlu Wang and Luke Zettlemoyer","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2205.01068","year":"2022"}}
{"bib_id":"touvron2023llama","title":"LLaMA: Open and Efficient Foundation Language Models","author":"Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2302.13971","year":"2023"}}
{"bib_id":"COT","title":"Chain of Thought Prompting Elicits Reasoning in Large Language Models","author":"Jason Wei and\nXuezhi Wang and\nDale Schuurmans and\nMaarten Bosma and\nEd H. Chi and\nQuoc Le and\nDenny Zhou","meta_info":{"bibsource":"dblp computer science bibliography, https:\/\/dblp.org","biburl":"https:\/\/dblp.org\/rec\/journals\/corr\/abs-2201-11903.bib","timestamp":"Fri, 22 Apr 2022 16:06:31 +0200","eprint":"2201.11903","eprinttype":"arXiv","url":"https:\/\/arxiv.org\/abs\/2201.11903","year":"2022","volume":"abs\/2201.11903","journal":"CoRR"}}
{"bib_id":"lewis2021retrievalaugmented","title":"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks","author":"Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2005.11401","year":"2021"}}
{"bib_id":"alpaca","title":"Stanford Alpaca: An Instruction-following LLaMA model","author":"Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto ","meta_info":{"howpublished":"r̆lhttps:\/\/github.com\/tatsu-lab\/stanford_alpaca","journal":"GitHub repository","publisher":"GitHub","year":"2023"}}
{"bib_id":"vicuna2023","title":"Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality","author":"Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.","meta_info":{"year":"2023","month":"March","url":"https:\/\/lmsys.org\/blog\/2023-03-30-vicuna\/"}}
{"bib_id":"yao2023tree","title":"Tree of Thoughts: Deliberate Problem Solving with Large Language Models","author":"Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik Narasimhan","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2305.10601","year":"2023"}}
{"bib_id":"zeng2023glm-130b","title":"GLM-130B: An Open Bilingual Pre-trained Model","author":"Aohan Zeng and Xiao Liu and Zhengxiao Du and Zihan Wang and Hanyu Lai and Ming Ding and Zhuoyi Yang and Yifan Xu and Wendi Zheng and Xiao Xia and Weng Lam Tam and Zixuan Ma and Yufei Xue and Jidong Zhai and Wenguang Chen and Zhiyuan Liu and Peng Zhang and Yuxiao Dong and Jie Tang","meta_info":{"url":"https:\/\/openreview.net\/forum?id=-Aw0rrrPUF","year":"2023","booktitle":"The Eleventh International Conference on Learning Representations (ICLR)"}}
{"bib_id":"du2022glm","title":"GLM: General Language Model Pretraining with Autoregressive Blank Infilling","author":"Du, Zhengxiao and Qian, Yujie and Liu, Xiao and Ding, Ming and Qiu, Jiezhong and Yang, Zhilin and Tang, Jie","meta_info":{"year":"2022","pages":"320--335","booktitle":"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)"}}
{"bib_id":"zhang2023xuanyuan","title":"XuanYuan 2.0: A Large Chinese Financial Chat Model with Hundreds of Billions Parameters","author":"Xuanyu Zhang and Qing Yang and Dongliang Xu","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2305.12002","year":"2023"}}
{"bib_id":"lu2023bbtfin","title":"BBT-Fin: Comprehensive Construction of Chinese Financial Domain Pre-trained Language Model, Corpus and Benchmark","author":"Dakuan Lu and Hengkui Wu and Jiaqing Liang and Yipei Xu and Qianyu He and Yipeng Geng and Mengkun Han and Yingsi Xin and Yanghua Xiao","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2302.09432","year":"2023"}}
{"bib_id":"chowdhery2022palm","title":"PaLM: Scaling Language Modeling with Pathways","author":"Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra and Adam Roberts and Paul Barham and Hyung Won Chung and Charles Sutton and Sebastian Gehrmann and Parker Schuh and Kensen Shi and Sasha Tsvyashchenko and Joshua Maynez and Abhishek Rao and Parker Barnes and Yi Tay and Noam Shazeer and Vinodkumar Prabhakaran and Emily Reif and Nan Du and Ben Hutchinson and Reiner Pope and James Bradbury and Jacob Austin and Michael Isard and Guy Gur-Ari and Pengcheng Yin and Toju Duke and Anselm Levskaya and Sanjay Ghemawat and Sunipa Dev and Henryk Michalewski and Xavier Garcia and Vedant Misra and Kevin Robinson and Liam Fedus and Denny Zhou and Daphne Ippolito and David Luan and Hyeontaek Lim and Barret Zoph and Alexander Spiridonov and Ryan Sepassi and David Dohan and Shivani Agrawal and Mark Omernick and Andrew M. Dai and Thanumalayan Sankaranarayana Pillai and Marie Pellat and Aitor Lewkowycz and Erica Moreira and Rewon Child and Oleksandr Polozov and Katherine Lee and Zongwei Zhou and Xuezhi Wang and Brennan Saeta and Mark Diaz and Orhan Firat and Michele Catasta and Jason Wei and Kathy Meier-Hellstern and Douglas Eck and Jeff Dean and Slav Petrov and Noah Fiedel","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2204.02311","year":"2022"}}
{"bib_id":"Cornucopia-LLaMA-Fin-Chinese","title":"Cornucopia-LLaMA-Fin-Chinese","author":"YangMu Yu","meta_info":{"howpublished":"r̆lhttps:\/\/github.com\/jerry1993-tech\/Cornucopia-LLaMA-Fin-Chinese","journal":"GitHub repository","publisher":"GitHub","year":"2023"}}
{"bib_id":"Fin-LLAMA","title":"Fin-LLAMA: Efficient Finetuning of Quantized LLMs for Finance","author":"William Todt, Ramtin Babaei, Pedram Babaei","meta_info":{"howpublished":"r̆lhttps:\/\/github.com\/Bavest\/fin-llama","journal":"GitHub repository","publisher":"GitHub","year":"2023"}}
