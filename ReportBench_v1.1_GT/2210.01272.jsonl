{"bib_id":"abares_catchment_2021","title":"Catchment Scale Land Use of Australia - Update December 2020","author":"ABARES","meta_info":{"doi":"10.25814\/aqjw-rq15","journal":"Australian Bureau of Agricultural and Resource Economics and Sciences, Canberra","year":"2021"}}
{"bib_id":"abebe_combined_2022","title":"Combined Use of Landsat 8 and Sentinel 2A Imagery for Improved Sugarcane Yield Estimation in Wonji-Shoa, Ethiopia","author":"Abebe, Gebeyehu and Tadesse, Tsegaye and Gessesse, Berhan","meta_info":{"keywords":"Agriculture,Best Model: SVM,Deep Learning,Images: Landsat,Images: Sentinel,Labels: Field survey,Model: MLP,Model: SVM,Satellite,Yield prediction,Yield: Field-level","abstract":"In this study, a support vector regression (SVR) approach based on a radial basis function was used for estimating sugarcane yield in the Wonji-Shoa sugarcane plantation (Ethiopia) combining Landsat 8 (L8) and sentinel 2A (S2A) data. Vegetation Indices(VIs) involving visible, near-infrared, and shortwave infrared bands were calculated from the L8 and S2A sensor observations, and seasonal cumulative values were computed for the period June to October in the 9th month and June to November in the 10th month of the year for 2016\/17 to 2018\/19 cropping seasons. Sugarcane yield was predicted using the SVR, Multilayer perceptron neural network (MLPNN), and Multiple linear regression (MLR) methods. Then, a tenfold cross-validation approach was implemented for the performance evaluation. The results showed significant correlations between sugarcane yield and cumulative values of VIs computed during the 10th month in the growing season. The results also revealed that the estimation accuracy of sugarcane was better using the combined L8 and S2A (RMSE = 12.95 t\/ha, and MAE = 10.14 t\/ha) than using the S2A data alone (RMSE = 14.71 t\/ha, and MAE = 12.18 t\/ha). Comparing SVR results with MLPNN and MLR disclosed that SVR outperforms the other two models in terms of prediction accuracy. Overall, this study demonstrated the successful application of the SVR in developing a model for Sugarcane yield estimation and it may provide a guideline for improving the estimations of sugarcane in the study area.","doi":"10.1007\/s12524-021-01466-8","issn":"0255-660X","pages":"143--157","number":"1","volume":"50","journal":"JOURNAL OF THE INDIAN SOCIETY OF REMOTE SENSING","month":"January","year":"2022"}}
{"bib_id":"abozeid_large-scale_2022","title":"A Large-Scale Dataset and Deep Learning Model for Detecting and Counting Olive Trees in Satellite Imagery","author":"Abozeid, Amr and Alanazi, Rayan and Elhadad, Ahmed and Taloba, Ahmed I. and Abd El-Aziz, Rasha M.","meta_info":{"keywords":"Agriculture,Deep Learning,Images: Satellites.pro,Labels: Image survey,Model: Transformer,Satellite,Tree detection","unique-id":"WOS:000769756200002","researcherid-numbers":"Elhadad, Ahmed\/AAA-2477-2022","orcid-numbers":"Abozeid, Amr\/0000-0001-9632-3602 Ibrahim Taloba, Ahmed\/0000-0003-3558-423X Alanazi, Rayan\/0000-0002-7559-0493 Elhadad, Ahmed\/0000-0001-6425-7460","eissn":"1687-5273","article-number":"1549842","doi":"10.1155\/2022\/1549842","issn":"1687-5265","volume":"2022","journal":"COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE","month":"January","year":"2022"}}
{"bib_id":"adams_classification_1995","title":"Classification of Multispectral Images Based on Fractions of Endmembers: Application to Land-Cover Change in the Brazilian Amazon","author":"Adams, John B. and Sabol, Donald E. and Kapos, Valerie and Almeida Filho, Raimundo and Roberts, Dar A. and Smith, Milton O. and Gillespie, Alan R.","meta_info":{"langid":"english","abstract":"Four time-sequential Landsat Thematic Mapper (TM) images of an area of Amazon forest, pasture, and second growth near Manaus, Brazil were classified according to dominant ground cover, using a new technique based on fractions of spectral endmembers. A simple four-endmember model consisting of reflectance spectra of green vegetation, nonphotosynthetic vegetation, soil, and shade was applied to all four images. Fractions of endmembers were used to define seven categories, each of which consisted of one or more classes of ground cover, where class names were based on field observations. Endmember fractions varied over time for many pixels, reflecting processes operating on the ground such as felling of forest, or regrowth of vegetation in previously cleared areas. Changes in classes over time were used to establish superclasses which grouped pixels having common histories. Sources of classification error were evaluated, including system noise, endmember variability, and low spectral contrast. Field work during each of the four years showed consistently high accuracy in per-image classification. Classification accuracy in any one year was improved by considering the multiyear context. Although the method was tested in the Amazon basin, the results suggest that endmember classification may be generally useful for comparing multispectral images in space and time.","urldate":"2022-09-16","doi":"10.1016\/0034-4257(94)00098-8","issn":"0034-4257","pages":"137--154","number":"2","volume":"52","journal":"Remote Sensing of Environment","month":"May","year":"1995","shorttitle":"Classification of Multispectral Images Based on Fractions of Endmembers"}}
{"bib_id":"ahlswede_hedgerow_2021","title":"Hedgerow Object Detection in Very High-Resolution Satellite Images Using Convolutional Neural Networks","author":"Ahlswede, Steve and Asam, Sarah and Roeder, Achim","meta_info":{"keywords":"Agriculture,Deep Learning,Hedgerow detection,Images: IKONOS,Labels: Field survey,Labels: Image survey,Model: DeepLabv3,Model: MaskRCNN,Satellite","abstract":"Hedgerows are one of the few remaining natural landscape features within European agricultural areas. To facilitate hedgerow monitoring, cost-effective and accurate mapping of hedgerows across large spatial scales is required. Current methods used for automatic hedgerow detection are overly complicated and generalize poorly to larger areas. We examine the application of transfer learning using two neural networks (Mask R-CNN and DeepLab v3+) for hedgerow mapping in south-eastern Germany using IKONOS imagery. We demonstrate the potential of such networks for hedgerow monitoring by investigating performances across varying input image bands, seasonal imagery, and image augmentation strategies. Both networks successfully detected hedgerows across a large spatial scale (562 km(2)), with DeepLab v3+ (75% F1-score) outperforming Mask R-CNN. Differences between band combinations were minimal, implying hedgerow detection could be achieved using RGB sensors. Results suggested that using all available training images across seasons is preferred and should have the same model generalizing effects as data augmentation. Experiments with varying data augmentations found augmentations effecting object geometries to greatly increase performance for both networks while results using augmentations modifying pixel spectral values showed concerning effects. Overall, our study finds that transfer learning in neural networks offers a simplified approach that outperforms previously established methods. (C) 2021 Society of Photo-Optical Instrumentation Engineers (SPIE)","doi":"10.1117\/1.JRS.15.018501","number":"1","volume":"15","journal":"JOURNAL OF APPLIED REMOTE SENSING","month":"January","year":"2021"}}
{"bib_id":"akca_semantic_2022","title":"Semantic Segmentation of Soil Salinity Using In-Situ EC Measurements and Deep Learning Based U-NET Architecture","author":"Akca, Seyma and Gungor, Oguz","meta_info":{"keywords":"Best Model: 2DCNN,Deep Learning,Images: RapidEye,Labels: Field survey,Model comparison,Model: 2DCNN,Model: SVM,Satellite,Used VI","unique-id":"WOS:000841087200002","orcid-numbers":"AKCA, Seyma\/0000-0002-7888-5078","eissn":"1872-6887","article-number":"106529","doi":"10.1016\/j.catena.2022.106529","issn":"0341-8162","volume":"218","journal":"CATENA","month":"November","year":"2022"}}
{"bib_id":"ali_modeling_2017","title":"Modeling Managed Grassland Biomass Estimation by Using Multitemporal Remote Sensing Data-A Machine Learning Approach","author":"Ali, Iftikhar and Cawkwell, Fiona and Dwyer, Edward and Green, Stuart","meta_info":{"keywords":"Agriculture,Deep Learning,Grassland biomass prediction,Images: MODIS,Labels: Field survey,Model: MLP,Satellite,Used VI","abstract":"More than 80% of agricultural land in Ireland is grassland, which is a major feed source for the pasture based dairy farming and livestock industry. Many studies have been undertaken globally to estimate grassland biomass by using satellite remote sensing data, but rarely in systems like Ireland's intensively managed, but small-scale pastures, where grass is grazed as well as harvested for winter fodder. Multiple linear regression (MLR), artificial neural network (ANN) and adaptive neuro-fuzzy inference system (ANFIS) models were developed to estimate the grassland biomass (kg dry matter\/ha\/day) of two intensively managed grassland farms in Ireland. For the first test site (Moorepark) 12 years (2001-2012) and for second test site (Grange) 6 years (2001-2005, 2007) of in situ measurements (weekly measured biomass) were used for model development. Five vegetation indices plus two raw spectral bands (RED=red band, NIR=Near Infrared band) derived from an 8-day MODIS product (MOD09Q1) were used as an input for all three models. Model evaluation shows that the ANFIS (R-Moorepark(2) = 0.85, RMSEMoorepark = 11.07; R-Grange(2) = 0.76, RMSEGrange = 15.35) has produced improved estimation of biomass as compared to the ANN and MLR. The proposed methodology will help to better explore the future inflow of remote sensing data from spaceborne sensors for the retrieval of different biophysical parameters, and with the launch of new members of satellite families (ALOS-2, Radarsat2, Sentinel, TerraSAR-X, TanDEM-X\/L) the development of tools to process large volumes of image data will become increasingly important.","doi":"10.1109\/JSTARS.2016.2561618","issn":"1939-1404","pages":"3254--3264","number":"7","volume":"10","journal":"IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING","month":"July","year":"2017"}}
{"bib_id":"arab_prediction_2021","title":"Prediction of Grape Yields from Time-Series Vegetation Indices Using Satellite Remote Sensing and a Machine-Learning Approach","author":"Arab, Sara Tokhi and Noguchi, Ryozo and Matsushita, Shusuke and Ahamed, Tofael","meta_info":{"keywords":"Agriculture,Deep Learning,Images: Landsat,Labels: Field survey,Model: MLP,Satellite,Used VI,Yield prediction,Yield: Field-level","abstract":"Grape yield prediction is an important tool used by growers to optimize vineyard management and obtain better income. In this regard, the growth stages of grapes play important roles in the evaluation of vineyard production throughout the season. Predicted yield maps allow growers to view spatial variability across fields and to determine the best harvesting time and marketing strategy. Different methods are used to estimate yield; however, large-scale estimation is difficult due to labor and time requirements. Machine learning and satellite remote sensing have the potential to obtain quick and rapid assessments over large areas with lower costs and in shorter timeframes. In this context, the purpose of this research was to develop yield prediction models based on a machine-learning approach using satellite-based time-series images. In this study, Landsat 8 surface reflectance products from 2017, 2018 and 2019 were used to map the satellite-based normalized difference vegetation index (NDVI), leaf area index (LAI) and normalized difference water index (NDWI). Moreover, different growth stages were observed using moving averages and exponential smoothing methods based on the per-pixel values from the satellite imagery. The vegetation indices had particularly close relationships with each other at the time of maximum canopy expansion. To remove the seasonality of the vegetation indices, a moving average was applied to determine one representative mean for each vineyard. The generated models were validated using regression analysis and an artificial neural network (ANN) approach. The results indicated that of all the vegetation indices, NDVI had the highest accuracy (r(2) = 0.79) in 2017 and 2019; however, the LAI accuracy was higher than the accuracies of the other indices (r(2) = 0.79) in 2019. Nevertheless, the artificial neural network-based machine learning results indicated that NDVI had the highest accuracy in 2017 (R = 0.94), 2018 (R = 0.95) and 2019 (R = 0.92) among all the vegetation indices. Thus, machine learning achieved reliable grape yield monitoring across the studied years at local and regional levels. Ground reference yield datasets were used for comparison with the predicted yields. The findings suggest that vegetation indices can be used for calculating site-specific management of vineyards and for predicting yields. The machine-learning methods applied with satellite time-series images can achieve reliable table grape yield prediction models. These integrated models could be used for logistics and decision-making regarding table grape production.","doi":"10.1016\/j.rsase.2021.100485","issn":"2352-9385","volume":"22","journal":"REMOTE SENSING APPLICATIONS: SOCIETY AND ENVIRONMENT","month":"April","year":"2021"}}
{"bib_id":"asming_processing_2022","title":"Processing and Classification of Landsat and Sentinel Images for Oil Palm Plantation Detection","author":"Asming, Muhammad Anwar Azizan and Ibrahim, Azhar Mohd and Abir, Intiaz Mohammad","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Landsat,Images: Sentinel,Labels: Image survey,Model: MLP,Satellite","unique-id":"WOS:000793464700001","orcid-numbers":"Abir, Intiaz Mohammad\/0000-0002-3069-3544","article-number":"100747","doi":"10.1016\/j.rsase.2022.100747","issn":"2352-9385","volume":"26","journal":"REMOTE SENSING APPLICATIONS: SOCIETY AND ENVIRONMENT","month":"April","year":"2022"}}
{"bib_id":"ba_layer_2016","title":"Layer Normalization","author":"Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.","meta_info":{"archiveprefix":"arxiv","abstract":"Training state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This significantly reduces the training time in feed-forward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques.","urldate":"2022-07-21","doi":"10.48550\/arXiv.1607.06450","publisher":"arXiv","primaryclass":"cs, stat","eprint":"1607.06450","number":"arXiv:1607.06450","month":"July","year":"2016"}}
{"bib_id":"baghdadi_coupling_2016","title":"Coupling SAR C-Band and Optical Data for Soil Moisture and Leaf Area Index Retrieval Over Irrigated Grasslands","author":"Baghdadi, Nicolas N. and El Hajj, Mohamad and Zribi, Mehrez and Fayad, Ibrahim","meta_info":{"keywords":"Agriculture,Canopy cover prediction,Deep Learning,Images: Landsat,Images: Radarsat-2,Labels: Field survey,Model: MLP,Satellite,Soil moisture prediction","abstract":"The objective of this study was to develop an approach for estimating soil moisture and vegetation parameters in irrigated grasslands by coupling C-band polarimetric synthetic aperture radar (SAR) and optical data. A huge data set of satellite images acquired from RADARSAT-2 and LANDSAT-7\/8, and in situ measurements were used to assess the relevance of several inversion configurations. A neural network (NN) inversion technique was used. The approach for this study was to use RADARSAT-2 and LANDSAT-7\/8 images to investigate the potential for the combined use of new data from the new SAR sensor SENTINEL-1 and the new optical sensors LANDSAT-8 and SENTINEL-2. First, the impact of SAR polarization (mono-, dual-, and full-polarizations configurations) and the normalized difference vegetation index (NDVI) calculated from optical data for the estimation error of soil moisture and vegetation parameters was studied. Next, the effect of some polarimetric parameters [Shannon entropy (SE) and Pauli components] on the inversion technique was also analyzed. Finally, configurations using in situ measurements of the fraction of absorbed photosynthetically active radiation (FAPAR) and the fraction of green vegetation cover (FCover) were also tested. The results showed that HH polarization is the SAR polarization most relevant to soil moisture estimates. A root-mean-square error (RMSE) for soil moisture estimates of approximately 6 vol.% was obtained even for dense grassland cover. The use of in situ FAPAR and FCover only improved the estimate of the leaf area index (LAI) with an RMSE of approximately 0.37 m(2)\/m(2). The use of polarimetric parameters did not improve the estimate of soil moisture and vegetation parameters. Good results were obtained for the biomass (BIO) and vegetation water content (VWC) estimates for BIO and VWC values lower than 2 and 1.5 kg\/m(2), respectively (RMSE is of 0.38 kg\/m(2) for BIO and 0.32 kg\/m(2) for VWC). In addition, a high underestimate was observed for BIO and VWC higher than 2 and 1.5 kg\/m(2), respectively, (a bias of -0.65 kg\/m(2) on BIO estimates and -0.49 kg\/m(2) on VWC estimates). Finally, the estimation of vegetation height (VEH) was carried out with an RMSE of 13.45 cm.","doi":"10.1109\/JSTARS.2015.2464698","issn":"1939-1404","pages":"1229--1243","number":"3, SI","volume":"9","journal":"IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING","month":"March","year":"2016"}}
{"bib_id":"ban_synergy_2003","title":"Synergy of Multitemporal ERS-1 SAR and Landsat TM Data for Classification of Agricultural Crops","author":"Ban, e̊lax YF","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: ERS-1,Images: Landsat,Labels: Field survey,Model: MLP,Satellite","abstract":"The objective of this research was to evaluate the synergistic effects of multitemporal European remote sensing satellite 1 (ERS-1) synthetic aperture radar (SAR) and Landsat thematic mapper (TM) data for crop classification using a per-field artificial neural network (ANN) approach. Eight crop types and conditions were identified: winter wheat, corn (good growth), corn (poor growth), soybeans (good growth), soybeans (poor growth), barley\/oats, alfalfa, and pasture. With the per-field approach using a feed-forward ANN, the overall classification accuracy of three-date early- to mid-season SAR data improved almost 20%, and the best classification of a single-date (5 August) SAR image improved the overall accuracy by about 26%, in comparison to a per-pixel maximum-likelihood classifier (MLC). Both single-date and multitemporal SAR data demonstrated their abilities to discriminate certain crops in the early and mid-season; however, these overall classification accuracies ($<$60%) were not sufficiently high for operational crop inventory and analysis, as the single-parameter, high-incidence-angle ERS-1 SAR system does not provide sufficient differences for eight crop types and conditions. The synergy of TM3, TM4, and TM5 images acquired on 6 August and SAR data acquired on 5 August yielded the best per-field ANN classification of 96.8% (kappa coefficient = 0.96). It represents an 8.3% improvement over TM3, TM4, and TM5 classification alone and a 5% improvement over the per-pixel classification of TM and 5 August SAR data. These results clearly demonstrated that the synergy of TM and SAR data is superior to that of a single sensor and the ANN is more robust than MLC for per-field classification. The second-best classification accuracy of 95.9% was achieved using the combination of TM3, TM4, TM5, and 24 July SAR data. The combination of TM3, TM4, and TM5 images and three-date SAR data, however, only yielded an overall classification accuracy of 93.89% (kappa = 0.93), and the combination of TM3, TM4, TM5, and 15 June SAR data decreased the classification accuracy slightly (88.08%; kappa = 0.86) from that of TM alone. These results indicate that the synergy of satellite SAR and Landsat TM data can produce much better classification accuracy than that of Landsat TM alone only when careful consideration is given to the temporal compatibility of SAR and visible and infrared data.","doi":"10.5589\/m03-014","issn":"0703-8992","pages":"518--526","number":"4","volume":"29","journal":"CANADIAN JOURNAL OF REMOTE SENSING","month":"August","year":"2003"}}
{"bib_id":"barnetson_climate-resilient_2021","title":"Climate-Resilient Grazing in the Pastures of Queensland: An Integrated Remotely Piloted Aircraft System and Satellite-Based Deep-Learning Method for Estimating Pasture Yield","author":"Barnetson, Jason and Phinn, Stuart and Scarth, Peter","meta_info":{"keywords":"Agriculture,Deep Learning,Extra data: UAV,Grassland biomass prediction,Images: PlanetScope,Labels: Field survey,Model: MLP,Satellite","abstract":"The aim of this research is to expand recent developments in the mapping of pasture yield with remotely piloted aircraft systems to that of satellite-borne imagery. To date, spatially explicit and accurate information of the pasture resource base is needed for improved climate-adapted livestock rangeland grazing. This study developed deep learning predictive models of pasture yield, as total standing dry matter in tonnes per hectare (TSDM (tha(-1))), from field measurements and both remotely piloted aircraft systems and satellite imagery. Repeated remotely piloted aircraft system structure measurements derived from structure from motion photogrammetry provided measures of pasture biomass from many overlapping high-resolution images. These measurements were taken throughout a growing season and were modelled with persistent photosynthetic pasture responses from various Planet Dove high spatial resolution satellite image-derived vegetation indices. Pasture height modelling as an input to the modelling of yield was assessed against terrestrial laser scanning and reported correlation coefficients (R-2) from 0.3 to 0.8 for both a coastal grassland and inland woodland pasture. Accuracy of the predictive modelling from both the remotely piloted aircraft system and the Planet Dove satellite image estimates of pasture yield ranged from 0.8 to 1.8 TSDM (tha(-1)). These results indicated that the practical application of repeated remotely piloted aircraft system derived measures of pasture yield can, with some limitations, be scaled-up to satellite-borne imagery to provide more temporally and spatially explicit measures of the pasture resource base.","doi":"10.3390\/agriengineering3030044","pages":"681--702","number":"3","volume":"3","journal":"AGRIENGINEERING","month":"September","year":"2021"}}
{"bib_id":"benedetti_m3fusion_2018","title":"M(3)Fusion: A Deep Learning Architecture for Multiscale Multimodal Multitemporal Satellite Data Fusion","author":"Benedetti, Paola and Ienco, Dino and Gaetano, Raffaele and Ose, Kenji and Pensa, Ruggero G. and Dupuy, Stephane","meta_info":{"keywords":"Agriculture,Crop segmentation,Dataset: Reunion Island,Deep Learning,Labels: Dataset,Model: RF,Multitemporal,Satellite","abstract":"Modern Earth Observation systems provide remote sensing data at different temporal and spatial resolutions. Among all the available spatial mission, today the Sentinel-2 program supplies high temporal (every five days) and high spatial resolution (HSR) (10 m) images that can be useful to monitor land cover dynamics. On the other hand, very HSR (VHSR) imagery is still essential to figure out land cover mapping characterized by fine spatial patterns. Understanding how to jointly leverage these complementary sources in an efficient way when dealing with land cover mapping is a current challenge in remote sensing. With the aim of providing land cover mapping through the fusion of multi-temporal HSR and VHSR satellite images, we propose a suitable end-to-end deep learning framework, namely M-3 Fusion, which is able to simultaneously leverage the temporal knowledge contained in time series data as well as the fine spatial information available in VHSR images. Experiments carried out on the Reunion Island study area confirm the quality of our proposal considering both quantitative and qualitative aspects.","doi":"10.1109\/JSTARS.2018.2876357","issn":"1939-1404","pages":"4939--4949","number":"12","volume":"11","journal":"IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING","month":"December","year":"2018"}}
{"bib_id":"beyer_are_2020","title":"Are We Done with ImageNet?","author":"Beyer, Lucas and Hénaff, Olivier J. and Kolesnikov, Alexander and Zhai, Xiaohua and van den Oord, Aäron","meta_info":{"langid":"english","archiveprefix":"arxiv","abstract":"Yes, and no. We ask whether recent progress on the ImageNet classification benchmark continues to represent meaningful generalization, or whether the community has started to overfit to the idiosyncrasies of its labeling procedure. We therefore develop a significantly more robust procedure for collecting human annotations of the ImageNet validation set. Using these new labels, we reassess the accuracy of recently proposed ImageNet classifiers, and find their gains to be substantially smaller than those reported on the original labels. Furthermore, we find the original ImageNet labels to no longer be the best predictors of this independently-collected set, indicating that their usefulness in evaluating vision models may be nearing an end. Nevertheless, we find our annotation procedure to have largely remedied the errors in the original labels, reinforcing ImageNet as a powerful benchmark for future research in visual recognition3.","urldate":"2022-03-02","primaryclass":"cs","eprint":"2006.07159","journal":"arXiv:2006.07159 [cs]","month":"June","year":"2020"}}
{"bib_id":"bi_gated_2020","title":"A Gated Recurrent Units (GRU)-Based Model for Early Detection of Soybean Sudden Death Syndrome through Time-Series Satellite Imagery","author":"Bi, Luning and Hu, Guiping and Raza, Muhammad Mohsin and Kandel, Yuba and Leandro, Leonor and Mueller, Daren","meta_info":{"keywords":"Agriculture,Deep Learning,Disease detection,Images: PlanetScope,Labels: Field survey,Model comparison,Model: GRU,Model: MLP,Multitemporal,Satellite,Used VI","abstract":"In general, early detection and timely management of plant diseases are essential for reducing yield loss. Traditional manual inspection of fields is often time-consuming and laborious. Automated imaging techniques have recently been successfully applied to detect plant diseases. However, these methods mostly focus on the current state of the crop. This paper proposes a gated recurrent unit (GRU)-based model to predict soybean sudden death syndrome (SDS) disease development. To detect SDS at a quadrat level, the proposed method uses satellite images collected from PlanetScope as the training set. The pixel image data include the spectral bands of red, green, blue and near-infrared (NIR). Data collected during the 2016 and 2017 soybean-growing seasons were analyzed. Instead of using individual static imagery, the GRU-based model converts the original imagery into time-series data. SDS predictions were made on different data scenarios and the results were compared with fully connected deep neural network (FCDNN) and XGBoost methods. The overall test accuracy of classifying healthy and diseased quadrates in all methods was above 76%. The test accuracy of the FCDNN and XGBoost were 76.3-85.5% and 80.6-89.2%, respectively, while the test accuracy of the GRU-based model was 82.5-90.4%. The calculation results show that the proposed method can improve the detection accuracy by up to 7% with time-series imagery. Thus, the proposed method has the potential to predict SDS at a future time.","doi":"10.3390\/rs12213621","number":"21","volume":"12","journal":"REMOTE SENSING","month":"November","year":"2020"}}
{"bib_id":"blaschke_geographic_2014","title":"Geographic Object-Based Image Analysis - Towards a New Paradigm","author":"Blaschke, Thomas and Hay, Geoffrey J. and Kelly, Maggi and Lang, Stefan and Hofmann, Peter and Addink, Elisabeth and Queiroz Feitosa, Raul and van der Meer, Freek and van der Werff, Harald and van Coillie, Frieke and Tiede, Dirk","meta_info":{"keywords":"GEOBIA,GIScience,Image classification,Image segmentation,OBIA,Remote sensing","langid":"english","abstract":"The amount of scientific literature on (Geographic) Object-based Image Analysis -- GEOBIA has been and still is sharply increasing. These approaches to analysing imagery have antecedents in earlier research on image segmentation and use GIS-like spatial analysis within classification and feature extraction approaches. This article investigates these development and its implications and asks whether or not this is a new paradigm in remote sensing and Geographic Information Science (GIScience). We first discuss several limitations of prevailing per-pixel methods when applied to high resolution images. Then we explore the paradigm concept developed by Kuhn (1962) and discuss whether GEOBIA can be regarded as a paradigm according to this definition. We crystallize core concepts of GEOBIA, including the role of objects, of ontologies and the multiplicity of scales and we discuss how these conceptual developments support important methods in remote sensing such as change detection and accuracy assessment. The ramifications of the different theoretical foundations between the `per-pixel paradigm' and GEOBIA are analysed, as are some of the challenges along this path from pixels, to objects, to geo-intelligence. Based on several paradigm indications as defined by Kuhn and based on an analysis of peer-reviewed scientific literature we conclude that GEOBIA is a new and evolving paradigm.","urldate":"2022-04-01","doi":"10.1016\/j.isprsjprs.2013.09.014","issn":"0924-2716","pages":"180--191","volume":"87","journal":"ISPRS Journal of Photogrammetry and Remote Sensing","month":"January","year":"2014"}}
{"bib_id":"blaschke_whats_2001","title":"What's Wrong with Pixels? Some Recent Developments Interfacing Remote Sensing and GIS","author":"Blaschke, Thomas and Strobl, Josef","meta_info":{"abstract":"While remote sensing made enormous progress over the last years in terms of improved resolution, data availability and public awareness, a vast majority of applications rely on basic image processing concepts developed in the 70s: per-pixel classification of in a multi-dimensional feature space. It is argued that this methodology does not make use of any spatial concepts. Especially in high-resolution images it is very likely that neighbouring pixels belong to the same land cover class as the pixel under consideration. The authors argue for classification of homogeneous groups of pixels reflecting our objects of interest in reality and use algorithms to delineate objects based on contextual information in an image on the basis of texture or fractal dimension.","pages":"12--17","volume":"14","journal":"Zeitschrift für Geoinformationssysteme","month":"June","year":"2001","shorttitle":"What's Wrong with Pixels?"}}
{"bib_id":"bocco_estimating_2012","title":"Estimating Soybean Ground Cover from Satellite Images Using Neural-Networks Models","author":"Bocco, Monica and Ovando, Gustavo and Sayago, Silvina and Willington, Enrique and Heredia, Susana","meta_info":{"keywords":"Agriculture,Canopy cover prediction,Deep Learning,Images: Landsat,Images: MODIS,Labels: Field survey,Model: MLP,Satellite","abstract":"The ground cover is a necessary parameter for agronomic and environmental applications. In Argentina, soybean (Glycine max (L.) Merill) is the most important crop; therefore it is necessary to determine its amount and configuration. In this work, neural-network (NN) models were developed to calculate soybean percentage ground cover (fractional vegetation cover, fCover) and to compare the accuracy of the estimate from Moderate-Resolution Imaging Spectroradiometer (MODIS) and Landsat satellites data. The NN design included spectral values of the red and near-infrared (NIR) bands as input variables and one neuron output, which expressed the estimated coverage. Data of fCover were acquired throughout the growing season in the central plains of Cordoba (Argentina); they were used for training and validating the networks. The results show that the NNs are an appropriate methodology for estimating the temporal evolution of soybean coverage fraction from MODIS and Landsat images, with coefficients of determination (R-2) equal to 0.90 and 0.91, respectively.","doi":"10.1080\/01431161.2011.600347","issn":"0143-1161","pages":"1717--1728","number":"6","volume":"33","journal":"INTERNATIONAL JOURNAL OF REMOTE SENSING","year":"2012"}}
{"bib_id":"boogaard_worldcereal_2023","title":"WorldCereal Open Global Harmonized Reference Data Repository (CC-BY Licensed Data Sets)","author":"Boogaard, Hendrik and Pratihast, Arun and Bayas, Juan Carlos Laso and Karanam, Santosh and Fritz, Steffen and Tricht, Kristof Van and Degerickx, Jeroen and Gilliams, Sven","meta_info":{"langid":"english","abstract":"Within the ESA funded WorldCereal project we have built an open harmonized reference data repository at global extent~for model training or product validation~in support of land cover and crop type mapping. Data from 2017 onwards were collected from many different sources and then~harmonized, annotated and evaluated. These steps are explained in the harmonization protocol (10.5281\/zenodo.7584463). This protocol also clarifies the naming convention of the shape files and the WorldCereal attributes~(LC, CT, IRR, valtime and sampleID) that were added to the original data sets. This publication~includes those harmonized~data sets of which the original data set was~published under the CC-BY license or a license similar to CC-BY. See document \"_In-situ-data-World-Cereal - license - CC-BY.pdf\" for an overview of the original data sets.","urldate":"2024-05-31","doi":"10.5281\/zenodo.7593734","publisher":"Zenodo","month":"February","year":"2023"}}
{"bib_id":"boroughani_assessment_2022","title":"Assessment of the Impact of Dust Aerosols on Crop and Water Loss in the Great Salt Desert in Iran","author":"Boroughani, Mahdi and Mohammadi, Maziar and Mirchooli, Fahimeh and Fiedler, Stephanie","meta_info":{"keywords":"Agriculture,Deep Learning,Dusty day detection,Images: MODIS,Labels: Field survey,Labels: Image survey,Model: MLP,Model: RF,Satellite,Used VI","abstract":"Knowledge of the spatial distribution of dust aerosols and their effects on crops is important for policy formulation and food security. This study aims to investigate the impact of dust source susceptibility areas (DSSA) on the loss of agricultural crop and corresponding water consumption in terms of Water Footprint in the Great Salt Desert, Iran. To this goal, MODIS satellite images during the 2005-2020 period were used to identify dust sources and 135 dust source zones were identified. Machine learning algorithm viz. Random Forest (RF), generalized linear model (GLM), and Artificial neural network (ANN) were tested to reproduce DSSA. The best method was RF and applied to calculate and classify DSSA in five risk levels from very low to very high. The amount of wheat production under high risk of DSSA was estimated using the average crop yield from recent years using agriculture statistics. We calculated the loss of crops and corresponding water consumption for three scenarios, assuming a typical loss of 20, 40, and 60% of the wheat production for better crop loss estimation. Finally, the spatial relationships between wheat farmland and high-risk DSSA were assessed using ordinary least squares regression (OLS) and geographically weighted regression (GWR) at sub-watershed scale. The area of wheat cultivation in high and very high risk of DSSA is 10188.04 km(2), which is 36% of all agricultural land for wheat in the region. Loss of wheat crop to DSSA meant that 1270.58 to 3811 million m(3) water used for the production of wheat were lost, corresponding to 2%, to 7% of lost water compared to the total water consumption for wheat production in the study area.","doi":"10.1016\/j.compag.2021.106605","issn":"0168-1699","volume":"192","journal":"COMPUTERS AND ELECTRONICS IN AGRICULTURE","month":"January","year":"2022"}}
{"bib_id":"boryan_monitoring_2011","title":"Monitoring US Agriculture: The US Department of Agriculture, National Agricultural Statistics Service, Cropland Data Layer Program","author":"Boryan, Claire and Yang, Zhengwei and Mueller, Rick and Craig, Mike","meta_info":{"abstract":"The National Agricultural Statistics Service (NASS) of the US Department of Agriculture (USDA) produces the Cropland Data Layer (CDL) product, which is a raster-formatted, geo-referenced, crop-specific, land cover map. CDL program inputs include medium resolution satellite imagery, USDA collected ground truth and other ancillary data, such as the National Land Cover Data set. A decision tree-supervised classification method is used to generate the freely available state-level crop cover classifications and provide crop acreage estimates based upon the CDL and NASS June Agricultural Survey ground truth to the NASS Agricultural Statistics Board. This paper provides an overview of the NASS CDL program. It describes various input data, processing procedures, classification and validation, accuracy assessment, CDL product specifications, dissemination venues and the crop acreage estimation methodology. In general, total crop mapping accuracies for the 2009 CDLs ranged from 85% to 95% for the major crop categories.","urldate":"2022-06-27","doi":"10.1080\/10106049.2011.562309","issn":"1010-6049","publisher":"Taylor & Francis","pages":"341--358","number":"5","volume":"26","journal":"Geocarto International","month":"August","year":"2011","shorttitle":"Monitoring US Agriculture"}}
{"bib_id":"breizhcrops2020","title":"BreizhCrops: A Time Series Dataset for Crop Type Mapping","author":"Rußwurm, Marc and Pelletier, Charlotte and Zollner, Maximilian and Lefèvre, Sébastien and Körner, Marco","meta_info":{"doi":"10.5194\/isprs-archives-XLIII-B2-2020-1545-2020","pages":"1545--1551","journal":"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences ISPRS (2020)","year":"2020"}}
{"bib_id":"brodrick_uncovering_2019","title":"Uncovering Ecological Patterns with Convolutional Neural Networks.","author":"Brodrick, Philip G. and Davies, Andrew B. and Asner, Gregory P.","meta_info":{"pmid":"null","pmcid":"null","abstract":"Using remotely sensed imagery to identify biophysical components across landscapes is an important avenue of investigation for ecologists studying ecosystem dynamics. With high-resolution remotely sensed imagery, algorithmic utilization of image context is crucial for accurate identification of biophysical components at large scales. In recent years, convolutional neural networks (CNNs) have become ubiquitous in image processing, and are rapidly becoming more common in ecology. Because the quantity of high-resolution remotely sensed imagery continues to rise, CNNs are increasingly essential tools for large-scale ecosystem analysis. We discuss here the conceptual advantages of CNNs, demonstrate how they can be used by ecologists through distinct examples of their application, and provide a walkthrough of how to use them for ecological applications.","doi":"10.1016\/j.tree.2019.03.006","journal":"Trends in Ecology and Evolution","year":"2019"}}
{"bib_id":"bsaibes_albedo_2009","title":"Albedo and LAI Estimates from FORMOSAT-2 Data for Crop Monitoring","author":"Bsaibes, Aline and Courault, Dorninique and Baret, Frederic and Weiss, Marie and Olioso, Albert and Jacob, Frederic and Hagolle, Olivier and Marloie, Olivier and Bertrand, Nadine and Desfond, Veronique and Kzemipour, Farzaneh","meta_info":{"keywords":"Agriculture,Canopy cover prediction,Deep Learning,Images: FORMOSAT,Labels: Field survey,Model: MLP,Satellite","abstract":"This paper aimed at estimating albedo and Leaf Area Index (LAI) from FORMOSAT-2 satellite that offers a unique source of high spatial resolution (eight meters) images with a high revisit frequency (one to three days). It mainly consisted of assessing the FORMOSAT-2 spectral and directional configurations that are unusual, with a single off nadir viewing angle over four visible-near infra red wavebands. Images were collected over an agricultural region located in South Eastern France, with a three day frequency from the growing season to post-harvest. Simultaneously, numerous ground based measurements were performed over various crops such as wheat, meadow, rice and maize. Albedo and LAI were estimated using empirical approaches that have been widely used for usual directional and spectral configurations (i.e. multidirectional or single nadir viewing angle over visible-near infrared wavebands). Two methods devoted to albedo estimation were assessed. based on stepwise multiple regression and neural network (NNT). Although both methods gave satisfactory results, the NNT performed better (relative RMSE=3.5% versus 7.3%), especially for low vegetation covers over dark or wet soils that corresponded to albedo values lower than 0.20. Four approaches for LAI estimation were assessed. The first approach based on a stepwise multiple regression over reflectances had the worst performance (relative RMSE=65%), when compared to the equally performing NDVI based heuristic relationship and reflectance based NNT approach (relative RMSE=34%).The NDVI based neural network approach had the best performance (relative RMSE=27.5%), due to the combination of NDVI efficient normalization properties and NNT flexibility. The high FORMOSAT-2 revisit frequency allowed next replicating the dynamics of albedo and LAI, and detecting to some extents cultural practices like vegetation cuts. It also allowed investigating possible relationships between albedo and LAI. The latter depicted specific trends according to vegetation types, and were very similar when derived from ground based data, remotely sensed observations or radiative transfer simulations. These relationships also depicted large albedo variabilities for low LAI values, which confirmed that estimating one variable from the other would yield poor performances for low vegetation cover with varying soil backgrounds. Finally, this empirical study demonstrated, in the context of exhaustively describing the spatiotemporal variability of surface properties, the potential synergy between 1) ground based web-sensors that continuously monitor specific biophysical variables over few locations, and 2) high spatial resolution satellite with high revisit frequencies. (C) 2008 Elsevier Inc. All rights reserved.","doi":"10.1016\/j.rse.2008.11.014","issn":"0034-4257","pages":"716--729","number":"4","volume":"113","journal":"REMOTE SENSING OF ENVIRONMENT","month":"April","year":"2009"}}
{"bib_id":"cai_integrating_2019","title":"Integrating Satellite and Climate Data to Predict Wheat Yield in Australia Using Machine Learning Approaches","author":"Cai, Yaping and Guan, Kaiyu and Lobell, David and Potgieter, Andries B. and Wang, Shaowen and Peng, Jian and Xu, Tianfang and Asseng, Senthold and Zhang, Yongguang and You, Liangzhi and Peng, Bin","meta_info":{"keywords":"Agriculture,Best Model: SVM,Deep Learning,Extra data: climate,Images: MODIS,Labels: Public government data,Model comparison,Model: MLP,Model: RF,Model: SVM,Satellite,Used VI,Yield prediction,Yield: County-level","abstract":"Wheat is the most important staple crop grown in Australia, and Australia is one of the top wheat exporting countries globally. Timely and reliable wheat yield prediction in Australia is important for regional and global food security. Prior studies use either climate data, or satellite data, or a combination of these two to build empirical models to predict crop yield. However, though the performance of yield prediction using empirical methods is improved by combining the use of climate and satellite data, the contributions from different data sources are still not clear. In addition, how the regression-based methods compare with various machine learning based methods in their performance in yield prediction is also not well understood and needs in-depth investigation. This work integrated various sources of data to predict wheat yield across Australia from 2000 to 2014 at the statistical division (SD) level. We adopted a well-known regression method (LASSO, as a benchmark) and three mainstream machine learning methods (support vector machine, random forest, and neural network) to build various empirical models for yield prediction. For satellite data, we used the enhanced vegetation index (EVI) from MODIS and solar-induced chlorophyll fluorescence (SIF) from GOME-2 and SCIAMACHY as metrics to approximate crop productivity. The machine-learning based methods outperform the regression method in modeling crop yield. Our results confirm that combining climate and satellite data can achieve high performance of yield prediction at the SD level (R-2 similar to 0.75). The satellite data track crop growth condition and gradually capture the variability of yield evolving with the growing season, and their contributions to yield prediction usually saturate at the peak of the growing season. Climate data provide extra and unique information beyond what the satellite data have offered for yield prediction, and our empirical modeling work shows the added values of climate variables exist across the whole season, not only at some certain stages. We also find that using EVI as an input can achieve better performance in yield prediction than SIF, primarily due to the large noise in the satellite-based SIF data (i.e. coarse resolution in both space and time). In addition, we also explored the potential for timely wheat yield prediction in Australia, and we can achieve the optimal prediction performance with approximately two-month lead time before wheat maturity. The proposed methodology in this paper can be extended to different crops and different regions for crop yield prediction.","doi":"10.1016\/j.agrformet.2019.03.010","issn":"0168-1923","pages":"144--159","volume":"274","journal":"AGRICULTURAL AND FOREST METEOROLOGY","month":"August","year":"2019"}}
{"bib_id":"cao_integrating_2021","title":"Integrating Multi-Source Data for Rice Yield Prediction across China Using Machine Learning and Deep Learning Approaches","author":"Cao, Juan and Zhang, Zhao and Tao, Fulu and Zhang, Liangliang and Luo, Yuchuan and Zhang, Jing and Han, Jichong and Xie, Jun","meta_info":{"keywords":"Agriculture,Best Model: LSTM,Deep Learning,Extra data: climate,Extra data: soil,Images: MODIS,Labels: Public government data,Model comparison,Model: LSTM,Model: RF,Multitemporal,Satellite,Used VI,Yield prediction,Yield: County-level","abstract":"Timely and reliable yield prediction at a large scale is imperative and prerequisite to prevent climate risk and ensure food security, especially with climate change and increasing extreme climate events. In this study, integrating the publicly available data (i.e., satellite vegetation indexes, meteorological indexes, and soil properties) within the Google Earth Engine (GEE) platform, we developed one Least Absolute Shrinkage and Selection Operator (LASSO) regression, one machine learning (Random Forest, RF), and one deep learning (Long Short-Term Memory Networks, LSTM) model to predict rice yield at county-level across China. For satellite data, we compared the contiguous solar-induced chlorophyll fluorescence (SIF), a newly emerging satellite retrieval, with a traditional vegetation index (enhanced vegetation index, EVI). The results showed that LSTM (with R-2 ranging from 0.77 to 0.87, RMSE from 298.11 to 724kg\/ha) and RF (with R-2 ranging from 0.76 to 0.82, RMSE from 366 to 723.3 kg\/ha) models outperformed LASSO (with R-2 ranging from 0.33 to 0.42, RMSE from 633.46 kg\/ha to 1231.39 kg\/ha) in yield prediction; and LSTM was better than RF. Besides, ESI (combining EVI and SIF together) could slightly improve the model performance compared with only using EVI or SIF as the single input, primarily due to the ability of satellite-based SIF in capturing extra information on drought and heat stress. Furthermore, we also explored the potential for timely rice yield prediction, and concluded that the optimal prediction could be achieved with approximately two\/one-month leading-time before single\/double rice maturity. Our findings demonstrated a scalable, simple and inexpensive methods for timely predicting rice yield over a large area with publicly available multi-source data, which can potentially be applied to areas with sparsely observed data and worldwide for estimating crop yields.","doi":"10.1016\/j.agrformet.2020.108275","issn":"0168-1923","volume":"297","journal":"AGRICULTURAL AND FOREST METEOROLOGY","month":"February","year":"2021"}}
{"bib_id":"cao_wheat_2021","title":"Wheat Yield Predictions at a County and Field Scale with Deep Learning, Machine Learning, and Google Earth Engine","author":"Cao, Juan and Zhang, Zhao and Luo, Yuchuan and Zhang, Liangliang and Zhang, Jing and Li, Ziyue and Tao, Fulu","meta_info":{"keywords":"Agriculture,Deep Learning,Extra data: climate,Images: MODIS,Labels: Public government data,Model comparison,Model: 1DCNN,Model: LSTM,Model: MLP,Model: RF,Multitemporal,Satellite,Used VI,Yield prediction,Yield: County-level","abstract":"To meet the challenges of climate change, increasing population and food demand, a timely, accurate and reliable estimation of crop yield at a large scale is more imperative than ever for crop management, food security evaluation, food trade and policy-making. In this study, taking the major winter wheat production regions of China as an example, we compared a traditional machine learning method (random forest, RF) and three deep learning (DL) models, including DNN (deep neural networks), 1D-CNN (1D convolutional neural networks), and LSTM (long short-term memory networks) to predict crop yields by integrating publicly available data within the GEE (Google Earth Engine) platform, including climate, satellite, soil properties, and spatial information data. The results showed that all four models could capture winter wheat yield variations in all the county-years, with R-2 of recorded and simulated yields ranging from 0.83 to 0.90 and RMSE ranging from 561.18 to 959.62 kg\/ha. They all performed well for winter wheat yield prediction at a county level from 2011 to 2015, with mean R-2 $>$= 0.85 and RMSE $<$= 768 kg\/ha. At a field level, the spatial pattern of estimated winter wheat yield could capture the spatial heterogeneity and yield differences between individual fields across a county fairly well. However, only the DNN and RF models had relatively good performance at the field level, with mean R2 values of 0.71, 0.66 and RMSE values of 1127 kg\/ha and 956 kg\/ha, respectively. The model comparisons showed that the performance of RF was not always worse than DL at both the county and field levels. Our findings demonstrated a scalable, simple and inexpensive framework for estimating crop yields at various scales in a timely manner and with reliable accuracy, which has important implications for crop yield forecasting, agricultural disaster monitoring, food trade policy, and food security warning.","doi":"10.1016\/j.eja.2020.126204","issn":"1161-0301","volume":"123","journal":"EUROPEAN JOURNAL OF AGRONOMY","month":"February","year":"2021"}}
{"bib_id":"carvajal_estimating_2016","title":"Estimating the Evaporation from Irrigation Reservoirs of Greenhouses Using Satellite Imagery","author":"Carvajal, F. and Aguera, F. and Sanchez-Hermosilla, J.","meta_info":{"keywords":"Agriculture,Dam detection,Deep Learning,Images: QuickBird,Labels: ???,Model: MLP,Satellite","abstract":"The agricultural system in south-eastern Spain is based on intensive horticulture in greenhouses. Public and private organizations have spent substantial resources on optimizing irrigation, due to the scant annual precipitation (close to 250 mm). In order to preserve natural water resources, avoiding overexploitation and salinization aquifers, the water loss has to be minimized. Farmers save water in irrigation reservoirs, which are open to the atmosphere most of the time. In this work, the loss to evaporation from open water reservoirs was estimated in a typical agricultural greenhouse area in Almeria province, south-eastern Spain. The data source was both a high-resolution satellite image, and a set of climatic data from the Agro-climatic Information Network of Andalusia (AINA) and from a Class-A pan evaporimeter. The image was used for detecting and delineating open water bodies applying a supervised classification algorithm based on an artificial neural network. The climatic data were used to estimate the distribution of monthly evaporation. It was concluded that irrigation water reservoirs can evaporate 3.76% of the input water used for crops. If all of the water bodies were covered with shade materials and if the precipitation intercepted by the roofs of greenhouses were saved in the irrigation water reservoirs, 49.87% of water annually consumed by greenhouse crops could be saved. (C) 2016 American Institute of Chemical Engineers Environ Prog, 35: 1750-1757, 2016","doi":"10.1002\/ep.12419","issn":"1944-7442","pages":"1750--1757","number":"6","volume":"35","journal":"ENVIRONMENTAL PROGRESS & SUSTAINABLE ENERGY","month":"November","year":"2016"}}
{"bib_id":"chelali_deep-star_2021","title":"Deep-STaR: Classification of Image Time Series Based on Spatio-Temporal Representations","author":"Chelali, Mohamed and Kurtz, Camille and Puissant, Anne and Vincent, Nicole","meta_info":{"keywords":"Agriculture,Best Model: 2DCNN,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Public government data,Model comparison,Model: 1DCNN,Model: 2DCNN,Model: ConvLSTM,Model: LSTM,Multitemporal,Satellite","abstract":"Image time series (ITS) represent complex 3D (2D+t in practice) data that are now daily produced in various domains, from medical imaging to remote sensing. They contain rich spatio-temporal information allowing the observation of the evolution of a sensed scene over time. In this work, we focus on the classification task of ITS, as often available in remote sensing tasks. An underlying problem here is to consider jointly the spatial and the temporal dimensions of the data. We present Deep-STaR, a method to learn such features from ITS data to proceed to their classification. Instead of reasoning in the original 2D+t space, we investigate novel 2D planar data representations, containing both temporal and spatial information. Such representations are a novel way to structure the ITS, compatible with deep learning architectures. They are used to feed a convolutional neural network to learn spatio-temporal features with 2D convolutions, leading ultimately to classification decision. To enhance the explainability of the results, we also propose a post-hoc attention mechanism, enabled by this new approach, providing a semantic map giving some insights for the taken decision. Deep-STaR is evaluated on a remote sensing application, for the classification of agricultural crops from satellite ITS. The results highlight the benefice of this method, compared to the literature, and its interest to make easier the interpretation of ITS to understand spatio-temporal phenomena.","doi":"10.1016\/j.cviu.2021.103221","issn":"1077-3142","volume":"208","journal":"COMPUTER VISION AND IMAGE UNDERSTANDING","month":"July","year":"2021"}}
{"bib_id":"chen_defining_1992","title":"Defining Leaf Area Index for Non-Flat Leaves","author":"Chen, J. M. and Black, T. A.","meta_info":{"langid":"english","abstract":"To eliminate the confusion in the definition of leaf area index (L) for non-flat leaves, the projection coefficients of several objects including spheres, cylinders, hemicircular cylinders, and triangular and square bars are investigated through mathematical derivation and numerical calculation for a range of ellipsoidal angular distributions. It is shown that the projection coefficient calculated based on half the total intercepting area is close to a constant of 0.5 when the inclination angle of the objects is randomly (spherically) distributed, whereas the calculated results based on the object's largest projected area are strongly dependent on the shape of the objects. Therefore, it is suggested that the leaf area index of non-flat leaves be defined as half the total intercepting area per unit ground surface area and that the definition of L based on the projected leaf area be abandoned.","urldate":"2022-04-22","doi":"10.1111\/j.1365-3040.1992.tb00992.x","issn":"1365-3040","pages":"421--429","number":"4","volume":"15","journal":"Plant, Cell & Environment","year":"1992"}}
{"bib_id":"chen_rethinking_2017","title":"Rethinking Atrous Convolution for Semantic Image Segmentation","author":"Chen, Liang-Chieh and Papandreou, George and Schroff, Florian and Adam, Hartwig","meta_info":{"archiveprefix":"arxiv","abstract":"In this work, we revisit atrous convolution, a powerful tool to explicitly adjust filter's field-of-view as well as control the resolution of feature responses computed by Deep Convolutional Neural Networks, in the application of semantic image segmentation. To handle the problem of segmenting objects at multiple scales, we design modules which employ atrous convolution in cascade or in parallel to capture multi-scale context by adopting multiple atrous rates. Furthermore, we propose to augment our previously proposed Atrous Spatial Pyramid Pooling module, which probes convolutional features at multiple scales, with image-level features encoding global context and further boost performance. We also elaborate on implementation details and share our experience on training our system. The proposed `DeepLabv3' system significantly improves over our previous DeepLab versions without DenseCRF post-processing and attains comparable performance with other state-of-art models on the PASCAL VOC 2012 semantic image segmentation benchmark.","urldate":"2022-07-21","doi":"10.48550\/arXiv.1706.05587","publisher":"arXiv","primaryclass":"cs","eprint":"1706.05587","number":"arXiv:1706.05587","month":"December","year":"2017"}}
{"bib_id":"choung_comparison_2021","title":"Comparison of Machine and Deep Learning Methods for Mapping Sea Farms Using High-Resolution Satellite Image","author":"Choung, Yun-Jae and Jung, Donghwi","meta_info":{"keywords":"Agriculture,Aquaculture,Best Model: MLP,Crop segmentation,Deep Learning,Images: KOMPSAT-3,Labels: Image survey,Model comparison,Model: MLP,Model: SVM,Satellite","abstract":"Previous research had shown that the supervised machine learning approach performed better than unsupervised machine learning for mapping sea farms using a high-resolution satellite image. The present work compares a support vector machine (SVM), which represents the supervised machine learning approach, and a deep neural network (DNN), which represents the deep learning approach, for mapping sea farms using KOMPSAT-3 satellite images acquired in the South Sea of South Korea. First, coastal maps were generated from the image source given by SVM and DNN. Next, the above-water and underwater farms were detected separately from both the maps based on the minimum and maximum thresholds. Finally, the detection accuracy of both the above-water and underwater farms from both coastal maps was assessed. Statistical results showed that deep learning (DNN) provided better performance than machine learning (SVM) for detecting above-water farms from the given high-resolution satellite image, while both DNN and SVM yielded the same performance for underwater farms. However, a few errors occurred in the detection because of the limitations of the pixel-based classification approaches. In future research, the deep learning algorithm combined with object-based classification, such as the convolutional neural network, can be used to detect sea farms from the given high-resolution image more accurately.","urldate":"2022-03-04","doi":"10.2112\/JCR-SI114-085.1","issn":"0749-0208, 1551-5036","publisher":"Coastal Education and Research Foundation","pages":"420--423","number":"sp1","volume":"114","journal":"Journal of Coastal Research","month":"October","year":"2021"}}
{"bib_id":"colligan_deep_2022","title":"A Deep Learning Approach to Mapping Irrigation Using Landsat: IrrMapper U-net","author":"Colligan, Thomas and Ketchum, David and Brinkerhoff, Douglas and Maneta, Marco","meta_info":{"keywords":"Agriculture,Deep Learning,Images: Landsat,Irrigation segmentation,Labels: Field survey,Labels: Image survey,Model: 2DCNN,Satellite","unique-id":"WOS:000809416400013","orcid-numbers":"Colligan, Thomas\/0000-0003-4315-2074","eissn":"1558-0644","article-number":"4411611","doi":"10.1109\/TGRS.2022.3175635","issn":"0196-2892","volume":"60","journal":"IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","year":"2022"}}
{"bib_id":"dandrimont_lucas_2021","title":"LUCAS Copernicus 2018: Earth-observation-relevant in Situ Data on Land Cover and Use throughout the European Union","author":"d'Andrimont, Raphaël and Verhegghen, Astrid and Meroni, Michele and Lemoine, Guido and Strobl, Peter and Eiselt, Beatrice and Yordanov, Momchil and Martinez-Sanchez, Laura and van der Velde, Marijn","meta_info":{"langid":"english","abstract":"$<$p$><$strong class=\"journal-contentHeaderColor\"$>$Abstract.$<$\/strong$>$ The Land Use\/Cover Area frame Survey (LUCAS) is an evenly spaced in situ land cover and land use ground survey exercise that extends over the whole of the European Union. LUCAS was carried out in 2006, 2009, 2012, 2015, and 2018. A new LUCAS module specifically tailored to Earth observation (EO) was introduced in 2018: the LUCAS Copernicus module. The module surveys the land cover extent up to 51 m in four cardinal directions around a point of observation, offering in situ data compatible with the spatial resolution of high-resolution sensors. However, the use of the Copernicus module being marginal, the goal of the paper is to facilitate its uptake by the EO community. First, the paper summarizes the LUCAS Copernicus protocol to collect homogeneous land cover on a surface area of up to 0.52 ha. Secondly, it proposes a methodology to create a ready-to-use dataset for Earth observation land cover and land use applications with high-resolution satellite imagery. As a result, a total of 63 364 LUCAS points distributed over 26 level-2 land cover classes were surveyed on the ground. Using homogeneous extent information in the four cardinal directions, a polygon was delineated for each of these points. Through geospatial analysis and by semantically linking the LUCAS core and Copernicus module land cover observations, 58 426 polygons are provided with level-3 land cover (66 specific classes including crop type) and land use (38 classes) information as inherited from the LUCAS core observation. The open-access dataset supplied with this paper ($<$a href=\"https:\/\/doi.org\/10.6084\/m9.figshare.12382667.v4\"$>$https:\/\/doi.org\/10.6084\/m9.figshare.12382667.v4$<$\/a$>$ $<$a href=\"#bib1.bibx2\"$>$d'Andrimont$<$\/a$>$, $<$a href=\"#bib1.bibx2\"$>$2020$<$\/a$>$) provides a unique opportunity to train and validate decametric sensor-based products such as those obtained from the Copernicus Sentinel-1 and Sentinel-2 satellites. A follow-up of the LUCAS Copernicus module is already planned for 2022. In 2022, a simplified version of the LUCAS Copernicus module will be carried out on 150 000 LUCAS points for which in situ surveying is planned. This guarantees a continuity in the effort to find synergies between statistical in situ surveying and the need to collect in situ data relevant for Earth observation in the European Union.$<$\/p$>$","urldate":"2022-07-12","doi":"10.5194\/essd-13-1119-2021","issn":"1866-3508","publisher":"Copernicus GmbH","pages":"1119--1133","number":"3","volume":"13","journal":"Earth System Science Data","month":"March","year":"2021","shorttitle":"LUCAS Copernicus 2018"}}
{"bib_id":"de_albuquerque_deep_2020","title":"Deep Semantic Segmentation of Center Pivot Irrigation Systems from Remotely Sensed Data","author":"de Albuquerque, Anesmar Olino and de Carvalho Junior, Osmar Abilio and Ferreira de Carvalho, Osmar Luiz and de Bem, Pablo Pozzobon and Guimaraes Ferreira, Pedro Henrique and de Moura, Rebeca dos Santos and Silva, Cristiano Rosa and Trancoso Gomes, Roberto Arnaldo and Guimaraes, Renato Fontes","meta_info":{"keywords":"Agriculture,Best Model: 2DCNN,Center pivot irrigation detection,Deep Learning,Images: Landsat,Labels: Public government data,Model: SharpMask,Model: UNet,Satellite","abstract":"The center pivot irrigation system (CPIS) is a modern irrigation technique widely used in precision agriculture due to its high efficiency in water consumption and low labor compared to traditional irrigation methods. The CPIS is a leader in mechanized irrigation in Brazil, with growth forecast for the coming years. Therefore, the mapping of center pivot areas is a strategic factor for the estimation of agricultural production, ensuring food security, water resources management, and environmental conservation. In this regard, digital processing of satellite images is the primary tool allowing regional and continuous monitoring with low costs and agility. However, the automatic detection of CPIS using remote sensing images remains a challenge, and much research has adopted visual interpretation. Although CPIS presents a consistent circular shape in the landscape, these areas can have a high internal variation with different plantations that vary over time, which is difficult with just the spectral behavior. Deep learning using convolutional neural networks (CNNs) is an emerging approach that provokes a revolution in image segmentation, surpassing traditional methods, and achieving higher accuracy and efficiency. This research aimed to evaluate the use of deep semantic segmentation of CPIS from CNN-based algorithms using Landsat-8 surface reflectance images (seven bands). The developed methodology can be subdivided into the following steps: (a) Definition of three study areas with a high concentration of CPIS in Central Brazil; (b) acquisition of Landsat-8 images considering the seasonal variations of the rain and drought periods; (c) definition of CPIS datasets containing Landsat images and ground truth mask of 256x256 pixels; (d) training using three CNN architectures (U-net, Deep ResUnet, and SharpMask); (e) accuracy analysis; and (f) large image reconstruction using six stride values (8, 16, 32, 64, 128, and 256). The three methods achieved state-of-the-art results with a slight prevalence of U-net over Deep ResUnet and SharpMask (0.96, 0.95, and 0.92 Kappa coefficients, respectively). A novelty in this research was the overlapping pixel analysis in the large image reconstruction. Lower stride values had improvements quantified by the Receiver Operating Characteristic curve (ROC curve) and Kappa, and fewer errors in the frame edges were also perceptible. The overlapping images significantly improved the accuracy and reduced the error present in the edges of the classified frames. Additionally, we obtained greater accuracy results during the beginning of the dry season. The present study enabled the establishment of a database of center pivot images and an adequate methodology for mapping the center pivot in central Brazil.","doi":"10.3390\/rs12132159","number":"13","volume":"12","journal":"REMOTE SENSING","month":"July","year":"2020"}}
{"bib_id":"debella-gilo_mapping_2021","title":"Mapping Seasonal Agricultural Land Use Types Using Deep Learning on Sentinel-2 Image Time Series","author":"Debella-Gilo, Misganu and Gjertsen, Arnt Kristian","meta_info":{"keywords":"Agriculture,Best Model: 2DCNN,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Public government data,Model comparison,Model: 1DCNN,Model: 2DCNN,Model: MLP,Satellite","abstract":"The size and location of agricultural fields that are in active use and the type of use during the growing season are among the vital information that is needed for the careful planning and forecasting of agricultural production at national and regional scales. In areas where such data are not readily available, an independent seasonal monitoring method is needed. Remote sensing is a widely used tool to map land use types, although there are some limitations that can partly be circumvented by using, among others, multiple observations, careful feature selection and appropriate analysis methods. Here, we used Sentinel-2 satellite image time series (SITS) over the land area of Norway to map three agricultural land use classes: cereal crops, fodder crops (grass) and unused areas. The Multilayer Perceptron (MLP) and two variants of the Convolutional Neural Network (CNN), are implemented on SITS data of four different temporal resolutions. These enabled us to compare twelve model-dataset combinations to identify the model-dataset combination that results in the most accurate predictions. The CNN is implemented in the spectral and temporal dimensions instead of the conventional spatial dimension. Rather than using existing deep learning architectures, an autotuning procedure is implemented so that the model hyperparameters are empirically optimized during the training. The results obtained on held-out test data show that up to 94 % overall accuracy and 90% Cohen's Kappa can be obtained when the 2D CNN is applied on the SITS data with a temporal resolution of 7 days. This is closely followed by the 1D CNN on the same dataset. However, the latter performs better than the former in predicting data outside the training set. It is further observed that cereal is predicted with the highest accuracy, followed by grass. Predicting the unused areas has been found to be difficult as there is no distinct surface condition that is common for all unused areas.","doi":"10.3390\/rs13020289","number":"2","volume":"13","journal":"REMOTE SENSING","month":"January","year":"2021"}}
{"bib_id":"del_frate_wheat_2004","title":"Wheat Cycle Monitoring Using Radar Data and a Neural Network Trained by a Model","author":"Del Frate, F and Ferrazzoli, P and Guerriero, L and Strozzi, T and Wegmuller, U and Cookmartin, G and Quegan, S","meta_info":{"keywords":"Agriculture,Canopy cover prediction,Deep Learning,Extra data: soil,Images: ERS-2,Labels: Model-based,Model: MLP,Satellite,Soil moisture prediction,Yield prediction,Yield: Field-level","abstract":"This paper describes an algorithm aimed at monitoring the soil moisture and the growth cycle of wheat fields using radar data. The algorithm is based on neural networks trained by model simulations and multitemporal ground data measured on fields taken as a reference. The backscatter of wheat canopies is modeled by a discrete approach, based on the radiative transfer theory and including multiple scattering effects. European Remote Sensing satellite synthetic aperture radar signatures and detailed ground truth, collected over wheat fields at the Great Driffield (U.K.) site, are used to test the model and train the networks. Multitemporal, multifirequency data collected by the Radiometer-Scatterometer (RASAM) instrument at the Central Plain site are used to test the retrieval algorithm.","doi":"10.1109\/TGRS.2003.817200","issn":"0196-2892","pages":"35--44","number":"1","volume":"42","journal":"IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","month":"January","year":"2004"}}
{"bib_id":"delloye_retrieval_2018","title":"Retrieval of the Canopy Chlorophyll Content from Sentinel-2 Spectral Bands to Estimate Nitrogen Uptake in Intensive Winter Wheat Cropping Systems","author":"Delloye, Cindy and Weiss, Marie and Defourny, Pierre","meta_info":{"keywords":"Agriculture,Canopy cover prediction,Chlorophyll prediction,Deep Learning,Images: Sentinel,Labels: Model-based,Model: MLP,Satellite","abstract":"One of the most common approaches to reducing the environmental impact of nitrogen (N) fertilisation in intensive agrosystems is to adjust the N input of the crop requirement. This adjustment is frequently related to the nitrogen nutrition index (NNI) based on the concepts of the critical and actual N absorbed (kg\/ha) in the crop canopy (respectively, N-c and CNC). Accurate estimation of the N-c and CNC at the field scale over large areas based on freely available satellite imagery is thus a key issue to address. Relying on a large dataset of farmers' fields, this study highlights the high correlation (R-2 = 0.90) between the wheat CNC and canopy chlorophyll content (CCC) retrieved from Sentinel-2 (S2) with an Artificial Neural Network (ANN). The estimation is related to errors of 4 and 21 kg\/ha (depending on the growing stage), which is a promising result for evaluating the NNI. There are four major outcomes from this result: (i) the importance of working at the canopy level; (ii) the independence of the relationship to the considered cultivars; (iii) the dependence of the relationship on the growing stage; and (iv) the potential to use only the 10 m S2 bands, opening the way for precision agriculture. In parallel, estimation accuracies were investigated for the three biophysical variables (BV) related to the CNC and N-c, i.e., the green area index (GAI), leaf chlorophyll content (Cab) and CCC. From this analysis, the added value of the red-edge bands for improving the estimation of the 3 BVs of interest was quantified as was the performance reduction related to the field heterogeneity.","doi":"10.1016\/j.rse.2018.06.037","issn":"0034-4257","pages":"245--261","volume":"216","journal":"REMOTE SENSING OF ENVIRONMENT","month":"October","year":"2018"}}
{"bib_id":"deng_imagenet_2009","title":"ImageNet: A Large-Scale Hierarchical Image Database","author":"Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li","meta_info":{"abstract":"The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called ``ImageNet'', a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500--1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.","doi":"10.1109\/CVPR.2009.5206848","issn":"1063-6919","pages":"248--255","month":"June","year":"2009","booktitle":"2009 IEEE Conference on Computer Vision and Pattern Recognition","shorttitle":"ImageNet"}}
{"bib_id":"desloires_positive_2022","title":"Positive Unlabelled Learning for Satellite Images'Time Series Analysis: An Application to Cereal and Forest Mapping","author":"Desloires, Johann and Ienco, Dino and Botrel, Antoine and Ranc, Nicolas","meta_info":{"keywords":"Agriculture,Best Model: GRU,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Public government data,Model comparison,Model: GRU,Model: RF,Model: SVM,Satellite,Used VI","abstract":"Applications in which researchers aim to extract a single land type from remotely sensed data are quite common in practical scenarios: extract the urban footprint to make connections with socio-economic factors; map the forest extent to subsequently retrieve biophysical variables and detect a particular crop type to successively calibrate and deploy yield prediction models. In this scenario, the (positive) targeted class is well defined, while the negative class is difficult to describe. This one-class classification setting is also referred to as positive unlabelled learning (PUL) in the general field of machine learning. To deal with this challenging setting, when satellite image time series data are available, we propose a new framework named positive and unlabelled learning of satellite image time series (PUL-SITS). PUL-SITS involves two different stages: In the first one, a recurrent neural network autoencoder is trained to reconstruct only positive samples with the aim to higight reliable negative ones. In the second stage, both labelled and unlabelled samples are exploited in a semi-supervised manner to build the final binary classification model. To assess the quality of our approach, experiments were carried out on a real-world benchmark, namely Haute-Garonne, located in the southwest area of France. From this study site, we considered two different scenarios: a first one in which the process has the objective to map Cereals\/Oilseeds cover versus the rest of the land cover classes and a second one in which the class of interest is the Forest land cover. The evaluation was carried out by comparing the proposed approach with recent competitors to deal with the considered positive and unlabelled learning scenarios.","doi":"10.3390\/rs14010140","number":"1","volume":"14","journal":"REMOTE SENSING","month":"January","year":"2022"}}
{"bib_id":"dobson_microwave_1985","title":"Microwave Dielectric Behavior of Wet Soil-Part II: Dielectric Mixing Models","author":"Dobson, Myron C. and Ulaby, Fawwaz T. and Hallikainen, Martti T. and El-rayes, Mohamed A.","meta_info":{"file":"\/home\/brandon\/Zotero\/storage\/II2WT5NX\/Dobson et al. - 1985 - Microwave Dielectric Behavior of Wet Soil-Part II.pdf;\/home\/brandon\/Zotero\/storage\/9ST67ILP\/4072240.html","abstract":"This paper is the second in a series evaluating the microwave dielectric behavior of soil-water mixtures as a function of water content and soil textural composition. Part II draws upon the data presented in Part 1 [13] to develop appropriate empirical and theoretical dielectric mixing models for the 1.4-to 18-GHz region. A semiempirical mixing model based upon the index of refraction is presented, requiring only easily ascertained soil physical parameters such as volumetric moisture and soil textural composition as inputs. In addition, a theoretical model accounting explicitly for the presence of a hydration layer of bound water adjacent to hydrophilic soil particle surfaces is presented. A four-component dielectric mixing model treats the soil-water system as a host medium of dry soil solids containing randomly distributed and randomly oriented disc-shaped inclusions of bound water, bulk water, and air. The bulk water component is considered to be dependent upon frequency, temperature, and salinity. The soil solution is differentiated by means of a soil physical model into 1) a bound component and 2) a bulk soil solution. The performance of each model is evaluated as a function of soil moisture, soil texture, and frequency, using the dielectric measurements of five soils ranging from sandy loam to silty clay (as presented in Part I [13]) at frequencies between 1.4 and 18 GHz. The semiempirical mixing model yields an excellent fit to the measured data at frequencies above 4 GHz. At 1.","doi":"10.1109\/TGRS.1985.289498","issn":"1558-0644","pages":"35--46","number":"1","volume":"GE-23","journal":"IEEE Transactions on Geoscience and Remote Sensing","month":"January","year":"1985","shorttitle":"Microwave Dielectric Behavior of Wet Soil-Part II"}}
{"bib_id":"dorigo_international_2011","title":"The International Soil Moisture Network: A Data Hosting Facility for Global in Situ Soil Moisture Measurements","author":"Dorigo, W. A. and Wagner, W. and Hohensinn, R. and Hahn, S. and Paulik, C. and Xaver, A. and Gruber, A. and Drusch, M. and Mecklenburg, S. and van Oevelen, P. and Robock, A. and Jackson, T.","meta_info":{"langid":"english","abstract":"In situ measurements of soil moisture are invaluable for calibrating and validating land surface models and satellite-based soil moisture retrievals. In addition, long-term time series of in situ soil moisture measurements themselves can reveal trends in the water cycle related to climate or land cover change. Nevertheless, on a worldwide basis the number of meteorological networks and stations measuring soil moisture, in particular on a continuous basis, is still limited and the data they provide lack standardization of technique and protocol. To overcome many of these limitations, the International Soil Moisture Network (ISMN; http:\/\/www.ipf.tuwien.ac.at\/insitu) was initiated to serve as a centralized data hosting facility where globally available in situ soil moisture measurements from operational networks and validation campaigns are collected, harmonized, and made available to users. Data collecting networks share their soil moisture datasets with the ISMN on a voluntary and no-cost basis. Incoming soil moisture data are automatically transformed into common volumetric soil moisture units and checked for outliers and implausible values. Apart from soil water measurements from different depths, important metadata and meteorological variables (e.g., precipitation and soil temperature) are stored in the database. These will assist the user in correctly interpreting the soil moisture data. The database is queried through a graphical user interface while output of data selected for download is provided according to common standards for data and metadata. Currently (status May 2011), the ISMN contains data of 19 networks and more than 500 stations located in North America, Europe, Asia, and Australia. The time period spanned by the entire database runs from 1952 until the present, although most datasets have originated during the last decade. The database is rapidly expanding, which means that both the number of stations and the time period covered by the existing stations are still growing. Hence, it will become an increasingly important resource for validating and improving satellite-derived soil moisture products and studying climate related trends. As the ISMN is animated by the scientific community itself, we invite potential networks to enrich the collection by sharing their in situ soil moisture data.","urldate":"2024-05-23","doi":"10.5194\/hess-15-1675-2011","issn":"1027-5606","publisher":"Copernicus GmbH","pages":"1675--1698","number":"5","volume":"15","journal":"Hydrology and Earth System Sciences","month":"May","year":"2011","shorttitle":"The International Soil Moisture Network"}}
{"bib_id":"dosovitskiy_image_2021","title":"An Image Is Worth 16x16 Words: Transformers for Image Recognition at Scale","author":"Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil","meta_info":{"archiveprefix":"arxiv","abstract":"While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.","urldate":"2021-11-23","primaryclass":"cs","eprint":"2010.11929","journal":"arXiv:2010.11929 [cs]","month":"June","year":"2021","shorttitle":"An Image Is Worth 16x16 Words"}}
{"bib_id":"drusch_sentinel-2_2012","title":"Sentinel-2: ESA's Optical High-Resolution Mission for GMES Operational Services","author":"Drusch, M. and Del Bello, U. and Carlier, S. and Colin, O. and Fernandez, V. and Gascon, F. and Hoersch, B. and Isola, C. and Laberinti, P. and Martimort, P. and Meygret, A. and Spoto, F. and Sy, O. and Marchese, F. and Bargellini, P.","meta_info":{"langid":"english","abstract":"Global Monitoring for Environment and Security (GMES) is a joint initiative of the European Commission (EC) and the European Space Agency (ESA), designed to establish a European capacity for the provision and use of operational monitoring information for environment and security applications. ESA's role in GMES is to provide the definition and the development of the space- and ground-related system elements. GMES Sentinel-2 mission provides continuity to services relying on multi-spectral high-resolution optical observations over global terrestrial surfaces. The key mission objectives for Sentinel-2 are: (1) To provide systematic global acquisitions of high-resolution multi-spectral imagery with a high revisit frequency, (2) to provide enhanced continuity of multi-spectral imagery provided by the SPOT (Satellite Pour l'Observation de la Terre) series of satellites, and (3) to provide observations for the next generation of operational products such as land-cover maps, land change detection maps, and geophysical variables. Consequently, Sentinel-2 will directly contribute to the Land Monitoring, Emergency Response, and Security services. The corresponding user requirements have driven the design toward a dependable multi-spectral Earth-observation system featuring the Multi Spectral Instrument (MSI) with 13 spectral bands spanning from the visible and the near infrared to the short wave infrared. The spatial resolution varies from 10m to 60m depending on the spectral band with a 290km field of view. This unique combination of high spatial resolution, wide field of view and spectral coverage will represent a major step forward compared to current multi-spectral missions. The mission foresees a series of satellites, each having a 7.25-year lifetime over a 15-year period starting with the launch of Sentinel-2A foreseen in 2013. During full operations two identical satellites will be maintained in the same orbit with a phase delay of 180$^∘$ providing a revisit time of five days at the equator. This paper provides an overview of the GMES Sentinel-2 mission including a technical system concept overview, image quality, Level 1 data processing and operational applications.","urldate":"2022-06-20","doi":"10.1016\/j.rse.2011.11.026","issn":"0034-4257","pages":"25--36","volume":"120","series":"The Sentinel Missions - New Opportunities for Science","journal":"Remote Sensing of Environment","month":"May","year":"2012","shorttitle":"Sentinel-2"}}
{"bib_id":"duggin_assumptions_1990","title":"Assumptions Implicit in Remote Sensing Data Acquisition and Analysis","author":"DUGGIN, M. J. and ROBINOVE, C. J.","meta_info":{"abstract":"The literature contains many examples of image acquisition and analysis which have been inappropriately applied and which have led to empirical results which may not be reproducible, or which are not conclusive. In this paper, we deal with eleven major assumptions which are implicit in the acquisition and in the analysis of passively sensed digital image data. It is hoped that an enumeration of such assumptions might lead to improved rules for image acquisition and analysis.","urldate":"2022-07-21","doi":"10.1080\/01431169008955124","issn":"0143-1161","publisher":"Taylor & Francis","pages":"1669--1694","number":"10","volume":"11","journal":"International Journal of Remote Sensing","month":"October","year":"1990"}}
{"bib_id":"elmetwalli_assessing_2022","title":"Assessing the Efficiency of Remote Sensing and Machine Learning Algorithms to Quantify Wheat Characteristics in the Nile Delta Region of Egypt","author":"Elmetwalli, Adel H. and Mazrou, Yasser S. A. and Tyler, Andrew N. and Hunter, Peter D. and Elsherbiny, Osama and Yaseen, Zaher Mundher and Elsayed, Salah","meta_info":{"keywords":"Agriculture,Deep Learning,Images: QuickBird,Labels: Field survey,Model: MLP,Model: RF,Plant Physiology,Satellite,Used VI","unique-id":"WOS:000775573700001","researcherid-numbers":"Mazrou, Yasser S.A\/AAI-6332-2021 Yaseen, Zaher Mundher\/G-7029-2018 Elsayed, Salah\/AAF-1701-2019 Elsherbiny, Osama\/Q-4394-2018","orcid-numbers":"Mazrou, Yasser S.A\/0000-0002-8197-7483 Yaseen, Zaher Mundher\/0000-0003-3647-7137 Elsayed, Salah\/0000-0002-5808-3561 Elsherbiny, Osama\/0000-0003-3031-7108","eissn":"2077-0472","article-number":"332","doi":"10.3390\/agriculture12030332","number":"3","volume":"12","journal":"AGRICULTURE-BASEL","month":"March","year":"2022"}}
{"bib_id":"engen_farm-scale_2021","title":"Farm-Scale Crop Yield Prediction from Multi-Temporal Data Using Deep Hybrid Neural Networks","author":"Engen, Martin and Sandø, Erik and Sjølander, Benjamin Lucas Oscar and Arenberg, Simon and Gupta, Rashmi and Goodwin, Morten","meta_info":{"keywords":"Agriculture,Deep Learning,Extra data: climate,Images: Sentinel,Labels: Public government data,Model comparison,Model: CNN,Model: GRU,Model: MLP,Multitemporal,Satellite,Used VI,Yield prediction,Yield: Farm-level","langid":"english","copyright":"http:\/\/creativecommons.org\/licenses\/by\/3.0\/","abstract":"Farm-scale crop yield prediction is a natural development of sustainable agriculture, producing a rich amount of food without depleting and polluting environmental resources. Recent studies on crop yield production are limited to regional-scale predictions. The regional-scale crop yield predictions usually face challenges in capturing local yield variations based on farm management decisions and the condition of the field. For this research, we identified the need to create a large and reusable farm-scale crop yield production dataset, which could provide precise farm-scale ground-truth prediction targets. Therefore, we utilise multi-temporal data, such as Sentinel-2 satellite images, weather data, farm data, grain delivery data, and cadastre-specific data. We introduce a deep hybrid neural network model to train this multi-temporal data. This model combines the features of convolutional layers and recurrent neural networks to predict farm-scale crop yield production across Norway. The proposed model could efficiently make the target predictions with the mean absolute error of 76 kg per 1000 m2. In conclusion, the reusable farm-scale multi-temporal crop yield dataset and the proposed novel model could meet the actual requirements for the prediction targets in this paper, providing further valuable insights for the research community.","urldate":"2022-03-07","doi":"10.3390\/agronomy11122576","issn":"2073-4395","publisher":"Multidisciplinary Digital Publishing Institute","pages":"2576","number":"12","volume":"11","journal":"Agronomy","month":"December","year":"2021"}}
{"bib_id":"entekhabi_mutual_1996","title":"Mutual Interaction of Soil Moisture State and Atmospheric Processes","author":"Entekhabi, Dara and Rodriguez-Iturbe, Ignacio and Castelli, Fabio","meta_info":{"langid":"english","abstract":"The purpose of this paper is to outline the pathways through which soil moisture and meteorological phenomena mutually influence one another at local, regional and global scales. This constitutes two-way land-atmosphere interaction, as meteorological phenomena both act as the forcing and react to the forcing by the soil moisture state. Land surface modification of the atmospheric environment and the atmospheric forcing of these land surface conditions from feedback loops which are significant factors in modulating the variability of the climatic system. The predictability and analysis of fluctuations and changes in regional hydrology and the atmospheric environment require an understanding of these feedback mechanisms and two-way land-atmosphere interaction. The dynamics of soil moisture at the land surface is governed by components with diverse time scales. Variability in both weather and climate are therefore influenced by the soil moisture state. In this paper, we present an overview of several studies on the mutual interaction of the soil moisture state and the atmospheric environment. We also outline possible directions for innovative investigations on the determination of soil moisture variation influences on the moist thermodynamics, energetics and dynamics of the overlying atmosphere.","urldate":"2022-05-24","doi":"10.1016\/0022-1694(95)02965-6","issn":"0022-1694","pages":"3--17","number":"1","volume":"184","series":"Soil Moisture Theories and Observations","journal":"Journal of Hydrology","month":"October","year":"1996"}}
{"bib_id":"entekhabi_soil_2010","title":"The Soil Moisture Active Passive (SMAP) Mission","author":"Entekhabi, Dara and Njoku, Eni G. and O'Neill, Peggy E. and Kellogg, Kent H. and Crow, Wade T. and Edelstein, Wendy N. and Entin, Jared K. and Goodman, Shawn D. and Jackson, Thomas J. and Johnson, Joel and Kimball, John and Piepmeier, Jeffrey R. and Koster, Randal D. and Martin, Neil and McDonald, Kyle C. and Moghaddam, Mahta and Moran, Susan and Reichle, Rolf and Shi, J. C. and Spencer, Michael W. and Thurman, Samuel W. and Tsang, Leung and Van Zyl, Jakob","meta_info":{"file":"\/home\/brandon\/Zotero\/storage\/5EK63CBC\/Entekhabi et al. - 2010 - The Soil Moisture Active Passive (SMAP) Mission.pdf;\/home\/brandon\/Zotero\/storage\/XNTM3HVQ\/5460980.html","abstract":"The Soil Moisture Active Passive (SMAP) mission is one of the first Earth observation satellites being developed by NASA in response to the National Research Council's Decadal Survey. SMAP will make global measurements of the soil moisture present at the Earth's land surface and will distinguish frozen from thawed land surfaces. Direct observations of soil moisture and freeze\/thaw state from space will allow significantly improved estimates of water, energy, and carbon transfers between the land and the atmosphere. The accuracy of numerical models of the atmosphere used in weather prediction and climate projections are critically dependent on the correct characterization of these transfers. Soil moisture measurements are also directly applicable to flood assessment and drought monitoring. SMAP observations can help monitor these natural hazards, resulting in potentially great economic and social benefits. SMAP observations of soil moisture and freeze\/thaw timing will also reduce a major uncertainty in quantifying the global carbon balance by helping to resolve an apparent missing carbon sink on land over the boreal latitudes. The SMAP mission concept will utilize L-band radar and radiometer instruments sharing a rotating 6-m mesh reflector antenna to provide high-resolution and high-accuracy global maps of soil moisture and freeze\/thaw state every two to three days. In addition, the SMAP project will use these observations with advanced modeling and data assimilation to provide deeper root-zone soil moisture and net ecosystem exchange of carbon. SMAP is scheduled for launch in the 2014-2015 time frame.","doi":"10.1109\/JPROC.2010.2043918","issn":"1558-2256","pages":"704--716","number":"5","volume":"98","journal":"Proceedings of the IEEE","month":"May","year":"2010"}}
{"bib_id":"eroglu_high_2019","title":"High Spatio-Temporal Resolution CYGNSS Soil Moisture Estimates Using Artificial Neural Networks","author":"Eroglu, Orhan and Kurum, Mehmet and Boyd, Dylan and Gurbuz, Ali Cafer","meta_info":{"keywords":"Deep Learning,Extra data: soil,Extra data: vegetation,Images: CYGNSS,Labels: Public government data,Model: MLP,Satellite,Soil moisture prediction","abstract":"This paper presents a learning-based, physics-aware soil moisture (SM) retrieval algorithm for NASA's Cyclone Global Navigation Satellite System (CYGNSS) mission. The goal of the proposed novel method is to advance CYGNSS-based SM estimations, exploiting the spatio-temporal resolution of the GNSS reflectometry (GNSS-R) signals to its highest potential within a machine learning framework. The methodology employs a fully connected Artificial Neural Network (ANN) regression model to perform SM predictions through learning the nonlinear relations of SM and other land geophysical parameters to the CYGNSS observables. In situ SM measurements from several International SM Network (ISMN) sites are used as reference labels; CYGNSS incidence angles, derived reflectivity and trailing edge slope (TES) values, as well as ancillary data, are exploited as input features for training and validation of the ANN model. In particular, the utilized ancillary data consist of normalized difference vegetation index (NDVI), vegetation water content (VWC), terrain elevation, terrain slope, and h-parameter (surface roughness). Land cover classification and inland water body masks are also used for the intermediate derivations and quality control purposes. The proposed algorithm assumes uniform SM over a 0.0833ffi similar to 0.0833ffi (approximately 9 km similar to 9 km around the equator) lat\/lon grid for any CYGNSS observation that falls within this window. The proposed technique is capable of generating sub-daily and high-resolution SM predictions as it does not rely on time-series or spatial averaging of the CYGNSS observations. Once trained on the data from ISMN sites, the model is independent from other SM sources for retrieval. The estimation results obtained over unseen test data are promising: SM predictions with an unbiased root mean squared error of 0.0544 cm3\/cm3 and Pearson correlation coefficient of 0.9009 are reported for 2017 and 2018.","doi":"10.3390\/rs11192272","number":"19","volume":"11","journal":"REMOTE SENSING","month":"October","year":"2019"}}
{"bib_id":"evans_long-term_2021","title":"Long-Term Hindcasts of Wheat Yield in Fields Using Remotely Sensed Phenology, Climate Data and Machine Learning","author":"Evans, Fiona H. and Shen, Jianxiu","meta_info":{"keywords":"Agriculture,Best Model: MLP,Deep Learning,Extra data: climate,Images: Landsat,Labels: Field survey,Model: MLP,Model: RF,Model: SVM,Satellite,Used VI,Yield prediction","abstract":"Satellite remote sensing offers a cost-effective means of generating long-term hindcasts of yield that can be used to understand how yield varies in time and space. This study investigated the use of remotely sensed phenology, climate data and machine learning for estimating yield at a resolution suitable for optimising crop management in fields. We used spatially weighted growth curve estimation to identify the timing of phenological events from sequences of Landsat NDVI and derive phenological and seasonal climate metrics. Using data from a 17,000 ha study area, we investigated the relationships between the metrics and yield over 17 years from 2003 to 2019. We compared six statistical and machine learning models for estimating yield: multiple linear regression, mixed effects models, generalised additive models, random forests, support vector regression using radial basis functions and deep learning neural networks. We used a 50-50 train-test split on paddock-years where 50% of paddock-year combinations were randomly selected and used to train each model and the remaining 50% of paddock-years were used to assess the model accuracy. Using only phenological metrics, accuracy was highest using a linear mixed model with a random effect that allowed the relationship between integrated NDVI and yield to vary by year (R-2 = 0.67, MAE = 0.25 t ha(-1), RMSE = 0.33 t ha(-1), NRMSE = 0.25). We quantified the improvements in accuracy when seasonal climate metrics were also used as predictors. We identified two optimal models using the combined phenological and seasonal climate metrics: support vector regression and deep learning models (R-2 = 0.68, MAE = 0.25 t ha(-1), RMSE = 0.32 t ha(-1), NRMSE = 0.25). While the linear mixed model using only phenological metrics performed similarly to the nonlinear models that are also seasonal climate metrics, the nonlinear models can be more easily generalised to estimate yield in years for which training data are unavailable. We conclude that long-term hindcasts of wheat yield in fields, at 30 m spatial resolution, can be produced using remotely sensed phenology from Landsat NDVI, climate data and machine learning.","doi":"10.3390\/rs13132435","number":"13","volume":"13","journal":"REMOTE SENSING","month":"July","year":"2021"}}
{"bib_id":"feng_geographically_2021","title":"Geographically and Temporally Weighted Neural Network for Winter Wheat Yield Prediction","author":"Feng, Luwei and Wang, Yumiao and Zhang, Zhou and Du, Qingyun","meta_info":{"keywords":"Agriculture,Deep Learning,Extra data: climate,Images: MODIS,Labels: Public government data,Model: MLP,Satellite,Used VI,Yield prediction,Yield: County-level","abstract":"Accurate prediction of crop yield is essential for agricultural trading, market risk management and food security. Although various statistical models and machine learning models have been developed to enhance prediction accuracy, spatial and temporal non-stationarity, an intrinsic attribute of many geographical processes, is still rarely considered in crop yield modeling. From a statistical point of view, this study respectively provided evidence for the existence of spatial non-stationarity and temporal non-stationarity in winter wheat yield prediction based on geographically weighted regression (GWR) and temporally weighted regression (TWR). Then, a geographically and temporally weighted neural network (GTWNN) model was proposed by integrating artificial neural network (ANN) into geographically and temporally weighted regression (GTWR) using publicly available data sources, including satellite imagery and climate data. For a more credible evaluation, the leave-one-year-out strategy was adopted to make out-of-sample prediction resulting in a total of 12 test years from 2008 to 2019. The experiment results showed that the proposed GTWNN outperformed ANN, GTWR and support vector regression (SVR) achieving the average coefficient of determination (R2) values of 0.766, 0.759 and 0.720 at the three prediction times of end of July, end of June and end of May. Moreover, an extended Moran's I was adopted to assess the degree of spatiotemporal autocorrelation of the prediction errors. The error aggregation of GTWNN was lower than other models, indicating that GTWNN is applicable to addressing spatial non-stationarity in modeling the relationship between predictors and yield response. The methodology proposed in this paper can be extended to handle spatiotemporal non-stationarity in other crop yield predictions and even other environmental phenomena.","doi":"10.1016\/j.rse.2021.112514","issn":"0034-4257","volume":"262","journal":"REMOTE SENSING OF ENVIRONMENT","month":"September","year":"2021"}}
{"bib_id":"feng_machine_2019","title":"Machine Learning-Based Integration of Remotely-Sensed Drought Factors Can Improve the Estimation of Agricultural Drought in South-Eastern Australia","author":"Feng, Puyu and Wang, Bin and Liu, De Li and Yu, Qiang","meta_info":{"keywords":"Agriculture,Best Model: RF,Deep Learning,Extra data: climate,Images: MODIS,Labels: Public government data,Model comparison,Model: MLP,Model: RF,Model: SVM,Satellite,Used VI,Yield prediction,Yield: County-level","abstract":"Agricultural drought is a natural hazard arising from insufficient crop water supply. Many drought indices have been developed to characterize agricultural drought, relying on either ground-based climate data or various remotely-sensed drought proxies. Ground-based drought indices are more accurate but limited in coverage, while remote sensing drought indices cover large areas but have poor precision. Application of advanced data fusion approaches based on remotely-sensed data to estimate ground-based drought indices may help fill this gap. The overall objective of this study was to determine whether various remotely-sensed drought factors could be effectively used for monitoring agricultural drought in south-eastern Australia. In this study, thirty remotely-sensed drought factors from the Tropical Rainfall Measuring Mission (TRMM) and the Moderate Resolution Imaging Spectroradiometer (MODIS) satellite sensors were used to reproduce a ground-based drought index, SPEI (Standardized Precipitation Evapotranspiration Index) during 2001-2017 for the New South Wales wheat belt in south-eastern Australia. Three advanced machine learning methods, i.e. bias-corrected random forest, support vector machine, and multi-layer perceptron neural network, were adopted as the regression models in this procedure. A station-based historical climate dataset and observed wheat yields were used as reference data to evaluate the performance of the model-predicted SPEI in reflecting agricultural drought. Results show that the bias-corrected random forest model outperformed the other two models for SPEI prediction, as quantified by the lowest root mean square error (RMSE) and the highest R-2 values ($<$ 0.28 and similar to 0.9, respectively). Drought distribution maps produced by the bias-corrected random forest model were then compared with the station-based drought maps, showing strong visual and statistical agreement. Furthermore, the model-predicted SPEI values were more highly correlated with observed wheat yields than the station-based SPEI. The method used in this study is effective and fast, and based on data that are readily available. It can be easily extended to other cropping areas to produce a rapid overview of drought conditions and to enhance the present capabilities of real-time drought monitoring.","doi":"10.1016\/j.agsy.2019.03.015","issn":"0308-521X","pages":"303--316","volume":"173","journal":"AGRICULTURAL SYSTEMS","month":"July","year":"2019"}}
{"bib_id":"fernandez-sellers_finding_2021","title":"Finding a Suitable Sensing Time Period for Crop Identification Using Heuristic Techniques with Multi-Temporal Satellite Images","author":"Fernandez-Sellers, Marcos and Siesto, Guillermo and Lozano-Tello, Adolfo and Clemente, Pedro J.","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Public government data,Model: MLP,Satellite","abstract":"Satellite crop identification processes are increasingly being used on a large scale, both to verify the crop and to improve production. As it is necessary to study phenological data over a period of time across a large territory, a lot of storage space is needed to save the satellite images and a lot of calculation time to analyse all this information. Sensing periods are usually established based on subjective expert criteria or previous experience. However, this decision may cause several differences when discriminating crop patterns, besides not guaranteeing good precision. These processes would greatly improve if the appropriate time periods could be found systematically using the minimum number of satellite images in the shortest possible time. In this paper, we propose a new methodology to determine a suitable sensing period for crop identification using Sentinel-2 images, applying hill climbing algorithms to the training sets of neural network models. We have used the method successfully in the 2020 Common Agricultural Policy campaign in the Extremadura region, Spain. The article also describes the use of the method in a case on tobacco detection in this region.","doi":"10.1080\/01431161.2021.1975846","issn":"0143-1161","journal":"INTERNATIONAL JOURNAL OF REMOTE SENSING","month":"September","year":"2021"}}
{"bib_id":"ferreira_accurate_2021","title":"Accurate Mapping of Brazil Nut Trees (Bertholletia Excelsa) in Amazonian Forests Using WorldView-3 Satellite Images and Convolutional Neural Networks","author":"Ferreira, Matheus Pinheiro and Lotte, Rodolfo Georjute and D'Elia, V, Francisco and Stamatopoulos, Christos and Kim, Do-Hyung and Benjamin, Adam R.","meta_info":{"keywords":"Agriculture,Deep Learning,Images: WV-3,Labels: Field survey,Model: DeepLabv3,Model: ResNet,Satellite,Tree detection","abstract":"The commercialization of Brazil nuts, seeds of Bertholletia excelsa Bonpl. (Lecythidaceae), represents one of the main income-generation activities for local and indigenous people from the Brazilian Amazon region. Because trees of B. excelsa grow and bear fruit almost exclusively in natural forests, information on their spatial distribution is crucial for nut harvest planning. However, this information is difficult to obtain with traditional approaches such as ground-based surveys. Here, we show the potential of convolutional neural networks (CNNs) and WorldView-3 satellite images (pixel size = 30 cm) to map individual tree crowns (ITCs) and groves of B. excelsa in Amazonian forests. First, we manually outlined B. excelsa ITCs in the WorldView-3 images using field-acquired geolocation information. Then, based on ITC boundaries, we sequentially extracted image patches and selected 80% of them for training and 20% for testing. We trained the DeepLabv3+ architecture with three backbones: ResNet-18, ResNet-50, and MobileNetV2. The average producer's accuracy was 93.87 +\/- 0.85%, 93.89 +\/- 1.6% and 93.47 +\/- 3.6% for ResNet-18, ResNet-50 and MobileNetV2, respectively. We then developed a new random patch extraction training strategy and assessed how a reduction in the percentage of training patches impacted the classification accuracy. To illustrate the robustness of the new training strategy, similar F1scores were achieved whether 80% or 10% of the total number of patches were used to train the CNN model. By analyzing the feature maps derived from ResNet-18, we found that the shadow of emergent B. excelsa trees are important for their discrimination. Geometric distortions in the WorldView-3 images resulting from extreme offnadir viewing angles compromise the presence of shadows, thus potentially hampering B. excelsa detection. Our results show that ITCs and groves of B. excelsa can be mapped by integrating CNNs and very-high-resolution (VHR) satellite images, paving the way for monitoring this important tree species in large tracts of Amazonian forests.","doi":"10.1016\/j.ecoinf.2021.101302","issn":"1574-9541","volume":"63","journal":"ECOLOGICAL INFORMATICS","month":"July","year":"2021"}}
{"bib_id":"fontanelli_early-season_2022","title":"Early-Season Crop Mapping on an Agricultural Area in Italy Using X-band Dual-Polarization SAR Satellite Data and Convolutional Neural Networks","author":"Fontanelli, Giacomo and Lapini, Alessandro and Santurri, Leonardo and Pettinato, Simone and Santi, Emanuele and Ramat, Giuliano and Pilia, Simone and Baroni, Fabrizio and Tapete, Deodato and Cigna, Francesca and Paloscia, Simonetta","meta_info":{"keywords":"Agriculture,Best Model: 3DCNN,Crop segmentation,Deep Learning,Images: COSMO-SkyMed,Labels: Field survey,Model: 1DCNN,Model: 3DCNN,Satellite","unique-id":"WOS:000845070100009","researcherid-numbers":"Cigna, Francesca\/B-9173-2015 Tapete, Deodato\/AAB-7528-2021","orcid-numbers":"Cigna, Francesca\/0000-0001-8134-1576 Tapete, Deodato\/0000-0002-7242-4473","eissn":"2151-1535","doi":"10.1109\/JSTARS.2022.3198475","issn":"1939-1404","pages":"6789--6803","volume":"15","journal":"IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING","year":"2022"}}
{"bib_id":"fritz_comparison_2019","title":"A Comparison of Global Agricultural Monitoring Systems and Current Gaps","author":"Fritz, Steffen and See, Linda and Bayas, Juan Carlos Laso and Waldner, François and Jacques, Damien and Becker-Reshef, Inbal and Whitcraft, Alyssa and Baruth, Bettina and Bonifacio, Rogerio and Crutchfield, Jim and Rembold, Felix and Rojas, Oscar and Schucknecht, Anne and Van der Velde, Marijn and Verdin, James and Wu, Bingfang and Yan, Nana and You, Liangzhi and Gilliams, Sven and Mücher, Sander and Tetrault, Robert and Moorthy, Inian and McCallum, Ian","meta_info":{"langid":"english","abstract":"Global and regional scale agricultural monitoring systems aim to provide up-to-date information regarding food production to different actors and decision makers in support of global and national food security. To help reduce price volatility of the kind experienced between 2007 and 2011, a global system of agricultural monitoring systems is needed to ensure the coordinated flow of information in a timely manner for early warning purposes. A number of systems now exist that fill this role. This paper provides an overview of the eight main global and regional scale agricultural monitoring systems currently in operation and compares them based on the input data and models used, the outputs produced and other characteristics such as the role of the analyst, their interaction with other systems and the geographical scale at which they operate. Despite improvements in access to high resolution satellite imagery over the last decade and the use of numerous remote-sensing based products by the different systems, there are still fundamental gaps. Based on a questionnaire, discussions with the system experts and the literature, we present the main gaps in the data and in the methods. Finally, we propose some recommendations for addressing these gaps through ongoing improvements in remote sensing, harnessing new and innovative data streams and the continued sharing of more and more data.","urldate":"2022-07-14","doi":"10.1016\/j.agsy.2018.05.010","issn":"0308-521X","pages":"258--272","volume":"168","journal":"Agricultural Systems","month":"January","year":"2019"}}
{"bib_id":"fu_new_2021","title":"A New Satellite-Derived Dataset for Marine Aquaculture Areas in China's Coastal Region","author":"Fu, Yongyong and Deng, Jinsong and Wang, Hongquan and Comber, Alexis and Yang, Wu and Wu, Wenqiang and You, Shixue and Lin, Yi and Wang, Ke","meta_info":{"keywords":"Agriculture,Aquaculture,Crop segmentation,Deep Learning,Images: GF1,Labels: Field survey,Labels: Image survey,Model: CNN,Satellite","abstract":"China has witnessed extensive development of the marine aquaculture industry over recent years. However, such rapid and disordered expansion posed risks to coastal environment, economic development, and biodiversity protection. This study aimed to produce an accurate national-scale marine aquaculture map at a spatial resolution of 16 m, using a proposed model based on deep convolution neural networks (CNNs) and applied it to satellite data from China's GF-1 sensor in an end-to-end way. The analyses used homogeneous CNNs to extract high-dimensional features from the input imagery and preserve information at full resolution. Then, a hierarchical cascade architecture was followed to capture multi-scale features and contextual information. This hierarchical cascade homogeneous neural network (HCHNet) was found to achieve better classification performance than current state-of-the-art models (FCN-32s, Deeplab V2, U-Net, and HCNet). The resulting marine aquaculture area map has an overall classification accuracy $>$ 95%(95.2 %-96.4, 95% confidence interval). And marine aquaculture was found to cover a total area of similar to 1100 km(2) (1096.8-1110.6 km(2), 95% confidence interval) in China, of which more than 85% is marine plant culture areas, with 87% found in the Fujian, Shandong, Liaoning, and Jiangsu provinces. The results confirm the applicability and effectiveness of HCHNet when applied to GF-1 data, identifying notable spatial distributions of different marine aquaculture areas and supporting the sustainable management and ecological assessments of coastal resources at a national scale. The nationalscale marine aquaculture map at 16m spatial resolution is published in the Google Maps kmz file format with georeferencing information at https:\/\/doi.org\/10.5281\/zenodo.3881612 (Fu et al., 2020).","doi":"10.5194\/essd-13-1829-2021","issn":"1866-3508","pages":"1829--1842","number":"4","volume":"13","journal":"EARTH SYSTEM SCIENCE DATA","month":"May","year":"2021"}}
{"bib_id":"funck_image_2003","title":"Image Segmentation Algorithms Applied to Wood Defect Detection","author":"Funck, J. W and Zhong, Y and Butler, D. A and Brunner, C. C and Forrer, J. B","meta_info":{"langid":"english","abstract":"Image segmentation is a key stage in the detection of defects in images of wood surfaces. While there are many segmentation algorithms, they can be broadly divided into two categories based on whether they use discontinuities or similarities in the image data. Each algorithm can also be categorized based on other factors such as whether it uses color or gray-scale data and is a local or global operator. While this presents a wide variety of approaches for segmenting images of features on wood surfaces, it also makes it difficult to select the most appropriate techniques. This paper presents the results obtained from using a variety of algorithms for wood surface feature detection and defines several measures used for examining algorithm performance. A region-based, similarity algorithm that was a combination of clustering and region-growing techniques exhibited the best overall performance. This was particularly true for defects that are subtle, meaning they blend in with other natural features on wood surfaces that are not considered defects. Examples include blue stain, pitch streaks, and wane. The clustering with region growing algorithm improved the detection accuracy of pitch streaks by over 20 percentage points compared to the next best algorithm. However, if subtle defects are not of interest, the edge detection algorithms performed as well as the region growing algorithm but with slightly better clearwood detection accuracies. The influence of color information, local-basis analysis, and camera resolution on algorithm performance varied by segmentation technique and defect category. Because each wood processing application has its own unique set of defect detection requirements, conclusions regarding which algorithms and factors are best must be made in the context of those processing requirements.","urldate":"2022-07-25","doi":"10.1016\/S0168-1699(03)00049-8","issn":"0168-1699","pages":"157--179","number":"1","volume":"41","series":"Developments in Image Processing and Scanning of Wood","journal":"Computers and Electronics in Agriculture","month":"December","year":"2003"}}
{"bib_id":"gallo_sentinel_2021","title":"Sentinel 2 Time Series Analysis with 3D Feature Pyramid Network and Time Domain Class Activation Intervals for Crop Mapping","author":"Gallo, Ignazio and La Grassa, Riccardo and Landro, Nicola and Boschetti, Mirco","meta_info":{"keywords":"Agriculture,Crop segmentation,Dataset: Munich land cover,Deep Learning,Images: Sentinel,Labels: Dataset,Model: 3DCNN,Satellite","abstract":"In this paper, we provide an innovative contribution in the research domain dedicated to crop mapping by exploiting the of Sentinel-2 satellite images time series, with the specific aim to extract information on ``where and when'' crops are grown. The final goal is to set up a workflow able to reliably identify (classify) the different crops that are grown in a given area by exploiting an end-to-end (3+2)D convolutional neural network (CNN) for semantic segmentation. The method also has the ambition to provide information, at pixel level, regarding the period in which a given crop is cultivated during the season. To this end, we propose a solution called Class Activation Interval (CAI) which allows us to interpret, for each pixel, the reasoning made by CNN in the classification determining in which time interval, of the input time series, the class is likely to be present or not. Our experiments, using a public domain dataset, show that the approach is able to accurately detect crop classes with an overall accuracy of about 93% and that the network can detect discriminatory time intervals in which crop is cultivated. These results have twofold importance: (i) demonstrate the ability of the network to correctly interpret the investigated physical process (i.e., bare soil condition, plant growth, senescence and harvesting according to specific cultivated variety) and (ii) provide further information to the end-user (e.g., the presence of crops and its temporal dynamics).","doi":"10.3390\/ijgi10070483","number":"7","volume":"10","journal":"ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION","month":"July","year":"2021"}}
{"bib_id":"garnot_multi-modal_2022","title":"Multi-Modal Temporal Attention Models for Crop Mapping from Satellite Time Series","author":"Garnot, Vivien Sainte Fare and Landrieu, Loic and Chehata, Nesrine","meta_info":{"keywords":"Agriculture,Crop segmentation,Dataset: PASTIS-R,Deep Learning,Images: Sentinel,Labels: Public government data,Model: 2DCNN,Model: TAE,Satellite","unique-id":"WOS:000788064700004","eissn":"1872-8235","doi":"10.1016\/j.isprsjprs.2022.03.012","issn":"0924-2716","pages":"294--305","volume":"187","journal":"ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING","month":"May","year":"2022"}}
{"bib_id":"garnot_panoptic_2021","title":"Panoptic Segmentation of Satellite Image Time Series With Convolutional Temporal Attention Networks","author":"Garnot, Vivien Sainte Fare and Landrieu, Loic","meta_info":{"langid":"english","urldate":"2024-05-20","pages":"4872--4881","year":"2021","booktitle":"Proceedings of the IEEE\/CVF International Conference on Computer Vision"}}
{"bib_id":"garnot_satellite_2020","title":"Satellite Image Time Series Classification With Pixel-Set Encoders and Temporal Self-Attention","author":"Garnot, Vivien Sainte Fare and Landrieu, Loic and Giordano, Sebastien and Chehata, Nesrine","meta_info":{"urldate":"2022-07-13","pages":"12325--12334","year":"2020","booktitle":"Proceedings of the IEEE\/CVF Conference on Computer Vision and Pattern Recognition"}}
{"bib_id":"gascon_using_2007","title":"Using Multi-Directional High-Resolution Imagery from POLDER Sensor to Retrieve Leaf Area Index","author":"Gascon, F. and Gastellu-Etchegorry, J. P. and Leroy, M.","meta_info":{"keywords":"Agriculture,Canopy cover prediction,Deep Learning,Images: POLDER,Labels: Model-based,Model: MLP,Satellite,Whole pixels only","abstract":"Multi-directional satellite optical imagery collected at high spatial resolution potentially allows improving the accuracy of biophysical variable retrieval. The improvements result from the inclusion of the directional anisotropy of the target, which provides additional information related to vegetation structural properties. The research presented here analyses airborne imagery and ground reference data in order to quantify the accuracy of the retrieval methods for LAI (leaf area index). Both variables are estimated through processing of airborne POLDER (POLarization and Directionality of Earth Reflectances) sensor images from an agricultural area. In a first step, the BRDF (Bi-directional Reflectance Distribution Function) of the surface is estimated using a simple parametric model, whose parameters where derived from fitting POLDER BRF (Bi-directional Reflectance Factor) measurements. LAI estimation was performed using two different approaches, both based on an artificial neural network designed to invert a I D soil-vegetation radiative transfer model. The difference between the two methods is that one of them uses only the isotropic component of the BRDF parametric model and the other the full BRDF information, i.e. adding the anisotropic components. The algorithm using isotropic information shows a clear improvement when compared to semiempirical approaches. Root mean square error between estimated and ground measured LAI values is 0.87. However, the method using the full BRDF information yielded poorer estimates, pointing out the difficulty of fully exploiting the multi-directional information. The performance decrease is partially explained by the incoherence between real and modelled BRDF measurements.","doi":"10.1080\/01431160600647217","issn":"0143-1161","pages":"167--181","number":"1-2","volume":"28","journal":"INTERNATIONAL JOURNAL OF REMOTE SENSING","month":"January","year":"2007"}}
{"bib_id":"gautam_residual_2011","title":"Residual Soil Nitrate Prediction from Imagery and Non-Imagery Information Using Neural Network Technique","author":"Gautam, Ramesh and Panigrahi, Suranjan and Franzen, David and Sims, Albert","meta_info":{"keywords":"Agriculture,Deep Learning,Extra data: geological,Extra data: yield,Images: Landsat,Labels: Field survey,Model: MLP,Satellite,Soil nitrogen prediction","abstract":"Textural features extracted from LANDSAT satellite image and non-imagery information like soil electrical conductivity, crop yield, topography, and crop dry residue matter etc., were used to develop residual soil nitrate prediction models using three neural networks; back propagation, modular, and radial basis function architectures. Statistical parameters were compared to evaluate the performance of three neural network models. The residual soil nitrate prediction model based on back propagation neural network (BPNN) architecture depicted the highest average accuracy of 83.29% and the lowest root mean square error of 10.61%. The corresponding correlation coefficient of 91% was the highest among those provided by all three NN models. Sensitivity analysis showed equal importance of both imagery and non-imagery variables for predicting residual soil nitrate content in field conditions. Published by Elsevier Ltd on behalf of IAgrE.","doi":"10.1016\/j.biosystemseng.2011.06.002","issn":"1537-5110","pages":"20--28","number":"1","volume":"110","journal":"BIOSYSTEMS ENGINEERING","month":"September","year":"2011"}}
{"bib_id":"gbodjo_benchmarking_2021","title":"Benchmarking Statistical Modelling Approaches with Multi-Source Remote Sensing Data for Millet Yield Monitoring: A Case Study of the Groundnut Basin in Central Senegal","author":"Gbodjo, Yawogan Jean Eudes and Ienco, Dino and Leroux, Louise","meta_info":{"keywords":"Agriculture,Best Model: MLP,Deep Learning,Images: Sentinel,Labels: Field survey,Model comparison,Model: CNN,Model: LSTM,Model: MLP,Model: RF,Satellite,Used VI,Yield prediction,Yield: Field-level","abstract":"In Sub-Saharan Africa, smallholder farms play a key role in agriculture, occupying most of the agricultural land. Design policies for increasing smallholder productivity remains a safe way to establish sustainable food systems and boost local economies. However, efforts are still needed in order to achieve accurate and timely monitoring in smallholder farming systems. With the advent of modern Earth Observation programmes such as the Sentinel satellites, which provide quasi-synchronous and high-resolution multi-source information over any area of the continental surfaces, new opportunities are opened up to accurately map crop yields in smallholder farming systems. This study intends to estimate and forecast millet yields in central Senegal, making the use of multi-source (synthetic-aperture radar (SAR) and optical) image time series and state-of-the-art machine learning models. A Random Forest (RF) model explained up to 50% of the millet yield variability, while deep learning models such as Convolutional Neural Network (CNN) showed promise results but performed lower. We also found that the concatenation of SAR polarizations and vegetation indices improved our crop yield modelling, but such improvement was tightly related to the modelling approach, namely RF and CNN. Using RF to forecast millet yields, we achieved stable and satisfactory accuracy 2 weeks before the harvest period.","doi":"10.1080\/01431161.2021.1993465","issn":"0143-1161","pages":"9277--9300","number":"24","volume":"42","journal":"INTERNATIONAL JOURNAL OF REMOTE SENSING","month":"December","year":"2021"}}
{"bib_id":"gebbers_precision_2010","title":"Precision Agriculture and Food Security","author":"Gebbers, Robin and Adamchuk, Viacheslav I.","meta_info":{"urldate":"2022-07-14","doi":"10.1126\/science.1183899","publisher":"American Association for the Advancement of Science","pages":"828--831","number":"5967","volume":"327","journal":"Science","month":"February","year":"2010"}}
{"bib_id":"ghasemloo_estimating_2022","title":"Estimating the Agricultural Farm Soil Moisture Using Spectral Indices of Landsat 8, and Sentinel-1, and Artificial Neural Networks","author":"Ghasemloo, Nima and Matkan, Ali Akbar and Alimohammadi, Abbas and Aghighi, Hossein and Mirbagheri, Babak","meta_info":{"keywords":"Agriculture,Deep Learning,Images: Landsat,Images: Sentinel,Model: MLP,Satellite,Soil moisture prediction,Used VI","unique-id":"WOS:000805769200001","eissn":"2509-8829","article-number":"19","doi":"10.1007\/s41651-022-00110-4","issn":"2509-8810","number":"2","volume":"6","journal":"JOURNAL OF GEOVISUALIZATION AND SPATIAL ANALYSIS","month":"December","year":"2022"}}
{"bib_id":"gomez_optical_2016","title":"Optical Remotely Sensed Time Series Data for Land Cover Classification: A Review","author":"Gómez, Cristina and White, Joanne C. and Wulder, Michael A.","meta_info":{"langid":"english","abstract":"Accurate land cover information is required for science, monitoring, and reporting. Land cover changes naturally over time, as well as a result of ant\\dots","urldate":"2022-07-12","doi":"10.1016\/j.isprsjprs.2016.03.008","issn":"0924-2716","publisher":"Elsevier","pages":"55--72","volume":"116","journal":"ISPRS Journal of Photogrammetry and Remote Sensing","month":"June","year":"2016","shorttitle":"Optical Remotely Sensed Time Series Data for Land Cover Classification"}}
{"bib_id":"gomez_use_2010","title":"Use of High-Resolution Satellite Imagery in an Integrated Model to Predict the Distribution of Shade Coffee Tree Hybrid Zones","author":"Gomez, C. and Mangeas, M. and Petit, M. and Corbane, C. and Hamon, P. and Hamon, S. and De Kochko, A. and Le Pierres, D. and Poncet, V. and Despinoy, M.","meta_info":{"keywords":"Agriculture,Deep Learning,Images: QuickBird,Labels: ???,Model: MLP,Model: Tree,Satellite,Tree detection","abstract":"In New Caledonia (21 S, 165 E), shade-grown coffee plantations were abandoned for economic reasons in the middle of the 20th century. Coffee species (Coffee arabica, C canephora and C liberica) were introduced from Africa in the late 19th century, they survived in the wild and spontaneously cross-hybridized. Coffee species were originally planted in native forest in association with leguminous trees (mostly introduced species) to improve their growth. Thus the canopy cover over rustic shade coffee plantations is heterogeneous with a majority of large crowns, attributed to leguminous trees. The aim of this study was to identify suitable areas for coffee inter-specific hybridization in New Caledonia using field based environmental parameters and remotely sensed predictors. Due to the complex structure of tropical vegetation, remote sensing imagery needs to be spatially accurate and to have the appropriate bands for monitoring vegetation cover. Quickbird panchromatic (black and white) imagery at 0.6 to 0.7 m spatial resolutions and multispectral imagery at 2.4 m spatial resolution were pansharpened and used for this study. The two most suitable remotely sensed indicators, canopy heterogeneity and tree crown size, were acquired by the sequential use of tree crown detection (neural network), image processing (such as textural analysis) and classification. All models were supervised and trained on learning data determined by human expertise. The final model has two remotely sensed indicators and three physical parameters based on the Digital Elevation Model: elevation, slope and water flow accumulation. Using these five predictive variables as inputs, two modelling methods, a decision tree and a neural network, were implemented. The decision tree, which showed 96.9% accuracy on the test set, revealed the involvement of ecological parameters in the hybridization of Coffea species. We showed that hybrid zones could be characterized by combinations of modalities, underlining the complexity of the environment concerned. For instance, forest heterogeneity and large crown size, steep slopes ($>$53.5%) and elevation between 194 and 429 m asl, are favourable factors for Coffea inter-specific hybridization. The application of the neural network on the whole area gave a predictive map that distinguished the most suitable areas by means of a nonlinear continuous indicator. The map provides a confidence level for each area. The most favourable areas were geographically localized, providing a clue for the detection and conservation of favourable areas for Coffea species neo-diversity. (C) 2010 Elsevier Inc. All rights reserved.","doi":"10.1016\/j.rse.2010.06.007","issn":"0034-4257","pages":"2731--2744","number":"11","volume":"114","journal":"REMOTE SENSING OF ENVIRONMENT","month":"November","year":"2010"}}
{"bib_id":"goodfellow_deep_2016","title":"Deep Learning","author":"Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron","meta_info":{"publisher":"MIT Press","year":"2016"}}
{"bib_id":"griffin_worldwide_2005","title":"Worldwide Adoption and Profitability of Precision Agriculture Implications for Brazil","author":"Griffin, T. W. and Lowenberg-DeBoer, J.","meta_info":{"langid":"english","abstract":"Precision agriculture (PA) technology has been on the market for almost 15 years. Global Positioning Systems (GPS), Geographic Information Systems (GIS), yield monitors, variable rate technologies (VRT) and other spatial management technologies are being used by farmers worldwide, but questions remain about the profitability of the technology and its future. This paper summarizes: 1) data on worldwide adoption of PA technology,2) review of PA economics studies and 3) implications for Brazil. Worldwide adoption estimates are based on reports by an international network of collaborators. The PA profitability summary goes beyond previous reviews by including a large number of publications from the last three years, a more detailed breakdown of results by technology type and new technologies. For Brazil, low land prices, low wage rates, focus on commodity crops, and the high cost of imported technology would tend to discourage PA adoption, especially for the classic PA technologies like VRT. The large scale of many Brazilian farms may favor adoption of GPS guidance and use of PA to automate record keeping, employee supervision and quality control. PA adoption may grow rapidly in areas with higher value crops, such as citrus and sugar cane, states with higher land values and regions with a strong agricultural research base. Strong public sector agricultural research organizations will help Brazil develop site-specific PA uses, but the shortage of farm and field level economics in those public sector research organizations may inhibit PA adoption decisions.","urldate":"2022-07-14","issn":"2317-224X","pages":"20--37","number":"4","volume":"14","journal":"Revista de Política Agŗ́ola","year":"2005"}}
{"bib_id":"guo_recognition_2022","title":"Recognition of Areca Leaf Yellow Disease Based on PlanetScope Satellite Imagery","author":"Guo, Jiawei and Jin, Yu and Ye, Huichun and Huang, Wenjiang and Zhao, Jinling and Cui, Bei and Liu, Fucheng and Deng, Jiajian","meta_info":{"keywords":"Agriculture,Deep Learning,Disease detection,Images: Commercial,Labels: Field survey,Model: MLP,Satellite,Used VI","abstract":"Areca yellow leaf disease is a major attacker of the planting and production of arecanut. The continuous expansion of arecanut (Areca catechu L.) planting areas in Hainan has placed a great need to strengthen the monitoring of this disease. At present, there is little research on the monitoring of areca yellow leaf disease. PlanetScope imagery can achieve daily global coverage at a high spatial resolution (3 m) and is thus suitable for the high-precision monitoring of plant pest and disease. In this paper, PlanetScope images were employed to extract spectral features commonly used in disease, pest and vegetation growth monitoring for primary models. In this paper, 13 spectral features commonly used in vegetation growth and pest monitoring were selected to form the initial feature space, followed by the implementation of the Correlation Analysis (CA) and independent t-testing to optimize the feature space. Then, the Random Forest (RF), Backward Propagation Neural Network (BPNN) and AdaBoost algorithms based on feature space optimization to construct double-classification (healthy, diseased) monitoring models for the areca yellow leaf disease. The results indicated that the green, blue and red bands, and plant senescence reflectance index (PSRI) and enhanced vegetation index (EVI) exhibited highly significant differences and strong correlations with healthy and diseased samples. The RF model exhibits the highest overall recognition accuracy for areca yellow leaf disease (88.24%), 2.95% and 20.59% higher than the BPNN and AdaBoost models, respectively. The commission and omission errors were lowest with the RF model for both healthy and diseased samples. This model also exhibited the highest Kappa coefficient at 0.765. Our results exhibit the feasible application of PlanetScope imagery for the regional large-scale monitoring of areca yellow leaf disease, with the RF method identified as the most suitable for this task. Our study provides a reference for the monitoring, a rapid assessment of the area affected and the management planning of the disease in the agricultural and forestry industries.","doi":"10.3390\/agronomy12010014","number":"1","volume":"12","journal":"AGRONOMY-BASEL","month":"January","year":"2022"}}
{"bib_id":"habibi_quantitative_2021","title":"Quantitative Assessment of Soil Salinity Using Remote Sensing Data Based on the Artificial Neural Network, Case Study: Sharif Abad Plain, Central Iran","author":"Habibi, Vahid and Ahmadi, Hasan and Jafari, Mohammad and Moeini, Abolfazl","meta_info":{"keywords":"Agriculture,Deep Learning,Model: MLP,Salinity prediction,Satellite","abstract":"Land salinization is one of the most important factors in reducing the soil quality of agricultural land. Accordingly, these regions affected agricultural production and ecological development. Therefore, it is important to assess soil salinity driving factors. However, it is difficult to characterize soil salinity using single-factor and linear models. This research was carried out for soil digital mapping using remote sensing to classify saline lands and their spatial distribution in SharifAbad plain. The methodology is based on the differentiation of saline soils by combining the Landsat 8 data, fieldwork, and neural network model for prediction of soil salinity. The Latin hypercube method is based on the stratified sampling method. Based on this technique, 63 samples were selected from 0 to 30 cm of the soil surface. In the ANN model, considered 30% of the soil EC as the validation set and the rest (70%) for the testing set. To model soil salinity, auxiliary variables such as Landsat 8 satellite image of 2016 including 2-5 main bands and band 7, topographic auxiliary data includes DEM, TWI, TCI, and spectral parameters were extracted. The result revealed that the GFF algorithm which, according to R-2 and MSE statistics, the best way to prepare a soil salinity map in Sharif Abad plain. The ANN model in most cases satisfies the EC amount less than the real value. We found that the average values of SI5, TCI, and TWI values in the non-saline, the class were lower than the saline class, and the average values of DEM and NDVI indices in the non-saline class were higher than the saline class and showed a statistically significant difference.","doi":"10.1007\/s40808-020-01015-1","issn":"2363-6203","pages":"1373--1383","number":"2","volume":"7","journal":"MODELING EARTH SYSTEMS AND ENVIRONMENT","month":"June","year":"2021"}}
{"bib_id":"haghverdi_prediction_2018","title":"Prediction of Cotton Lint Yield from Phenology of Crop Indices Using Artificial Neural Networks","author":"Haghverdi, Amir and Washington-Allen, Robert A. and Leib, Brian G.","meta_info":{"keywords":"Agriculture,Deep Learning,Extra data: climate,Extra data: geological,Images: Landsat,Labels: Field survey,Model: MLP,Multitemporal,Satellite,Used VI,Yield prediction,Yield: Plot-level","abstract":"A primary utility of satellite remote sensing technology is monitoring and assessment of agricultural lands for determining the area, amount, type, and quality of crop production. Since the mid-1970s agricultural scientists have sought to advance this utility through development of precision agriculture (PA) methods and technologies. Consequently, PA has taken advantage of freely available medium-spatial resolution remote sensing technology and instrumented fields to monitor crop biomass, phenology, and yield of crops at the sub-field to larger scales. The main goal of this study was to determine cotton lint yield in a 73-ha irrigated field in western Tennessee using remote sensing technology. We used two growing seasons (2013 and 2014) of Landsat 8 transformed to 8 input predictors including Red, near infra-red (NIR), the simple ratio (SR), normalized difference vegetation index (NDVI), green NDVI (GNDVI), and the tasselled cap transformation's greenness, wetness, and soil brightness indices: GI, WI, and SBI, respectively, as proxies for cotton lint yield and crop phenology (in this study all input predictors are being referred to as crop indices, CIs). We used artificial neural network (ANN) approach to generate 61,200 models relating individual CIs and CI phenology to field estimates of lint yield to predict and map the field's cotton lint yield in two cropping seasons. The correlation between cotton lint yield and CIs ranged from -0.20 to 0.60 in 2013 and from -0.79 to 0.84 in 2014. The best ANN models were in 2013 (r = 0.68 and the normalized MAE = 11%) and 2014 (r = 0.86 and the normalized MAE = 8%) growing seasons. The WI and GI were the best CI predictors of cotton lint yield, and overall for the early to mid-season prediction, CI phenologies had better performance than single date CI models. Consequently, we recommend the use of Landsat 8 derived WI or GI phenology to predict crop yields.","doi":"10.1016\/j.compag.2018.07.021","issn":"0168-1699","pages":"186--197","volume":"152","journal":"COMPUTERS AND ELECTRONICS IN AGRICULTURE","month":"September","year":"2018"}}
{"bib_id":"hamer_replacing_2021","title":"Replacing Human Interpretation of Agricultural Land in Afghanistan with a Deep Convolutional Neural Network","author":"Hamer, A. M. and Simms, D. M. and Waine, T. W.","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: DMC,Labels: Model-assisted survey,Model: ResNet,Satellite","abstract":"Afghanistan's annual opium survey relies upon time-consuming human interpretation of satellite images to map the area of potential poppy cultivation for statistical sample design. Deep Convolutional Neural Networks (CNNs) have shown ground-breaking performance for image classification tasks by encoding local contextual information, in some cases outperforming trained analysts. In this study, we investigate the development of a CNN to automate the classification of agriculture from medium-resolution satellite imagery as an alternative to manual interpretation. The residual network (ResNet50) CNN architecture was trained and validated for delineating the agricultural area using labelled multi-seasonal Disaster Monitoring Constellation (DMC) satellite imagery (32 m) of Helmand and Kandahar provinces. The effect of input image chip size, training sampling strategy, elevation data, and multi-seasonal imagery were investigated. The best-performing single-year classification used an input chip size of 33 x 33 pixels, a targeted sampling strategy and transfer learning, resulting in high overall accuracy (94%). The inclusion of elevation data marginally lowered performance (93%). Multi-seasonal classification achieved an overall accuracy of 89% using the previous two years' data. Only 25% of the target year's training samples were necessary to update the model to achieve $>$94% overall accuracy. A data-driven approach to automate agricultural mask production using CNNs is proposed to reduce the burden of human interpretation. The ability to continually update CNN models with new data has the potential to significantly improve automatic classification of vegetation across years.","doi":"10.1080\/01431161.2020.1864059","issn":"0143-1161","pages":"3017--3038","number":"8","volume":"42","journal":"INTERNATIONAL JOURNAL OF REMOTE SENSING","month":"April","year":"2021"}}
{"bib_id":"he_identity_2016","title":"Identity Mappings in Deep Residual Networks","author":"He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian","meta_info":{"file":"\/home\/brandon\/Zotero\/storage\/AG3FHPXA\/He et al. - 2016 - Identity Mappings in Deep Residual Networks.pdf","langid":"english","isbn":"978-3-319-46493-0","abstract":"Deep residual networks have emerged as a family of extremely deep architectures showing compelling accuracy and nice convergence behaviors. In this paper, we analyze the propagation formulations behind the residual building blocks, which suggest that the forward and backward signals can be directly propagated from one block to any other block, when using identity mappings as the skip connections and after-addition activation. A series of ablation experiments support the importance of these identity mappings. This motivates us to propose a new residual unit, which makes training easier and improves generalization. We report improved results using a 1001-layer ResNet on CIFAR-10 (4.62 % error) and CIFAR-100, and a 200-layer ResNet on ImageNet. Code is available at: https:\/\/github.com\/KaimingHe\/resnet-1k-layers.","doi":"10.1007\/978-3-319-46493-0_38","address":"Cham","publisher":"Springer International Publishing","pages":"630--645","series":"Lecture Notes in Computer Science","year":"2016","editor":"Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max","booktitle":"Computer Vision - ECCV 2016"}}
{"bib_id":"herold_evolving_2006","title":"Evolving Standards in Land Cover Characterization","author":"Herold, M. and Latham, J. S. and Di Gregorio, A. and Schmullius, C. C.","meta_info":{"abstract":"Reliable observations of the terrestrial environment are of crucial importance to understanding climate change and its impacts, to sustainable economic development, natural resources management, conservation, biodiversity and a scientific understanding of ecosystems and biogeochemical cycling. GOFC-GOLD (Global Observations of Forest Cover and Land Dynamics) as panel of GTOS (Global Terrestrial Observing System) and the Global Land Cover Network of FAO-UNEP (GLCN) brings together key participants and stake-holders involved in global land cover observations. The objective is to provide a platform for cooperation and communication on current and planned activities including developments on the political programs, international strategic frameworks as well as related implementation initiatives. Harmonization and validation of land cover datasets are central implementation issues.","urldate":"2022-07-12","doi":"10.1080\/17474230601079316","issn":"1747-423X","publisher":"Taylor & Francis","pages":"157--168","number":"2-4","volume":"1","journal":"Journal of Land Use Science","month":"December","year":"2006"}}
{"bib_id":"hinton_improving_2012","title":"Improving Neural Networks by Preventing Co-Adaptation of Feature Detectors","author":"Hinton, Geoffrey E. and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R.","meta_info":{"archiveprefix":"arxiv","abstract":"When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This \"overfitting\" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random \"dropout\" gives big improvements on many benchmark tasks and sets new records for speech and object recognition.","urldate":"2022-07-25","doi":"10.48550\/arXiv.1207.0580","publisher":"arXiv","primaryclass":"cs","eprint":"1207.0580","number":"arXiv:1207.0580","month":"July","year":"2012"}}
{"bib_id":"houghton_carbon_2012","title":"Carbon Emissions from Land Use and Land-Cover Change","author":"Houghton, R. A. and House, J. I. and Pongratz, J. and van der Werf, G. R. and DeFries, R. S. and Hansen, M. C. and Le Quéré, C. and Ramankutty, N.","meta_info":{"langid":"english","abstract":"The net flux of carbon from land use and land-cover change (LULCC) accounted for 12.5% of anthropogenic carbon emissions from 1990 to 2010. This net flux is the most uncertain term in the global carbon budget, not only because of uncertainties in rates of deforestation and forestation, but also because of uncertainties in the carbon density of the lands actually undergoing change. Furthermore, there are differences in approaches used to determine the flux that introduce variability into estimates in ways that are difficult to evaluate, and not all analyses consider the same types of management activities. Thirteen recent estimates of net carbon emissions from LULCC are summarized here. In addition to deforestation, all analyses considered changes in the area of agricultural lands (croplands and pastures). Some considered, also, forest management (wood harvest, shifting cultivation). None included emissions from the degradation of tropical peatlands. Means and standard deviations across the thirteen model estimates of annual emissions for the 1980s and 1990s, respectively, are 1.14 \\textpm 0.23 and 1.12 \\textpm 0.25 Pg C yr\\textsuperscript-1 (1 Pg = 10\\textsuperscript15 g carbon). Four studies also considered the period 2000--2009, and the mean and standard deviations across these four for the three decades are 1.14 \\textpm 0.39, 1.17 \\textpm 0.32, and 1.10 \\textpm 0.11 Pg C yr\\textsuperscript-1. For the period 1990--2009 the mean global emissions from LULCC are 1.14 \\textpm 0.18 Pg C yr\\textsuperscript-1. The standard deviations across model means shown here are smaller than previous estimates of uncertainty as they do not account for the errors that result from data uncertainty and from an incomplete understanding of all the processes affecting the net flux of carbon from LULCC. Although these errors have not been systematically evaluated, based on partial analyses available in the literature and expert opinion, they are estimated to be on the order of \\textpm 0.5 Pg C yr\\textsuperscript-1","urldate":"2022-07-12","doi":"10.5194\/bg-9-5125-2012","issn":"1726-4170","publisher":"Copernicus GmbH","pages":"5125--5142","number":"12","volume":"9","journal":"Biogeosciences","month":"December","year":"2012"}}
{"bib_id":"hunter_agriculture_2017","title":"Agriculture in 2050: Recalibrating Targets for Sustainable Intensification","author":"Hunter, Mitchell C. and Smith, Richard G. and Schipanski, Meagan E. and Atwood, Lesley W. and Mortensen, David A.","meta_info":{"file":"\/home\/brandon\/Zotero\/storage\/Q3C2IL5M\/Hunter et al. - 2017 - Agriculture in 2050 Recalibrating Targets for Sus.pdf;\/home\/brandon\/Zotero\/storage\/LT3YAXHZ\/3016049.html","abstract":"The prevailing discourse on the future of agriculture is dominated by an imbalanced narrative that calls for food production to increase dramatically---potentially doubling by 2050---without specifying commensurate environmental goals. We aim to rebalance this narrative by laying out quantitative and compelling midcentury targets for both production and the environment. Our analysis shows that an increase of approximately 25%--70% above current production levels may be sufficient to meet 2050 crop demand. At the same time, nutrient losses and greenhouse gas emissions from agriculture must drop dramatically to restore and maintain ecosystem functioning. Specifying quantitative targets will clarify the scope of the challenges that agriculture must face in the coming decades, focus research and policy on achieving specific outcomes, and ensure that sustainable intensification efforts lead to measurable environmental improvements. We propose new directions for research and policy to help meet both sustainability and production goals.","urldate":"2022-07-13","doi":"10.1093\/biosci\/bix010","issn":"0006-3568","pages":"386--391","number":"4","volume":"67","journal":"BioScience","month":"April","year":"2017","shorttitle":"Agriculture in 2050"}}
{"bib_id":"igder_multivariate_2022","title":"Multivariate Assimilation of Satellite-Based Leaf Area Index and Ground-Based River Streamflow for Hydrological Modelling of Irrigated Watersheds Using SWAT","author":"Igder, Omid Mohammadi and Alizadeh, Hosein and Mojaradi, Barat and Bayat, Mehrad","meta_info":{"keywords":"Agriculture,Canopy cover prediction,Deep Learning,Images: Sentinel,Labels: Model-based,Model: MLP,Satellite","unique-id":"WOS:000811888100008","eissn":"1879-2707","article-number":"128012","doi":"10.1016\/j.jhydrol.2022.128012","issn":"0022-1694","volume":"610","journal":"JOURNAL OF HYDROLOGY","month":"July","year":"2022"}}
{"bib_id":"inglada_assessment_2015","title":"Assessment of an Operational System for Crop Type Map Production Using High Temporal and Spatial Resolution Satellite Optical Imagery","author":"Inglada, Jordi and Arias, Marcela and Tardy, Benjamin and Hagolle, Olivier and Valero, Silvia and Morin, David and Dedieu, Gérard and Sepulcre, Guadalupe and Bontemps, Sophie and Defourny, Pierre and Koetz, Benjamin","meta_info":{"langid":"english","copyright":"http:\/\/creativecommons.org\/licenses\/by\/3.0\/","abstract":"Crop area extent estimates and crop type maps provide crucial information for agricultural monitoring and management. Remote sensing imagery in general and, more specifically, high temporal and high spatial resolution data as the ones which will be available with upcoming systems, such as Sentinel-2, constitute a major asset for this kind of application. The goal of this paper is to assess to what extent state-of-the-art supervised classification methods can be applied to high resolution multi-temporal optical imagery to produce accurate crop type maps at the global scale. Five concurrent strategies for automatic crop type map production have been selected and benchmarked using SPOT4 (Take5) and Landsat 8 data over 12 test sites spread all over the globe (four in Europe, four in Africa, two in America and two in Asia). This variety of tests sites allows one to draw conclusions applicable to a wide variety of landscapes and crop systems. The results show that a random forest classifier operating on linearly temporally gap-filled images can achieve overall accuracies above 80% for most sites. Only two sites showed low performances: Madagascar due to the presence of fields smaller than the pixel size and Burkina Faso due to a mix of trees and crops in the fields. The approach is based on supervised machine learning techniques, which need in situ data collection for the training step, but the map production is fully automatic.","urldate":"2022-07-25","doi":"10.3390\/rs70912356","issn":"2072-4292","publisher":"Multidisciplinary Digital Publishing Institute","pages":"12356--12379","number":"9","volume":"7","journal":"Remote Sensing","month":"September","year":"2015"}}
{"bib_id":"interdonato_duplo_2019","title":"DuPLO: A DUal View Point Deep Learning Architecture for Time Series classificatiOn","author":"Interdonato, Roberto and Ienco, Dino and Gaetano, Raffaele and Ose, Kenji","meta_info":{"keywords":"Agriculture,Best Model: ItsComplicated,Crop segmentation,Dataset: Reunion Island,Deep Learning,Images: Sentinel,Labels: Dataset,Model comparison,Model: 2DCNN,Model: ConvLSTM,Model: GRU,Model: LSTM,Model: RF,Satellite,Used VI","abstract":"Nowadays, modem Earth Observation systems continuously generate huge amounts of data. A notable example is represented by the Sentinel-2 mission, which provides images at high spatial resolution (up to 10 m) with high temporal revisit period (every 5 days), which can be organized in Satellite Image Time Series (SITS). While the use of SITS has been proved to be beneficial in the context of Land Use\/Land Cover (LULC) map generation, unfortunately, most of machine learning approaches commonly leveraged in remote sensing field fail to take advantage of spatio-temporal dependencies present in such data. Recently, new generation deep learning methods allowed to significantly advance research in this field. These approaches have generally focused on a single type of neural network, i.e., Convolutional Neural Networks (CNNs) or Recurrent Neural Networks (RNNs), which model different but complementary information: spatial autocorrelation (CNNs) and temporal dependencies (RNNs). In this work, we propose the first deep learning architecture for the analysis of SITS data, namely DuPLO (DUal view Point deep Learning architecture for time series classificatiOn), that combines Convolutional and Recurrent neural networks to exploit their complementarity. Our hypothesis is that, since CNNs and RNNs capture different aspects of the data, a combination of both models would produce a more diverse and complete representation of the information for the underlying land cover classification task. Experiments carried out on two study sites characterized by different land cover characteristics (i.e., the Gard site in Mainland France and Reunion Island, a overseas department of France in the Indian Ocean), demonstrate the significance of our proposal.","doi":"10.1016\/j.isprsjprs.2019.01.011","issn":"0924-2716","pages":"91--104","volume":"149","journal":"ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING","month":"March","year":"2019"}}
{"bib_id":"ioffe_batch_2015","title":"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift","author":"Ioffe, Sergey and Szegedy, Christian","meta_info":{"langid":"english","abstract":"Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a stateof-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters.","urldate":"2022-07-21","issn":"1938-7228","publisher":"PMLR","pages":"448--456","month":"June","year":"2015","booktitle":"Proceedings of the 32nd International Conference on Machine Learning","shorttitle":"Batch Normalization"}}
{"bib_id":"jacquemoud_prospectsail_2009","title":"PROSPECT+SAIL Models: A Review of Use for Vegetation Characterization","author":"Jacquemoud, Stéphane and Verhoef, Wout and Baret, Frédéric and Bacour, Cédric and Zarco-Tejada, Pablo J. and Asner, Gregory P. and François, Christophe and Ustin, Susan L.","meta_info":{"keywords":"Canopy spectral and directional reflectance,PROSAIL,PROSPECT,Radiative transfer models,SAIL,Vegetation","langid":"english","abstract":"The combined PROSPECT leaf optical properties model and SAIL canopy bidirectional reflectance model, also referred to as PROSAIL, has been used for about sixteen years to study plant canopy spectral and directional reflectance in the solar domain. PROSAIL has also been used to develop new methods for retrieval of vegetation biophysical properties. It links the spectral variation of canopy reflectance, which is mainly related to leaf biochemical contents, with its directional variation, which is primarily related to canopy architecture and soil\/vegetation contrast. This link is key to simultaneous estimation of canopy biophysical\/structural variables for applications in agriculture, plant physiology, or ecology, at different scales. PROSAIL has become one of the most popular radiative transfer tools due to its ease of use, general robustness, and consistent validation by lab\/field\/space experiments over the years. However, PROSPECT and SAIL are still evolving: they have undergone recent improvements both at the leaf and the plant levels. This paper provides an extensive review of the PROSAIL developments in the context of canopy biophysics and radiative transfer modeling.","urldate":"2022-04-14","doi":"10.1016\/j.rse.2008.01.026","issn":"0034-4257","pages":"S56-S66","volume":"113","series":"Imaging Spectroscopy Special Issue","journal":"Remote Sensing of Environment","month":"September","year":"2009","shorttitle":"PROSPECT+SAIL Models"}}
{"bib_id":"jeong_predicting_2022","title":"Predicting Rice Yield at Pixel Scale through Synthetic Use of Crop and Deep Learning Models with Satellite Data in South and North Korea","author":"Jeong, Seungtaek and Ko, Jonghan and Yeom, Jong-Min","meta_info":{"keywords":"Agriculture,Deep Learning,Images: MODIS,Labels: Model-based,Model: 1DCNN,Model: LSTM,Satellite,Used VI,Yield prediction,Yield: Pixel-level","abstract":"Prediction of rice yields at pixel scale rather than county scale can benefit crop management and scientific understanding because it is useful for monitoring how crop yields respond to various agricultural systems and environmental factors. In this study, we propose a methodology for the early prediction of rice yield at pixel scale combining a crop model and a deep learning model for different agricultural systems throughout South and North Korea. Initially, satellite-integrated crop models were applied to obtain a pixel-scale reference rice yield. Then, the pixel-scale reference rice yields were used as target labels in the deep learning model to leverage the advantages of crop models. Models of five different deep learning network architectures were employed to help determine the hybrid structure of long-short term memory (LSTM) and one-dimensional convolutional neural network (1D-CNN) layers by predicting the optimal model about two months ahead of harvest time. The suggested model showed good performance [R-2 = 0.859, Nash-Sutcliffe model efficiency = 0.858, root mean squared error = 0.605 Mg ha(-1)], with specific spatial patterns of rice yields for South and North Korea. Analysis of the relative importance of the input variables showed the water-related index and maximum temperature in North Korea and the vegetation indices and geographic variables in South Korea to be crucial for predicting rice yields. The proposed approach successfully predicted and diagnosed rice yield at the pixel scale for inaccessible locations where reliable ground measurements are not available, especially North Korea. (C) 2021 The Authors. Published by Elsevier B.V.","doi":"10.1016\/j.scitotenv.2021.149726","issn":"0048-9697","volume":"802","journal":"SCIENCE OF THE TOTAL ENVIRONMENT","month":"January","year":"2022"}}
{"bib_id":"ji_3d_2018","title":"3D Convolutional Neural Networks for Crop Classification with Multi-Temporal Remote Sensing Images","author":"Ji, Shunping and Zhang, Chi and Xu, Anjian and Shi, Yun and Duan, Yulin","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Commercial,Images: GF2,Model: VGG,Multitemporal,Satellite","abstract":"This study describes a novel three-dimensional (3D) convolutional neural networks (CNN) based method that automatically classifies crops from spatio-temporal remote sensing images. First, 3D kernel is designed according to the structure of multi-spectral multi-temporal remote sensing data. Secondly, the 3D CNN framework with fine-tuned parameters is designed for training 3D crop samples and learning spatio-temporal discriminative representations, with the full crop growth cycles being preserved. In addition, we introduce an active learning strategy to the CNN model to improve labelling accuracy up to a required threshold with the most efficiency. Finally, experiments are carried out to test the advantage of the 3D CNN, in comparison to the two-dimensional (2D) CNN and other conventional methods. Our experiments show that the 3D CNN is especially suitable in characterizing the dynamics of crop growth and outperformed the other mainstream methods.","doi":"10.3390\/rs10010075","number":"1","volume":"10","journal":"REMOTE SENSING","month":"January","year":"2018"}}
{"bib_id":"ji_prediction_2022","title":"Prediction of Corn Yield in the USA Corn Belt Using Satellite Data and Machine Learning: From an Evapotranspiration Perspective","author":"Ji, Zhonglin and Pan, Yaozhong and Zhu, Xiufang and Zhang, Dujuan and Dai, Jiajia","meta_info":{"keywords":"Agriculture,Deep Learning,Images: MODIS,Labels: Public government data,Model: LSTM,Satellite,Yield prediction,Yield: County-level","unique-id":"WOS:000846363800001","eissn":"2077-0472","article-number":"1263","doi":"10.3390\/agriculture12081263","number":"8","volume":"12","journal":"AGRICULTURE-BASEL","month":"August","year":"2022"}}
{"bib_id":"jiang_crop_2022","title":"Crop Mapping Using the Historical Crop Data Layer and Deep Neural Networks: A Case Study in Jilin Province, China","author":"Jiang, Deyang and Chen, Shengbo and Useya, Juliana and Cao, Lisai and Lu, Tianqi","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Sentinel,Labels: CDL,Labels: Field survey,Labels: Model-based,Model: RF,Model: SVM,Model: Tree,Satellite","unique-id":"WOS:000839798500001","orcid-numbers":"Lu, Tianqi\/0000-0002-7807-3942","eissn":"1424-8220","article-number":"5853","doi":"10.3390\/s22155853","number":"15","volume":"22","journal":"SENSORS","month":"August","year":"2022"}}
{"bib_id":"jin_extraction_2021","title":"Extraction of Arecanut Planting Distribution Based on the Feature Space Optimization of PlanetScope Imagery","author":"Jin, Yu and Guo, Jiawei and Ye, Huichun and Zhao, Jinling and Huang, Wenjiang and Cui, Bei","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: PlanetScope,Labels: Field survey,Model comparison,Model: MLP,Model: RF,Model: SVM,Satellite,Used VI","abstract":"The remote sensing extraction of large areas of arecanut (Areca catechu L.) planting plays an important role in investigating the distribution of arecanut planting area and the subsequent adjustment and optimization of regional planting structures. Satellite imagery has previously been used to investigate and monitor the agricultural and forestry vegetation in Hainan. However, the monitoring accuracy is affected by the cloudy and rainy climate of this region, as well as the high level of land fragmentation. In this paper, we used PlanetScope imagery at a 3 m spatial resolution over the Hainan arecanut planting area to investigate the high-precision extraction of the arecanut planting distribution based on feature space optimization. First, spectral and textural feature variables were selected to form the initial feature space, followed by the implementation of the random forest algorithm to optimize the feature space. Arecanut planting area extraction models based on the support vector machine (SVM), BP neural network (BPNN), and random forest (RF) classification algorithms were then constructed. The overall classification accuracies of the SVM, BPNN, and RF models optimized by the RF features were determined as 74.82%, 83.67%, and 88.30%, with Kappa coefficients of 0.680, 0.795, and 0.853, respectively. The RF model with optimized features exhibited the highest overall classification accuracy and kappa coefficient. The overall accuracy of the SVM, BPNN, and RF models following feature optimization was improved by 3.90%, 7.77%, and 7.45%, respectively, compared with the corresponding unoptimized classification model. The kappa coefficient also improved. The results demonstrate the ability of PlanetScope satellite imagery to extract the planting distribution of arecanut. Furthermore, the RF is proven to effectively optimize the initial feature space, composed of spectral and textural feature variables, further improving the extraction accuracy of the arecanut planting distribution. This work can act as a theoretical and technical reference for the agricultural and forestry industries.","doi":"10.3390\/agriculture11040371","number":"4","volume":"11","journal":"AGRICULTURE-BASEL","month":"April","year":"2021"}}
{"bib_id":"jong_improving_2022","title":"Improving Field Boundary Delineation in ResUNets via Adversarial Deep Learning","author":"Jong, Maxwell and Guan, Kaiyu and Wang, Sibo and Huang, Yizhi and Peng, Bin","meta_info":{"keywords":"Agriculture,Deep Learning,Field boundary detection,Images: Landsat,Images: MODIS,Images: Sentinel,Labels: Image survey,Labels: Public government data,Model: 2DCNN,Satellite","unique-id":"WOS:000844312300002","eissn":"1872-826X","article-number":"102877","doi":"10.1016\/j.jag.2022.102877","issn":"1569-8432","volume":"112","journal":"INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION","month":"August","year":"2022"}}
{"bib_id":"ju_optimal_2021","title":"Optimal County-Level Crop Yield Prediction Using MODIS-based Variables and Weather Data: A Comparative Study on Machine Learning Models","author":"Ju, Sungha and Lim, Hyoungjoon and Ma, Jong Won and Kim, Soohyun and Lee, Kyungdo and Zhao, Shuhe and Heo, Joon","meta_info":{"keywords":"Agriculture,Best Model: SVM,Deep Learning,Extra data: climate,Images: MODIS,Labels: Public government data,Model comparison,Model: CNN,Model: LSTM,Model: MLP,Model: RF,Model: SVM,Satellite,Used VI,Yield prediction,Yield: County-level","abstract":"Accurate crop yield prediction for more precise forecasting of price volatility in crop markets, better agricultural planning and enhanced national food security is one of the important utilities of crop monitoring systems. Due to the spatiotemporal nonlinear characteristic of crop yields, recent studies have actively used various machine learning approaches to predict crop yields. However, there are few studies that have compared these approaches, and even in those cases, the comparison was restricted to one or two crops or a specific region. In this study, we evaluated seven popular machine learning approaches, for the same input variables, over three crops: paddy rice in South Korea and corn and soybean in Illinois and Iowa, USA. Based on the data from April to September, six time-series scenarios of different range of months for each crop were tested for prediction accuracy with 14-year (2003-2016). The time-series data include vegetation indices from Moderate resolution imaging spectroradiometer (MODIS), weather data, crop yield statistics, and a land cover map of county-level spatial resolution and 16-day-aggregated temporal resolution. In the results, regardless of crop type, support vector machine (SVM) presented the most accurate result with the lowest average root mean square error (RRMSE), in comparison with a decision tree (DT), random forest (RF), artificial neural network (ANN), stacked-sparse autoencoder (SSAE), convolutional neural network (CNN), and long short-term memory (LSTM). Also, we derived best cases for each crop yield prediction out of six time-series scenarios, which were May - September data for rice and corn and June - August data for soybean for the test sites. Considering all of the findings together, SVM is an appropriate method for crop yield prediction based on MODIS-based vegetation indices and weather data of county-level spatial resolution and approximately one-half-month temporal resolution.","doi":"10.1016\/j.agrformet.2021.108530","issn":"0168-1923","volume":"307","journal":"AGRICULTURAL AND FOREST METEOROLOGY","month":"September","year":"2021"}}
{"bib_id":"kang_comparative_2020","title":"Comparative Assessment of Environmental Variables and Machine Learning Algorithms for Maize Yield Prediction in the US Midwest","author":"Kang, Yanghui and Ozdogan, Mutlu and Zhu, Xiaojin and Ye, Zhiwei and Hain, Christopher and Anderson, Martha","meta_info":{"keywords":"Agriculture,Best Model: LSTM,Deep Learning,Extra data: climate,Extra data: soil,Images: MODIS,Labels: Public government data,Model comparison,Model: CNN,Model: LSTM,Model: RF,Model: XGB,Satellite,Used VI,Yield prediction,Yield: County-level","abstract":"Crop yield estimates over large areas are conventionally made using weather observations, but a comprehensive understanding of the effects of various environmental indicators, observation frequency, and the choice of prediction algorithm remains elusive. Here we present a thorough assessment of county-level maize yield prediction in U.S. Midwest using six statistical\/machine learning algorithms (Lasso, Support Vector Regressor, Random Forest, XGBoost, Long-short term memory (LSTM), and Convolutional Neural Network (CNN)) and an extensive set of environmental variables derived from satellite observations, weather data, land surface model results, soil maps, and crop progress reports. Results show that seasonal crop yield forecasting benefits from both more advanced algorithms and a large composite of information associated with crop canopy, environmental stress, phenology, and soil properties (i.e. hundreds of features). The XGBoost algorithm outperforms other algorithms both in accuracy and stability, while deep neural networks such as LSTM and CNN are not advantageous. The compositing interval (8-day, 16-day or monthly) of time series variable does not have significant effects on the prediction. Combining the best algorithm and inputs improves the prediction accuracy by 5% when compared to a baseline statistical model (Lasso) using only basic climatic and satellite observations. Reasonable county-level yield foresting is achievable from early June, almost four months prior to harvest. At the national level, early-season (June and July) prediction from the best model outperforms that of the United States Department of Agriculture (USDA) World Agricultural Supply and Demand Estimates (WASDE). This study provides insights into practical crop yield forecasting and the understanding of yield response to climatic and environmental conditions.","doi":"10.1088\/1748-9326\/ab7df9","issn":"1748-9326","number":"6","volume":"15","journal":"ENVIRONMENTAL RESEARCH LETTERS","month":"June","year":"2020"}}
{"bib_id":"karkee_quantifying_2009","title":"Quantifying Sub-Pixel Signature of Paddy Rice Field Using an Artificial Neural Network","author":"Karkee, Manoj and Steward, Brian L. and Tang, Lie and Aziz, Sarnsuzana A.","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: MODIS,Labels: Model-based,Model: MLP,Satellite,Used VI","abstract":"Remote sensing (RS) can be used for regional and global scale monitoring of crop development, crop health, and cropping practices and also for water resources planning and designing. Lower spatial resolution, such as 1 km. MODIS imagery, for example, is useful for national, regional and global scale studies, but sub-pixel mixing of different landuses may occur. In the case of rice production, one pixel of such resolution may include land area with rice grown under different cropping practices such as one, two and three crops per year rice. A method was developed for quantifying sub-pixel landuses of individual rice types using an artificial neural network (ANN). Temporal patterns of normalized differential vegetation index (NDVI) depend on and result from the complex relationship between NDVI and cropping practice parameters associated with a pixel. In the case of a rice field, these parameters consist of the area fractions of different types of rice and their emergence dates. An ANN was used as a model inverter to estimate these parameters. The data for this research were produced numerically using the soil-water-atmosphere-plant (SWAP) crop growth model. Crop area fractions within a pixel were predicted with an RMSE of 1.3% and an average estimated emergence date error of 4 days. A representative experiment conducted using a 2.4 GHz Pentium processor based desktop computer took about 1.22 mu s per pixel, which was substantially faster than the genetic algorithm based approach of Ines and Honda [Ines, A.V.M., Honda, K., 2005. On quantifying agricultural and water management practices from low spatial resolution RS data using genetic algorithms: a numerical study for mixed-pixel environment. Advances in Water Resources 28 (8), 856-870]. The ANN based approach was computationally, very efficient and thus practical to apply to satellite imagery consisting of millions of pixels. (C) 2008 Elsevier B.V. All rights reserved.","doi":"10.1016\/j.compag.2008.07.009","issn":"0168-1699","pages":"65--76","number":"1","volume":"65","journal":"COMPUTERS AND ELECTRONICS IN AGRICULTURE","month":"January","year":"2009"}}
{"bib_id":"kattenborn_review_2021","title":"Review on Convolutional Neural Networks (CNN) in Vegetation Remote Sensing","author":"Kattenborn, Teja and Leitloff, Jens and Schiefer, Felix and Hinz, Stefan","meta_info":{"keywords":"Convolutional Neural Networks (CNN),Deep learning,Earth observation,Plants,Remote sensing,Vegetation","langid":"english","abstract":"Identifying and characterizing vascular plants in time and space is required in various disciplines, e.g. in forestry, conservation and agriculture. Remote sensing emerged as a key technology revealing both spatial and temporal vegetation patterns. Harnessing the ever growing streams of remote sensing data for the increasing demands on vegetation assessments and monitoring requires efficient, accurate and flexible methods for data analysis. In this respect, the use of deep learning methods is trend-setting, enabling high predictive accuracy, while learning the relevant data features independently in an end-to-end fashion. Very recently, a series of studies have demonstrated that the deep learning method of Convolutional Neural Networks (CNN) is very effective to represent spatial patterns enabling to extract a wide array of vegetation properties from remote sensing imagery. This review introduces the principles of CNN and distils why they are particularly suitable for vegetation remote sensing. The main part synthesizes current trends and developments, including considerations about spectral resolution, spatial grain, different sensors types, modes of reference data generation, sources of existing reference data, as well as CNN approaches and architectures. The literature review showed that CNN can be applied to various problems, including the detection of individual plants or the pixel-wise segmentation of vegetation classes, while numerous studies have evinced that CNN outperform shallow machine learning methods. Several studies suggest that the ability of CNN to exploit spatial patterns particularly facilitates the value of very high spatial resolution data. The modularity in the common deep learning frameworks allows a high flexibility for the adaptation of architectures, whereby especially multi-modal or multi-temporal applications can benefit. An increasing availability of techniques for visualizing features learned by CNNs will not only contribute to interpret but to learn from such models and improve our understanding of remotely sensed signals of vegetation. Although CNN has not been around for long, it seems obvious that they will usher in a new era of vegetation remote sensing.","urldate":"2022-04-05","doi":"10.1016\/j.isprsjprs.2020.12.010","issn":"0924-2716","pages":"24--49","volume":"173","journal":"ISPRS Journal of Photogrammetry and Remote Sensing","month":"March","year":"2021"}}
{"bib_id":"kerr_smos_2012","title":"The SMOS Soil Moisture Retrieval Algorithm","author":"Kerr, Yann H. and Waldteufel, Philippe and Richaume, Philippe and Wigneron, Jean Pierre and Ferrazzoli, Paolo and Mahmoodi, Ali and Al Bitar, Ahmad and Cabot, François and Gruhier, Claire and Juglea, Silvia Enache and Leroux, Delphine and Mialon, Arnaud and Delwart, Steven","meta_info":{"file":"\/home\/brandon\/Zotero\/storage\/BIY2JY62\/Kerr et al. - 2012 - The SMOS Soil Moisture Retrieval Algorithm.pdf;\/home\/brandon\/Zotero\/storage\/TGZW96DS\/6161633.html","abstract":"The Soil Moisture and Ocean Salinity (SMOS) mission is European Space Agency (ESA's) second Earth Explorer Opportunity mission, launched in November 2009. It is a joint program between ESA Centre National d'Etudes Spatiales (CNES) and Centro para el Desarrollo Tecnologico Industrial. SMOS carries a single payload, an L-Band 2-D interferometric radiometer in the 1400-1427 MHz protected band. This wavelength penetrates well through the atmosphere, and hence the instrument probes the earth surface emissivity. Surface emissivity can then be related to the moisture content in the first few centimeters of soil, and, after some surface roughness and temperature corrections, to the sea surface salinity over ocean. The goal of the level 2 algorithm is thus to deliver global soil moisture (SM) maps with a desired accuracy of 0.04 m3\/m3. To reach this goal, a retrieval algorithm was developed and implemented in the ground segment which processes level 1 to level 2 data. Level 1 consists mainly of angular brightness temperatures (TB), while level 2 consists of geophysical products in swath mode, i.e., as acquired by the sensor during a half orbit from pole to pole. In this context, a group of institutes prepared the SMOS algorithm theoretical basis documents to be used to produce the operational algorithm. The principle of the SM retrieval algorithm is based on an iterative approach which aims at minimizing a cost function. The main component of the cost function is given by the sum of the squared weighted differences between measured and modeled TB data, for a variety of incidence angles. The algorithm finds the best set of the parameters, e.g., SM and vegetation characteristics, which drive the direct TB model and minimizes the cost function. The end user Level 2 SM product contains SM, vegetation opacity, and estimated dielectric constant of any surface, TB computed at 42.5$^∘$, flags and quality indices, and other parameters of interest. This paper gives an overview of the algorithm, discusses the caveats, and provides a glimpse of the Cal Val exercises.","doi":"10.1109\/TGRS.2012.2184548","issn":"1558-0644","pages":"1384--1403","number":"5","volume":"50","journal":"IEEE Transactions on Geoscience and Remote Sensing","month":"May","year":"2012"}}
{"bib_id":"khaki_simultaneous_2021","title":"Simultaneous Corn and Soybean Yield Prediction from Remote Sensing Data Using Deep Transfer Learning","author":"Khaki, Saeed and Pham, Hieu and Wang, Lizhi","meta_info":{"keywords":"Agriculture,Best Model: CNN,Deep Learning,Images: MODIS,Model comparison,Model: 3DCNN,Model: CNN,Model: MLP,Model: RF,Satellite,Yield prediction,Yield: County-level","abstract":"Large-scale crop yield estimation is, in part, made possible due to the availability of remote sensing data allowing for the continuous monitoring of crops throughout their growth cycle. Having this information allows stakeholders the ability to make real-time decisions to maximize yield potential. Although various models exist that predict yield from remote sensing data, there currently does not exist an approach that can estimate yield for multiple crops simultaneously, and thus leads to more accurate predictions. A model that predicts the yield of multiple crops and concurrently considers the interaction between multiple crop yields. We propose a new convolutional neural network model called YieldNet which utilizes a novel deep learning framework that uses transfer learning between corn and soybean yield predictions by sharing the weights of the backbone feature extractor. Additionally, to consider the multi-target response variable, we propose a new loss function. We conduct our experiment using data from 1132 counties for corn and 1076 counties for soybean across the United States. Numerical results demonstrate that our proposed method accurately predicts corn and soybean yield from one to four months before the harvest with an MAE being 8.74% and 8.70% of the average yield, respectively, and is competitive to other state-of-the-art approaches.","doi":"10.1038\/s41598-021-89779-z","issn":"2045-2322","number":"1","volume":"11","journal":"SCIENTIFIC REPORTS","month":"May","year":"2021"}}
{"bib_id":"khan_artificial_2020","title":"An Artificial Neural Network Model for Estimating Mentha Crop Biomass Yield Using Landsat 8 OLI","author":"Khan, Mohammad Saleem and Semwal, Manoj and Sharma, Ashok and Verma, Rajesh Kumar","meta_info":{"keywords":"Agriculture,Deep Learning,Images: Landsat,Labels: Field survey,Model: MLP,Satellite,Used VI,Yield prediction,Yield: Field-level","abstract":"Yield forecasting is essential for management of the food and agriculture economic growth of a country. Artificial Neural Network (ANN) based models have been used widely to make precise and realistic forecasts, especially for the nonlinear and complicated problems like crop yield prediction, biomass change detection and crop evapo-transpiration examination. In the present study, various parameters viz. spectral bands of Landsat 8 OLI (Operational Land Imager) satellite data and derived spectral indices along with field inventory data were evaluated for Mentha crop biomass estimation using ANN technique of Multilayer Perceptron. The estimated biomass showed a good relationship (R-2 = 0.762 and root mean square error (RMSE) = 2.74 t\/ha) with field-measured biomass.","doi":"10.1007\/s11119-019-09655-9","issn":"1385-2256","pages":"18--33","number":"1","volume":"21","journal":"PRECISION AGRICULTURE","month":"February","year":"2020"}}
{"bib_id":"khatami_meta-analysis_2016","title":"A Meta-Analysis of Remote Sensing Research on Supervised Pixel-Based Land-Cover Image Classification Processes: General Guidelines for Practitioners and Future Research","author":"Khatami, Reza and Mountrakis, Giorgos and Stehman, Stephen V.","meta_info":{"langid":"english","abstract":"Classification of remotely sensed imagery for land-cover mapping purposes has attracted significant attention from researchers and practitioners. Numerous studies conducted over several decades have investigated a broad array of input data and classification methods. However, this vast assemblage of research results has not been synthesized to provide coherent guidance on the relative performance of different classification processes for generating land cover products. To address this problem, we completed a statistical meta-analysis of the past 15years of research on supervised per-pixel image classification published in five high-impact remote sensing journals. The two general factors evaluated were classification algorithms and input data manipulation as these are factors that can be controlled by analysts to improve classification accuracy. The meta-analysis revealed that inclusion of texture information yielded the greatest improvement in overall accuracy of land-cover classification with an average increase of 12.1%. This increase in accuracy can be attributed to the additional spatial context information provided by including texture. Inclusion of ancillary data, multi-angle and time images also provided significant improvement in classification overall accuracy, with 8.5%, 8.0%, and 6.9% of average improvements, respectively. In contrast, other manipulation of spectral information such as index creation (e.g. Normalized Difference Vegetation Index) and feature extraction (e.g. Principal Components Analysis) offered much smaller improvements in accuracy. In terms of classification algorithms, support vector machines achieved the greatest accuracy, followed by neural network methods. The random forest classifier performed considerably better than the traditional decision tree classifier. Maximum likelihood classifiers, often used as benchmarking algorithms, offered low accuracy. Our findings will help guide practitioners to decide which classification to implement and also provide direction to researchers regarding comparative studies that will further solidify our understanding of different classification processes. However, these general guidelines do not preclude an analyst from incorporating personal preferences or considering specific algorithmic benefits that may be pertinent to a particular application.","urldate":"2022-06-20","doi":"10.1016\/j.rse.2016.02.028","issn":"0034-4257","pages":"89--100","volume":"177","journal":"Remote Sensing of Environment","month":"May","year":"2016","shorttitle":"A Meta-Analysis of Remote Sensing Research on Supervised Pixel-Based Land-Cover Image Classification Processes"}}
{"bib_id":"kira_extraction_2020","title":"Extraction of Sub-Pixel C3\/C4 Emissions of Solar-Induced Chlorophyll Fluorescence (SIF) Using Artificial Neural Network","author":"Kira, Oz and Sun, Ying","meta_info":{"keywords":"Agriculture,Deep Learning,Satellite,SIF prediction","abstract":"Solar-induced chlorophyll fluorescence (SIF) is a signal directly and functionally related to photosynthetic activity and thus holds great promise for large-scale agricultural monitoring. However, the coarse spatial resolution of existing satellite SIF observations usually consist of mixed SIF signals contributed by different crop types with distinct phenology (modulated by management practices) and varying SIF emission capacities, which impedes effective utilization of existing SIF records for large-scale agricultural applications. This study makes the first effort to overcome this challenge by developing a sub-pixel SIF extraction framework for corn and soybean in the US Corn Belt as a case study. Here we developed a machine learning (ML) based sub-pixel SIF extraction framework using Orbiting Carbon Observatory 2 (OCO-2), whose high-resolution SIF acquired along orbits at nadir enables the identification of relatively pure pixels dominated by single corn or soybean crops, facilitating validation of the developed framework. To achieve this, we first generated artificially mixed SIF pixels from pure pixels randomly weighted by fractional area coverage. We then employed a standard feed forward artificial neural network (ANN) to estimate sub-pixel SIF for corn and soybean respectively, using the following predictors: total mixed SIF, spectral reflectance of corn\/soybean (from Moderate Resolution Imaging Spectroradiometer MODIS), and the fractional area coverage of corn\/soybean (derived from CropScape-Cropland Data Layer). Our results demonstrated that the estimated sub-pixel SIF could successfully reproduce the original pure SIF values constituting the mixed pixel, with a normalized root mean squared error (NRMSE) of $<$ 10% during the peak growing season. We further demonstrated that this ANN-based framework substantially outperforms the parsimonious linear extraction methods. This developed sub-pixel SIF extraction framework was then applied to generate regional-scale SIF maps for corn and soybean at 0.05 degrees in the US Midwest. Although tested for corn and soybean only, the developed framework has the potential to resolve subpixel SIF of more endmembers from coarse SIF observations.","doi":"10.1016\/j.isprsjprs.2020.01.017","issn":"0924-2716","pages":"135--146","volume":"161","journal":"ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING","month":"March","year":"2020"}}
{"bib_id":"kira_toward_2017","title":"Toward Generic Models for Green LAI Estimation in Maize and Soybean: Satellite Observations","author":"Kira, Oz and Nguy-Robertson, Anthony L. and Arkebauer, Timothy J. and Linker, Raphael and Gitelson, Anatoly A.","meta_info":{"keywords":"Agriculture,Canopy cover prediction,Deep Learning,Images: Landsat,Images: MERIS,Images: MODIS,Labels: Field survey,Model: MLP,Satellite","abstract":"Informative spectral bands for green leaf area index (LAI) estimation in two crops were identified and generic models for soybean and maize were developed and validated using spectral data taken at close range. The objective of this paper was to test developed models using Aqua and Terra MODIS, Landsat TM and ETM+, ENVISAT MERIS surface reflectance products, and simulated data of the recently-launched Sentinel 2 MSI and Sentinel 3 OLCI. Special emphasis was placed on testing generic models which require no re-parameterization for these species. Four techniques were investigated: support vector machines (SVM), neural network (NN), multiple linear regression (MLR), and vegetation indices (VI). For each technique two types of models were tested based on (a) reflectance data, taken at close range and resampled to simulate spectral bands of satellite sensors; and (b) surface reflectance satellite products. Both types of models were validated using MODIS, TM\/ETM+, and MERIS data. MERIS was used as a prototype of OLCI Sentinel-3 data which allowed for assessment of the anticipated accuracy of OLCI. All models tested provided a robust and consistent selection of spectral bands related to green LAI in crops representing a wide range of biochemical and structural traits. The MERIS observations had the lowest errors (around 11%) compared to the remaining satellites with observational data. Sentinel 2 MSI and OLCI Sentinel 3 estimates, based on simulated data, had errors below 8%. However the accuracy of these models with actual MSI and OLCI surface reflectance products remains to be determined.","doi":"10.3390\/rs9040318","issn":"2072-4292","number":"4","volume":"9","journal":"REMOTE SENSING","month":"April","year":"2017"}}
{"bib_id":"kolassa_estimating_2018","title":"Estimating Surface Soil Moisture from SMAP Observations Using a Neural Network Technique","author":"Kolassa, J. and Reichle, R. H. and Liu, Q. and Alemohammad, S. H. and Gentine, P. and Aida, K. and Asanuma, J. and Bircher, S. and Caldwell, T. and Colliander, A. and Cosh, M. and Collins, C. Holifield and Jackson, T. J. and Martinez-Fernandez, J. and McNairn, H. and Pacheco, A. and Thibeault, M. and Walker, J. P.","meta_info":{"keywords":"Deep Learning,Satellite,Soil moisture prediction","abstract":"A Neural Network (NN) algorithm was developed to estimate global surface soil moisture for April 2015 to March 2017 with a 2-3 day repeat frequency using passive microwave observations from the Soil Moisture Active Passive (SMAP) satellite, surface soil temperatures from the NASA Goddard Earth Observing System Model version 5 (GEOS-5) land modeling system, and Moderate Resolution Imaging Spectroradiometer-based vegetation water content. The NN was trained on GEOS-5 soil moisture target data, making the NN estimates consistent with the GEOS-5 climatology, such that they may ultimately be assimilated into this model without further bias correction. Evaluated against in situ soil moisture measurements, the average unbiased root mean square error (ubRMSE), correlation and anomaly correlation of the NN retrievals were 0.037 m(3)m(-3), 0.70 and 0.66, respectively, against SMAP core validation site measurements and 0.026 m(3)m(-3), 0.58 and 0.48, respectively, against International Soil Moisture Network (ISMN) measurements. At the core validation sites, the NN retrievals have a significantly higher skill than the GEOS-5 model estimates and a slightly lower correlation skill than the SMAP Level-2 Passive (L2P) product. The feasibility of the NN method was reflected by a lower ubRMSE compared to the L2P retrievals as well as a higher skill when ancillary parameters in physically-based retrievals were uncertain. Against ISMN measurements, the skill of the two retrieval products was more comparable. A triple collocation analysis against Advanced Microwave Scanning Radiometer 2 (AMSR2) and Advanced Scatterometer (ASCAT) soil moisture retrievals showed that the NN and L2P retrieval errors have a similar spatial distribution, but the NN retrieval errors are generally lower in densely vegetated regions and transition zones.","doi":"10.1016\/j.rse.2017.10.045","issn":"0034-4257","pages":"43--59","volume":"204","journal":"REMOTE SENSING OF ENVIRONMENT","month":"January","year":"2018"}}
{"bib_id":"kondmann_denethor_2021","title":"DENETHOR: The DynamicEarthNET Dataset for Harmonized, Inter-Operable, Analysis-Ready, Daily Crop Monitoring from Space","author":"Kondmann, Lukas and Toker, Aysim and Ruß wurm, Marc and Camero, Andrés and Peressuti, Devis and Milcinski, Grega and Mathieu, Pierre-Philippe and Longepe, Nicolas and Davis, Timothy and Marchisio, Giovanni and Leal-Taixé, Laura and Zhu, Xiaoxiang","meta_info":{"volume":"1","year":"2021","editor":"Vanschoren, J. and Yeung, S.","booktitle":"Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks"}}
{"bib_id":"krizhevsky_imagenet_2012","title":"ImageNet Classification with Deep Convolutional Neural Networks","author":"Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E","meta_info":{"abstract":"We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the LSVRC-2010 ImageNet training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7\\% and 18.9\\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.","urldate":"2022-07-21","publisher":"Curran Associates, Inc.","pages":"1106--1114","volume":"25","year":"2012","booktitle":"Advances in Neural Information Processing Systems"}}
{"bib_id":"krupavathi_field-scale_2022","title":"Field-Scale Estimation and Comparison of the Sugarcane Yield from Remote Sensing Data: A Machine Learning Approach","author":"Krupavathi, K. and Raghubabu, M. and Mani, A. and Parasad, P. R. K. and Edukondalu, L.","meta_info":{"keywords":"Agriculture,Deep Learning,Images: Landsat,Labels: Field survey,Model: MLP,Satellite,Used VI,Yield prediction,Yield: Field-level","abstract":"The present work describes about estimation of crop yield of sugarcane crop from medium resolution LANDSAT 8 OLI (30 m) imageries by the development of a nonlinear empirical model using classical artificial neural networks. Sugarcane crop attributes were retrieved from high-resolution (30 m) satellite imageries to develop yield prediction models. The feed-forward back-propagation neural network algorithm developed and calibrated using the remote sensing retrieved crop parameters and ground truth data in MATLAB environment. The perceptron was trained with 75 out of the 100 possible inputs upto10,000 epochs with 1-10 hidden neurons. Four performance indices: coefficient of determination (R-2), root mean squared error (RMSE), mean absolute error (MAE) and the average ratio of estimated yield to target crop yield (R-ratio) were calculated, to achieve optimum neural network. Several runs were performed in determining the optimum number of hidden neurons. The best performance of the models was observed at i + 1 and i + 2 hidden nodes (i = No of input parameters). The range of R-2 values of best performed models were between 0.867 and 0.916 for training and same for testing it ranged from 0.829 to 0.991 and R-ratio values from 0.997 to 1.006, the normalized RMSE values ranged from 0.066 to 0.150; MAE ranged from 0.034 to 0.119 for training and 0.017-0.184 for testing. The statistical analysis recommends the reliability of the ANN model in sugarcane yield estimation. Multivariate linear regression was also performed for training and testing data separately to test the superiority of the ANN model. The estimated yield was in the range of 60,000 kg\/ha-1,30,000 with an average of 73,000 kg\/ha.","doi":"10.1007\/s12524-021-01448-w","issn":"0255-660X","journal":"JOURNAL OF THE INDIAN SOCIETY OF REMOTE SENSING","month":"February","year":"2022"}}
{"bib_id":"kumar_comparison_2015","title":"Comparison of Support Vector Machine, Artificial Neural Network, and Spectral Angle Mapper Algorithms for Crop Classification Using LISS IV Data","author":"Kumar, Pradeep and Gupta, Dileep Kumar and Mishra, Varun Narayan and Prasad, Rajendra","meta_info":{"keywords":"Agriculture,Best Model: SVM,Crop segmentation,Deep Learning,Images: LISS IV,Labels: Field survey,Model comparison,Model: MLP,Model: SVM,Satellite","abstract":"The Resourcesat-2 is a highly suitable satellite for crop classification studies with its improved features and capabilities. Data from one of its sensors, the linear imaging and self-scanning (LISS IV), which has a spatial resolution of 5.8 m, was used to compare the relative accuracies achieved by support vector machine (SVM), artificial neural network (ANN), and spectral angle mapper (SAM) algorithms for the classification of various crops and non-crop covering a part of Varanasi district, Uttar Pradesh, India. The separability analysis was performed using a transformed divergence (TD) method between categories to assess the quality of training samples. The outcome of the present study indicates better performance of SVM and ANN algorithms in comparison to SAM for the classification using LISS IV sensor data. The overall accuracies obtained by SVM and ANN were 93.45% and 92.32%, respectively, whereas the lower accuracy of 74.99% was achieved using the SAM algorithm through error matrix analysis. Results derived from SVM, ANN, and SAM classification algorithms were validated with the ground truth information acquired by the field visit on the same day of satellite data acquisition.","doi":"10.1080\/2150704X.2015.1019015","issn":"0143-1161","pages":"1604--1617","number":"6","volume":"36","journal":"INTERNATIONAL JOURNAL OF REMOTE SENSING","year":"2015"}}
{"bib_id":"kumar_comprehensive_2019","title":"Comprehensive Evaluation of Soil Moisture Retrieval Models under Different Crop Cover Types Using C-band Synthetic Aperture Radar Data","author":"Kumar, P. and Prasad, R. and Choudhary, A. and Gupta, D. K. and Mishra, V. N. and Vishwakarma, A. K. and Singh, A. K. and Srivastava, P. K.","meta_info":{"keywords":"Agriculture,Best Model: SVM,Deep Learning,Images: Envisat,Images: Sentinel,Labels: Field survey,Model comparison,Model: MLP,Model: RF,Model: SVM,Satellite,Soil moisture prediction","abstract":"In the present study, random forest regression (RFR), support vector regression (SVR) and artificial neural network regression (ANNR) models were evaluated for the retrieval of soil moisture covered by winter wheat, barley and corn crops. SVR with radial basis function kernel was provided the highest adj. R-2 (0.95) value for soil moisture retrieval covered by the wheat crop at VV polarization. However, RFR provided the adj. R-2 (0.94) value for soil moisture retrieval covered by barley crop at VV polarization using Sentinel-1A satellite data. The adj. R-2 (0.94) values were found for the soil moisture covered by corn crop at VV polarization using RFR, SVR linear and radial basis function kernels. The least performance was reported using ANNR model for almost all the crops under investigation. The soil moisture retrieval outcomes were found better at VV polarization in comparison to VH polarization using three different models.","doi":"10.1080\/10106049.2018.1464601","issn":"1010-6049","pages":"1022--1041","number":"9","volume":"34","journal":"GEOCARTO INTERNATIONAL","month":"July","year":"2019"}}
{"bib_id":"kussul_crop_2018","title":"Crop Inventory at Regional Scale in Ukraine: Developing in Season and End of Season Crop Maps with Multi-Temporal Optical and SAR Satellite Imagery","author":"Kussul, Nataliia and Mykola, Lavreniuk and Shelestov, Andrii and Skakun, Sergii","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Landsat,Images: Sentinel,Labels: Field survey,Model: MLP,Multitemporal,Satellite","abstract":"Along the season crop classification maps based on satellite data is a challenging task for countries with large diversity of agricultural crops with different phenology (crop calendars). In this paper, we investigate feasibility of delivering early and along the season crop specific maps using available free satellite data over multiple years, including Landsat-8, Sentinel-1 and Sentinel-2. For this study, a test site in Kyiv region (Ukraine) is selected, for which we have been collecting ground data on crop types every year since 2011. Crop type maps are generated through a supervised classification of multi-temporal multi-source satellite data using previously developed artificial neural network algorithms. It is shown, how multi-year crop classification maps are used for crop rotation violation detection. The study shows that in case of considerable cloud cover, synthetic aperture radar (SAR) data, for example acquired by Sentinel-1 satellite, can be interchangeably used with optical imagery to achieve the target 85% accuracy for crop classification.","doi":"10.1080\/22797254.2018.1454265","pages":"627--636","number":"1","volume":"51","journal":"EUROPEAN JOURNAL OF REMOTE SENSING","year":"2018"}}
{"bib_id":"kussul_deep_2017","title":"Deep Learning Classification of Land Cover and Crop Types Using Remote Sensing Data","author":"Kussul, Nataliia and Lavreniuk, Mykola and Skakun, Sergii and Shelestov, Andrii","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Landsat,Images: Sentinel,Labels: Field survey,Model comparison,Model: 1DCNN,Model: CNN,Model: MLP,Multitemporal,Satellite","langid":"english","abstract":"Deep learning (DL) is a powerful state-of-the-art technique for image processing including remote sensing (RS) images. This letter describes a multilevel DL architecture that targets land cover and crop type classification from multitemporal multisource satellite imagery. The pillars of the architecture are unsupervised neural network (NN) that is used for optical imagery segmentation and missing data restoration due to clouds and shadows, and an ensemble of supervised NNs. As basic supervised NN architecture, we use a traditional fully connected multilayer perceptron (MLP) and the most commonly used approach in RS community random forest, and compare them with convolutional NNs (CNNs). Experiments are carried out for the joint experiment of crop assessment and monitoring test site in Ukraine for classification of crops in a heterogeneous environment using nineteen multitemporal scenes acquired by Landsat-8 and Sentinel-1A RS satellites. The architecture with an ensemble of CNNs outperforms the one with MLPs allowing us to better discriminate certain summer crop types, in particular maize and soybeans, and yielding the target accuracies more than 85% for all major crops (wheat, maize, sunflower, soybeans, and sugar beet).","doi":"10.1109\/LGRS.2017.2681128","issn":"1545-598X","address":"445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","publisher":"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC","pages":"778--782","number":"5","volume":"14","journal":"IEEE GEOSCIENCE AND REMOTE SENSING LETTERS","month":"May","year":"2017","type":"Article"}}
{"bib_id":"kuznetsova_open_2020","title":"The Open Images Dataset V4: Unified Image Classification, Object Detection, and Visual Relationship Detection at Scale","author":"Kuznetsova, Alina and Rom, Hassan and Alldrin, Neil and Uijlings, Jasper and Krasin, Ivan and Pont-Tuset, Jordi and Kamali, Shahab and Popov, Stefan and Malloci, Matteo and Kolesnikov, Alexander and Duerig, Tom and Ferrari, Vittorio","meta_info":{"file":"\/home\/brandon\/Zotero\/storage\/MGDNHD94\/Kuznetsova et al. - 2020 - The Open Images Dataset V4 Unified Image Classifi.pdf","langid":"english","abstract":"We present Open Images V4, a dataset of 9.2M images with unified annotations for image classification, object detection and visual relationship detection. The images have a Creative Commons Attribution license that allows to share and adapt the material, and they have been collected from Flickr without a predefined list of class names or tags, leading to natural class statistics and avoiding an initial design bias. Open Images V4 offers large scale across several dimensions: 30.1M image-level labels for 19.8k concepts, 15.4M bounding boxes for 600 object classes, and 375k visual relationship annotations involving 57 classes. For object detection in particular, we provide 15× more bounding boxes than the next largest datasets (15.4M boxes on 1.9M images). The images often show complex scenes with several objects (8 annotated objects per image on average). We annotated visual relationships between them, which support visual relationship detection, an emerging task that requires structured reasoning. We provide in-depth comprehensive statistics about the dataset, we validate the quality of the annotations, we study how the performance of several modern models evolves with increasing amounts of training data, and we demonstrate two applications made possible by having unified annotations of multiple types coexisting in the same images. We hope that the scale, quality, and variety of Open Images V4 will foster further research and innovation even beyond the areas of image classification, object detection, and visual relationship detection.","urldate":"2022-03-02","doi":"10.1007\/s11263-020-01316-z","issn":"0920-5691, 1573-1405","pages":"1956--1981","number":"7","volume":"128","journal":"International Journal of Computer Vision","month":"July","year":"2020","shorttitle":"The Open Images Dataset V4"}}
{"bib_id":"laban_sparse_2021","title":"Sparse Pixel Training of Convolutional Neural Networks for Land Cover Classification","author":"Laban, Noureldin and Abdellatif, Bassam and Ebeid, Hala M. and Shedeed, Howida A. and Tolba, Mohamed F.","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Field survey,Model: UNet,Satellite","langid":"english","abstract":"Convolutional Neural Networks (CNN) have become the core of modern machine learning approaches. In addition to its inspiring interior design idea, the success of CNN depends mainly on two factors, the first is the availability of training data and the second is the computing power of the used devices. In the field of remote sensing, data availability is difficult and expensive. Furthermore, processing large remote sensing data to accommodate different models is a laborious process. At the same time, training data is often collected in the form of points distributed over crop fields rather than regions, which results in the scarcity of training data. To specifically address the scarcity of training points, in this paper we present a sparse pixel-based training of U-Net convolutional neural networks for land cover classification. Training images are reconstructed from the points' collection in a random manner, they are used as an input for the convolution networks. Based on this proposed method, the amount of training data is reproduced from the different spectral signals for each land cover. We conducted extensive experiments on eight classes, using ground truth data collected from several locations in Fayoum Governorate, Egypt. The obtained results showed the superiority of the proposed method over other methods.","doi":"10.1109\/ACCESS.2021.3069882","issn":"2169-3536","address":"445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","publisher":"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC","pages":"52067--52078","volume":"9","journal":"IEEE ACCESS","year":"2021","type":"Article"}}
{"bib_id":"lei_docc_2021","title":"DOCC: Deep One-Class Crop Classification via Positive and Unlabeled Learning for Multi-Modal Satellite Imagery","author":"Lei, Lei and Wang, Xinyu and Zhong, Yanfei and Zhao, Hengwei and Hu, Xin and Luo, Chang","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Sentinel,Images: Zhuhai-1,Labels: Field survey,Labels: Image survey,Model: 2DCNN,Satellite","abstract":"Large-scale crop mapping is an important task in agricultural resource monitoring, but it does usually require the ground-truth labels of all the land-cover types in the remotely sensed imagery. However, labeling each land cover type is time-consuming and labor-intensive. One-class classification, which only needs samples of the class of interest, can solve the problem of redundant labeling. However, the traditional one-class classifiers require well-designed features to realize fine classification, and are thus difficult to apply to complex multi modal remote sensing data, i.e., optical imagery and synthetic aperture radar (SAR) imagery. In this paper, a deep one-class crop (DOCC) framework that includes a deep one-class crop extraction module and a one-class crop extraction loss module is proposed for large-scale one-class crop mapping. The DOCC framework takes only the samples of one target class as the input to extract the crop of interest by positive and unlabeled learning and can automatically extract the features for one-class crop mapping, without requiring a large amount of labeling for all the land-cover type or feature design based on prior expert knowledge. Experiments conducted on multi-modal remote sensing data, i.e., Zhuhai-1 hyperspectral satellite data, Sentinel-2 multispectral time-series satellite data and Sentinel-1 SAR satellite data, illustrate that DOCC can automatically extract the effective features for one-class classification from multi-modal satellite imagery and reaches the highest F1 accuracy compared with other methods on respective satellite imagery. The results also reveal the different performance of multi-modal satellite imagery when they are used to extract different crop types. Meanwhile, the feasibility of DOCC for multi-modal data can be beneficial for large-scale mapping under different conditions when the samples of multi-class are difficult to obtain.","doi":"10.1016\/j.jag.2021.102598","issn":"1569-8432","volume":"105","journal":"INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION","month":"December","year":"2021"}}
{"bib_id":"lei_multi-temporal_2022","title":"Multi-Temporal Data Fusion in MS and SAR Images Using the Dynamic Time Warping Method for Paddy Rice Classification","author":"Lei, Tsu Chiang and Wan, Shiuan and Wu, You Cheng and Wang, Hsin-Ping and Hsieh, Chia-Wen","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Sentinel,Images: SPOT,Labels: Public government data,Model: MLP,Model: SVM,Model: Tree,Satellite,Used VI","unique-id":"WOS:000758694700001","eissn":"2077-0472","article-number":"77","doi":"10.3390\/agriculture12010077","number":"1","volume":"12","journal":"AGRICULTURE-BASEL","month":"January","year":"2022"}}
{"bib_id":"li_adversarial_2021","title":"An Adversarial Generative Network for Crop Classification from Remote Sensing Timeseries Images","author":"Li, Jingtao and Shen, Yonglin and Yang, Chao","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Landsat,Labels: CDL,Model: 2DCNN,Model: LSTM,Satellite","abstract":"Due to the increasing demand for the monitoring of crop conditions and food production, it is a challenging and meaningful task to identify crops from remote sensing images. The state-of the-art crop classification models are mostly built on supervised classification models such as support vector machines (SVM), convolutional neural networks (CNN), and long- and short-term memory neural networks (LSTM). Meanwhile, as an unsupervised generative model, the adversarial generative network (GAN) is rarely used to complete classification tasks for agricultural applications. In this work, we propose a new method that combines GAN, CNN, and LSTM models to classify crops of corn and soybeans from remote sensing time-series images, in which GAN's discriminator was used as the final classifier. The method is feasible on the condition that the training samples are small, and it fully takes advantage of spectral, spatial, and phenology features of crops from satellite data. The classification experiments were conducted on crops of corn, soybeans, and others. To verify the effectiveness of the proposed method, comparisons with models of SVM, SegNet, CNN, LSTM, and different combinations were also conducted. The results show that our method achieved the best classification results, with the Kappa coefficient of 0.7933 and overall accuracy of 0.86. Experiments in other study areas also demonstrate the extensibility of the proposed method.","doi":"10.3390\/rs13010065","number":"1","volume":"13","journal":"REMOTE SENSING","month":"January","year":"2021"}}
{"bib_id":"li_agricultural_2020","title":"Agricultural Greenhouses Detection in High-Resolution Satellite Images Based on Convolutional Neural Networks: Comparison of Faster R-CNN, YOLO v3 and SSD","author":"Li, Min and Zhang, Zhijie and Lei, Liping and Wang, Xiaofan and Guo, Xudong","meta_info":{"keywords":"Agriculture,Deep Learning,Greenhouse detection,Images: GF2,Labels: Image survey,Model: FasterRCNN,Model: SSD,Model: YOLO,Satellite","abstract":"Agricultural greenhouses (AGs) are an important facility for the development of modern agriculture. Accurately and effectively detecting AGs is a necessity for the strategic planning of modern agriculture. With the advent of deep learning algorithms, various convolutional neural network (CNN)-based models have been proposed for object detection with high spatial resolution images. In this paper, we conducted a comparative assessment of the three well-established CNN-based models, which are Faster R-CNN, You Look Only Once-v3 (YOLO v3), and Single Shot Multi-Box Detector (SSD) for detecting AGs. The transfer learning and fine-tuning approaches were implemented to train models. Accuracy and efficiency evaluation results show that YOLO v3 achieved the best performance according to the average precision (mAP), frames per second (FPS) metrics and visual inspection. The SSD demonstrated an advantage in detection speed with an FPS twice higher than Faster R-CNN, although their mAP is close on the test set. The trained models were also applied to two independent test sets, which proved that these models have a certain transability and the higher resolution images are significant for accuracy improvement. Our study suggests YOLO v3 with superiorities in both accuracy and computational efficiency can be applied to detect AGs using high-resolution satellite images operationally.","doi":"10.3390\/s20174938","number":"17","volume":"20","journal":"SENSORS","month":"September","year":"2020"}}
{"bib_id":"li_crop_2022","title":"Crop Classification Based on GDSSM-CNN Using Multi-Temporal RADARSAT-2 SAR with Limited Labeled Data","author":"Li, Heping and Lu, Jing and Tian, Guixiang and Yang, Huijin and Zhao, Jianhui and Li, Ning","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Radarsat-2,Labels: Field survey,Model: 1DCNN,Satellite","unique-id":"WOS:000845382000001","orcid-numbers":"Li, Ning\/0000-0002-4358-6449","eissn":"2072-4292","article-number":"3889","doi":"10.3390\/rs14163889","number":"16","volume":"14","journal":"REMOTE SENSING","month":"August","year":"2022"}}
{"bib_id":"li_estimating_2007","title":"Estimating Crop Yield from Multi-Temporal Satellite Data Using Multivariate Regression and Neural Network Techniques","author":"Li, Ainong and Liang, Shunlin and Wang, Angsheng and Qin, Jun","meta_info":{"keywords":"Agriculture,Deep Learning,Images: MODIS,Labels: Public government data,Model: ANN,Satellite,Used VI,Yield prediction,Yield: County-level","abstract":"Accurate, objective, reliable, and timely predictions of crop yield over large areas are critical to helping ensure the adequacy of a nation's food supply and aiding policy makers on import\/export plans and prices. Development Of objective mathematical models of crop yield prediction using remote sensing is highly desirable. In this study, we develop a new methodology using an artificial neural network (ANN) to estimate and predict corn and soybean yields on a county-by-county basis, in the ``corn belt'' area in the Midwestern and Great Plains regions of the United States. The historical yield data and long time-series NDVI derived from AVHRR and MODIS are used to develop the models. A new procedure is developed to train the ANN model using the SCE-UA optimization algorithm. The performance of ANN models is compared with multivariate linear regression (MLR) models and validation is made on the model's stability and forecasting ability. The new algorithms can effectively train ANN models, and the prediction accuracy can be as high as 85 percent.","doi":"10.14358\/PERS.73.10.1149","issn":"0099-1112","pages":"1149--1157","number":"10","volume":"73","journal":"PHOTOGRAMMETRIC ENGINEERING AND REMOTE SENSING","month":"October","year":"2007"}}
{"bib_id":"li_full_2022","title":"Full Convolution Neural Network Combined with Contextual Feature Representation for Cropland Extraction from High-Resolution Remote Sensing Images","author":"Li, Zhuqiang and Chen, Shengbo and Meng, Xiangyu and Zhu, Ruifei and Lu, Junyan and Cao, Lisai and Lu, Peng","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: GF2,Images: Jilin-1,Model: 2DCNN,Satellite","unique-id":"WOS:000794589600001","orcid-numbers":"Li, Zhuqiang\/0000-0003-3836-681X Lu, Junyan\/0000-0001-7830-3704","eissn":"2072-4292","article-number":"2157","doi":"10.3390\/rs14092157","number":"9","volume":"14","journal":"REMOTE SENSING","month":"May","year":"2022"}}
{"bib_id":"li_large-scale_2019","title":"Large-Scale Oil Palm Tree Detection from High-Resolution Satellite Images Using Two-Stage Convolutional Neural Networks","author":"Li, Weijia and Dong, Runmin and Fu, Haohuan and Yu, Le","meta_info":{"keywords":"Agriculture,Deep Learning,Images: QuickBird,Labels: Image survey,Model: AlexNet,Model: LeNet,Model: VGG,Satellite,Tree detection","abstract":"Being an important economic crop that contributes 35% of the total consumption of vegetable oil, remote sensing-based quantitative detection of oil palm trees has long been a key research direction for both agriculture and environmental purposes. While existing methods already demonstrate satisfactory effectiveness for small regions, performing the detection for a large region with satisfactory accuracy is still challenging. In this study, we proposed a two-stage convolutional neural network (TS-CNN)-based oil palm detection method using high-resolution satellite images (i.e. Quickbird) in a large-scale study area of Malaysia. The TS-CNN consists of one CNN for land cover classification and one CNN for object classification. The two CNNs were trained and optimized independently based on 20,000 samples collected through human interpretation. For the large-scale oil palm detection for an area of 55 km(2), we proposed an effective workflow that consists of an overlapping partitioning method for large-scale image division, a multi-scale sliding window method for oil palm coordinate prediction, and a minimum distance filter method for post-processing. Our proposed approach achieves a much higher average F1-score of 94.99% in our study area compared with existing oil palm detection methods (87.95%, 81.80%, 80.61%, and 78.35% for single-stage CNN, Support Vector Machine (SVM), Random Forest (RF), and Artificial Neural Network (ANN), respectively), and much fewer confusions with other vegetation and buildings in the whole image detection results.","doi":"10.3390\/rs11010011","number":"1","volume":"11","journal":"REMOTE SENSING","month":"January","year":"2019"}}
{"bib_id":"li_machine_2022","title":"A Machine Learning Approach for Identifying and Delineating Agricultural Fields and Their Multi-Temporal Dynamics Using Three Decades of Landsat Data","author":"Li, Ting and Johansen, Kasper and McCabe, Matthew F.","meta_info":{"keywords":"Agriculture,Deep Learning,Field shape classification,Images: Landsat,Labels: Image survey,Model: 2DCNN,Satellite,Used VI","unique-id":"WOS:000782580600002","researcherid-numbers":"McCabe, Matthew\/G-5194-2011","orcid-numbers":"McCabe, Matthew\/0000-0002-1279-5272","eissn":"1872-8235","doi":"10.1016\/j.isprsjprs.2022.02.002","issn":"0924-2716","pages":"83--101","volume":"186","journal":"ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING","month":"April","year":"2022"}}
{"bib_id":"li_mapping_2016","title":"Mapping Grazing Intensity Using Remote Sensing in the Xilingol Steppe Region, Inner Mongolia, China","author":"Li, Fei and Zheng, Jiajia and Wang, Hao and Luo, Juhua and Zhao, Ying and Zhao, Ruibin","meta_info":{"keywords":"Agriculture,Deep Learning,Grassland biomass prediction,Images: Landsat,Labels: Field survey,Model: MLP,Satellite","abstract":"Satellite remote sensing has been used in many fields but less commonly for monitoring grazing intensity (GI). In this study, grassland above-ground biomass (AGB) was simulated by multispectral reflectance derived from an artificial neural network (ANN) to investigate GI. One-way analysis of variance (ANOVA) and frequency histograms from sample plots were used to determine the thresholds of AGB for four levels of GI characterized as ungrazed, lightly grazed, moderately grazed and heavily grazed. The distribution of GI in the Xilingol steppe region of Inner Mongolia, China, was then mapped from the remotely sensed grassland AGB. This study could be used as a guide for management interventions and grassland restoration.","doi":"10.1080\/2150704X.2015.1137987","issn":"2150-704X","pages":"328--337","number":"4","volume":"7","journal":"REMOTE SENSING LETTERS","year":"2016"}}
{"bib_id":"lin_microsoft_2014","title":"Microsoft COCO: Common Objects in Context","author":"Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Dollár, Piotr and Zitnick, C. Lawrence","meta_info":{"isbn":"978-3-319-10602-1","abstract":"We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.","doi":"10.1007\/978-3-319-10602-1_48","address":"Cham","publisher":"Springer","pages":"740--755","volume":"8693","year":"2014","editor":"Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne","booktitle":"Computer Vision - ECCV 2014. ECCV 2014. Lecture Notes in Computer Science"}}
{"bib_id":"lin_toward_2021","title":"Toward Large-Scale Mapping of Tree Crops with High-Resolution Satellite Imagery and Deep Learning Algorithms: A Case Study of Olive Orchards in Morocco","author":"Lin, Chenxi and Jin, Zhenong and Mulla, David and Ghosh, Rahul and Guan, Kaiyu and Kumar, Vipin and Cai, Yaping","meta_info":{"keywords":"Agriculture,Deep Learning,Images: PlanetScope,Images: WV-2,Images: WV-3,Labels: Private government data,Model: VGG,Satellite,Tree detection","abstract":"Timely and accurate monitoring of tree crop extent and productivities are necessary for informing policy-making and investments. However, except for a very few tree species (e.g., oil palms) with obvious canopy and extensive planting, most small-crown tree crops are understudied in the remote sensing domain. To conduct large-scale small-crown tree mapping, several key questions remain to be answered, such as the choice of satellite imagery with different spatial and temporal resolution and model generalizability. In this study, we use olive trees in Morocco as an example to explore the two abovementioned questions in mapping small-crown orchard trees using 0.5 m DigitalGlobe (DG) and 3 m Planet imagery and deep learning (DL) techniques. Results show that compared to DG imagery whose mean overall accuracy (OA) can reach 0.94 and 0.92 in two climatic regions, Planet imagery has limited capacity to detect olive orchards even with multi-temporal information. The temporal information of Planet only helps when enough spatial features can be captured, e.g., when olives are with large crown sizes (e.g., $>$3 m) and small tree spacings (e.g., $<$3 m). Regarding model generalizability, experiments with DG imagery show a decrease in F1 score up to 5% and OA to 4% when transferring models to new regions with distribution shift in the feature space. Findings from this study can serve as a practical reference for many other similar mapping tasks (e.g., nuts and citrus) around the world.","doi":"10.3390\/rs13091740","number":"9","volume":"13","journal":"REMOTE SENSING","month":"May","year":"2021"}}
{"bib_id":"liu_exploring_2022","title":"Exploring the Superiority of Solar-Induced Chlorophyll Fluorescence Data in Predicting Wheat Yield Using Machine Learning and Deep Learning Methods","author":"Liu, Yuanyuan and Wang, Shaoqiang and Wang, Xiaobo and Chen, Bin and Chen, Jinghua and Wang, Junbang and Huang, Mei and Wang, Zhaosheng and Ma, Li and Wang, Pengyuan and Amir, Muhammad and Zhu, Kai","meta_info":{"keywords":"Agriculture,Deep Learning,Images: MODIS,Labels: Public government data,Satellite,SIF,Yield prediction,Yield: County-level","unique-id":"WOS:000766369300002","researcherid-numbers":"wang, zhaosheng\/AAX-1350-2021","orcid-numbers":"wang, zhaosheng\/0000-0001-7307-2249","eissn":"1872-7107","article-number":"106612","doi":"10.1016\/j.compag.2021.106612","issn":"0168-1699","volume":"192","journal":"COMPUTERS AND ELECTRONICS IN AGRICULTURE","month":"January","year":"2022"}}
{"bib_id":"liu_mapping_2022","title":"Mapping the Complex Crop Rotation Systems in Southern China Considering Cropping Intensity, Crop Diversity, and Their Seasonal Dynamics","author":"Liu, Yuan and Yu, Qiangyi and Zhou, Qingbo and Wang, Cong and Bellingrath-Kimura, Sonoko Dorothea and Wu, Wenbin","meta_info":{"abstract":"Crop rotation increases crop yield, improves soil health, and reduces plant disease. Mapping crop rotation is difficult because crop data from a single time point do not sufficiently represent the dynamics of a system. Studies have tried to map crop rotation by sequentially combining crop maps. However, this produced a large number of meaningless crop sequences, hindering the assessment of rotational benefits at regional scales. Here, we propose a crop rotation classification scheme that integrates temporal information into static crop maps and develop an innovative approach to map crop rotation. We chose a typical multiple cropping region in southern China. Given that the landscape is characterized by high crop diversity (e.g., food crops, cash crops, and permanent crops) and variable cropping intensity, our classification scheme first defines three main rotation systems, i.e., paddy, vegetable, and orchard systems, and then further divides the systems into nine subsystems according to their seasonal dynamics. Finally, we apply time series of Sentinel-1 and Sentinel-2 images to identify the systems by a hierarchical rule-based method. The map of crop rotation systems in 2020 had producer, user, and overall accuracies of 81%, 79%, and 81%, respectively. The results indicate that integrating temporal information into the classification scheme is vital to representing complex rotation systems and that remotely sensed temporal dynamics of crops are useful to characterize these systems. It also shows that crop rotation can be mapped directly rather than aggregating multiple crop layers, thus providing a new perspective for mapping and understanding crop rotation systems.","urldate":"2024-05-20","doi":"10.1109\/JSTARS.2022.3218881","issn":"2151-1535","pages":"9584--9598","volume":"15","journal":"IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","year":"2022"}}
{"bib_id":"loew_decision_2015","title":"Decision Fusion and Non-Parametric Classifiers for Land Use Mapping Using Multi-Temporal RapidEye Data","author":"Loew, Fabian and Conrad, Christopher and Michel, Ulrich","meta_info":{"keywords":"Agriculture,Best Model: SVM,Crop segmentation,Deep Learning,Images: RapidEye,Labels: Field survey,Model: MLP,Model: RF,Model: SVM,Satellite","abstract":"This study addressed the classification of multi-temporal satellite data from RapidEye by considering different classifier algorithms and decision fusion. Four non-parametric classifier algorithms, decision tree (DT), random forest (RF), support vector machine (SVM), and multilayer perceptron (MLP), were applied to map crop types in various irrigated landscapes in Central Asia. A novel decision fusion strategy to combine the outputs of the classifiers was proposed. This approach is based on randomly selecting subsets of the input dataset and aggregating the probabilistic outputs of the base classifiers with another meta-classifier. During the decision fusion, the reliability of each base classifier algorithm was considered to exclude less reliable inputs at the class-basis. The spatial and temporal transferability of the classifiers was evaluated using data sets from four different agricultural landscapes with different spatial extents and from different years. A detailed accuracy assessment showed that none of the stand-alone classifiers was the single best performing. Despite the very good performance of the base classifiers, there was still up to 50% disagreement in the maps produced by the two single best classifiers, RF and SVM. The proposed fusion strategy, however, increased overall accuracies up to 6%. In addition, it was less sensitive to reduced training set sizes and produced more realistic land use maps with less speckle. The proposed fusion approach was better transferable to data sets from other years, i.e. resulted in higher accuracies for the investigated classes. The fusion approach is computationally efficient and appears well suited for mapping diverse crop categories based on sensors with a similar high repetition rate and spatial resolution like RapidEye, for instance the upcoming Sentinel-2 mission. (C) 2015 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS). Published by Elsevier B.V. All rights reserved.","doi":"10.1016\/j.isprsjprs.2015.07.001","issn":"0924-2716","pages":"191--204","volume":"108","journal":"ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING","month":"October","year":"2015"}}
{"bib_id":"long_delineation_2022","title":"Delineation of Agricultural Fields Using Multi-Task BsiNet from High-Resolution Satellite Images","author":"Long, Jiang and Li, Mengmeng and Wang, Xiaoqin and Stein, Alfred","meta_info":{"keywords":"Agriculture,Deep Learning,Field boundary detection,Images: GF1,Images: GF2,Labels: Image survey,Model: 2DCNN,Satellite","unique-id":"WOS:000844083000001","eissn":"1872-826X","article-number":"102871","doi":"10.1016\/j.jag.2022.102871","issn":"1569-8432","volume":"112","journal":"INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION","month":"August","year":"2022"}}
{"bib_id":"lozano-tello_crop_2021","title":"Crop Identification by Massive Processing of Multiannual Satellite Imagery for EU Common Agriculture Policy Subsidy Control","author":"Lozano-Tello, Adolfo and Fernandez-Sellers, Marcos and Quiros, Elia and Fragoso-Campon, Laura and Garcia-Martin, Abelardo and Gutierrez Gallego, Jose Antonio and Mateos, Carmen and Trenado, Ruben and Munoz, Pedro","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Public government data,Model: MLP,Multitemporal,Satellite","abstract":"The early and automatic identification of crops declared by farmers is essential for streamlining European Union Common Agricultural Policy (CAP) payment processes. Currently, field inspections are partial, expensive and entail a considerable delay in the process. Chronological satellite images of cultivated plots can be used so that neural networks can form the model of the declared crop. Once the patterns of a crop are obtained, the correspondence of the declaration with the model of the neural network can be systematically predicted, and can be used for monitoring the CAP. In this article, we propose a learning model with neural networks, using as examples of training the pixels of the cultivated plots from the satellite images over a period of time. We also propose using several years in the training model to generalise the patterns without linking them to the climatic characteristics of a specific year. The article also describes the use of the model in learning the multi-year pattern of tobacco cultivation with very good results.","doi":"10.1080\/22797254.2020.1858723","pages":"1--12","number":"1","volume":"54","journal":"EUROPEAN JOURNAL OF REMOTE SENSING","month":"January","year":"2021"}}
{"bib_id":"lu_mapping_2022","title":"Mapping the Abundance of Multipurpose Agroforestry Faidherbia Albida Trees in Senegal","author":"Lu, Tingting and Brandt, Martin and Tong, Xiaoye and Hiernaux, Pierre and Leroux, Louise and Ndao, Babacar and Fensholt, Rasmus","meta_info":{"keywords":"Agriculture,Deep Learning,Images: Sentinel,Labels: Field survey,Model: MLP,Satellite,Tree detection,Used VI","abstract":"Multi-purpose Faidherbia albida trees represent a vital component of agroforestry parklands in West Africa as they provide resources (fodder for livestock, fruits and firewood) and support water lifting and nutrient recycling for cropping. Faidherbia albida trees are characterized by their inverse phenology, growing leaf flowers and pods during the dry season, thereby providing fodder and shedding leaves during the wet season, which minimizes competition with pastures and crops for resources. Multi-spectral and multi-temporal satellite systems and novel computational methods open new doors for classifying single trees and identifying species. This study used a Multi-Layer Perception feedforward artificial neural network to classify pixels covered by Faidherbia albida canopies from Sentinel-2 time series in Senegal, West Africa. To better discriminate the Faidherbia albida signal from the background, monthly images from vegetation indices were used to form relevant variables for the model. We found that NDI54\/NDVI from the period covering onset of leaf senescence (February) until end of senescence (leaf-off in June) to be the most important, resulting in a high precision and recall rate of 0.91 and 0.85. We compared our result with a potential Faidherbia albida occurrence map derived by empirical modelling of the species ecology, which deviates notably from the actual species occurrence mapped by this study. We have shown that even small differences in dry season leaf phenology can be used to distinguish tree species. The Faidherbia albida distribution maps, as provided here, will be key in managing farmlands in drylands, helping to optimize economic and ecological services from both tree and crop products.","doi":"10.3390\/rs14030662","number":"3","volume":"14","journal":"REMOTE SENSING","month":"February","year":"2022"}}
{"bib_id":"lu_survey_2007","title":"A Survey of Image Classification Methods and Techniques for Improving Classification Performance","author":"Lu, D. and Weng, Q.","meta_info":{"abstract":"Image classification is a complex process that may be affected by many factors. This paper examines current practices, problems, and prospects of image classification. The emphasis is placed on the summarization of major advanced classification approaches and the techniques used for improving classification accuracy. In addition, some important issues affecting classification performance are discussed. This literature review suggests that designing a suitable image-processing procedure is a prerequisite for a successful classification of remotely sensed data into a thematic map. Effective use of multiple features of remotely sensed data and the selection of a suitable classification method are especially significant for improving classification accuracy. Non-parametric classifiers such as neural network, decision tree classifier, and knowledge-based classification have increasingly become important approaches for multisource data classification. Integration of remote sensing, geographical information systems (GIS), and expert system emerges as a new research frontier. More research, however, is needed to identify and reduce uncertainties in the image-processing chain to improve classification accuracy.","urldate":"2022-06-20","doi":"10.1080\/01431160600746456","issn":"0143-1161","publisher":"Taylor & Francis","pages":"823--870","number":"5","volume":"28","journal":"International Journal of Remote Sensing","month":"March","year":"2007"}}
{"bib_id":"luo_accurately_2022","title":"Accurately Mapping Global Wheat Production System Using Deep Learning Algorithms","author":"Luo, Yuchuan and Zhang, Zhao and Cao, Juan and Zhang, Liangliang and Zhang, Jing and Han, Jichong and Zhuang, Huimin and Cheng, Fei and Tao, Fulu","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: AVHRR,Satellite,Used VI,Yield prediction","unique-id":"WOS:000805028900003","eissn":"1872-826X","article-number":"102823","doi":"10.1016\/j.jag.2022.102823","issn":"1569-8432","volume":"110","journal":"INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION","month":"June","year":"2022"}}
{"bib_id":"ma_corn_2021","title":"Corn Yield Prediction and Uncertainty Analysis Based on Remotely Sensed Variables Using a Bayesian Neural Network Approach","author":"Ma, Yuchi and Zhang, Zhou and Kang, Yanghui and Ozdogan, Mutlu","meta_info":{"keywords":"Agriculture,Deep Learning,Extra data: climate,Extra data: soil,Images: MODIS,Labels: Public government data,Model: MLP,Satellite,Used VI,Yield prediction,Yield: County-level","abstract":"As the world's leading corn producer, the United States supplies more than 30% of the global corn production. Accurate and timely estimation of corn yield is therefore essential for commodity trading and global food security. Recently, several deep learning models have been explored for corn yield forecasting. Despite success, most existing models only provide yield estimations without quantifying the uncertainty associated with the predictions. Also, the traditional deep learning approaches typically require a large training set and are easily prone to overfitting when the number of samples in the training set is relatively small. To address these limitations, in this study, we developed a county-level corn yield prediction model based on Bayesian Neural Network (BNN) using multiple data sources that are publicly available, including time-series satellite products, sequential climate observations, soil property maps, and historical corn yield records. Using preceding years since 2001 for model training, the developed BNN model achieved an average coefficient of determination (R-2) of 0.77 for late-season prediction across the U.S. Corn Belt in testing years 2010-2019, and outperformed five other state-of-the-art machine learning models. Detailed evaluation in three representative testing years demonstrated that the proposed BNN model could accurately estimate corn yield not only in normal years but also in abnormal years when extreme weather events happened. Moreover, the timeliness of the prediction was evaluated within the growing season with an R-2 similar to 0.75 achieved by middle August, which is about 2 months before the harvest. We also assessed the predictive uncertainty, and more than 84% of the observed yield records were successfully enveloped in the 95% confidence interval of the predictive yield distribution. Our results also showed that the uncertainty level decreased steadily as time proceeded and stabilized around early August. Uncertainties in yield prediction were mainly induced by the observation noise and also related to the inter-annual and seasonal variabilities of environmental stress such as heat and water stress. This paper provides a robust framework for the within-season prediction of crop yield and highlights the need to obtain a deeper understanding of the effects of environmental stress on agricultural productivity and crop yield estimation.","doi":"10.1016\/j.rse.2021.112408","issn":"0034-4257","volume":"259","journal":"REMOTE SENSING OF ENVIRONMENT","month":"June","year":"2021"}}
{"bib_id":"ma_deep_2021","title":"Deep Learning for Geological Hazards Analysis: Data, Models, Applications, and Opportunities","author":"Ma, Zhengjing and Mei, Gang","meta_info":{"file":"\/home\/brandon\/Zotero\/storage\/NFR75226\/Ma and Mei - 2021 - Deep learning for geological hazards analysis Dat.pdf","langid":"english","abstract":"As natural disasters are induced by geodynamic activities or abnormal changes in the environment, geological hazards tend to wreak havoc on the environment and human society. Recently, the dramatic increase in the volume of various types of Earth observation `big data' from multiple sources, and the rapid development of deep learning as a state-of-the-art data analysis tool, have enabled novel advances in geological hazard analysis, with the ultimate aim to mitigate the devastation associated with these hazards. Motivated by numerous applications, this paper presents an overview of the advances in the utilization of deep learning for geological hazard analysis. First, six commonly available Earth observation data sources are described, e.g., unmanned aerial vehicles, satellite platforms, and in-situ monitoring systems. Second, the deep learning background and six typical deep learning models are introduced, such as convolutional neural networks and recurrent neural networks. Third, focusing on six typical geological hazards, i.e., landslides, debris flows, rockfalls, avalanches, earthquakes, and volcanoes, the deep learning applications for geological hazard analysis are reviewed, and common application paradigms are summarized. Finally, the challenges and opportunities for the application of deep learning models for geological hazard analysis are highlighted, with the aim to inspire further related research.","urldate":"2022-03-01","doi":"10.1016\/j.earscirev.2021.103858","issn":"00128252","pages":"103858","volume":"223","journal":"Earth-Science Reviews","month":"December","year":"2021","shorttitle":"Deep Learning for Geological Hazards Analysis"}}
{"bib_id":"ma_identifying_2022","title":"Identifying Dike-Pond System Using an Improved Cascade R-CNN Model and High-Resolution Satellite Images","author":"Ma, Yintao and Zhou, Zheng and She, Xiaoxiong and Zhou, Longyu and Ren, Tao and Liu, Shishi and Lu, Jianwei","meta_info":{"keywords":"Agriculture,Dam detection,Deep Learning,Images: GF1,Images: GF2,Labels: Image survey,Model: R-CNN,Model: YOLO,Satellite","abstract":"The dike-pond system (DPS) is the integration of a natural or man-made pond and crop cultivation on dikes, widely distributed in the Pearl River Delta and Jianghan plain in China. It plays a key role in preserving biodiversity, enhancing the nutrient cycle, and increasing crop production. However, DPS is rarely mapped at a large scale with satellite data, due to the limitations in the training dataset and traditional classification methods. This study improved the deep learning algorithm Cascade Region Convolutional Neural Network (Cascade R-CNN) algorithm to detect the DPS in Qianjiang City using high-resolution satellite data. In the proposed mCascade R-CNN, the regular convolution layer in the backbone was modified into the deformable convolutional layer, which was more suitable for learning the features of DPS with variable shapes and orientations. The mCascade R-CNN yielded the most accurate detection of DPS, with an average precision (AP) value that was 2.71% higher than Cascade R-CNN and 11.84% higher than You Look Only Once-v4 (YOLOv4). The area of oilseed rape growing on the dikes accounted for 3.42% of the total oilseed rape planting area. This study demonstrates the potential of the deep leaning methods combined with high-resolution satellite images in detecting integrated agriculture systems.","doi":"10.3390\/rs14030717","number":"3","volume":"14","journal":"REMOTE SENSING","month":"February","year":"2022"}}
{"bib_id":"ma_integrating_2019","title":"Integrating Growth and Environmental Parameters to Discriminate Powdery Mildew and Aphid of Winter Wheat Using Bi-Temporal Landsat-8 Imagery","author":"Ma, Huiqin and Huang, Wenjiang and Jing, Yuanshu and Yang, Chenghai and Han, Liangxiu and Dong, Yingying and Ye, Huichun and Shi, Yue and Zheng, Qiong and Liu, Linyi and Ruan, Chao","meta_info":{"keywords":"Agriculture,Deep Learning,Disease detection,Images: Landsat,Labels: Field survey,Model: MLP,Satellite,Used VI","abstract":"Monitoring and discriminating co-epidemic diseases and pests at regional scales are of practical importance in guiding differential treatment. A combination of vegetation and environmental parameters could improve the accuracy for discriminating crop diseases and pests. Different diseases and pests could cause similar stresses and symptoms during the same crop growth period, so combining growth period information can be useful for discerning different changes in crop diseases and pests. Additionally, problems associated with imbalanced data often have detrimental effects on the performance of image classification. In this study, we developed an approach for discriminating crop diseases and pests based on bi-temporal Landsat-8 satellite imagery integrating both crop growth and environmental parameters. As a case study, the approach was applied to data during a period of typical co-epidemic outbreak of winter wheat powdery mildew and aphids in the Shijiazhuang area of Hebei Province, China. Firstly, bi-temporal remotely sensed features characterizing growth indices and environmental factors were calculated based on two Landsat-8 images. The synthetic minority oversampling technique (SMOTE) algorithm was used to resample the imbalanced training data set before model construction. Then, a back propagation neural network (BPNN) based on a new training data set balanced by the SMOTE approach (SMOTE-BPNN) was developed to generate the regional wheat disease and pest distribution maps. The original training data set-based BPNN and support vector machine (SVM) methods were used for comparison and testing of the initial results. Our findings suggest that the proposed approach incorporating both growth and environmental parameters of different crop periods could distinguish wheat powdery mildew and aphids at the regional scale. The bi-temporal growth indices and environmental factors-based SMOTE-BPNN, BPNN, and SVM models all had an overall accuracy high than 80%. Meanwhile, the SMOTE-BPNN method had the highest G-means among the three methods. These results revealed that the combination of bi-temporal crop growth and environmental parameters is essential for improving the accuracy of the crop disease and pest discriminating models. The combination of SMOTE and BPNN could effectively improve the discrimination accuracy of the minor disease or pest.","doi":"10.3390\/rs11070846","number":"7","volume":"11","journal":"REMOTE SENSING","month":"April","year":"2019"}}
{"bib_id":"macdonald_global_1980","title":"Global Crop Forecasting","author":"MacDonald, R. B. and Hall, F. G.","meta_info":{"urldate":"2022-04-14","doi":"10.1126\/science.208.4445.670","publisher":"American Association for the Advancement of Science","pages":"670--679","number":"4445","volume":"208","journal":"Science","month":"May","year":"1980"}}
{"bib_id":"mahmood_land_2014","title":"Land Cover Changes and Their Biogeophysical Effects on Climate","author":"Mahmood, Rezaul and Pielke Sr., Roger A. and Hubbard, Kenneth G. and Niyogi, Dev and Dirmeyer, Paul A. and McAlpine, Clive and Carleton, Andrew M. and Hale, Robert and Gameda, Samuel and Beltrán-Przekurat, Adriana and Baker, Bruce and McNider, Richard and Legates, David R. and Shepherd, Marshall and Du, Jinyang and Blanken, Peter D. and Frauenfeld, Oliver W. and Nair, U.s. and Fall, Souleymane","meta_info":{"abstract":"ABSTRACT Land cover changes (LCCs) play an important role in the climate system. Research over recent decades highlights the impacts of these changes on atmospheric temperature, humidity, cloud cover, circulation, and precipitation. These impacts range from the local- and regional-scale to sub-continental and global-scale. It has been found that the impacts of regional-scale LCC in one area may also be manifested in other parts of the world as a climatic teleconnection. In light of these findings, this article provides an overview and synthesis of some of the most notable types of LCC and their impacts on climate. These LCC types include agriculture, deforestation and afforestation, desertification, and urbanization. In addition, this article provides a discussion on challenges to, and future research directions in, assessing the climatic impacts of LCC.","urldate":"2022-07-12","doi":"10.1002\/joc.3736","issn":"0899-8418","publisher":"John Wiley & Sons, Ltd","pages":"929--953","number":"4","volume":"34","journal":"International Journal of Climatology","month":"March","year":"2014"}}
{"bib_id":"malerba_australian_2022","title":"Australian Farm Dams Are Becoming Less Reliable Water Sources under Climate Change","author":"Malerba, Martino E. and Wright, Nicholas and Macreadie, Peter I.","meta_info":{"keywords":"Agriculture,Dam detection,Deep Learning,Images: Various,Labels: Image survey,Model: 2DCNN,Satellite","unique-id":"WOS:000791226500013","eissn":"1879-1026","article-number":"154360","doi":"10.1016\/j.scitotenv.2022.154360","issn":"0048-9697","volume":"829","journal":"SCIENCE OF THE TOTAL ENVIRONMENT","month":"July","year":"2022"}}
{"bib_id":"malerba_continental-scale_2021","title":"A Continental-Scale Assessment of Density, Size, Distribution and Historical Trends of Farm Dams Using Deep Learning Convolutional Neural Networks","author":"Malerba, Martino E. and Wright, Nicholas and Macreadie, Peter I.","meta_info":{"keywords":"Agriculture,Dam detection,Deep Learning,Images: Various,Labels: Model-assisted survey,Model: ResNet,Satellite","abstract":"Farm dams are a ubiquitous limnological feature of agricultural landscapes worldwide. While their primary function is to capture and store water, they also have disproportionally large effects on biodiversity and biogeochemical cycling, with important relevance to several Sustainable Development Goals (SDGs). However, the abundance and distribution of farm dams is unknown in most parts of the world. Therefore, we used artificial intelligence and remote sensing data to address this critical global information gap. Specifically, we trained a deep learning convolutional neural network (CNN) on high-definition satellite images to detect farm dams and carry out the first continental-scale assessment on density, distribution and historical trends. We found that in Australia there are 1.765 million farm dams that occupy an area larger than Rhode Island (4678 km(2)) and store over 20 times more water than Sydney Harbour (10,990 GL). The State of New South Wales recorded the highest number of farm dams (654,983; 37% of the total) and Victoria the highest overall density (1.73 dams km(-2)). We also estimated that 202,119 farm dams (11.5%) remain omitted from any maps, especially in South Australia, Western Australia and the Northern Territory. Three decades of historical records revealed an ongoing decrease in the construction rate of farm dams, from $>$3% per annum before 2000, to similar to 1% after 2000, to $<$0.05% after 2010-except in the Australian Capital Territory where rates have remained relatively high. We also found systematic trends in construction design: farm dams built in 2015 are on average 50% larger in surface area and contain 66% more water than those built in 1989. To facilitate sharing information on sustainable farm dam management with authorities, scientists, managers and local communities, we developed AusDams.org-a free interactive portal to visualise and generate statistics on the physical, environmental and ecological impacts of farm dams.","doi":"10.3390\/rs13020319","number":"2","volume":"13","journal":"REMOTE SENSING","month":"January","year":"2021"}}
{"bib_id":"martini_domain-adversarial_2021","title":"Domain-Adversarial Training of Self-Attention-Based Networks for Land Cover Classification Using Multi-Temporal Sentinel-2 Satellite Imagery","author":"Martini, Mauro and Mazzia, Vittorio and Khaliq, Aleem and Chiaberge, Marcello","meta_info":{"keywords":"Agriculture,Crop segmentation,Dataset: Breizhcrops,Deep Learning,Images: Sentinel,Labels: Dataset,Model: Transformer,Satellite","abstract":"The increasing availability of large-scale remote sensing labeled data has prompted researchers to develop increasingly precise and accurate data-driven models for land cover and crop classification (LC&CC). Moreover, with the introduction of self-attention and introspection mechanisms, deep learning approaches have shown promising results in processing long temporal sequences in the multi-spectral domain with a contained computational request. Nevertheless, most practical applications cannot rely on labeled data, and in the field, surveys are a time-consuming solution that pose strict limitations to the number of collected samples. Moreover, atmospheric conditions and specific geographical region characteristics constitute a relevant domain gap that does not allow direct applicability of a trained model on the available dataset to the area of interest. In this paper, we investigate adversarial training of deep neural networks to bridge the domain discrepancy between distinct geographical zones. In particular, we perform a thorough analysis of domain adaptation applied to challenging multi-spectral, multi-temporal data, accurately highlighting the advantages of adapting state-of-the-art self-attention-based models for LC&CC to different target zones where labeled data are not available. Extensive experimentation demonstrated significant performance and generalization gain in applying domain-adversarial training to source and target regions with marked dissimilarities between the distribution of extracted features.","doi":"10.3390\/rs13132564","number":"13","volume":"13","journal":"REMOTE SENSING","month":"July","year":"2021"}}
{"bib_id":"masoud_delineation_2020","title":"Delineation of Agricultural Field Boundaries from Sentinel-2 Images Using a Novel Super-Resolution Contour Detector Based on Fully Convolutional Networks","author":"Masoud, Khairiya Mudrik and Persello, Claudio and Tolpekin, Valentyn A.","meta_info":{"keywords":"Agriculture,Deep Learning,Field boundary detection,Images: RapidEye,Images: Sentinel,Labels: Public government data,Model: 2DCNN,Satellite","abstract":"Boundaries of agricultural fields are important features necessary for defining the location, shape, and spatial extent of agricultural units. They are commonly used to summarize production statistics at the field level. In this study, we investigate the delineation of agricultural field boundaries (AFB) from Sentinel-2 satellite images acquired over the Flevoland province, the Netherlands, using a deep learning technique based on fully convolutional networks (FCNs). We designed a multiple dilation fully convolutional network (MD-FCN) for AFB detection from Sentinel-2 images at 10 m resolution. Furthermore, we developed a novel super-resolution semantic contour detection network (named SRC-Net) using a transposed convolutional layer in the FCN architecture to enhance the spatial resolution of the AFB output from 10 m to 5 m resolution. The SRC-Net also improves the AFB maps at 5 m resolution by exploiting the spatial-contextual information in the label space. The results of the proposed SRC-Net outperform alternative upsampling techniques and are only slightly inferior to the results of the MD-FCN for AFB detection from RapidEye images acquired at 5 m resolution.","doi":"10.3390\/rs12010059","number":"1","volume":"12","journal":"REMOTE SENSING","month":"January","year":"2020"}}
{"bib_id":"mazzia_improvement_2020","title":"Improvement in Land Cover and Crop Classification Based on Temporal Features Learning from Sentinel-2 Data Using Recurrent-Convolutional Neural Network (R-CNN)","author":"Mazzia, Vittorio and Khaliq, Aleem and Chiaberge, Marcello","meta_info":{"keywords":"Agriculture,Crop segmentation,Dataset: LUCAS,Deep Learning,Images: Sentinel,Labels: Dataset,Model: 2DCNN,Model: RNN,Multitemporal,Satellite,Used VI","abstract":"Understanding the use of current land cover, along with monitoring change over time, is vital for agronomists and agricultural agencies responsible for land management. The increasing spatial and temporal resolution of globally available satellite images, such as provided by Sentinel-2, creates new possibilities for researchers to use freely available multi-spectral optical images, with decametric spatial resolution and more frequent revisits for remote sensing applications such as land cover and crop classification (LC&CC), agricultural monitoring and management, environment monitoring. Existing solutions dedicated to cropland mapping can be categorized based on per-pixel based and object-based. However, it is still challenging when more classes of agricultural crops are considered at a massive scale. In this paper, a novel and optimal deep learning model for pixel-based LC&CC is developed and implemented based on Recurrent Neural Networks (RNN) in combination with Convolutional Neural Networks (CNN) using multi-temporal sentinel-2 imagery of central north part of Italy, which has diverse agricultural system dominated by economic crop types. The proposed methodology is capable of automated feature extraction by learning time correlation of multiple images, which reduces manual feature engineering and modeling crop phenological stages. Fifteen classes, including major agricultural crops, were considered in this study. We also tested other widely used traditional machine learning algorithms for comparison such as support vector machine SVM, random forest (RF), Kernal SVM, and gradient boosting machine, also called XGBoost. The overall accuracy achieved by our proposed Pixel R-CNN was 96.5%, which showed considerable improvements in comparison with existing mainstream methods. This study showed that Pixel R-CNN based model offers a highly accurate way to assess and employ time-series data for multi-temporal classification tasks.","doi":"10.3390\/app10010238","number":"1","volume":"10","journal":"APPLIED SCIENCES-BASEL","month":"January","year":"2020"}}
{"bib_id":"mcnairn_integration_2009","title":"Integration of Optical and Synthetic Aperture Radar (SAR) Imagery for Delivering Operational Annual Crop Inventories","author":"McNairn, Heather and Champagne, Catherine and Shang, Jiali and Holmstrom, Delmar and Reichert, Gordon","meta_info":{"langid":"english","abstract":"Agriculture plays a critical role within Canada's economy and, as such, sustainability of this sector is of high importance. Targeting and monitoring programs designed to promote economic and environmental sustainability are a vital component within Canada's agricultural policy. A hierarchy of land information, including up to date information on cropping practices, is needed to measure the impacts of programs on land use decision-making and to gauge the environmental and economic benefits of these investments. A multi-year, multi-site research activity was completed to develop a robust methodology to inventory crops across Canada's large and diverse agricultural landscapes. To move towards operational implementation the methodology must deliver accurate crop inventories, with consistency and reliability. In order to meet these operational requirements and to mitigate risk associated with reliance on a single data source, the methodology integrated both optical and Synthetic Aperture Radar (SAR) imagery. The results clearly demonstrated that multi-temporal satellite data can successfully classify crops for a variety of cropping systems present across Canada. Overall accuracies of at least 85% were achieved, and most major crops were also classified to this level of accuracy. Although multi-temporal optical data would be the preferred data source for crop classification, a SAR-optical dataset (two Envisat ASAR images and one optical image) provided acceptable accuracies and will mitigate risk associated with operational implementation. The preferred dual-polarization mode would be VV--VH. Not only were these promising classification results repeated year after year, but the target accuracies were met consistently for multiple sites across Canada, all with varying cropping systems.","urldate":"2022-03-30","doi":"10.1016\/j.isprsjprs.2008.07.006","issn":"0924-2716","pages":"434--449","number":"5","volume":"64","series":"Theme Issue: Mapping with SAR: Techniques and Applications","journal":"ISPRS Journal of Photogrammetry and Remote Sensing","month":"September","year":"2009"}}
{"bib_id":"mei_using_2022","title":"Using Deep Learning and Very-High-Resolution Imagery to Map Smallholder Field Boundaries","author":"Mei, Weiye and Wang, Haoyu and Fouhey, David and Zhou, Weiqi and Hinks, Isabella and Gray, Josh M. and Van Berkel, Derek and Jain, Meha","meta_info":{"keywords":"Agriculture,Deep Learning,Field boundary detection,Images: WV-3,Labels: Image survey,Model: 2DCNN,Satellite","unique-id":"WOS:000824389000001","orcid-numbers":"Jain, Meha\/0000-0002-6821-473X Gray, Josh\/0000-0003-4341-4353 Van Berkel, Derek\/0000-0002-1001-783X","eissn":"2072-4292","article-number":"3046","doi":"10.3390\/rs14133046","number":"13","volume":"14","journal":"REMOTE SENSING","month":"July","year":"2022"}}
{"bib_id":"meng_deep_2021","title":"Deep Learning-Based Crop Mapping in the Cloudy Season Using One-Shot Hyperspectral Satellite Imagery","author":"Meng, Shiyao and Wang, Xinyu and Hu, Xin and Luo, Chang and Zhong, Yanfei","meta_info":{"keywords":"Agriculture,Best Model: 3DCNN,Crop segmentation,Deep Learning,Images: Sentinel,Images: Zhuhai-1,Labels: Field survey,Labels: Image survey,Model comparison,Model: 1DCNN,Model: 3DCNN,Model: CNN,Model: RF,Model: SVM,Satellite","abstract":"Crop mapping is essential for agricultural management, economic development planning, and ecological conservation. Remote sensing with a large field of view provides us with a potential technique for large-scale crop mapping. However, most of the previous studies have focused on multi-temporal crop mapping, requiring multiple imaging over a period of time, which is impossible in the cloudy season due to the absence of clear atmospheric windows. Recently, with the progress of spaceborne hyperspectral imaging technology, wide-width hyperspectral satellite images, which provide abundant spectral and spatial structure information, have made the precision crop mapping of large areas possible. This paper focuses on deep learning based crop mapping using one-shot hyperspectral satellite imagery, where three convolutional neural network (CNN) models, i.e., 1D-CNN, 2D-CNN, and 3D-CNN models, are applied for end-to-end crop mapping. In addition, a manifold learning based visualization approach, i.e., t-distributed stochastic neighbor embedding (t-SNE), is introduced to illustrate the discriminative ability of the deep semantic features extracted by the different CNN models. To demonstrate the advantages of one-shot hyperspectral satellite images, an experiment was designed to compare the crop mapping performance of different remote sensing data sources, where both mono-temporal and multi-temporal multispectral images (MSIs) of the same research area were introduced for a systematic comparison. The classification accuracy when using hyperspectral satellite images was found to reach more than 94%, which was much better than that when using mono-temporal MSIs, and was comparable to the result when using multi-temporal MSIs. These findings will be important for the application of hyperspectral data when mapping large-area crop landscapes, and they confirm the potential of CNN models, particularly 3D-CNN models, for crop recognition.","doi":"10.1016\/j.compag.2021.106188","issn":"0168-1699","volume":"186","journal":"COMPUTERS AND ELECTRONICS IN AGRICULTURE","month":"July","year":"2021"}}
{"bib_id":"metternicht_remote_2003","title":"Remote Sensing of Soil Salinity: Potentials and Constraints","author":"Metternicht, G. I and Zinck, J. A","meta_info":{"file":"\/home\/brandon\/Zotero\/storage\/TPERIWDP\/S0034425702001888.html","langid":"english","abstract":"Soil salinity caused by natural or human-induced processes is a major environmental hazard. The global extent of primary salt-affected soils is about 955 M ha, while secondary salinization affects some 77 M ha, with 58% of these in irrigated areas. Nearly 20% of all irrigated land is salt-affected, and this proportion tends to increase in spite of considerable efforts dedicated to land reclamation. This requires careful monitoring of the soil salinity status and variation to curb degradation trends, and secure sustainable land use and management. Multitemporal optical and microwave remote sensing can significantly contribute to detecting temporal changes of salt-related surface features. Airborne geophysics and ground-based electromagnetic induction meters, combined with ground data, have shown potential for mapping depth of salinity occurrence. This paper reviews various sensors (e.g. aerial photographs, satellite- and airborne multispectral sensors, microwave sensors, video imagery, airborne geophysics, hyperspectral sensors, and electromagnetic induction meters) and approaches used for remote identification and mapping of salt-affected areas. Constraints on the use of remote sensing data for mapping salt-affected areas are shown related to the spectral behaviour of salt types, spatial distribution of salts on the terrain surface, temporal changes on salinity, interference of vegetation, and spectral confusions with other terrain surfaces. As raw remote sensing data need substantial transformation for proper feature recognition and mapping, techniques such as spectral unmixing, maximum likelihood classification, fuzzy classification, band ratioing, principal components analysis, and correlation equations are discussed. Lastly, the paper presents modelling of temporal and spatial changes of salinity using combined approaches that incorporate different data fusion and data integration techniques.","urldate":"2022-06-09","doi":"10.1016\/S0034-4257(02)00188-8","issn":"0034-4257","pages":"1--20","number":"1","volume":"85","journal":"Remote Sensing of Environment","month":"April","year":"2003","shorttitle":"Remote Sensing of Soil Salinity"}}
{"bib_id":"metzger_crop_2022","title":"Crop Classification Under Varying Cloud Cover With Neural Ordinary Differential Equations","author":"Metzger, Nando and Turkoglu, Mehmet Ozgur and D'Aronco, Stefano and Wegner, Jan Dirk and Schindler, Konrad","meta_info":{"keywords":"Agriculture,Best Model: GRU,Crop segmentation,Dataset: ZueriCrop,Deep Learning,Images: Sentinel,Labels: Dataset,Model comparison,Model: GRU,Model: LSTM,Model: Transformer,Satellite","abstract":"Optical satellite sensors cannot see the earth's surface through clouds. Despite the periodic revisit cycle, image sequences acquired by earth observation satellites are, therefore, irregularly sampled in time. State-of-the-art methods for crop classification (and other time-series analysis tasks) rely on techniques that implicitly assume regular temporal spacing between observations, such as recurrent neural networks (RNNs). We propose to use neural ordinary differential equations (NODEs) in combination with RNNs to classify crop types in irregularly spaced image sequences. The resulting ODE-RNN models consist of two steps: an update step, where a recurrent unit assimilates new input data into the model's hidden state, and a prediction step, in which NODE propagates the hidden state until the next observation arrives. The prediction step is based on a continuous representation of the latent dynamics, which has several advantages. At the conceptual level, it is a more natural way to describe the mechanisms that govern the phenological cycle. From a practical point of view, it makes it possible to sample the system state at arbitrary points in time such that one can integrate observations whenever they are available and extrapolate beyond the last observation. Our experiments show that ODE-RNN, indeed, improves classification accuracy over common baselines, such as LSTM, GRU, temporal convolutional network, and transformer. The gains are most prominent in the challenging scenario where only few observations are available (i.e., frequent cloud cover). Moreover, we show that the ability to extrapolate translates to better classification performance early in the season, which is important for forecasting.","doi":"10.1109\/TGRS.2021.3101965","issn":"1558-0644","pages":"1--12","volume":"60","journal":"IEEE Transactions on Geoscience and Remote Sensing","year":"2022"}}
{"bib_id":"miller_users_2013","title":"Users, Uses, and Value of Landsat Satellite Imagery: Results from the 2012 Survey of Users","author":"Miller, Holly M. and Richardson, Leslie A. and Koontz, Stephen R. and Loomis, John and Koontz, Lynne","meta_info":{"langid":"english","abstract":"Landsat satellites have been operating since 1972, providing a continuous global record of the Earth's land surface. The imagery is currently available at no cost through the U.S. Geological Survey (USGS). Social scientists at the USGS Fort Collins Science Center conducted an extensive survey in early 2012 to explore who uses Landsat imagery, how they use the imagery, and what the value of the imagery is to them. The survey was sent to all users registered with USGS who had accessed Landsat imagery in the year prior to the survey and over 11,000 current Landsat imagery users responded. The results of the survey revealed that respondents from many sectors use Landsat imagery in myriad project locations and scales, as well as application areas. The value of Landsat imagery to these users was demonstrated by the high importance of and dependence on the imagery, the numerous environmental and societal benefits observed...","urldate":"2024-05-17","doi":"10.3133\/ofr20131269","issn":"2331-1258","institution":"U.S. Geological Survey","number":"2013-1269","journal":"Open-File Report","year":"2013","shorttitle":"Users, Uses, and Value of Landsat Satellite Imagery"}}
{"bib_id":"moreno-revelo_enhanced_2021","title":"Enhanced Convolutional-Neural-Network Architecture for Crop Classification","author":"Moreno-Revelo, Monica Y. and Guachi-Guachi, Lorena and Gomez-Mendoza, Juan Bernardo and Revelo-Fuelagan, Javier and Peluffo-Ordonez, Diego H.","meta_info":{"keywords":"Agriculture,Crop segmentation,Dataset: Campo verde,Deep Learning,Images: Landsat,Images: Sentinel,Labels: Dataset,Model: CNN,Model: LSTM,Multitemporal,Satellite","abstract":"Automatic crop identification and monitoring is a key element in enhancing food production processes as well as diminishing the related environmental impact. Although several efficient deep learning techniques have emerged in the field of multispectral imagery analysis, the crop classification problem still needs more accurate solutions. This work introduces a competitive methodology for crop classification from multispectral satellite imagery mainly using an enhanced 2D convolutional neural network (2D-CNN) designed at a smaller-scale architecture, as well as a novel post-processing step. The proposed methodology contains four steps: image stacking, patch extraction, classification model design (based on a 2D-CNN architecture), and post-processing. First, the images are stacked to increase the number of features. Second, the input images are split into patches and fed into the 2D-CNN model. Then, the 2D-CNN model is constructed within a small-scale framework, and properly trained to recognize 10 different types of crops. Finally, a post-processing step is performed in order to reduce the classification error caused by lower-spatial-resolution images. Experiments were carried over the so-named Campo Verde database, which consists of a set of satellite images captured by Landsat and Sentinel satellites from the municipality of Campo Verde, Brazil. In contrast to the maximum accuracy values reached by remarkable works reported in the literature (amounting to an overall accuracy of about 81%, a f(1) score of 75.89%, and average accuracy of 73.35%), the proposed methodology achieves a competitive overall accuracy of 81.20%, a f(1) score of 75.89%, and an average accuracy of 88.72% when classifying 10 different crops, while ensuring an adequate trade-off between the number of multiply-accumulate operations (MACs) and accuracy. Furthermore, given its ability to effectively classify patches from two image sequences, this methodology may result appealing for other real-world applications, such as the classification of urban materials.","doi":"10.3390\/app11094292","number":"9","volume":"11","journal":"APPLIED SCIENCES-BASEL","month":"May","year":"2021"}}
{"bib_id":"moumni_machine_2021","title":"Machine Learning-Based Classification for Crop-Type Mapping Using the Fusion of High-Resolution Satellite Imagery in a Semiarid Area","author":"Moumni, Aicha and Lahrouni, Abderrahman","meta_info":{"keywords":"Agriculture,Best Model: SVM,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Field survey,Labels: Image survey,Model comparison,Model: MLP,Model: RF,Model: SVM,Satellite","abstract":"The monitoring of cultivated crops and the types of different land covers is a relevant environmental and economic issue for agricultural lands management and crop yield prediction. In this context, this paper aims to use and evaluate the contribution of multisensors classification based on machine learning classifiers to crop-type identification in a semiarid area of Morocco. It is a very heterogeneous zone characterized by mixed crops (tree crops with annual crops, same crop with different phenological states during the same agricultural season, crop rotation, etc.). Therefore, such heterogeneity made the crop-type discrimination more complicated. To overcome these challenges, the present work is the first study in this area which used the fusion of high spatiotemporal resolution Sentinel-1 and Sentinel-2 satellite images for land use and land cover mapping. Three machine learning classifier algorithms, artificial neural network (ANN), support vector machine (SVM), and maximum likelihood (ML), were applied to identify and map crop types in irrigated perimeter. In situ observations of the year 2018, for the R3 perimeter of Haouz plain in central Morocco, were used with satellite data of the same year to perform this work. The results showed that combined images acquired in C-band and the optical range improved clearly the crop-type classification performance (overall accuracy = 89%; Kappa = 0.85) compared to the classification results of optical or SAR data alone.","doi":"10.1155\/2021\/8810279","issn":"2090-908X","volume":"2021","journal":"SCIENTIFICA","month":"April","year":"2021"}}
{"bib_id":"mukharamova_estimating_2021","title":"Estimating the Soil Erosion Cover-Management Factor at the European Part of Russia","author":"Mukharamova, Svetlana and Saveliev, Anatoly and Ivanov, Maxim and Gafurov, Artur and Yermolaev, Oleg","meta_info":{"keywords":"Agriculture,Best Model: LSTM,Crop segmentation,Deep Learning,Images: MODIS,Model comparison,Model: LSTM,Model: MLP,Model: RF,Satellite","abstract":"Evaluation of the vegetation and agricultural-management factor (C-factor) is an important task, the solution of which affects the correct assessment of the intensity of soil erosion. For the vast area of the European part of Russia (EPR), this task is particularly relevant since no products allow taking into account the C-factor. An approach based on automated interpretation of the main crop groups based on MODIS satellite imaging data from Terra and Aqua satellites with the LSTM machine-learning method was used to achieve this goal. The accuracy of crop group recognition compared to the open data of the Federal State Statistics Service of Russia was 94%. The resulting crop maps were used to calculate the C-factor for each month of a particular year from 2014 to 2019. After that, summaries were made at the regional and landscape levels. The average C-factor value for the EPR was 0.401, for the forest landscape zone 0.262, for the forest-steppe zone 0.362, and for the steppe zone 0.454. The obtained results are in good correlation with the results of previous field studies and provide up-to-date (based on 2014-2019 data) estimates of C-factor for rainfall erosion (monthly, annual) with high spatial detail (250 m).","doi":"10.3390\/ijgi10100645","number":"10","volume":"10","journal":"ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION","month":"October","year":"2021"}}
{"bib_id":"muradyan_estimating_2020","title":"Estimating Mo, Cu, Ni, Cd Contents in the Crop Leaves Growing on Small Land Plots Using Satellite Data","author":"Muradyan, Vahagn and Tepanosyan, Garegin and Asmaryan, Shushanik and Maghakyan, Nairuhi and Sahakyan, Lilit and Saghatelyan, Armen","meta_info":{"keywords":"Agriculture,Deep Learning,Heavy metal pollution regression,Heavy metal pollution regression through plants,Images: SPOT,Labels: Field survey,Model: Non-standard MLP,Satellite","abstract":"The main goal of this research was to estimate heavy metals (HMs) (molybdenum (Mo), copper (Cu), nickel (Ni), cadmium (Cd)) contents in crop leaves through multispectral satellite imagery. During the acquisition of a SPOT 7 satellite image (28 July 2017) in situ sampling (38 samples) was done from the leaves of potatoes and beans growing close to the mining town of Kajaran (Armenia). To estimate HMs contents, multivariate regression (multiple linear regression (MLR), partial least squares regression (PLSR)), and artificial neural network (ANN) were used. As input data for the models raw, atmospherically corrected (Dark Object Subtraction (DOS)) and hyperspherical direction cosines (HSDC) normalized values of SPOT 7 spectral data in combination with one or combined log10, multiplicative scatter correction (MSC), standard normal variate transform (SNV) preprocessing methods were utilized. The best results were obtained for Cu using MLR (R-cal.(2) = 0.79, R-CV(2) = 0.70, RMSEcal. = 11.27, RMSECV = 13.47) and ANN (R-Train(2)approximate to 0.80, R-Test(2)approximate to 0.72, RMSETrain approximate to 11, RMSETest approximate to 13) models in case of bean leaves. The results are quite optimistic, however, further research with the use of high spatial\/spectral resolution satellite images is needed to improve the accuracy of models.","doi":"10.1080\/00103624.2020.1784922","issn":"0010-3624","pages":"1457--1468","number":"11","volume":"51","journal":"COMMUNICATIONS IN SOIL SCIENCE AND PLANT ANALYSIS","month":"June","year":"2020"}}
{"bib_id":"ndikumana_deep_2018","title":"Deep Recurrent Neural Network for Agricultural Classification Using Multitemporal SAR Sentinel-1 for Camargue, France","author":"Ndikumana, Emile and Minh, Dinh Ho Tong and Baghdadi, Nicolas and Courault, Dominique and Hossard, Laure","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Image survey,Model comparison,Model: GRU,Model: LSTM,Model: RF,Model: SVM,Multitemporal,Satellite","abstract":"The development and improvement of methods to map agricultural land cover are currently major challenges, especially for radar images. This is due to the speckle noise nature of radar, leading to a less intensive use of radar rather than optical images. The European Space Agency Sentinel-1 constellation, which recently became operational, is a satellite system providing global coverage of Synthetic Aperture Radar (SAR) with a 6-days revisit period at a high spatial resolution of about 20 m. These data are valuable, as they provide spatial information on agricultural crops. The aim of this paper is to provide a better understanding of the capabilities of Sentinel-1 radar images for agricultural land cover mapping through the use of deep learning techniques. The analysis is carried out on multitemporal Sentinel-1 data over an area in Camargue, France. The data set was processed in order to produce an intensity radar data stack from May 2017 to September 2017. We improved this radar time series dataset by exploiting temporal filtering to reduce noise, while retaining as much as possible the fine structures present in the images. We revealed that even with classical machine learning approaches (K nearest neighbors, random forest, and support vector machines), good performance classification could be achieved with F-measure\/Accuracy greater than 86% and Kappa coefficient better than 0.82. We found that the results of the two deep recurrent neural network (RNN)-based classifiers clearly outperformed the classical approaches. Finally, our analyses of the Camargue area results show that the same performance was obtained with two different RNN-based classifiers on the Rice class, which is the most dominant crop of this region, with a F-measure metric of 96%. These results thus highlight that in the near future these RNN-based techniques will play an important role in the analysis of remote sensing time series.","doi":"10.3390\/rs10081217","number":"8","volume":"10","journal":"REMOTE SENSING","month":"August","year":"2018"}}
{"bib_id":"nguyen_monitoring_2020","title":"Monitoring Agriculture Areas with Satellite Images and Deep Learning","author":"Nguyen, Thanh Tam and Hoang, Thanh Dat and Pham, Minh Tam and Vu, Tuyet Trinh and Nguyen, Thanh Hung and Huynh, Quyet-Thang and Jo, Jun","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Commercial,Images: Landsat,Images: Sentinel,Labels: Field survey,Model: 2DCNN,Model: LSTM,Model: VGG,Satellite","abstract":"Agriculture applications rely on accurate land monitoring, especially paddy areas, for timely food security control and support actions. However, traditional monitoring requires field works or surveys performed by experts, which is costly, slow, and sparse. Agriculture monitoring systems are looking for sustainable land use monitoring solutions, starting with remote sensing on satellite data for cheap and timely paddy mapping. The aim of this study is to develop an autonomous and intelligent system built on top of imagery data streams, which is available from low-Earth orbiting satellites, to differentiate crop areas from non-crop areas. However, such agriculture mapping framework poses unique challenges for satellite image processing, including the seasonal nature of crop, the complexity of spectral channels, and adversarial conditions such as cloud and solar radiance. In this paper, we propose a novel multi-temporal high-spatial resolution classification method with an advanced spatiotemporal-spectral deep neural network to locate paddy fields at the pixel level for a whole year long and for each temporal instance. Our method is built and tested on the case study of Landsat 8 data due to its high spatial resolution. Empirical evaluations on real imagery datasets of different landscapes from 2016 to 2018 show the superior of our mapping model against the baselines with over 0.93 F1-score, the importance of each model design, the robustness against seasonal effects, and the visual mapping results. (C) 2020 Elsevier B.V. All rights reserved.","doi":"10.1016\/j.asoc.2020.106565","issn":"1568-4946","volume":"95","journal":"APPLIED SOFT COMPUTING","month":"October","year":"2020"}}
{"bib_id":"nickmilder_development_2021","title":"Development of Machine Learning Models to Predict Compressed Sward Height in Walloon Pastures Based on Sentinel-1, Sentinel-2 and Meteorological Data Using Multiple Data Transformations","author":"Nickmilder, Charles and Tedde, Anthony and Dufrasne, Isabelle and Lessire, Francoise and Tychon, Bernard and Curnel, Yannick and Bindelle, Jerome and Soyeurt, Helene","meta_info":{"keywords":"Agriculture,Deep Learning,Extra data: climate,Grassland biomass prediction,Images: Sentinel,Labels: Field survey,Model comparison,Model: MLP,Model: RF,Model: SVM,Satellite,Used VI","abstract":"Accurate information about the available standing biomass on pastures is critical for the adequate management of grazing and its promotion to farmers. In this paper, machine learning models are developed to predict available biomass expressed as compressed sward height (CSH) from readily accessible meteorological, optical (Sentinel-2) and radar satellite data (Sentinel-1). This study assumed that combining heterogeneous data sources, data transformations and machine learning methods would improve the robustness and the accuracy of the developed models. A total of 72,795 records of CSH with a spatial positioning, collected in 2018 and 2019, were used and aggregated according to a pixel-like pattern. The resulting dataset was split into a training one with 11,625 pixellated records and an independent validation one with 4952 pixellated records. The models were trained with a 19-fold cross-validation. A wide range of performances was observed (with mean root mean square error (RMSE) of cross-validation ranging from 22.84 mm of CSH to infinite-like values), and the four best-performing models were a cubist, a glmnet, a neural network and a random forest. These models had an RMSE of independent validation lower than 20 mm of CSH at the pixel-level. To simulate the behavior of the model in a decision support system, performances at the paddock level were also studied. These were computed according to two scenarios: either the predictions were made at a sub-parcel level and then aggregated, or the data were aggregated at the parcel level and the predictions were made for these aggregated data. The results obtained in this study were more accurate than those found in the literature concerning pasture budgeting and grassland biomass evaluation. The training of the 124 models resulting from the described framework was part of the realization of a decision support system to help farmers in their daily decision making.","doi":"10.3390\/rs13030408","number":"3","volume":"13","journal":"REMOTE SENSING","month":"February","year":"2021"}}
{"bib_id":"nielsen_canopy_2012","title":"Canopy Cover and Leaf Area Index Relationships for Wheat, Triticale, and Corn","author":"Nielsen, David C. and Miceli-Garcia, Juan J. and Lyon, Drew J.","meta_info":{"langid":"english","abstract":"Previously collected data sets that would be useful for calibrating and validating AquaCrop contain only leaf area index (LAI) data but could be used if relationships were available relating LAI to canopy cover (CC). The objective of this experiment was to determine relationships between LAI and CC for corn (Zea mays L.), winter wheat (Triticum aestivum L.), and spring triticale (×Triticosecale spp.) grown under dryland or very limited irrigation conditions. The LAI and CC data were collected during 2010 and 2011 at Akron, CO, and Sidney, NE, using a plant canopy analyzer and point analysis of above-canopy digital photographs. Strong relationships were found between LAI and CC that followed the exponential rise to a maximum form. The relationship for corn was similar to a previously published relationship for LAI $<$2 m2 m-2 but predicted lower CC for greater LAI. Relationships for wheat and triticale were similar to each other.","urldate":"2022-05-10","doi":"10.2134\/agronj2012.0107n","issn":"1435-0645","pages":"1569--1573","number":"6","volume":"104","journal":"Agronomy Journal","year":"2012"}}
{"bib_id":"njoku_soil_2003","title":"Soil Moisture Retrieval from AMSR-E","author":"Njoku, E.G. and Jackson, T.J. and Lakshmi, V. and Chan, T.K. and Nghiem, S.V.","meta_info":{"file":"\/home\/brandon\/Zotero\/storage\/HE2WH2XA\/Njoku et al. - 2003 - Soil moisture retrieval from AMSR-E.pdf;\/home\/brandon\/Zotero\/storage\/PGH2E9NC\/1196040.html","abstract":"The Advanced Microwave Scanning Radiometer (AMSR-E) on the Earth Observing System (EOS) Aqua satellite was launched on May 4, 2002. The AMSR-E instrument provides a potentially improved soil moisture sensing capability over previous spaceborne radiometers such as the Scanning Multichannel Microwave Radiometer and Special Sensor Microwave\/Imager due to its combination of low frequency and higher spatial resolution (approximately 60 km at 6.9 GHz). The AMSR-E soil moisture retrieval approach and its implementation are described in this paper. A postlaunch validation program is in progress that will provide evaluations of the retrieved soil moisture and enable improved hydrologic applications of the data. Key aspects of the validation program include assessments of the effects on retrieved soil moisture of variability in vegetation water content, surface temperature, and spatial heterogeneity. Examples of AMSR-E brightness temperature observations over land are shown from the first few months of instrument operation, indicating general features of global vegetation and soil moisture variability. The AMSR-E sensor calibration and extent of radio frequency interference are currently being assessed, to be followed by quantitative assessments of the soil moisture retrievals.","doi":"10.1109\/TGRS.2002.808243","issn":"1558-0644","pages":"215--229","number":"2","volume":"41","journal":"IEEE Transactions on Geoscience and Remote Sensing","month":"February","year":"2003"}}
{"bib_id":"nyborg_timematch_2022","title":"TimeMatch: Unsupervised Cross-Region Adaptation by Temporal Shift Estimation","author":"Nyborg, Joachim and Pelletier, Charlotte and Lefevre, Sebastien and Assent, Ira","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Public government data,Model: PSE-TAE,Satellite","unique-id":"WOS:000799999700001","orcid-numbers":"Assent, Ira\/0000-0002-1091-9948","eissn":"1872-8235","doi":"10.1016\/j.isprsjprs.2022.04.018","issn":"0924-2716","pages":"301--313","volume":"188","journal":"ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING","month":"June","year":"2022"}}
{"bib_id":"ofori-ampofo_crop_2021","title":"Crop Type Mapping from Optical and Radar Time Series Using Attention-Based Deep Learning","author":"Ofori-Ampofo, Stella and Pelletier, Charlotte and Lang, Stefan","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Public government data,Model: PSE-TAE,Satellite","langid":"english","copyright":"http:\/\/creativecommons.org\/licenses\/by\/3.0\/","abstract":"Crop maps are key inputs for crop inventory production and yield estimation and can inform the implementation of effective farm management practices. Producing these maps at detailed scales requires exhaustive field surveys that can be laborious, time-consuming, and expensive to replicate. With a growing archive of remote sensing data, there are enormous opportunities to exploit dense satellite image time series (SITS), temporal sequences of images over the same area. Generally, crop type mapping relies on single-sensor inputs and is solved with the help of traditional learning algorithms such as random forests or support vector machines. Nowadays, deep learning techniques have brought significant improvements by leveraging information in both spatial and temporal dimensions, which are relevant in crop studies. The concurrent availability of Sentinel-1 (synthetic aperture radar) and Sentinel-2 (optical) data offers a great opportunity to utilize them jointly; however, optimizing their synergy has been understudied with deep learning techniques. In this work, we analyze and compare three fusion strategies (input, layer, and decision levels) to identify the best strategy that optimizes optical-radar classification performance. They are applied to a recent architecture, notably, the pixel-set encoder--temporal attention encoder (PSE-TAE) developed specifically for object-based classification of SITS and based on self-attention mechanisms. Experiments are carried out in Brittany, in the northwest of France, with Sentinel-1 and Sentinel-2 time series. Input and layer-level fusion competitively achieved the best overall F-score surpassing decision-level fusion by 2%. On a per-class basis, decision-level fusion increased the accuracy of dominant classes, whereas layer-level fusion improves up to 13% for minority classes. Against single-sensor baseline, multi-sensor fusion strategies identified crop types more accurately: for example, input-level outperformed Sentinel-2 and Sentinel-1 by 3% and 9% in F-score, respectively. We have also conducted experiments that showed the importance of fusion for early time series classification and under high cloud cover condition.","urldate":"2022-03-10","doi":"10.3390\/rs13224668","issn":"2072-4292","publisher":"Multidisciplinary Digital Publishing Institute","pages":"4668","number":"22","volume":"13","journal":"Remote Sensing","month":"January","year":"2021"}}
{"bib_id":"paul_generating_2022","title":"Generating Pre-Harvest Crop Maps by Applying Convolutional Neural Network on Multi-Temporal Sentinel-1 Data","author":"Paul, Subir and Kumari, Mamta and Murthy, C. S. and Kumar, D. Nagesh","meta_info":{"keywords":"Agriculture,Best Model: 2DCNN,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Field survey,Model comparison,Model: 2DCNN,Model: RF,Model: SVM,Satellite","abstract":"Pre-harvest crop mapping, the fundamental requirement for many of the crop management decisions, continues to be challenging either due to cloud cover in satellite images or due to spectral separability issues. These limitations are overcome in this study by using Synthetic Aperture Radar (SAR) data and deep learning technique. Two-dimensional convolutional neural network (2D-CNN) architecture is applied on multi-temporal SAR data of Sentinel-1 to classify soybean, jowar, cotton and sugarcane crops in a large geographic area located in a Central Indian state. Classification experiments are conducted with full season data from nine overpasses in three modes namely VH alone, VH and VH\/VV ratio, and VH and VV, and these experimental results reveal that VH and VV combination performed better with an overall accuracy of 91.75% as compared to 84.96% and 88.75% respectively by others. Classification performances with three sets of temporal data, covering part of the season, reveal that crop map can be generated as early as 27th August (i.e. roughly 45 days prior harvesting) with an accuracy of 89.15% slightly less than the mapping accuracy achieved with full season data (i.e. till 14th October). 2D-CNN algorithm has performed better than SVM and RF techniques. This methodology can be extended to similar agro-ecological regions of the country. Richly available SAR data from Sentinel-1 and the potential of deep learning techniques for recognising complex phenological patterns offer immense opportunities for early-season crop mapping even during monsoon season in tropical countries like India.","doi":"10.1080\/01431161.2022.2030072","issn":"0143-1161","journal":"INTERNATIONAL JOURNAL OF REMOTE SENSING","month":"February","year":"2022"}}
{"bib_id":"pavlovic_monitoring_2022","title":"Monitoring the Impact of Large Transport Infrastructure on Land Use and Environment Using Deep Learning and Satellite Imagery","author":"Pavlovic, Marko and Ilic, Slobodan and Antonic, Nenad and Culibrk, Dubravko","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Image survey,Model: 2DCNN,Satellite","unique-id":"WOS:000803150200001","orcid-numbers":"Pavlovic, Marko\/0000-0003-0898-5441 Culibrk, Dubravko\/0000-0003-3417-1687 Antonic, Nenad\/0000-0002-8773-5776 Ilic, Slobodan\/0000-0001-7771-6128","eissn":"2072-4292","article-number":"2494","doi":"10.3390\/rs14102494","number":"10","volume":"14","journal":"REMOTE SENSING","month":"May","year":"2022"}}
{"bib_id":"pedrayes_evaluation_2021","title":"Evaluation of Semantic Segmentation Methods for Land Use with Spectral Imaging Using Sentinel-2 and PNOA Imagery","author":"Pedrayes, Oscar D. and Lema, Dario G. and Garcia, Daniel F. and Usamentiaga, Ruben and Alonso, Angela","meta_info":{"keywords":"Agriculture,Best Model: DeepLabv3,Crop segmentation,Dataset: UOPNOA,Dataset: UOS2,Deep Learning,Labels: Dataset,Model: DeepLabv3,Model: RF,Model: SVM,Model: UNet,Satellite","abstract":"Land use classification using aerial imagery can be complex. Characteristics such as ground sampling distance, resolution, number of bands and the information these bands convey are the keys to its accuracy. Random Forest is the most widely used approach but better and more modern alternatives do exist. In this paper, state-of-the-art methods are evaluated, consisting of semantic segmentation networks such as UNet and DeepLabV3+. In addition, two datasets based on aircraft and satellite imagery are generated as a new state of the art to test land use classification. These datasets, called UOPNOA and UOS2, are publicly available. In this work, the performance of these networks and the two datasets generated are evaluated. This paper demonstrates that ground sampling distance is the most important factor in obtaining good semantic segmentation results, but a suitable number of bands can be as important. This proves that both aircraft and satellite imagery can produce good results, although for different reasons. Finally, cost performance for an inference prototype is evaluated, comparing various Microsoft Azure architectures. The evaluation concludes that using a GPU is unnecessarily costly for deployment. A GPU need only be used for training.","doi":"10.3390\/rs13122292","number":"12","volume":"13","journal":"REMOTE SENSING","month":"June","year":"2021"}}
{"bib_id":"pena_object-based_2014","title":"Object-Based Image Classification of Summer Crops with Machine Learning Methods","author":"Pena, Jose M. and Gutierrez, Pedro A. and Hervas-Martinez, Cesar and Six, Johan and Plant, Richard E. and Lopez-Granados, Francisca","meta_info":{"keywords":"Agriculture,Best Model: SVM,Crop segmentation,Deep Learning,Images: ASTER,Labels: Private government data,Model comparison,Model: MLP,Model: RF,Model: SVM,Satellite","abstract":"The strategic management of agricultural lands involves crop field monitoring each year. Crop discrimination via remote sensing is a complex task, especially if different crops have a similar spectral response and cropping pattern. In such cases, crop identification could be improved by combining object-based image analysis and advanced machine learning methods. In this investigation, we evaluated the C4.5 decision tree, logistic regression (LR), support vector machine (SVM) and multilayer perceptron (MLP) neural network methods, both as single classifiers and combined in a hierarchical classification, for the mapping of nine major summer crops (both woody and herbaceous) from ASTER satellite images captured in two different dates. Each method was built with different combinations of spectral and textural features obtained after the segmentation of the remote images in an object-based framework. As single classifiers, MLP and SVM obtained maximum overall accuracy of 88%, slightly higher than LR (86%) and notably higher than C4.5 (79%). The SVM+SVM classifier (best method) improved these results to 89%. In most cases, the hierarchical classifiers considerably increased the accuracy of the most poorly classified class (minimum sensitivity). The SVM+SVM method offered a significant improvement in classification accuracy for all of the studied crops compared to the conventional decision tree classifier, ranging between 4% for safflower and 29% for corn, which suggests the application of object-based image analysis and advanced machine learning methods in complex crop classification tasks.","doi":"10.3390\/rs6065019","pages":"5019--5041","number":"6","volume":"6","journal":"REMOTE SENSING","month":"June","year":"2014"}}
{"bib_id":"peng_new_2022","title":"A New Method for Estimating Soil Fertility Using Extreme Gradient Boosting and a Backpropagation Neural Network","author":"Peng, Yiping and Liu, Zhenhua and Lin, Chenjie and Hu, Yueming and Zhao, Li and Zou, Runyan and Wen, Ya and Mao, Xiaoyun","meta_info":{"keywords":"Agriculture,Deep Learning,Images: Sentinel,Labels: Field survey,Model: MLP,Model: XGB,Satellite","unique-id":"WOS:000833160000001","eissn":"2072-4292","article-number":"3311","doi":"10.3390\/rs14143311","number":"14","volume":"14","journal":"REMOTE SENSING","month":"July","year":"2022"}}
{"bib_id":"persello_delineation_2019","title":"Delineation of Agricultural Fields in Smallholder Farms from Satellite Images Using Fully Convolutional Networks and Combinatorial Grouping","author":"Persello, C. and Tolpekin, V. A. and Bergado, J. R. and de By, R. A.","meta_info":{"keywords":"Agriculture,Deep Learning,Field boundary detection,Images: WV-2,Images: WV-3,Labels: Image survey,Model: 2DCNN,Satellite","abstract":"Accurate spatial information of agricultural fields in smallholder farms is important for providing actionable information to farmers, managers, and policymakers. Very High Resolution (VHR) satellite images can capture such information. However, the automated delineation of fields in smallholder farms is a challenging task because of their small size, irregular shape and the use of mixed-cropping systems, which make their boundaries vaguely defined. Physical edges between smallholder fields are often indistinct in satellite imagery and contours need to be identified by considering the transition of the complex textural pattern between fields. In these circumstances, standard edge-detection algorithms fail to extract accurate boundaries. This article introduces a strategy to detect field boundaries using a fully convolutional network in combination with a globalisation and grouping algorithm. The convolutional network using an encoder-decoder structure is capable of learning complex spatial-contextual features from the image and accurately detects sparse field contours. A hierarchical segmentation is derived from the contours using the oriented watershed transform and by iteratively merging adjacent regions based on the average strength of their common boundary. Finally, field segments are obtained by adopting a combinatorial grouping algorithm exploiting the information of the segmentation hierarchy. An extensive experimental analysis is performed in two study areas in Nigeria and Mali using WorldView-2\/3 images and comparing several state-of-the-art contour detection algorithms. The algorithms are compared based on the precision-recall accuracy assessment strategy which is tolerating small localisation errors in the detected contours. The proposed strategy shows promising results by automatically delineating field boundaries with F-scores higher than 0.7 and 0.6 on our two test areas, respectively, outperforming alternative techniques.","doi":"10.1016\/j.rse.2019.111253","issn":"0034-4257","volume":"231","journal":"REMOTE SENSING OF ENVIRONMENT","month":"September","year":"2019"}}
{"bib_id":"pignatti_sino-eu_2021","title":"Sino-EU Earth Observation Data to Support the Monitoring and Management of Agricultural Resources","author":"Pignatti, Stefano and Casa, Raffaele and Laneve, Giovanni and Li, Zhenhai and Liu, Linyi and Marzialetti, Pablo and Mzid, Nada and Pascucci, Simone and Silvestro, Paolo Cosmo and Tolomio, Massimo and Upreti, Deepak and Yang, Hao and Yang, Guijun and Huang, Wenjiang","meta_info":{"keywords":"Agriculture,Deep Learning,Disease detection,Images: PRISMA,Images: RapidEye,Images: Sentinel,Labels: Field survey,Model: MLP,Satellite","abstract":"Novel approaches and algorithms to estimate crop physiological processes from Earth Observation (EO) data are essential to develop more sustainable management practices in agricultural systems. Within this context, this paper presents the results of different research activities carried out within the ESA-MOST Dragon 4 programme. The paper encompasses two research avenues: (a) the retrieval of biophysical variables of crops and yield prediction; and (b) food security related to different crop management strategies. Concerning the retrieval of variables, results show that LAI, derived by radiative transfer model (RTM) inversion, when assimilated into a crop growth model (i.e., SAFY) provides a way to assess yields with a higher accuracy with respect to open loop model runs: 1.14 t center dot ha(-1) vs 4.42 t center dot ha(-1) RMSE for assimilation and open loop, respectively. Concerning food security, results show that different pathogens could be detected by remote sensing satellite data. A k coefficient higher than 0.84 was achieved for yellow rust, thus assuring a monitoring accuracy, and for the diseased samples k was higher than 0.87. Concerning permanent crops, neural network (NN) algorithms allow classification of the Pseudomonas syringae pathogen on kiwi orchards with an overall accuracy higher than 91%.","doi":"10.3390\/rs13152889","number":"15","volume":"13","journal":"REMOTE SENSING","month":"August","year":"2021"}}
{"bib_id":"potopova_statistical_2020","title":"Statistical Modelling of Drought-Related Yield Losses Using Soil Moisture-Vegetation Remote Sensing and Multiscalar Indices in the South-Eastern Europe","author":"Potopova, Vera and Trnka, Miroslav and Hamouz, Pavel and Soukup, Josef and Castravet, Tudor","meta_info":{"keywords":"Agriculture,Deep Learning,Extra data: climate,Extra data: soil,Images: MODIS,Labels: Public government data,Model comparison,Model: MLP,Satellite,Used VI,Yield prediction,Yield: County-level","abstract":"Meteorological and agricultural information coupled with remote sensing observations has been used to assess the effectiveness of satellite-derived indices in yield estimations. The estimate yield models generated by both the regression (MLR) and Bayesian network (BBN) algorithms and their levels of predictive skill were assessed. The enhanced vegetation index (EVI2), soil water index (SWI), standardized precipitation evaporation index (SPEI) have been considered predictors for three rainfed crops (maize, sunflower and grapevine) grown in 37 districts in the Republic of Moldova (RM). We used the weekly EVI2, which was collected by MODIS instruments aboard the Terra satellite with a 250m x 250m spatial resolution and aggregated for each district during the 2000-2018 period. We also used the weekly SWI, which was collected from the ASCAT instruments with a 12 km x 12 km spatial resolution and aggregated for each district at the topsoil (0-40 cm; SWI-12) and the root-zone layer (0-100 cm; SWI-14) during 2000-2018. The multiscalar SPEI during 1951-2018 farming years proved to be a significant addition to the remote sensing indices and led to the development of a model that improved the yield assessment. The study also summarized (i) the optimal time window of satellite-derived SWIi and EVI2i for yield estimation, and (ii) the capability of remotely sensed indices for representing the spatio-temporal variations of agricultural droughts. We developed statistical soil-vegetation-atmosphere models to explore drought-related yield losses. The skill scores of the sunflower MLR and BBN models were higher than those for the maize and grape models and were able to estimate yields with reasonable accuracy and predictive power. The accurate estimation of maize, sunflower and grapevine yields was observed two months before the harvest (RMSE of similar to 1.2 tha-1). Despite the fact that summer crops (maize, sunflower) are able to develop a root system that uses the entire root zone depth, however, the SWI-12 had the stronger correlation with crop yield, then SWI-14. This explains much better the fit between yields of the crops and SWI-12, which represents soil moisture anomaly in the key rooting layer of soil. In any case, all summer crops showed negative correlations with each of the remote sensing soil moisture indices in the early and middle of the growing season, with SWI-12 performing better than SWI-14. Based on the crop-specific soil moisture model, we found that topsoil moisture declines in the most drought-susceptible crop growth stages, which indicates that RM is a good candidate for studying drought persists as main driver of rainfed yield losses in the south-eastern Europe.","doi":"10.1016\/j.agwat.2020.106168","issn":"0378-3774","volume":"236","journal":"AGRICULTURAL WATER MANAGEMENT","month":"June","year":"2020"}}
{"bib_id":"qi_soil_2020","title":"Soil Salinity Inversion of Winter Wheat Areas Based on Satellite-Unmanned Aerial Vehicle-Ground Collaborative System in Coastal of the Yellow River Delta","author":"Qi, Guanghui and Zhao, Gengxing and Xi, Xue","meta_info":{"keywords":"Agriculture,Best Model: RF,Deep Learning,Images: Sentinel,Labels: Field survey,Labels: Model-based,Model comparison,Model: MLP,Model: RF,Model: SVM,Salinity prediction,Satellite","abstract":"Soil salinization is an important factor affecting winter wheat growth in coastal areas. The rapid, accurate and efficient estimation of soil salt content is of great significance for agricultural production. The Kenli area in the Yellow River Delta was taken as the research area. Three machine learning inversion models, namely, BP neural network (BPNN), support vector machine (SVM) and random forest (RF) were constructed using ground-measured data and UAV images, and the optimal model is applied to UAV images to obtain the salinity inversion result, which is used as the true salt value of the Sentinel-2A image to establish BPNN, SVM and RF collaborative inversion models, and apply the optimal model to the study area. The results showed that the RF collaborative inversion model is optimal, R-2 = 0.885. The inversion results are verified by using the measured soil salt data in the study area, which is significantly better than the directly satellite remote sensing inversion method. This study integrates the advantages of multi-scale data and proposes an effective ``Satellite-UAV-Ground'' collaborative inversion method for soil salinity, so as to obtain more accurate soil information, and provide more effective technical support for agricultural production.","doi":"10.3390\/s20226521","number":"22","volume":"20","journal":"SENSORS","month":"November","year":"2020"}}
{"bib_id":"qiao_exploiting_2021","title":"Exploiting Hierarchical Features for Crop Yield Prediction Based on 3-D Convolutional Neural Networks and Multikernel Gaussian Process","author":"Qiao, Mengjia and He, Xiaohui and Cheng, Xijie and Li, Panle and Luo, Haotian and Tian, Zhihui and Guo, Hengliang","meta_info":{"keywords":"Agriculture,Deep Learning,Images: MODIS,Labels: Public government data,Model: 3DCNN,Satellite,Yield prediction,Yield: County-level","langid":"english","abstract":"Accurate and timely prediction of crop yield based on remote sensing data is important for food security. However, crop growth is a complex process, which makes it quite difficult to achieve better performance. To address this problem, a novel 3-D convolutional neural multikernel network is proposed to capture hierarchical features for predicting crop yield. First, a full 3-D convolutional neural network is constructed to maximally explore deep spatial-spectral features from multispectral images. Then, a multikernel learning (MKL) approach is proposed for fusion of intraimage deep spatial-spectral features and intersample spatial consistency features. Specifically, we assign a group of nonlinear kernels for each feature in the MKL framework, which provides a robust way to fit features extracted from different domains. Finally, the probability distribution of prediction results is obtained by a kernel-based method. We evaluate the performance of the proposed method on China wheat yield prediction and offer detailed and systematic analyses of the performance of the proposed method. In addition, our method is compared with several competing methods. Experimental results demonstrate that the proposed method has certain advantages and can provide better prediction performance than the competitive methods.","doi":"10.1109\/JSTARS.2021.3073149","issn":"1939-1404","address":"445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA","publisher":"IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC","pages":"4476--4489","volume":"14","journal":"IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING","year":"2021","type":"Article"}}
{"bib_id":"quinton_crop_2021","title":"Crop Rotation Modeling for Deep Learning-Based Parcel Classification from Satellite Time Series","author":"Quinton, Félix and Landrieu, Loic","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Public government data,Satellite","langid":"english","copyright":"http:\/\/creativecommons.org\/licenses\/by\/3.0\/","abstract":"While annual crop rotations play a crucial role for agricultural optimization, they have been largely ignored for automated crop type mapping. In this paper, we take advantage of the increasing quantity of annotated satellite data to propose to model simultaneously the inter- and intra-annual agricultural dynamics of yearly parcel classification with a deep learning approach. Along with simple training adjustments, our model provides an improvement of over 6.3% mIoU over the current state-of-the-art of crop classification, and a reduction of over 21% of the error rate. Furthermore, we release the first large-scale multi-year agricultural dataset with over 300,000 annotated parcels.","urldate":"2022-03-10","doi":"10.3390\/rs13224599","issn":"2072-4292","publisher":"Multidisciplinary Digital Publishing Institute","pages":"4599","number":"22","volume":"13","journal":"Remote Sensing","month":"January","year":"2021"}}
{"bib_id":"rabiei_method_2021","title":"A Method to Estimate Surface Soil Moisture and Map the Irrigated Cropland Area Using Sentinel-1 and Sentinel-2 Data","author":"Rabiei, Saman and Jalilvand, Ehsan and Tajrishy, Massoud","meta_info":{"keywords":"Agriculture,Deep Learning,Images: Sentinel,Labels: Field survey,Model: 2DCNN,Model: MLP,Satellite,Soil moisture prediction","langid":"english","copyright":"http:\/\/creativecommons.org\/licenses\/by\/3.0\/","abstract":"Considering variations in surface soil moisture (SSM) is essential in improving crop yield and irrigation scheduling. Today, most remotely sensed soil moisture products have difficulties in resolving irrigation signals at the plot scale. This study aims to use Sentinel-1 radar backscatter and Sentinel-2 multispectral imagery to estimate SSM at high spatial (10 m) and temporal resolution (at least 5 days) over an agricultural domain. Three supervised machine learning algorithms, multilayer perceptron (MLP), a convolutional neural network (CNN), and linear regression models, were trained to estimate changes in SSM based on the variation in surface reflectance and backscatter over five different crops. Results showed that CNN is the best algorithm as it understands spatial relations and better represents two-dimensional images. Estimated values for SSM were in agreement with in-situ measurements regardless of the crop type, with RMSE=0.0292~(cm3\/cm3) and R2=0.92 for the Sentinel-2 derived SSM and RMSE=0.0317~(cm3\/cm3) and R2=0.84 for the Sentinel-1 soil moisture data. Moreover, a time series of estimated SSM based on Sentinel-1 (SSM-S1), Sentinel-2 (SSM-S2), and SSM derived from SMAP-Sentinel1 was compared. The developed SSM data showed a significantly higher mean SSM state over irrigated agriculture relative to the rainfed cropland area during the irrigation season. The multiple comparisons (fisher LSD) were tested and found that these two groups are different (pvalue=0.035 in 95% confidence interval). Therefore, by employing the maximum likelihood classification on the SSM data, we managed to map the irrigated agriculture. The overall accuracy of this unsupervised classification is 77%, with a kappa coefficient of 65%.","urldate":"2022-03-09","doi":"10.3390\/su132011355","issn":"2071-1050","publisher":"Multidisciplinary Digital Publishing Institute","pages":"11355","number":"20","volume":"13","journal":"Sustainability","month":"January","year":"2021"}}
{"bib_id":"rahimi-ajdadi_remote_2021","title":"Remote Sensing-Based Detection of Tea Land Losses: The Case of Lahijan, Iran","author":"Rahimi-Ajdadi, Fatemeh and Khani, Mahdi","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Landsat,Labels: Field survey,Model: MLP,Satellite","abstract":"Accurate change detection of cropland area and their spatial distributions are important for cropland monitoring, food security, and sustainable development. Tea as a strategic crop in northern Iran, has faced many challenges in the coming decades which has led to a decrease in its area under cultivation. The present study aims to identify changes in tea land area located in central district of Lahijan, Gilan, Iran by using Landsat 5 TM, Landsat 7 ETM+ and Landsat 8 OLI\/TIRS images. First, pre-processing stage was performed on satellite images including atmospheric, radiometric and geometric corrections. The supervized neural network classification method was employed, resulting in three classification maps with overall accuracies of 94.82, 95.36 and 97.84% and kappa coefficients of 96.22, 97.91, and 98.42 for 1999, 2011, and 2019, respectively which these were satisfactory. The images were categorized into four different classes, namely tea land, agriculture, forest and urban area. The results of Land Change Modeler showed that during 1999-2019, tea and agricultural lands decreased by 23.46% (2142 ha) and 41.71% (3872 ha). The loss trend of tea area in 1999-2011 has been more remarkable with a decrease of 1943 ha (21.28%). This downward trend continued with a slower slope (2.77% equal to 199 ha). Urbanization with growth rate of 381.71% consumed 2096 ha of tea land. Further, forestland contributed 251 ha to tea land losses. Reversely, the contribution of agricultural land to net change of tea area were positive so that 403 ha in 1999-2011 and 74 ha in 2011-2019 from cropland were converted to tea land. The paper highlights the advantage of digital change detection techniques for policy makers to take appropriate decision to return the situation and to conserve the productive agricultural lands.","doi":"10.1016\/j.rsase.2021.100568","issn":"2352-9385","volume":"23","journal":"REMOTE SENSING APPLICATIONS-SOCIETY AND ENVIRONMENT","month":"August","year":"2021"}}
{"bib_id":"rahman_exploring_2018","title":"Exploring the Potential of High Resolution WorldView-3 Imagery for Estimating Yield of Mango","author":"Rahman, Muhammad Moshiur and Robson, Andrew and Bristow, Mila","meta_info":{"keywords":"Agriculture,Deep Learning,Images: Commercial,Images: WV-3,Labels: Field survey,Model: MLP,Satellite,Used VI,Yield prediction","abstract":"Pre-harvest yield estimation of mango fruit is important for the optimization of inputs and other resources on the farm. Current industry practice of visual counting the fruit on a small number of trees for yield forecasting can be highly inaccurate due to the spatial variability, especially if the trees selected do not represent the entire crop. Therefore, this study evaluated the potential of high resolution WorldView-3 (WV3) satellite imagery to estimate yield of mango by integrating both geometric (tree crown area) and optical (spectral vegetation indices) data using artificial neural network (ANN) model. WV3 images were acquired in 2016-2017 and 2017-2018 growing seasons at the early fruit stage from three orchards in Acacia Hills region, Northern Territory, Australia. Stratified sampling technique (SST) was applied to select 18 trees from each orchard and subsequently ground truthed for yield (kg center dot tree(-1)) and fruit number per tree. For each sampled tree, spectral reflectance data and tree crown area (TCA) was extracted from WV3 imagery. The TCA was identified as the most important predictor of both fruit yield (kg center dot tree(-1)) and fruit number, followed by NDVI red-edge band when all trees from three orchards in two growing seasons were combined. The results of all sampled trees from three orchards in two growing seasons using ANN model produced a strong correlation (R-2 = 0.70 and 0.68 for total fruit yield (kg center dot tree(-1)) and fruit number respectively), which suggest that the model can be obtained to predict yield on a regional level. On orchard level also the ANN model produced a high correlation when both growing seasons were combined. However, the model developed in one season could not be applied in another season due to the influence of seasonal variation and canopy condition. Using the relationship derived from the measured yield parameters against combined VIs and TCA data, the total fruit yield (tha(-1)) and fruit number were estimated for each orchard, produced 7% under estimation to less than 1% over estimation. The accuracy of the findings showed the potential of WV3 imagery to better predict the yield parameters than the current practice across the mango industry as well as to quantify lost yield as a result of delayed harvest.","doi":"10.3390\/rs10121866","number":"12","volume":"10","journal":"REMOTE SENSING","month":"December","year":"2018"}}
{"bib_id":"rasheed_fluorescent_2018","title":"Fluorescent Sensor Based Models for the Detection of Environmentally-Related Toxic Heavy Metals","author":"Rasheed, Tahir and Bilal, Muhammad and Nabeel, Faran and Iqbal, Hafiz M. N. and Li, Chuanlong and Zhou, Yongfeng","meta_info":{"abstract":"The quest for industrial and biotechnological revolution has been contributed in increasing environmental contamination issues, worldwide. The controlled or uncontrolled release of hazardous pollutants from various industrial sectors is one of the key problems facing humanity. Among them, adverse influences of lead, cadmium, and mercury on human health are well known to cause many disorders like reproductive, neurological, endocrine system, and cardiovascular, etc. Besides their presence at lower concentrations, most of these toxic heavy metals are posing noteworthy toxicological concerns. In this context, notable efforts from various regulatory authorities, the increase in the concentration of these toxic heavy metals in the environment is of serious concern, so real-time monitoring is urgently required. This necessitates the exploration for novel and efficient probes for recognition of these toxic agents. Among various methodologies adopted for tailoring such probes, generally the methodologies, in which changes associated with spectral properties, are preferred for the deceptive ease in the recognition process. Accordingly, a promising modality has emerged in the form of radiometric and colorimetric monitoring of these toxic agents. Herein, we review fluorescent sensor based models and their potentialities to address the detection fate of hazardous pollutants for a cleaner environment. Second, recent advances regarding small molecule and rhodamine-based fluorescent sensors, radiometric and colorimetric probes are discussed. The information is also given on the photoinduced electron transfer (PET) mechanism, chelation enhancement fluorescence (CHEF) effect and spirocyclic ring opening mechanism.","urldate":"2024-05-30","doi":"10.1016\/j.scitotenv.2017.09.126","issn":"0048-9697","pages":"476--485","volume":"615","journal":"Science of The Total Environment","month":"February","year":"2018"}}
{"bib_id":"rauf_new_2022","title":"A New Method for Pixel Classification for Rice Variety Identification Using Spectral and Time Series Data from Sentinel-2 Satellite Imagery","author":"Rauf, Usman and Qureshi, Waqar S. and Jabbar, Hamid and Zeb, Ayesha and Mirza, Alina and Alanazi, Eisa and Khan, Umar S. and Rashid, Nasir","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Field survey,Labels: Model-based,Model: CNN,Satellite,Used VI","abstract":"In the agriculture sector food productivity, security, and sustainability, imposed challenges on farmers, regulatory bodies, and policymakers due to increasing demand and depleting natural resources and environmental concerns. Rice crop holds a prominent place in Pakistan's agriculture sector, it is not only consumed locally but also exported to many countries including China. Gathering crop information such as variety maps, yield estimation, or etc. can help farmers, regulatory bodies, policymakers, and rice mills in decision-making. In Pakistan, crop information is collected through manual field surveys that require a lot of human labor, are costly, and are time-consuming. One cannot ignore human error and bias in the process. A new framework for pixel classification is proposed that uses both spectral and time-series data of Sentinal-2 satellite for mapping two rice varieties ``Basmati'' and ``IRRI, grown in Pakistan. The data were collected from twelve rice fields (approx. 307 acres) of different geographical locations at 16-time instances to cover the complete rice-growing season (May-October) in 2019. A linear spectral unmixing model is used to determine sub-pixel information of water, soil, and vegetation content, which is used for labeling each pixel for supervised learning. The input to our classifier is a 16 x 15 image formed using 15 spectral features (12 spectral bands and 3 radiometric indices) of 16 carefully selected different time instances for each pixel. The output is a pixel-level classification (semantic segmentation) of each pixel into Basmati, IRRI, and others (soil, water, etc.). Experimental results have exhibited an excellent overall accuracy of 98.6% with the proposed approach. The Basmati rice obtained higher accuracy of 99.7% as compared to IRRI rice with an accuracy of 95.2%.","doi":"10.1016\/j.compag.2022.106731","issn":"0168-1699","volume":"193","journal":"COMPUTERS AND ELECTRONICS IN AGRICULTURE","month":"February","year":"2022"}}
{"bib_id":"rawat_comparative_2022","title":"A Comparative Study of 1D-Convolutional Neural Networks with Modified Possibilistic c-Mean Algorithm for Mapping Transplanted Paddy Fields Using Temporal Data","author":"Rawat, Anuvi and Kumar, Anil and Upadhyay, Priyadarshi and Kumar, Shashi","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Field survey,Model: 1DCNN,Satellite,Used VI","abstract":"With increasing availability of satellite data of high temporal resolution, a more robust classifier is needed which can exploit the temporal information along with the spectral information of the remote sensing images. Specific fuzzy-based and learning-based algorithms are two broad categories and have the potential to perform well in spectral-temporal domain. In the present study, for mapping paddy fields as a specific class two classification algorithms, viz. fuzzy-based modified possibilistic c-mean (MPCM) algorithm and learning-based 1D-convolutional neural networks (CNN), were tested using Sentinel-2A\/2B temporal data. The overall accuracy for learning-based 1D-CNN and fuzzy-based MPCM classifiers was found to be 96% and 93%, respectively. The F-measure values were found to be 0.95 and 0.92 for 1D-CNN- and MPCM-based classifier, respectively. Thus, it can be inferred from this study that the 1D-CNN classifier performed better than the traditional fuzzy-based classifier and can handle heterogeneity within class.","doi":"10.1007\/s12524-020-01303-4","issn":"0255-660X","journal":"JOURNAL OF THE INDIAN SOCIETY OF REMOTE SENSING","year":"2022"}}
{"bib_id":"rawat_deep_2021","title":"Deep Learning-Based Models for Temporal Satellite Data Processing: Classification of Paddy Transplanted Fields","author":"Rawat, Anuvi and Kumar, Anil and Upadhyay, Priyadarshi and Kumar, Shashi","meta_info":{"keywords":"Agriculture,Best Model: 1DCNN,Crop segmentation,Deep Learning,Images: Landsat,Images: Sentinel,Labels: Field survey,Model: 1DCNN,Model: ConvLSTM,Satellite","abstract":"Deep learning-based frameworks have not been much explored to incorporate the temporal dimension of the remote sensing data. In this research work, deep learning-based models have been developed which exploit the spectral-temporal domain of bi-sensor remote sensing data obtained from Sentinel-2 and Landsat-8 satellites. Application of proposed deep learning frameworks has been tested for mapping transplanted paddy fields using Class Based Sensor Independent -Normalised Difference Vegetation Index (CBSI-NDVI) spectral reduction approach. Two deep learning-based models viz., one-dimensional Convolutional Neural Network (1-D CNN) and hybrid 1-D Convolutional Neural Network ? Long Short Term Memory (CNN-LSTM) consisting of 1-D CNN and LSTM layers respectively were developed. For both of the models the optimized model hyper-parameters were also deduced. Though the performance of both the models were above satisfactory level still the 1-D CNN model performed slightly better than the hybrid 1-D CNN-LSTM based model with average overall accuracies of 93.75% and 91.25% respectively. The average F-measure values were computed as 0.93 and 0.90 respectively for the 1-D CNN based and hybrid CNN-LSTM based models. This study indicates that 1-D CNN based deep learning models provide an effective solution to handle mono\/bi-sensor temporal remote sensing data of medium spatial resolution with small size training datasets.","doi":"10.1016\/j.ecoinf.2021.101214","issn":"1574-9541","volume":"61","journal":"ECOLOGICAL INFORMATICS","month":"March","year":"2021"}}
{"bib_id":"richter_experimental_2009","title":"Experimental Assessment of the Sentinel-2 Band Setting for RTM-based LAI Retrieval of Sugar Beet and Maize","author":"Richter, K. and Atzberger, C. and Vuolo, F. and Weihs, P. and D'Urso, G.","meta_info":{"keywords":"Agriculture,Canopy cover prediction,Deep Learning,Extra data: UAV,Images: Sentinel,Labels: Model-based,Model: MLP,Satellite","abstract":"The present work aimed at testing the potential of the upcoming Earth Observation satellite Sentinel-2 (European Global Monitoring for Environment and Security (GMES) programme) for the operational estimation of the leaf area index (LAI) of two contrasting agricultural crops (sugar beet and maize). Mapping of LAI was achieved using a look-up table (LUT) based inversion of a physically based radiative transfer model (SAILH + PROSPECT). In addition to the Sentinel-2 spectral sampling, another band set described as ``ideal'' for vegetation studies has been evaluated in a comparative way. Analyses were mainly carried out using hyperspectral data acquired by the optical airborne instrument Compact Airborne Spectrographic Imager (CASI) during the European Space Agency (ESA) AgriSAR 2006 campaign. Additionally, data from two other experiments were tested to extend the validation database. Alternative inversion methods, i.e., an iterative optimization technique (SQP) and a neural network (NN), have been evaluated for comparison purposes. The GMES defined precision of 10% for LAI estimation, evaluated with in situ LAI measurements, was met for sugar beet (8%-9%) but not for maize (16%-22%). The inversion approach and band setting had only a minor influence on the retrieval accuracy, with the only exception being the iterative optimization technique, which failed to give reliable results. The results demonstrate the importance of using an appropriate radiative transfer model for each crop. For row crops with strong leaf clumping and not completely covering the soil surface, such as maize in the early stage, the standard SAILH + PROSPECT model does not appear to be suitable.","doi":"10.5589\/m09-010","issn":"0703-8992","pages":"230--247","number":"3","volume":"35","journal":"CANADIAN JOURNAL OF REMOTE SENSING","month":"June","year":"2009"}}
{"bib_id":"rodriguez_robust_2021","title":"Robust Damage Estimation of Typhoon Goni on Coconut Crops with Sentinel-2 Imagery","author":"Rodriguez, Andres C. and Daudt, Rodrigo Caye and D'Aronco, Stefano and Schindler, Konrad and Wegner, Jan D.","meta_info":{"keywords":"Agriculture,Crop damage detection,Deep Learning,Images: Commercial,Images: Sentinel,Labels: Image survey,Model: CNN,Model: ResNet,Satellite","abstract":"Typhoon Goni crossed several provinces in the Philippines where agriculture has high socioeconomic importance, including the top-3 provinces in terms of planted coconut trees. We have used a computational model to infer coconut tree density from satellite images before and after the typhoon's passage, and in this way estimate the number of damaged trees. Our area of study around the typhoon's path covers 15.7 Mha, and includes 47 of the 87 provinces in the Philippines. In validation areas our model predicts coconut tree density with a Mean Absolute Error of 5.9 Trees\/ha. In Camarines Sur we estimated that 3.5 M of the 4.6 M existing coconut trees were damaged by the typhoon. Overall we estimated that 14.1 M coconut trees were affected by the typhoon inside our area of study. Our validation images confirm that trees are rarely uprooted and damages are largely due to reduced canopy cover of standing trees. On validation areas, our model was able to detect affected coconut trees with 88.6% accuracy, 75% precision and 90% recall. Our method delivers spatially fine-grained change maps for coconut plantations in the area of study, including unchanged, damaged and new trees. Beyond immediate damage assessment, gradual changes in coconut density may serve as a proxy for future changes in yield.","doi":"10.3390\/rs13214302","number":"21","volume":"13","journal":"REMOTE SENSING","month":"November","year":"2021"}}
{"bib_id":"ronneberger_u-net_2015","title":"U-Net: Convolutional Networks for Biomedical Image Segmentation","author":"Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas","meta_info":{"file":"\/home\/brandon\/Zotero\/storage\/6JRK7CDP\/Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image.pdf","langid":"english","isbn":"978-3-319-24574-4","abstract":"There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http:\/\/lmb.informatik.uni-freiburg.de\/people\/ronneber\/u-net .","doi":"10.1007\/978-3-319-24574-4_28","address":"Cham","publisher":"Springer International Publishing","pages":"234--241","series":"Lecture Notes in Computer Science","year":"2015","editor":"Navab, Nassir and Hornegger, Joachim and Wells, William M. and Frangi, Alejandro F.","booktitle":"Medical Image Computing and Computer-Assisted Intervention - MICCAI 2015","shorttitle":"U-Net"}}
{"bib_id":"roughgarden_what_1991","title":"What Does Remote Sensing Do For Ecology?","author":"Roughgarden, J. and Running, S. W. and Matson, P. A.","meta_info":{"langid":"english","urldate":"2022-07-14","doi":"10.2307\/1941546","issn":"1939-9170","pages":"1918--1922","number":"6","volume":"72","journal":"Ecology","year":"1991"}}
{"bib_id":"roy_landsat8_2014","title":"Landsat-8: Science and Product Vision for Terrestrial Global Change Research","author":"Roy, D. P. and Wulder, M. A. and Loveland, T. R. and C.e., Woodcock and Allen, R. G. and Anderson, M. C. and Helder, D. and Irons, J. R. and Johnson, D. M. and Kennedy, R. and Scambos, T. A. and Schaaf, C. B. and Schott, J. R. and Sheng, Y. and Vermote, E. F. and Belward, A. S. and Bindschadler, R. and Cohen, W. B. and Gao, F. and Hipple, J. D. and Hostert, P. and Huntington, J. and Justice, C. O. and Kilic, A. and Kovalskyy, V. and Lee, Z. P. and Lymburner, L. and Masek, J. G. and McCorkel, J. and Shuai, Y. and Trezza, R. and Vogelmann, J. and Wynne, R. H. and Zhu, Z.","meta_info":{"file":"\/home\/brandon\/Zotero\/storage\/IVCIBHDG\/Roy et al. - 2014 - Landsat-8 Science and product vision for terrestr.pdf","langid":"english","abstract":"Landsat 8, a NASA and USGS collaboration, acquires global moderate-resolution measurements of the Earth's terrestrial and polar regions in the visible, near-infrared, short wave, and thermal infrared. Landsat 8 extends the remarkable 40year Landsat record and has enhanced capabilities including new spectral bands in the blue and cirrus cloud-detection portion of the spectrum, two thermal bands, improved sensor signal-to-noise performance and associated improvements in radiometric resolution, and an improved duty cycle that allows collection of a significantly greater number of images per day. This paper introduces the current (2012--2017) Landsat Science Team's efforts to establish an initial understanding of Landsat 8 capabilities and the steps ahead in support of priorities identified by the team. Preliminary evaluation of Landsat 8 capabilities and identification of new science and applications opportunities are described with respect to calibration and radiometric characterization; surface reflectance; surface albedo; surface temperature, evapotranspiration and drought; agriculture; land cover, condition, disturbance and change; fresh and coastal water; and snow and ice. Insights into the development of derived `higher-level' Landsat products are provided in recognition of the growing need for consistently processed, moderate spatial resolution, large area, long-term terrestrial data records for resource management and for climate and global change studies. The paper concludes with future prospects, emphasizing the opportunities for land imaging constellations by combining Landsat data with data collected from other international sensing systems, and consideration of successor Landsat mission requirements.","urldate":"2022-06-20","doi":"10.1016\/j.rse.2014.02.001","issn":"0034-4257","pages":"154--172","volume":"145","journal":"Remote Sensing of Environment","month":"April","year":"2014","shorttitle":"Landsat-8"}}
{"bib_id":"ruan_prediction_2021","title":"Prediction of Wheat Stripe Rust Occurrence with Time Series Sentinel-2 Images","author":"Ruan, Chao and Dong, Yingying and Huang, Wenjiang and Huang, Linsheng and Ye, Huichun and Ma, Huiqin and Guo, Anting and Ren, Yu","meta_info":{"keywords":"Agriculture,Deep Learning,Disease detection,Images: Sentinel,Labels: Field survey,Model: MLP,Satellite,Used VI","abstract":"Wheat stripe rust has a severe impact on wheat yield and quality. An effective prediction method is necessary for food security. In this study, we extract the optimal vegetation indices (VIs) sensitive to stripe rust at different time-periods, and develop a wheat stripe rust prediction model with satellite images to realize the multi-temporal prediction. First, VIs related to stripe rust stress are extracted as candidate features for disease prediction from time series Sentinel-2 images. Then, the optimal VI combinations are selected using sequential forward selection (SFS). Finally, the occurrence of wheat stripe rust in different time-periods is predicted using the support vector machine (SVM) method. The results of the features selected demonstrate that, before the jointing period, the optimal VIs are related to the biomass, pigment, and moisture of wheat. After the jointing period, the red-edge VIs related to the crop health status play important roles. The overall accuracy and Kappa coefficient of the prediction model, which is based on SVM, is generally higher than those of the k-nearest neighbor (KNN) and back-propagation neural network (BPNN) methods. The SVM method is more suitable for time series predictions of wheat stripe rust. The model obtained accuracy based on the optimal VI combinations and the SVM increased over time; the highest accuracy was 86.2%. These results indicate that the prediction model can provide guidance and suggestions for early disease prevention of the study site, and the method combines time series Sentinel-2 images and the SVM, which can be used to predict wheat stripe rust.","doi":"10.3390\/agriculture11111079","number":"11","volume":"11","journal":"AGRICULTURE-BASEL","month":"November","year":"2021"}}
{"bib_id":"ruswurm_convolutional_2018","title":"Convolutional LSTMs for Cloud-Robust Segmentation of Remote Sensing Imagery","author":"Rußwurm, Marc and Körner, Marco","meta_info":{"langid":"english","abstract":"Clouds frequently cover the Earth's surface and pose an omnipresent challenge to optical Earth observation methods. The vast majority of remote sensing approaches either selectively choose single cloud-free observations or employ a pre-classification strategy to identify and mask cloudy pixels. We follow a different strategy and treat cloud coverage as noise that is inherent to the observed satellite data. In prior work, we directly employed a straightforward \\empho̧nvolutional long short-term memory\\ network for vegetation classification without explicit cloud filtering and achieved state-of-the-art classification accuracies. In this work, we investigate this cloud-robustness further by visualizing internal cell activations and performing an ablation experiment on datasets of different cloud coverage. In the visualizations of network states, we identified some cells in which modulation and input gates closed on cloudy pixels. This indicates that the network has internalized a cloud-filtering mechanism without being specifically trained on cloud labels. Overall, our results question the necessity of sophisticated pre-processing pipelines for multi-temporal deep learning approaches.","urldate":"2024-06-05","month":"September","year":"2018","booktitle":"Proceedings of Neural Information Processing Systems Workshops"}}
{"bib_id":"ruswurm_multi-temporal_2018","title":"Multi-Temporal Land Cover Classification with Sequential Recurrent Encoders","author":"Rußwurm, Marc and Körner, Marco","meta_info":{"langid":"english","copyright":"http:\/\/creativecommons.org\/licenses\/by\/3.0\/","abstract":"Earth observation (EO) sensors deliver data at daily or weekly intervals. Most land use and land cover classification (LULC) approaches, however, are designed for cloud-free and mono-temporal observations. The increasing temporal capabilities of today's sensors enable the use of temporal, along with spectral and spatial features.Domains such as speech recognition or neural machine translation, work with inherently temporal data and, today, achieve impressive results by using sequential encoder-decoder structures. Inspired by these sequence-to-sequence models, we adapt an encoder structure with convolutional recurrent layers in order to approximate a phenological model for vegetation classes based on a temporal sequence of Sentinel 2 (S2) images. In our experiments, we visualize internal activations over a sequence of cloudy and non-cloudy images and find several recurrent cells that reduce the input activity for cloudy observations. Hence, we assume that our network has learned cloud-filtering schemes solely from input data, which could alleviate the need for tedious cloud-filtering as a preprocessing step for many EO approaches. Moreover, using unfiltered temporal series of top-of-atmosphere (TOA) reflectance data, our experiments achieved state-of-the-art classification accuracies on a large number of crop classes with minimal preprocessing, compared to other classification approaches.","urldate":"2022-07-25","doi":"10.3390\/ijgi7040129","issn":"2220-9964","publisher":"Multidisciplinary Digital Publishing Institute","pages":"129","number":"4","volume":"7","journal":"ISPRS International Journal of Geo-Information","month":"April","year":"2018"}}
{"bib_id":"ruswurm_self-attention_2020","title":"Self-Attention for Raw Optical Satellite Time Series Classification","author":"Rußwurm, Marc and Koerner, Marco","meta_info":{"keywords":"Agriculture,Best Model: LSTM,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Public government data,Model: 1DCNN,Model: 2DCNN,Model: GRU,Model: LSTM,Model: RF,Multitemporal,Satellite","abstract":"The amount of available Earth observation data has increased dramatically in recent years. Efficiently making use of the entire body of information is a current challenge in remote sensing; it demands lightweight problemagnostic models that do not require region- or problem-specific expert knowledge. End-to-end trained deep learning models can make use of raw sensory data by learning feature extraction and classification in one step, solely from data. Still, many methods proposed in remote sensing research require implicit feature extraction through data preprocessing or explicit design of features. In this work, we compare recent deep learning models on crop type classification on raw and preprocessed Sentinel 2 data. We concentrate on the common neural network architectures for time series, i.e., 1D-convolutions, recurrence, and the novel self-attention architecture. Our central findings are that data preprocessing still increased the overall classification performance for all models while the choice of model was less crucial. Self-attention and recurrent neural networks, by their architecture, outperformed convolutional neural networks on raw satellite time series. We explore this by a feature importance analysis based on gradient backpropagation that exploits the differentiable nature of deep learning models. Further, we qualitatively show how self-attention scores focus selectively on a few classification-relevant observations.","doi":"10.1016\/j.isprsjprs.2020.06.006","issn":"0924-2716","pages":"421--435","volume":"169","journal":"ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING","month":"November","year":"2020"}}
{"bib_id":"sagan_field-scale_2021","title":"Field-Scale Crop Yield Prediction Using Multi-Temporal WorldView-3 and PlanetScope Satellite Data and Deep Learning","author":"Sagan, Vasit and Maimaitijiang, Maitiniyazi and Bhadra, Sourav and Maimaitiyiming, Matthew and Brown, Davis R. and Sidike, Paheding and Fritschi, Felix B.","meta_info":{"keywords":"Agriculture,Deep Learning,Images: Commercial,Images: PlanetScope,Images: WV-3,Model: 3DCNN,Model: CNN,Model: ResNet,Satellite,Yield prediction,Yield: Plot-level","abstract":"Agricultural management at field-scale is critical for improving yield to address global food security, as providing enough food for the world's growing population has become a wicked problem for both scientists and policy-makers. County- or regional-scale data do not provide meaningful information to farmers who are interested in field-scale yield forecasting for effective and timely field management. No studies directly utilized raw satellite imagery for field-scale yield prediction using deep learning. The objectives of this paper were twofold: (1) to develop a raw imagery-based deep learning approach for field-scale yield prediction, (2) investigate the contribution of in-season multitemporal imagery for grain yield prediction with hand-crafted features and WorldView-3 (WV) and PlanetScope (PS) imagery as the direct input, respectively. Four WV-3 and 25 PS imagery collected during the growing season of soybean were utilized. Both 2-dimensional (2D) and 3-dimensional (3D) convolution neural network (CNN) architectures were developed that integrated spectral, spatial, temporal information contained in the satellite data. For comparison, hundreds of carefully selected spectral, spatial, textural, and temporal features that are optimal for crop growth monitoring were extracted and fed into the same deep learning model. Our results demonstrated that (1) deep learning was able to predict yield directly using raw satellite imagery to the extent that was comparable to feature-fed deep learning approaches; (2) both 2D and 3D CNN models were able to explain nearly 90% variance in field-scale yield; (3) limited number of WV-3 outperformed multi-temporal PS data collected during entire growing season mainly attributed to RedEdge and SWIR bands available with WV-3; and (4) 3D CNN increased the prediction power of PS data compared to 2D CNN due to its ability to digest temporal features extracted from PS data.","doi":"10.1016\/j.isprsjprs.2021.02.008","issn":"0924-2716","pages":"265--281","volume":"174","journal":"ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING","month":"April","year":"2021"}}
{"bib_id":"sanches_campo_2017","title":"Campo Verde Database","author":"Sanches, Ieda Del'Arco and Feitosa, Raul Queiroz and Diaz, Pedro Marco Achanccaray and Soares, Marinalva Dias and Luiz, Alfredo Jose Barreto and Schultz, Bruno and Maurano, Luis Eduardo Pinheiro","meta_info":{"file":"\/home\/brandon\/Zotero\/storage\/QR67EL5K\/campo-verde-database.html","langid":"english","abstract":"In tropical\/subtropical regions, the favorable climate associated with the use of agricultural technologies, such as no-tillage, minimum cultivation, irrigation, early varieties, desiccants, flowering inducing and crop rotation, makes agriculture highly dynamic. In this paper, we present the Campo Verde agricultural database. The purpose of creating and sharing these data is to foster advancement of remote sensing technology in areas of tropical agriculture, primarily the development and testing of methods for crop recognition and agricultural mapping.","urldate":"2022-07-22","doi":"https:\/\/dx.doi.org\/10.21227\/H2804B","publisher":"IEEE","journal":"IEEE Dataport","month":"October","year":"2017"}}
{"bib_id":"santi_comparison_2013","title":"Comparison between SAR Soil Moisture Estimates and Hydrological Model Simulations over the Scrivia Test Site","author":"Santi, Emanuele and Paloscia, Simonetta and Pettinato, Simone and Notarnicola, Claudia and Pasolli, Luca and Pistocchi, Alberto","meta_info":{"keywords":"Deep Learning,Images: ASAR,Model: MLP,Satellite,Soil moisture prediction","abstract":"In this paper, the results of a comparison between the soil moisture content (SMC) estimated from C-band SAR, the SMC simulated by a hydrological model, and the SMC measured on ground are presented. The study was carried out in an agricultural test site located in North-west Italy, in the Scrivia river basin. The hydrological model used for the simulations consists of a one-layer soil water balance model, which was found to be able to partially reproduce the soil moisture variability, retaining at the same time simplicity and effectiveness in describing the topsoil. SMC estimates were derived from the application of a retrieval algorithm, based on an Artificial Neural Network approach, to a time series of ENVISAT\/ASAR images acquired over the Scrivia test site. The core of the algorithm was represented by a set of ANNs able to deal with the different SAR configurations in terms of polarizations and available ancillary data. In case of crop covered soils, the effect of vegetation was accounted for using NDVI information, or, if available, for the cross-polarized channel. The algorithm results showed some ability in retrieving SMC with RMSE generally $<$0.04 m(3)\/m(3) and very low bias (i.e., $<$0.01 m(3)\/m(3)), except for the case of VV polarized SAR images: in this case, the obtained RMSE was somewhat higher than 0.04 m(3)\/m(3) (0.058 m(3)\/m(3)). The algorithm was implemented within the framework of an ESA project concerning the development of an operative algorithm for the SMC retrieval from Sentinel-1 data. The algorithm should take into account the GMES requirements of SMC accuracy (5% in volume), spatial resolution (1 km) and timeliness (3 h from observation). The SMC estimated by the SAR algorithm, the SMC estimated by the hydrological model, and the SMC measured on ground were found to be in good agreement. The hydrological model simulations were performed at two soil depths: 30 and 5 cm and showed that the 30 cm simulations indicated, as expected, SMC values higher than the satellites estimates, with RMSE higher than 0.08 m(3)\/m(3). In contrast, in the 5-cm simulations, the agreement between hydrological simulations, satellite estimates and ground measurements could be considered satisfactory, at least in this preliminary comparison, showing a RMSE ranging from 0.054 m(3)\/m(3) to 0.051 m(3)\/m(3) for comparison with ground measurements and SAR estimates, respectively.","doi":"10.3390\/rs5104961","pages":"4961--4976","number":"10","volume":"5","journal":"REMOTE SENSING","month":"October","year":"2013"}}
{"bib_id":"saraiva_automatic_2020","title":"Automatic Mapping of Center Pivot Irrigation Systems from Satellite Images Using Deep Learning","author":"Saraiva, Marciano and Protas, Eglen and Salgado, Moises and Souza Jr, Carlos","meta_info":{"keywords":"Agriculture,Center pivot irrigation detection,Deep Learning,Images: PlanetScope,Labels: Image survey,Model: UNet,Satellite","abstract":"The availability of freshwater is becoming a global concern. Because agricultural consumption has been increasing steadily, the mapping of irrigated areas is key for supporting the monitoring of land use and better management of available water resources. In this paper, we propose a method to automatically detect and map center pivot irrigation systems using U-Net, an image segmentation convolutional neural network architecture, applied to a constellation of PlanetScope images from the Cerrado biome of Brazil. Our objective is to provide a fast and accurate alternative to map center pivot irrigation systems with very high spatial and temporal resolution imagery. We implemented a modified U-Net architecture using the TensorFlow library and trained it on the Google cloud platform with a dataset built from more than 42,000 very high spatial resolution PlanetScope images acquired between August 2017 and November 2018. The U-Net implementation achieved a precision of 99% and a recall of 88% to detect and map center pivot irrigation systems in our study area. This method, proposed to detect and map center pivot irrigation systems, has the potential to be scaled to larger areas and improve the monitoring of freshwater use by agricultural activities.","doi":"10.3390\/rs12030558","number":"3","volume":"12","journal":"REMOTE SENSING","month":"February","year":"2020"}}
{"bib_id":"saralioglu_semantic_2022","title":"Semantic Segmentation of Land Cover from High Resolution Multispectral Satellite Images by Spectral-Spatial Convolutional Neural Network","author":"Saralioglu, Ekrem and Gungor, Oguz","meta_info":{"keywords":"Agriculture,Best Model: ItsComplicated,Crop segmentation,Deep Learning,Images: Deimos-2,Images: IKONOS,Images: Pleiades,Images: WV-2,Labels: Image survey,Model comparison,Model: 2DCNN,Model: 3DCNN,Model: RF,Model: SVM,Satellite","abstract":"Research to improve the accuracy of very high-resolution satellite image classification algorithms is still one of the hot topics in the field of remote sensing. Successful results of deep learning methods in areas such as image classification and object detection have led to the application of these methods to remote sensing problems. Recently, Convolutional Neural Networks (CNNs) are among the most common deep learning methods used in image classification, however, the use of CNN's in satellite image classification is relatively new. Due to the high computational complexity of 3D CNNs, which aim to extract both spatial and spectral information, 2D CNNs focussing on the extraction of spatial information are often preferred. High-resolution satellite images, however, contain crucial spectral information as well as spatial information. In this study, a 3D-2D CNN model using both spectral and spatial information was applied to extract more accurate land cover information from very high-resolution satellite images. The model was applied on a Worldview-2 satellite image including agricultural product areas such as tea, hazelnut groves and land use classes such as buildings and roads. The results of the CNN based model were also compared against those of the Support Vector Machine (SVM) and Random Forest (RF) algorithms. The post-classification accuracies were obtained using 800 control points generated by a web interface created for crowdsourcing purposes. The classification accuracy was 95.6% for the 3D-2D CNN model, 89.2% for the RF and 86.4% for the SVM.","doi":"10.1080\/10106049.2020.1734871","issn":"1010-6049","pages":"657--677","number":"2","volume":"37","journal":"GEOCARTO INTERNATIONAL","month":"January","year":"2022"}}
{"bib_id":"schwalbert_satellite-based_2020","title":"Satellite-Based Soybean Yield Forecast: Integrating Machine Learning and Weather Data for Improving Crop Yield Prediction in Southern Brazil","author":"Schwalbert, Rai A. and Amado, Telmo and Corassa, Geomar and Pott, Luan Pierre and Prasad, P. V. Vara and Ciampitti, Ignacio A.","meta_info":{"keywords":"Agriculture,Best Model: LSTM,Deep Learning,Extra data: climate,Images: MODIS,Labels: Public government data,Model comparison,Model: LSTM,Model: RF,Satellite,Used VI,Yield prediction,Yield: County-level","abstract":"Soybean yield predictions in Brazil are of great interest for market behavior, to drive governmental policies and to increase global food security. In Brazil soybean yield data generally demand various revisions through the following months after harvest suggesting that there is space for improving the accuracy and the time of yield predictions. This study presents a novel model to perform in-season (''near real-time'') soybean yield forecasts in southern Brazil using Long-Short Term Memory (LSTM), Neural Networks, satellite imagery and weather data. The objectives of this study were to: (i) compare the performance of three different algorithms (multivariate OLS linear regression, random forest and LSTM neural networks) for forecasting soybean yield using NDVI, EVI, land surface temperature and precipitation as independent variables, and (ii) evaluate how early (during the soybean growing season) this method is able to forecast yield with reasonable accuracy. Satellite and weather data were masked using a non-crop-specific layer with field boundaries obtained from the Rural Environment Registry that is mandatory for all farmers in Brazil. Main outcomes from this study were: (i) soybean yield forecasts at municipality-scale with a mean absolute error (MAE) of 0.24 Mg ha(-1) at DOY 64 (march 5) (ii) a superior performance of the LSTM neural networks relative to the other algorithms for all the forecast dates except DOY 16 where multivariate OLS linear regression provided the best performance, and (iii) model performance (e.g., MAE) for yield forecast decreased when predictions were performed earlier in the season, with MAE increasing from 0.24 Mg ha(-1) to 0.42 Mg ha(-1) (last values from OLS regression) when forecast timing changed from DOY 64 (March 5) to DOY 16 (January 6). This research portrays the benefits of integrating statistical techniques, remote sensing, weather to field survey data in order to perform more reliable in-season soybean yield forecasts.","doi":"10.1016\/j.agrformet.2019.107886","issn":"0168-1923","volume":"284","journal":"AGRICULTURAL AND FOREST METEOROLOGY","month":"April","year":"2020"}}
{"bib_id":"senanayake_estimating_2021","title":"Estimating Catchment Scale Soil Moisture at a High Spatial Resolution: Integrating Remote Sensing and Machine Learning","author":"Senanayake, I. P. and Yeo, I. -Y. and Walker, J. P. and Willgoose, G. R.","meta_info":{"keywords":"Deep Learning,Images: MODIS,Labels: Field survey,Model: MLP,Satellite,Soil moisture prediction,Used VI","abstract":"Soil moisture information is important for a wide range of applications including hydrologic modelling, climatic modelling and agriculture. L-band passivemicrowave satellite remote sensing is themost feasible option to estimate near-surface soil moisture (similar to 0-5 cmsoil depth) over large extents, but its coarse resolution (similar to 10s of km) means that it is unable to capture the variability of soil moisture in detail. Therefore, different downscaling methods have been tested as a solution tomeet the demand for high spatial resolution soil moisture. Downscaling algorithms based on the soil thermal inertia relationship between diurnal soil temperature difference (Delta T) and dailymean soil moisture content (mu(SM)) have shown promising results over arid and semi-arid landscapes. However, the linearity of these algorithms is affected by factors such as vegetation, soil texture and meteorology in a complex manner. This study tested a (i) Regression Tree (RT), an Artificial Neural Network (ANN), and a Gaussian Process Regression (GPR) model based on the soil thermal inertia theory over a semi-arid agricultural landscape in Australia, given the ability of machine learning algorithms to capture complex, non-linear relationships between predictors and responses. Downscaled soil moisture from the RT, ANN and GPR models showed root mean square errors (RMSEs) of 0.03, 0.09 and 0.07 cm(3)\/cm(3) compared to airborne retrievals and unbiased RMSEs (ubRMSEs) of 0.07, 0.08 and 0.05 cm(3)\/cm(3) compared to in-situ observations, respectively. The study showed encouraging results to integrate machine learning techniques in estimating near-surface soil moisture at a high spatial resolution. (c) 2021 Elsevier B.V. All rights reserved.","doi":"10.1016\/j.scitotenv.2021.145924","issn":"0048-9697","volume":"776","journal":"SCIENCE OF THE TOTAL ENVIRONMENT","month":"July","year":"2021"}}
{"bib_id":"serco_copernicus_2021","title":"Copernicus Sentinel Data Access Annual Report 2021","author":"SERCO","meta_info":{"howpublished":"https:\/\/sentinels.copernicus.eu\/web\/sentinel\/-\/copernicus-sentinel-data-access-annual-report-2021\/1.2","urldate":"2022-07-14","year":"2021"}}
{"bib_id":"sharifi_agricultural_2022","title":"Agricultural Field Extraction with Deep Learning Algorithm and Satellite Imagery","author":"Sharifi, Alireza and Mahdipour, Hadi and Moradi, Elahe and Tariq, Aqil","meta_info":{"keywords":"Agriculture,Deep Learning,Field boundary detection,Images: Landsat,Images: Sentinel,Labels: Image survey,Model: UNet,Satellite","abstract":"Automatic detection of borders using remote sensing images will minimize the dependency on time-consuming manual input. The lack of field border data sets indicates that current methods are ineffective. This article seeks to promote the detection of field borders from satellite images with general process based on a multi-task segmentation model. ResUNet-a is a convolutional neural network with a completely linked UNet backbone that supports sprawling and conditional inference. The algorithm will significantly increase model efficiency and its generalization by re-constructing connected outputs. Then individual field segmentation can be accomplished by post-processing model outputs. The model was extremely exact in field mapping, field borders, and thus individual fields using the Sentinel-2 and Landsat-8 images as inputs. The multitemporal images replacement with a single image similar to the composition time decreased slightly. The proposed model is able to reliably identify field borders and remove irrelevant limits from the image to acquire complex hierarchical contextual properties, thus outstriking classical edge filters. Our method is supposed to promote individual crop field extraction on a scale, by minimizing overfitting.","doi":"10.1007\/s12524-021-01475-7","issn":"0255-660X","journal":"JOURNAL OF THE INDIAN SOCIETY OF REMOTE SENSING","year":"2022"}}
{"bib_id":"sharma_countrywide_2022","title":"Countrywide Mapping of Plant Ecological Communities with 101 Legends Including Land Cover Types for the First Time at 10 m Resolution through Convolutional Learning of Satellite Images","author":"Sharma, Ram C.","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Public government data,Model: 1DCNN,Satellite,Used VI","unique-id":"WOS:000831870000001","orcid-numbers":"Sharma, Ram C.\/0000-0001-5706-4417","eissn":"2076-3417","article-number":"7125","doi":"10.3390\/app12147125","number":"14","volume":"12","journal":"APPLIED SCIENCES-BASEL","month":"July","year":"2022"}}
{"bib_id":"shelestov_exploring_2017","title":"Exploring Google Earth Engine Platform for Big Data Processing: Classification of Multi-Temporal Satellite Imagery for Crop Mapping","author":"Shelestov, Andrii and Lavreniuk, Mykola and Kussul, Nataliia and Novikov, Alexei and Skakun, Sergii","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Landsat,Labels: Field survey,Model comparison,Model: CART,Model: MLP,Model: RF,Model: SVM,Multitemporal,Satellite","abstract":"Many applied problems arising in agricultural monitoring and food security require reliable crop maps at national or global scale. Large scale crop mapping requires processing andmanagement of large amount of heterogeneous satellite imagery acquired by various sensors that consequently leads to a ``Big Data'' problem. The main objective of this study is to explore efficiency of using the Google Earth Engine (GEE) platform when classifying multi-temporal satellite imagery with potential to apply the platform for a larger scale (e.g., country level) and multiple sensors (e.g., Landsat-8 and Sentinel-2). In particular, multiple state-of-the-art classifiers available in the GEE platformare compared to produce a high resolution (30 m) crop classification map for a large territory (similar to 28,100 km(2) and 1.0 M ha of cropland). Though this study does not involve large volumes of data, it does address efficiency of the GEE platform to effectively execute complex workflows of satellite data processing required with large scale applications such as crop mapping. The study discusses strengths and weaknesses of classifiers, assesses accuracies that can be achieved with different classifiers for the Ukrainian landscape, and compares them to the benchmark classifier using a neural network approach that was developed in our previous studies. The study is carried out for the Joint Experiment of Crop Assessment and Monitoring (JECAM) test site in Ukraine covering the Kyiv region (North of Ukraine) in 2013. We found that GEE provides very good performance in terms of enabling access to the remote sensing products through the cloud platform and providing pre-processing; however, in terms of classification accuracy, the neural network based approach outperformed support vector machine (SVM), decision tree and random forest classifiers available in GEE.","doi":"10.3389\/feart.2017.00017","pages":"1--10","volume":"5","journal":"FRONTIERS IN EARTH SCIENCE","month":"February","year":"2017"}}
{"bib_id":"shi_convolutional_2015","title":"Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting","author":"Shi, Xingjian and Chen, Zhourong and Wang, Hao and Yeung, Dit-Yan and Wong, Wai-kin and WOO, Wang-chun","meta_info":{"abstract":"The goal of precipitation nowcasting is to predict the future rainfall intensity in a local region over a relatively short period of time. Very few previous studies have examined this crucial and challenging weather forecasting problem from the machine learning perspective. In this paper, we formulate precipitation nowcasting as a spatiotemporal sequence forecasting problem in which both the input and the prediction target are spatiotemporal sequences. By extending the fully connected LSTM (FC-LSTM) to have convolutional structures in both the input-to-state and state-to-state transitions, we propose the convolutional LSTM (ConvLSTM) and use it to build an end-to-end trainable model for the precipitation nowcasting problem. Experiments show that our ConvLSTM network captures spatiotemporal correlations better and consistently outperforms FC-LSTM and the state-of-the-art operational ROVER algorithm for precipitation nowcasting.","urldate":"2024-06-05","publisher":"Curran Associates, Inc.","volume":"28","year":"2015","booktitle":"Advances in Neural Information Processing Systems","shorttitle":"Convolutional LSTM Network"}}
{"bib_id":"sidike_dpen_2019","title":"dPEN: Deep Progressively Expanded Network for Mapping Heterogeneous Agricultural Landscape Using WorldView-3 Satellite Imagery","author":"Sidike, Paheding and Sagan, Vasit and Maimaitijiang, Maitiniyazi and Maimaitiyiming, Matthew and Shakoor, Nadia and Burken, Joel and Mockler, Todd and Fritschi, Felix B.","meta_info":{"keywords":"Agriculture,Best Model: 1DCNN,Crop segmentation,Deep Learning,Images: WV-3,Labels: Field survey,Model comparison,Model: 1DCNN,Model: RF,Model: SVM,Satellite","abstract":"Accurately mapping heterogeneous agricultural landscape is an important prerequisite for agricultural field management (e.g., weed control), plant phenotyping and yield prediction, as well as ecological characterization. Compared to traditional mapping practices that require intensive field surveys, remote sensing technologies offer efficient and cost-effective means for crop type mapping from regional to global scales. However, mapping heterogeneous agricultural landscape is a challenge because of diverse and complex spectral profiles of crops. We propose a novel deep learning method, namely deep progressively expanded network (dPEN), for mapping nineteen different objects including crop types, weeds and crop residues, in a heterogeneous agricultural field using WorldView-3 (WV-3) imagery. To assess the mapping accuracy of dPEN, we created a calibrated WV-3 dataset with the corresponding ground truth. In addition, the suitability of visible\/near-infrared (VNIR, 400-1040 nm) and short-wave infrared (SWIR, 1195 nm-2365 nm) bands of WV-3 to classification accuracy were examined and discussed in detail. To the best of our knowledge, this is the first effort to explore the significance of all SWIR bands in WV-3 for classification accuracy in a heterogeneous agricultural landscape. The results demonstrated that: (1) The proposed dPEN allows for building a deeper neural network from multi spectral data which was the limitation of many convolutional neural networks; (2) dPEN was able to extract more discriminative features from VNIR and SWIR bands by producing the highest overall accuracy (OA: 86.06%) over competing methods such as support vector machine and random forest; (3) The inclusion of WV-3 SWIR bands greatly improved the classification accuracy; (4) SWIR bands were particularly beneficial to improve the classification accuracy of some individual classes such as weeds, crop residues, and corn and soybean during late developmental stages; (5) The red-edge band (705-745 nm) was identified as the most important band affecting the classification accuracy nearly 10%, whereas the coastal band (400-450 nm) provided the lowest contribution; and (6) SWIR-5 band (2145-2185 nm) contributed most to OA by enhancing it approximately 4% when combined with VNIR bands, while SWIR-1 (1195-1225 nm) yielded the lowest improvement (1.55%) for OA. These research outcomes provide useful information for efficiently mapping agricultural landscape, and indicate the potential practices of dPEN and contributions of spectral bands in WV-3 for plant phenotyping, weed control, and crop residue retention.","doi":"10.1016\/j.rse.2018.11.031","issn":"0034-4257","pages":"756--772","volume":"221","journal":"REMOTE SENSING OF ENVIRONMENT","month":"February","year":"2019"}}
{"bib_id":"simonyan_very_2015","title":"Very Deep Convolutional Networks for Large-Scale Image Recognition","author":"Simonyan, Karen and Zisserman, Andrew","meta_info":{"archiveprefix":"arxiv","abstract":"In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.","urldate":"2022-07-13","doi":"10.48550\/arXiv.1409.1556","publisher":"arXiv","primaryclass":"cs","eprint":"1409.1556","number":"arXiv:1409.1556","month":"April","year":"2015"}}
{"bib_id":"song_predicting_2018","title":"Predicting Spatial Variations in Soil Nutrients with Hyperspectral Remote Sensing at Regional Scale","author":"Song, Ying-Qiang and Zhao, Xin and Su, Hui-Yue and Li, Bo and Hu, Yue-Ming and Cui, Xue-Sen","meta_info":{"keywords":"Agriculture,Best Model: MLP,Deep Learning,Images: HJ-1,Labels: Field survey,Model: MLP,Model: RF,Model: SVM,Satellite,Soil nitrogen prediction","abstract":"Rapid acquisition of the spatial distribution of soil nutrients holds great implications for farmland soil productivity safety, food security and agricultural management. To this end, we collected 1297 soil samples and measured the content of soil total nitrogen (TN), soil available phosphorus (AP) and soil available potassium (AK) in Zengcheng, north of the Pearl River Delta, China. Hyperspectral remote sensing images (115 bands) of the Chinese Environmental 1A satellite were used as auxiliary variables and dimensionality reduction was performed using Pearson correlation analysis and principal component analysis. The TN, AP and AK of soil were predicted in the study area based on auxiliary variables after dimensionality reduction, along with stepwise linear regression (SLR), support vector machine (SVM), random forest (RF) and back-propagation neural network (BPNN) models; 324 independent points were used to verify the predictive performance. The BPNN model, which demonstrated the best predictive accuracy among all methods, combined ordinary kriging (OK) with mapping the spatial variations of soil nutrients. Results show that the BPNN model with double hidden layers had better predictive accuracy for soil TN (root mean square error (RMSE) = 0.409 mg kg(-1), R-2 = 44.24%), soil AP (RMSE = 40.808 mg kg(-1), R-2 = 42.91%) and soil AK (RMSE = 67.464 mg kg(-1), R-2 = 48.53%) compared with the SLR, SVM and RF models. The back propagation neural network-ordinary kriging (BPNNOK) model showed the best predictive results of soil TN (RMSE = 0.292 mg kg(-1), R-2 = 68.51%), soil AP (RMSE = 29.62 mg kg(-1), R-2 = 69.30%) and soil AK (RMSE = 49.67 mg kg(-1) and R-2 = 70.55%), indicating the best fitting ability between hyperspectral remote sensing bands and soil nutrients. According to the spatial mapping results of the BPNNOK model, concentrations of soil TN (north-central), soil AP (central and southwest) and soil AK (central and southeast) were respectively higher in the study area. The most important bands (464-517 nm) for soil TN (b10, b14, b20 and b21), soil AP (b3, b19 and b22) and soil AK (b4, b11, b12 and b25) exhibited the best response and sensitivity according to the SLR, SVM, RF and BPNN models. It was concluded that the application of hyperspectral images (visible-near-infrared data) with BPNNOK model was found to be an efficient method for mapping and monitoring soil nutrients at the regional scale.","doi":"10.3390\/s18093086","number":"9","volume":"18","journal":"SENSORS","month":"September","year":"2018"}}
{"bib_id":"sun_leaf_2021","title":"Leaf Area Index Remote Sensing Based on Deep Belief Network Supported by Simulation Data","author":"Sun, Lin and Wang, Weiyan and Jia, Chen and Liu, Xirong","meta_info":{"keywords":"Agriculture,Canopy cover prediction,Deep Learning,Images: MODIS,Labels: Field survey,Labels: Model-based,Model: Non-standard MLP,Satellite","abstract":"Leaf area index (LAI) is a key variable in the exchange of substance and energy between the surface and the atmosphere. Remote sensing inversion is the most effective method used to obtain the LAI in a large area. However, owing to the complexity of the spatial structure of vegetation, it is difficult to obtain LAI measurements with high stability and precision. One of the main reasons for this is the lack of information mining ability provided by remote sensing images. To fully utilize the information provided by these images, deep learning technology, with strong self-learning ability and information mining ability, was proposed in this study to retrieve the LAI. The accuracy and stability of deep learning technology largely depends on the quality, quantity, and representativeness of the samples. Given the present difficulties in producing enough high-quality samples from land surface measurements, this paper proposes the use of a radiative transfer model to simulate samples to realize a remote sensing inversion of the LAI. The PROSAIL model is used to simulate the training samples for LAI inversion. A Deep Belief Network (DBN) was used for LAI inversion from MODIS (Moderate-Resolution Imaging Spectroradiometer) data with seven spectral bands, and the estimated LAI was compared with the current MODIS LAI product (MOD15A2H), on the basis of validation by ground-measured LAI. The inversion results (Root Mean Square Error RMSE and Pearson's correlation coefficient r) obtained by the DBN algorithm (RMSE = 0.8988, r = 0.7188) of this study and GLASS (Global LAnd Surface Satellite) algorithm (RMSE = 0.7111, r = 0.7995) showed a similar performance, and they are superior to the MODIS LAI product (RMSE = 1.0595, r = 0.6613).","doi":"10.1080\/01431161.2021.1942584","issn":"0143-1161","pages":"7637--7661","number":"20","volume":"42","journal":"INTERNATIONAL JOURNAL OF REMOTE SENSING","month":"October","year":"2021"}}
{"bib_id":"sykas_sentinel-2_2022","title":"A Sentinel-2 Multiyear, Multicountry Benchmark Dataset for Crop Classification and Segmentation with Deep Learning","author":"Sykas, Dimitrios and Sdraka, Maria and Zografakis, Dimitrios and Papoutsis, Ioannis","meta_info":{"keywords":"Agriculture,Crop segmentation,Dataset,Deep Learning,Images: Sentinel,Model: 1DCNN,Model: 2DCNN,Model: ConvLSTM,Model: LSTM,Model: Transformer,Satellite","unique-id":"WOS:000793810100001","researcherid-numbers":"Papoutsis, Ioannis\/L-5072-2013","orcid-numbers":"Papoutsis, Ioannis\/0000-0002-2845-9791 Zografakis, Dimitrios\/0000-0001-6955-3242","eissn":"2151-1535","doi":"10.1109\/JSTARS.2022.3164771","issn":"1939-1404","pages":"3323--3339","volume":"15","journal":"IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING","year":"2022"}}
{"bib_id":"tang_channel_2022","title":"Channel Attention-Based Temporal Convolutional Network for Satellite Image Time Series Classification","author":"Tang, Pengfei and Du, Peijun and Xia, Junshi and Zhang, Peng and Zhang, Wei","meta_info":{"keywords":"Agriculture,Best Model: 1DCNN,Best Model: SaE,Crop segmentation,Dataset: Breizhcrops,Deep Learning,Images: Sentinel,Labels: Dataset,Model comparison,Model: 1DCNN,Model: LSTM,Model: MHA,Model: PSE-TAE,Model: RF,Model: Squeeze-and-Excitation,Model: Transformer,Satellite","abstract":"Satellite image time series classification has become a research focus with the launch of new remote sensing sensors capable of capturing images with high spatial, spectral, and temporal resolutions. In particular, in the field of crop classification, time dimension information is particularly important. Although some advanced machine learning algorithms, such as random forests (RFs), can achieve good results, they often ignore the time series information. To make full use of temporal and spectral information in multitemporal remote sensing images, a channel attention-based temporal convolutional network (CA-TCN) is proposed in this letter. Specifically, the proposed method is composed of two main modules: temporal convolutional network and attention block. The temporal convolutional network can capture long-range dependence by using a hierarchy of temporal convolutional filters. To capture relevant information inside the sequence and enhance the important information, the attention block is used to enhance the important features in the channel dimension since not all bands contain equal information in crop type classification. The proposed CA-TCN can excavate deeper phenological characteristics. Compared to the temporal attention-based temporal convolutional network and other deep learning-based models, the proposed CA-TCN has achieved state-of-the-art performance in the Breizhcrops dataset with fewer parameters.","doi":"10.1109\/LGRS.2021.3095505","issn":"1558-0571","pages":"1--5","volume":"19","journal":"IEEE Geoscience and Remote Sensing Letters","year":"2022"}}
{"bib_id":"teimouri_fusion_2022","title":"Fusion of Time-Series Optical and SAR Images Using 3D Convolutional Neural Networks for Crop Classification","author":"Teimouri, Maryam and Mokhtarzade, Mehdi and Baghdadi, Nicolas and Heipke, Christian","meta_info":{"keywords":"Agriculture,Deep Learning,Images: Sentinel,Labels: Public government data,Model: 2DCNN,Model: 3DCNN,Model: MLP,Satellite","unique-id":"WOS:000827495000001","orcid-numbers":"baghdadi, nicolas\/0000-0002-9461-4120 Heipke, Christian\/0000-0002-7007-9549","eissn":"1752-0762","earlyaccessdate":"JUN 2022","doi":"10.1080\/10106049.2022.2095446","issn":"1010-6049","journal":"GEOCARTO INTERNATIONAL","year":"2022"}}
{"bib_id":"teimouri_novel_2019","title":"A Novel Spatio-Temporal FCN-LSTM Network for Recognizing Various Crop Types Using Multi-Temporal Radar Images","author":"Teimouri, Nima and Dyrmann, Mads and Jorgensen, Rasmus Nyholm","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Model-based,Model: 2DCNN,Model: ConvLSTM,Multitemporal,Satellite","abstract":"In recent years, analyzing Synthetic Aperture Radar (SAR) data has turned into one of the challenging and interesting topics in remote sensing. Radar sensors are capable of imaging Earth's surface independently of the weather conditions, local time of day, penetrating of waves through clouds, and containing spatial information on agricultural crop types. Based on these characteristics, the main goal sought in this research is to reveal the SAR imaging data capability in recognizing various agricultural crops in the main growth season in a more clarified and detailed way by using a deep-learning-based method. In the present research, the multi-temporal C-band Sentinel 1 images were used to classify 14 major classes of agricultural crops plus background in Denmark. By considering the capability of a deep learning method in analyzing satellite images, a novel, optimal, and lightweight network structure was developed and implemented based on a combination of a fully convolutional network (FCN) and a convolutional long short-term memory (ConvLSTM) network. The average pixel-based accuracy and Intersection over Union obtained from the proposed network were 86% and 0.64, respectively. Winter rapeseed, winter barley, winter wheat, spring barley, and sugar beet had the highest pixel-based accuracies of 95%, 94%, 93%, 90%, and 90%; respectively. The pixel-based accuracies for eight crop types and the background class were more than 84%. The network prediction showed that in field borders the classification confidence was lower than the center regions of the fields. However, the proposed structure has been able to identify different crops in multi-temporal Sentinel 1 data of a large area of around 254 thousand hectares with high performance.","doi":"10.3390\/rs11080990","number":"8","volume":"11","journal":"REMOTE SENSING","month":"April","year":"2019"}}
{"bib_id":"thorp_deep_2021","title":"Deep Machine Learning with Sentinel Satellite Data to Map Paddy Rice Production Stages across West Java, Indonesia","author":"Thorp, K. R. and Drajat, D.","meta_info":{"keywords":"Agriculture,Best Model: LSTM,Crop segmentation,Deep Learning,Growth stage prediction,Images: Sentinel,Labels: Private government data,Model comparison,Model: CNN,Model: ConvLSTM,Model: GRU,Model: LSTM,Model: MLP,Model: RF,Model: SVM,Satellite,Used VI","abstract":"Indonesia recently implemented a novel, technology-driven approach for conducting agricultural production surveys, which involves monthly observations at many thousands of strategic locations and automated data logging via a cellular phone application. Data from these comprehensive field surveys offer immense value for advancing remote sensing technology to map crop production across Indonesia, particularly through the development of machine learning approaches to relate survey data with satellite imagery. The objective of this study was to compare different machine learning scenarios for classifying and mapping the temporal progression of paddy rice production stages across West Java, Indonesia using synthetic aperture radar (SAR) and optical remote sensing data from Sentinel-1 and Sentinel-2 satellites. Monthly paddy rice survey data at 21,696 locations across West Java from November 2018 through April 2019 were used for model training and testing. Five classes related to rice production stage or other field conditions were defined, including rice at tillering, heading, and harvest stages, rice fields with little to no vegetation present, and non-rice areas. A recurrent neural network (RNN) with long short term memory (LSTM) nodes provided optimal performance with classification accuracies of 79.6% and 75.9% for model training and testing, respectively, and reduced computational effort. Other approaches that incorporated a convolutional neural network (CNN) either reduced classification accuracy or increased computational effort. Deep machine learning methods (RNN and CNN) generally outperformed other non-deep classifiers, which achieved up to 63.3% accuracy for model testing. Classification accuracies were optimized by inputting two Sentinel-1 channels (VH and VV polarizations) and ten Sentinel-2 channels. Temporal patterns of paddy rice production stages were consistent between the monthly ground-based agricultural survey data and 10-m, satellite-based rice classification maps obtained by applying the LSTM-based RNN across West Java. The results demonstrated the value of combining modern agricultural survey data, satellite remote sensing, and a recurrent neural network to develop multitemporal maps of paddy rice production stages.","doi":"10.1016\/j.rse.2021.112679","issn":"0034-4257","volume":"265","journal":"REMOTE SENSING OF ENVIRONMENT","month":"November","year":"2021"}}
{"bib_id":"tian_deep_2021","title":"A Deep Learning Framework under Attention Mechanism for Wheat Yield Estimation Using Remotely Sensed Indices in the Guanzhong Plain, PR China","author":"Tian, Huiren and Wang, Pengxin and Tansey, Kevin and Han, Dong and Zhang, Jingqi and Zhang, Shuyu and Li, Hongmei","meta_info":{"keywords":"Agriculture,Deep Learning,Extra data: climate,Images: MODIS,Labels: Public government data,Model: LSTM,Satellite,Used VI,Yield prediction,Yield: County-level,Yield: Plot-level","abstract":"The rapid and effective acquisition of crop yield information is critical to the stability of food markets and development and implementation of related policies. It is an important baseline observation that is used for ensuring regional and global food security. In this study, a novel deep learning framework was developed for winter wheat yield estimation using meteorological data and two remotely sensed indices, Vegetation Temperature Condition Index (VTCI) and Leaf Area Index (LAI) at the main growth stages of winter wheat in the Guanzhong Plain. The proposed deep learning model was based on Long Short-Term Memory (LSTM) neural network with an attention mechanism (ALSTM), which the main idea is to assign attention to the key parts of the input sequence that affect the target vectors so that the specific features can be accurately extracted. The ALSTM model provided an improved estimation accuracy (R2 = 0.63, MAPE = 8.20%, RMSE = 502.71 kg\/ha, NRMSE = 11.15%) as compared with the LSTM (R2 = 0.55, MAPE = 13.46%, RMSE = 699.92 kg\/ha, NRMSE = 15.52%). A validation based on leave-one-year-out-validation further substantiated the robustness of ALSTM with smaller values of NRMSE and MAPE (13.63% and 11.54%). We demonstrated that the ALSTM model provided good generalization ability for sampling sites under different farming systems, including irrigation and rain-fed sampling sites. In addition, we evaluated the relative importance of each input variable in determining yields based on stepwise sensitivity analysis. It was found that LAI at the heading-filling stage and the milk stage as well as VTCI at the jointing stage contributed more than other input feature variables towards the corresponding yield. In conclusion, our findings highlighted that the attention mechanism helped to improve the interpretability of neural networks and the ALSTM model along with remotely sensed biophysical indices can provide a reliable and robust estimation of crop yield. An accurate estimation of wheat yield is not only helping towards informed crop management decisions but it will improve efficiency and sustainability of farming operations.","doi":"10.1016\/j.jag.2021.102375","issn":"1569-8432","volume":"102","journal":"INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION","month":"October","year":"2021"}}
{"bib_id":"tirado_climate_2010","title":"Climate Change and Food Safety: A Review","author":"Tirado, M. C. and Clarke, R. and Jaykus, L. A. and McQuatters-Gollop, A. and Frank, J. M.","meta_info":{"langid":"english","abstract":"Climate change and variability may have an impact on the occurrence of food safety hazards at various stages of the food chain, from primary production through to consumption. There are multiple pathways through which climate related factors may impact food safety including: changes in temperature and precipitation patterns, increased frequency and intensity of extreme weather events, ocean warming and acidification, and changes in contaminants' transport pathways among others. Climate change may also affect socio-economic aspects related to food systems such as agriculture, animal production, global trade, demographics and human behaviour which all influence food safety. This paper reviews the potential impacts of predicted changes in climate on food contamination and food safety at various stages of the food chain and identifies adaptation strategies and research priorities to address food safety implications of climate change. The paper concludes that there is a need for intersectoral and international cooperation to better understand the changing food safety situation and in developing and implementing adaptation strategies to address emerging risks associated with climate change.","urldate":"2022-07-14","doi":"10.1016\/j.foodres.2010.07.003","issn":"0963-9969","pages":"1745--1765","number":"7","volume":"43","series":"Climate Change and Food Science","journal":"Food Research International","month":"August","year":"2010","shorttitle":"Climate Change and Food Safety"}}
{"bib_id":"tomicek_prototyping_2021","title":"Prototyping a Generic Algorithm for Crop Parameter Retrieval across the Season Using Radiative Transfer Model Inversion and Sentinel-2 Satellite Observations","author":"Tomicek, Jiri and Misurec, Jan and Lukes, Petr","meta_info":{"keywords":"Agriculture,Canopy cover prediction,Deep Learning,Images: Sentinel,Labels: Model-based,Model: MLP,Satellite","abstract":"In this study, Sentinel-2 data were used for the retrieval of three key biophysical parameters of crops: leaf area index (LAI), leaf chlorophyll content (LCC), and leaf water content (LWC) for dominant crop types in the Czech Republic, including winter wheat (Triticum aestivum), spring barley (Hordeum vulgare), winter rapeseed (Brassica napus subsp. napus), alfalfa (Medicago sativa), sugar beet (Beta vulgaris), and corn (Zea mays subsp. Mays) in different stages of crop development. Artificial neural networks were applied in combination with an approach using look-up tables that is based on PROSAIL simulations to retrieve the biophysical properties tailored for each crop type. Crop-specific PROSAIL model optimization and validation were based upon a large dataset of in situ measurements collected in 2017 and 2018 in lowland of Central Bohemia region. For LCC and LAI, respectively, low relative root mean square error (rRMSE; 25%, 37%) was achieved. Additionally, a relatively strong correlation with in situ measurements (r = 0.80) was obtained for LAI. On the contrary, the results of the LWC parameter retrieval proved to be unsatisfactory. We have developed a generic tool for biophysical monitoring of agricultural crops based on the interpretation of Sentinel-2 satellite data by inversion of the radiation transfer model. The resulting crop condition maps can serve as precision agriculture inputs for selective fertilizer and irrigation application as well as for yield potential assessment.","doi":"10.3390\/rs13183659","number":"18","volume":"13","journal":"REMOTE SENSING","month":"September","year":"2021"}}
{"bib_id":"torres_gmes_2012","title":"GMES Sentinel-1 Mission","author":"Torres, Ramon and Snoeij, Paul and Geudtner, Dirk and Bibby, David and Davidson, Malcolm and Attema, Evert and Potin, Pierre and Rommen, Björn and Floury, Nicolas and Brown, Mike and Traver, Ignacio Navas and Deghaye, Patrick and Duesmann, Berthyl and Rosich, Betlem and Miranda, Nuno and Bruno, Claudio and L'Abbate, Michelangelo and Croci, Renato and Pietropaolo, Andrea and Huchler, Markus and Rostan, Friedhelm","meta_info":{"file":"\/home\/brandon\/Zotero\/storage\/JLDMHUIN\/S0034425712000600.html","langid":"english","abstract":"In the frame of the Global Monitoring for Environment and Security (GMES) Space Component programme, the European Space Agency (ESA) undertook the development of a European Radar Observatory (Sentinel-1), a polar orbiting two-satellite constellation for the continuation and improvement of SAR operational services and applications. Satellite and payload are being built to provide routine, day-and-night, all-weather medium (typically 10m) resolution observation capability. Ground infrastructure is provided for planning, mission control, data processing, dissemination and archiving. Free and open data access is provided. Data quality of the Sentinel-1 data products is shown along with uncertainty estimation of retrieved information products confirming specified performance and indicating application growth potential. The unique data availability performance of the Sentinel-1 routine operations makes the mission particularly suitable for emergency response support, marine surveillance, ice monitoring and interferometric applications such as detection of subsidence and landslides.","urldate":"2022-06-20","doi":"10.1016\/j.rse.2011.05.028","issn":"0034-4257","pages":"9--24","volume":"120","series":"The Sentinel Missions - New Opportunities for Science","journal":"Remote Sensing of Environment","month":"May","year":"2012"}}
{"bib_id":"tripathi_deep_2022","title":"A Deep Learning Multi-Layer Perceptron and Remote Sensing Approach for Soil Health Based Crop Yield Estimation","author":"Tripathi, Akshar and Tiwari, Reet Kamal and Tiwari, Surya Prakash","meta_info":{"keywords":"Agriculture,Deep Learning,Images: Sentinel,Labels: Field survey,Labels: Private government data,Model: MLP,Salinity prediction,Satellite,Soil moisture prediction,Soil Organic matter prediction,Used VI,Yield prediction","unique-id":"WOS:000849822800002","eissn":"1872-826X","article-number":"102959","doi":"10.1016\/j.jag.2022.102959","issn":"1569-8432","volume":"113","journal":"INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION","month":"September","year":"2022"}}
{"bib_id":"turkoglu_crop_2021","title":"Crop Mapping from Image Time Series: Deep Learning with Multi-Scale Label Hierarchies","author":"Turkoglu, Mehmet Ozgur and D'Aronco, Stefano and Perich, Gregor and Liebisch, Frank and Streit, Constantin and Schindler, Konrad and Wegner, Jan Dirk","meta_info":{"keywords":"Agriculture,Best Model: ConvLSTM,Crop segmentation,Dataset: ZueriCrop,Deep Learning,Images: Sentinel,Labels: Dataset,Model comparison,Model: ConvLSTM,Multitemporal,Satellite","abstract":"The aim of this paper is to map agricultural crops by classifying satellite image time series. Domain experts in agriculture work with crop type labels that are organised in a hierarchical tree structure, where coarse classes (like orchards) are subdivided into finer ones (like apples, pears, vines, etc.). We develop a crop classification method that exploits this expert knowledge and significantly improves the mapping of rare crop types. The threelevel label hierarchy is encoded in a convolutional, recurrent neural network (convRNN), such that for each pixel the model predicts three labels at different level of granularity. This end-to-end trainable, hierarchical network architecture allows the model to learn joint feature representations of rare classes (e.g., apples, pears) at a coarser level (e.g., orchard), thereby boosting classification performance at the fine-grained level. Additionally, labelling at different granularity also makes it possible to adjust the output according to the classification scores; as coarser labels with high confidence are sometimes more useful for agricultural practice than fine-grained but very uncertain labels. We validate the proposed method on a new, large dataset that we make public. ZueriCrop covers an area of 50 km x 48 km in the Swiss cantons of Zurich and Thurgau with a total of 116 ` 000 individual fields spanning 48 crop classes, and 28,000 (multi-temporal) image patches from Sentinel-2. We compare our proposed hierarchical convRNN model with several baselines, including methods designed for imbalanced class distributions. The hierarchical approach performs superior by at least 9.9 percentage points in F1-score.","doi":"10.1016\/j.rse.2021.112603","issn":"0034-4257","volume":"264","journal":"REMOTE SENSING OF ENVIRONMENT","month":"October","year":"2021"}}
{"bib_id":"united_nations_world_2019","title":"World Population Prospects Highlights, 2019 Revision Highlights","author":"United Nations","meta_info":{"langid":"english","isbn":"978-92-1-148316-1","year":"2019"}}
{"bib_id":"usda_national_2022","title":"National Agricultural Statistics Service Cropland Data Layer. Published Crop-Specific Data Layer [Online]. Available at: https:\/\/nassgeodata.gmu.edu\/CropScape\/. USDA-NASS, Washington, DC","author":"USDA","meta_info":{"year":"2022"}}
{"bib_id":"van_der_schalie_effect_2018","title":"The Effect of Three Different Data Fusion Approaches on the Quality of Soil Moisture Retrievals from Multiple Passive Microwave Sensors","author":"van der Schalie, Robin and de Jeu, Richard and Rodriguez-Fernandez, Nemesio and Al-Yaari, Amen and Kerr, Yann and Wigneron, Jean-Pierre and Parinussa, Robert and Drusch, Matthias","meta_info":{"keywords":"Deep Learning,Images: AMSR-E,Images: ASCAT,Images: MIRAS,Labels: Self-labelled,Model comparison,Model: MLP,Satellite,Soil moisture prediction","abstract":"Long-term climate records of soil moisture are of increased importance to climate researchers. In this study, we aim to evaluate the quality of three different fusion approaches that combine soil moisture retrieval from multiple satellite sensors. The arrival of L-band missions has led to an increased focus on the integration of L-band-based soil moisture retrievals in climate records, emphasizing the need to improve our understanding based on its added value within a multi-sensor framework. The three evaluated approaches were developed on 10-year passive microwave data (2003-2013) from two different satellite sensors, i.e., SMOS (2010-2013) and AMSR-E (2003-2011), and are based on a neural network (NN), regressions (REG), and the Land Parameter Retrieval Model (LPRM). The ability of the different approaches to best match AMSR-E and SMOS in their overlapping period was tested using an inter-comparison exercise between the SMOS and AMSR-E datasets, while the skill of the individual soil moisture products, based on anomalies, was evaluated using two verification techniques; first, a data assimilation technique that links precipitation information to the quality of soil moisture (expressed as the R-value), and secondly the triple collocation analysis (TCA). ASCAT soil moisture was included in the skill evaluation, representing the active microwave-based counterpart of soil moisture retrievals. Besides a semi-global analysis, explicit focus was placed on two regions that have strong land-atmosphere coupling, the Sahel (SA) and the central Great Plains (CGP) of North America. The NN approach gives the highest correlation coefficient between SMOS and AMSR-E, closely followed by LPRM and REG, while the absolute error is approximately the same for all three approaches. The R-value and TCA show the strength of using different satellite sources and the impact of different merging approaches on the skill to correctly capture soil moisture anomalies. The highest performance is found for AMSR-E over sparse vegetation, for SMOS over moderate vegetation, and for ASCAT over dense vegetation cover. While the two SMOS datasets (L3 and LPRM) show a similar performance, the three AMSR-E datasets do not. The good performance for AMSR-E over spare vegetation is mainly perceived for AMSR-E LPRM, benefiting from the physically based model, while AMSR-E NN shows improved skill in densely vegetated areas, making optimal use of the SMOS L3 training dataset. AMSR-E REG has a reasonable performance over sparsely vegetated areas; however, it quickly loses skill with increasing vegetation density. The findings over the SA and CGP mainly reflect results that are found in earlier sections. This confirms that historical soil moisture datasets based on a combination of these sources are a valuable source of information for climate research.","doi":"10.3390\/rs10010107","issn":"2072-4292","number":"1","volume":"10","journal":"REMOTE SENSING","month":"January","year":"2018"}}
{"bib_id":"van_tricht_worldcereal_2023","title":"WorldCereal: A Dynamic Open-Source System for Global-Scale, Seasonal, and Reproducible Crop and Irrigation Mapping","author":"Van Tricht, Kristof and Degerickx, Jeroen and Gilliams, Sven and Zanaga, Daniele and Battude, Marjorie and Grosu, Alex and Brombacher, Joost and Lesiv, Myroslava and Bayas, Juan Carlos Laso and Karanam, Santosh and Fritz, Steffen and Becker-Reshef, Inbal and Franch, Belén and Mollà-Bononad, Bertran and Boogaard, Hendrik and Pratihast, Arun Kumar and Koetz, Benjamin and Szantoi, Zoltan","meta_info":{"langid":"english","abstract":"The challenge of global food security in the face of population growth, conflict, and climate change requires a comprehensive understanding of cropped areas, irrigation practices, and the distribution of major commodity crops like maize and wheat. However, such understanding should preferably be updated at seasonal intervals for each agricultural system rather than relying on a single annual assessment. Here we present the European Space Agency-funded WorldCereal system, a global, seasonal, and reproducible crop and irrigation mapping system that addresses existing limitations in current global-scale crop and irrigation mapping. WorldCereal generates a range of global products, including temporary crop extent, seasonal maize and cereal maps, seasonal irrigation maps, seasonal active cropland maps, and model confidence layers providing insights into expected product quality. The WorldCereal product suite for the year 2021 presented here serves as a global demonstration of the dynamic open-source WorldCereal system. Validation of the products was done based on best available reference data per product. A global statistical validation for the temporary crop extent product resulted in user's and producer's accuracies of 88.5 % and 92.1 %, respectively. For crop type, a verification was performed against a newly collected street view dataset (overall agreement 82.5 %) and a limited number of publicly available in situ datasets (reaching minimum agreement of 80 %). Finally, global irrigated-area estimates were derived from available maps and statistical datasets, revealing the conservative nature of the WorldCereal irrigation product. The WorldCereal system provides a vital tool for policymakers, international organizations, and researchers to better understand global crop and irrigation patterns and to inform decision-making related to food security and sustainable agriculture. Our findings highlight the need for continued community efforts such as additional reference data collection to support further development and to push the boundaries for global agricultural mapping from space. The global products are available at https:\/\/doi.org\/10.5281\/zenodo.7875104 (Van Tricht et al., 2023).","urldate":"2024-05-20","doi":"10.5194\/essd-15-5491-2023","issn":"1866-3508","publisher":"Copernicus GmbH","pages":"5491--5515","number":"12","volume":"15","journal":"Earth System Science Data","month":"December","year":"2023","shorttitle":"WorldCereal"}}
{"bib_id":"vaswani_attention_2017","title":"Attention Is All You Need","author":"Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia","meta_info":{"abstract":"The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.","urldate":"2022-07-21","publisher":"Curran Associates, Inc.","pages":"5998--6008","volume":"30","year":"2017","booktitle":"Advances in Neural Information Processing Systems"}}
{"bib_id":"verger_optimal_2011","title":"Optimal Modalities for Radiative Transfer-Neural Network Estimation of Canopy Biophysical Characteristics: Evaluation over an Agricultural Area with CHRIS\/PROBA Observations","author":"Verger, Aleixandre and Baret, Frederic and Camacho, Fernando","meta_info":{"keywords":"Agriculture,Canopy cover prediction,Deep Learning,Images: PROBA,Labels: Model-based,Model: MLP,Satellite","abstract":"Neural networks trained over radiative transfer simulations constitute the basis of several operational algorithms to estimate canopy biophysical variables from satellite reflectance measurements. However, only little attention was paid to the training process which has a major impact on retrieval performances. This study focused on the several modalities of the training process within neural network estimation of LAI, FCOVER and FAPAR biophysical variables. Performances were evaluated over both actual experimental observations and model simulations. The SAIL and PROSPECT radiative transfer models were used here to simulate the training and the synthetic test datasets. Measurements of LAI. FCOVER and FAPAR were achieved over the Barrax (Spain) agricultural site for a range of crop types concurrently to CHRIS\/PROBA satellite image acquisition. Results showed that the spectral band selection was specific to LAI, FCOVER and FAPAR variables. The optimal band set provided significantly improved performances for LAI, while only small differences were observed for the other variables. Gaussian distributions of the radiative transfer model input variables performed better than uniform distributions for which no prior information was exploited. Including moderate uncertainties in the reflectance simulations used in the training process improved the flexibility of the neural network in cases where simulations departed slightly from observations. Simple neural network architecture with a single hidden layer of five tangent sigmoid transfer functions was performing as good as more complex architectures if the training dataset was larger than ten times the number of coefficients to tune. Small sensitivity of performances was observed depending on the way the solution was selected when several networks were trained in parallel. Finally, comparison with a NDVI based approach showed the generally better retrieval accuracy of neural networks. (C) 2010 Elsevier Inc. All rights reserved.","doi":"10.1016\/j.rse.2010.09.012","issn":"0034-4257","pages":"415--426","number":"2","volume":"115","journal":"REMOTE SENSING OF ENVIRONMENT","month":"February","year":"2011"}}
{"bib_id":"virnodkar_denseresunet_2021","title":"DenseResUNet: An Architecture to Assess Water-Stressed Sugarcane Crops from Sentinel-2 Satellite Imagery","author":"Virnodkar, Shyamal S. and Pachghare, Vinod K. and Patil, Virupakshagouda C. and Jha, Sunil Kumar","meta_info":{"keywords":"Agriculture,Crop damage detection,Deep Learning,Images: Sentinel,Labels: Field survey,Model: CNN,Satellite","abstract":"A single most immense abiotic stress globally affecting the productivity of all the crops is water stress. Hence, timely and accurate detection of the water-stressed crops is a necessary task for high productivity. Agricultural crop production can be managed and enhanced by spatial and temporal evaluation of water-stressed crops through remotely sensed data. However, detecting water-stressed crops from remote sensing images is a challenging task as various factors impacting spectral bands, vegetation indices (VIs) at the canopy and landscape scales, as well as the fact that the water stress detection threshold is crop-specific, there has yet to be substantial agreement on their usage as a pre-visual signal of water stress. This research takes the benefits of freely available remote sensing data and convolutional neural networks to perform semantic segmentation of water-stressed sugarcane crops. Here an architecture `DenseResUNet' is proposed for water-stressed sugarcane crops using segmentation based on encoder-decoder approach. The novelty of the proposed approach lies in the replacement of classical convolution operation in the UNet with the dense block. The layers of a dense block are residual modules with a dense connection. The proposed model achieved 61.91% mIoU, and 80.53% accuracy on segmenting the water-stressed sugarcane fields. This study compares the proposed architecture with the UNet, ResUNet, and DenseUNet models achieving mIoU of 32.20%, 58.34%, and 53.15%, respectively. The results of this study reveal that the model has the potential to identify water-stressed crops from remotely sensed data through deep learning techniques.","doi":"10.18280\/ts.380424","issn":"0765-0019","pages":"1131--1139","number":"4","volume":"38","journal":"TRAITEMENT DU SIGNAL","month":"August","year":"2021"}}
{"bib_id":"wagle_parameterizing_2016","title":"Parameterizing Ecosystem Light Use Efficiency and Water Use Efficiency to Estimate Maize Gross Primary Production and Evapotranspiration Using MODIS EVI","author":"Wagle, Pradeep and Gowda, Prasanna H. and Xiao, Xiangming and Anup, K. C.","meta_info":{"keywords":"Agriculture,Deep Learning,Images: MODIS,Labels: Public government data,Light use efficiency,Model: MLP,Satellite","abstract":"Quantifying global carbon and water balances requires accurate estimation of gross primary production (GPP) and evapotranspiration (ET), respectively, across space and time. Models that are based on the theory of light use efficiency (LUE) and water use efficiency (WUE) have emerged as efficient methods for predicting GPP and ET, respectively. Currently, LUE and WUE estimates are obtained from biome-specific look-up tables and coarse resolution remote sensing data with large uncertainties. The major objective of this study was to parameterize eddy covariance tower-based ecosystem LUE (ELUEEc), defined as the ratio of tower-based GPP (GPPEc) to photosynthetically active radiation (PAR), and ecosystem WUE (EWUEEc), defined as the ratio of GPPEc to tower-based ET (ETEc), using the Moderate Resolution Imaging Spectroradiometer(MODIS)-derived enhanced vegetation index (EVI) for predicting maize (Zea mays L) GPP and ET, respectively. Three adjacent AmeriFlux maize sites with different rotations (continuous maize vs. annual rotation of maize and soybean, Glycine max L.) and water management practices (rainfed vs. irrigated) located near Mead, NE, USA were selected. The EVI tracked the seasonal variations of ELUEEC (R-2=0.83) and EWUEEC (R-2 =0.74) across sites, indicating that EVI can be explicitly used as a measure of ELUEEC and EWUEEC. The predicted GPP (GPFEwE) using the parameterized ELUE model correlated well with GPP(EC) (slope = 1.0, R-2 =0.83, and RMSE = 2.85 gC m(-2) d(-1)) and was significantly improved when compared to widely used models that estimate GPP by integrating EVI and climate variables (Greenness and Radiation, Temperature and Greenness, and Vegetation Index) and the standard MOD17 GPP product. Similarly, the predicted ET (ETEwuE) using the parameterized EWUE correlated well with ETEc (slope =1.02, R-2=0.62, and RMSE = 0.83 mm ET-1) and was significantly improved when compared to the standard MOD16 ET product. Preliminary data demonstrate that ELUE and EWUE can be parameterized using EVI, offering new methods for predicting GPP and ET. (C) 2016 Elsevier B.V. All rights reserved.","doi":"10.1016\/j.agrformet.2016.03.009","issn":"0168-1923","pages":"87--97","volume":"222","journal":"AGRICULTURAL AND FOREST METEOROLOGY","month":"May","year":"2016"}}
{"bib_id":"wagner_ascat_2013","title":"The ASCAT Soil Moisture Product: A Review of Its Specifications, Validation Results, and Emerging Applications","author":"Wagner, Wolfgang and Hahn, Sebastian and Kidd, Richard and Melzer, Thomas and Bartalis, Zoltan and Hasenauer, Stefan and Figa-Saldaña, Julia and de Rosnay, Patricia and Jann, Alexander and Schneider, Stefan and Komma, Jürgen and Kubu, Gerhard and Brugger, Katharina and Aubrecht, Christoph and Züger, Johann and Gangkofner, Ute and Kienberger, Stefan and Brocca, Luca and Wang, Yong and Blöschl, Günter and Eitzinger, Josef and Steinnocher, Kla","meta_info":{"langid":"english","urldate":"2022-06-09","doi":"10.1127\/0941-2948\/2013\/0399","issn":",","publisher":"Schweizerbart'sche Verlagsbuchhandlung","pages":"5--33","journal":"Meteorologische Zeitschrift","month":"February","year":"2013","shorttitle":"The ASCAT Soil Moisture Product"}}
{"bib_id":"waldner_deep_2019","title":"Deep Learning on Edge: Extracting Field Boundaries from Satellite Images with a Convolutional Neural Network","author":"Waldner, François and Diakogiannis, Foivos I.","meta_info":{"keywords":"Agriculture,Deep Learning,Field boundary detection,Images: Sentinel,Labels: Image survey,Model: 2DCNN,Satellite","abstract":"Applications of digital agricultural services often require either farmers or their advisers to provide digital records of their field boundaries. Automatic extraction of field boundaries from satellite imagery would reduce the reliance on manual input of these records, which is time consuming, and would underpin the provision of remote products and services. The lack of current field boundary data sets seems to indicate low uptake of existing methods, presumably because of expensive image preprocessing requirements and local, often arbitrary, tuning. In this paper, we propose a data-driven, robust and general method to facilitate field boundary extraction from satellite images. We formulated this task as a multi-task semantic segmentation problem. We used ResUNet-a, a deep convolutional neural network with a fully connected UNet backbone that features dilated convolutions and conditioned inference to identify: 1) the extent of fields; 2) the field boundaries; and 3) the distance to the closest boundary. By asking the algorithm to reconstruct three correlated outputs, the model's performance and its ability to generalise greatly improve. Segmentation of individual fields was then achieved by post-processing the three model outputs, e.g., via thresholding or watershed segmentation. Using a single monthly composite image from Sentinel-2 as input, our model was highly accurate in mapping field extent, field boundaries and, consequently, individual fields. Replacing the monthly composite with a single-date image close to the compositing period marginally decreased accuracy. We then showed in a series of experiments that, without recalibration, the same model generalised well across resolutions (10m to 30m), sensors (Sentinel-2 to Landsat-8), space and time. Building consensus by averaging model predictions from at least four images acquired across the season is the key to coping with the temporal variations of accuracy. Our convolutional neural network is capable of learning complex hierarchical contextual features from the image to accurately detect field boundaries and discard irrelevant boundaries, thereby outperforming conventional edge filters. By minimising over-fitting and image preprocessing requirements, and by replacing local arbitrary decisions by data-driven ones, our approach is expected to facilitate the extraction of individual crop fields at scale.","doi":"10.1016\/j.rse.2020.111741","journal":"Remote Sensing of Environment","year":"2019"}}
{"bib_id":"waldner_detect_2021","title":"Detect, Consolidate, Delineate: Scalable Mapping of Field Boundaries Using Satellite Images","author":"Waldner, Francois and Diakogiannis, Foivos I. and Batchelor, Kathryn and Ciccotosto-Camp, Michael and Cooper-Williams, Elizabeth and Herrmann, Chris and Mata, Gonzalo and Toovey, Andrew","meta_info":{"keywords":"Agriculture,Deep Learning,Field boundary detection,Images: Sentinel,Labels: Image survey,Model: UNet,Satellite","abstract":"Digital agriculture services can greatly assist growers to monitor their fields and optimize their use throughout the growing season. Thus, knowing the exact location of fields and their boundaries is a prerequisite. Unlike property boundaries, which are recorded in local council or title records, field boundaries are not historically recorded. As a result, digital services currently ask their users to manually draw their field, which is time-consuming and creates disincentives. Here, we present a generalized method, hereafter referred to as DECODE (DEtect, COnsolidate, and DElinetate), that automatically extracts accurate field boundary data from satellite imagery using deep learning based on spatial, spectral, and temporal cues. We introduce a new convolutional neural network (FracTAL ResUNet) as well as two uncertainty metrics to characterize the confidence of the field detection and field delineation processes. We finally propose a new methodology to compare and summarize field-based accuracy metrics. To demonstrate the performance and scalability of our method, we extracted fields across the Australian grains zone with a pixel-based accuracy of 0.87 and a field-based accuracy of up to 0.88 depending on the metric. We also trained a model on data from South Africa instead of Australia and found it transferred well to unseen Australian landscapes. We conclude that the accuracy, scalability and transferability of DECODE shows that large-scale field boundary extraction based on deep learning has reached operational maturity. This opens the door to new agricultural services that provide routine, near-real time field-based analytics.","doi":"10.3390\/rs13112197","number":"11","volume":"13","journal":"REMOTE SENSING","month":"June","year":"2021"}}
{"bib_id":"wang_cctnet_2022","title":"CCTNet: Coupled CNN and Transformer Network for Crop Segmentation of Remote Sensing Images","author":"Wang, Hong and Chen, Xianzhong and Zhang, Tianxiang and Xu, Zhiyong and Li, Jiangyun","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Public government data,Model: 2DCNN,Model: Transformer,Satellite","unique-id":"WOS:000794484600001","researcherid-numbers":"Wang, Hong\/AHD-6760-2022 Zhang, Tianxiang\/GOG-8400-2022","orcid-numbers":"Wang, Hong\/0000-0002-7780-1661 xianzhong, chen\/0000-0003-4113-6994 Xu, Zhiyong\/0000-0002-3210-8839 Li, Jiangyun\/0000-0003-2288-7901","eissn":"2072-4292","article-number":"1956","doi":"10.3390\/rs14091956","number":"9","volume":"14","journal":"REMOTE SENSING","month":"May","year":"2022"}}
{"bib_id":"wang_combining_2020","title":"Combining Multi-Source Data and Machine Learning Approaches to Predict Winter Wheat Yield in the Conterminous United States","author":"Wang, Yumiao and Zhang, Zhou and Feng, Luwei and Du, Qingyun and Runge, Troy","meta_info":{"keywords":"Agriculture,Best Model: Adaboost,Deep Learning,Extra data: climate,Images: MODIS,Labels: Public government data,Model comparison,Model: AdaBoost,Model: MLP,Model: RF,Model: SVM,Satellite,Used VI,Yield prediction,Yield: County-level","abstract":"Winter wheat (Triticum aestivum L.) is one of the most important cereal crops, supplying essential food for the world population. Because the United States is a major producer and exporter of wheat to the world market, accurate and timely forecasting of wheat yield in the United States (U.S.) is fundamental to national crop management as well as global food security. Previous studies mainly have focused on developing empirical models using only satellite remote sensing images, while other yield determinants have not yet been adequately explored. In addition, these models are based on traditional statistical regression algorithms, while more advanced machine learning approaches have not been explored. This study used advanced machine learning algorithms to establish within-season yield prediction models for winter wheat using multi-source data to address these issues. Specifically, yield driving factors were extracted from four different data sources, including satellite images, climate data, soil maps, and historical yield records. Subsequently, two linear regression methods, including ordinary least square (OLS) and least absolute shrinkage and selection operator (LASSO), and four well-known machine learning methods, including support vector machine (SVM), random forest (RF), Adaptive Boosting (AdaBoost), and deep neural network (DNN), were applied and compared for estimating the county-level winter wheat yield in the Conterminous United States (CONUS) within the growing season. Our models were trained on data from 2008 to 2016 and evaluated on data from 2017 and 2018, with the results demonstrating that the machine learning approaches performed better than the linear regression models, with the best performance being achieved using the AdaBoost model (R-2 = 0.86, RMSE = 0.51 t\/ha, MAE = 0.39 t\/ha). Additionally, the results showed that combining data from multiple sources outperformed single source satellite data, with the highest accuracy being obtained when the four data sources were all considered in the model development. Finally, the prediction accuracy was also evaluated against timeliness within the growing season, with reliable predictions (R-2 $>$ 0.84) being able to be achieved 2.5 months before the harvest when the multi-source data were combined.","doi":"10.3390\/rs12081232","number":"8","volume":"12","journal":"REMOTE SENSING","month":"April","year":"2020"}}
{"bib_id":"wang_deep_2022","title":"Deep Segmentation and Classification of Complex Crops Using Multi-Feature Satellite Imagery","author":"Wang, Lijun and Wang, Jiayao and Zhang, Xiwang and Wang, Laigang and Qin, Fen","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Field survey,Model: 2DCNN,Satellite,Used VI","unique-id":"WOS:000840602400001","eissn":"1872-7107","article-number":"107249","doi":"10.1016\/j.compag.2022.107249","issn":"0168-1699","volume":"200","journal":"COMPUTERS AND ELECTRONICS IN AGRICULTURE","month":"September","year":"2022"}}
{"bib_id":"wang_estimation_2018","title":"Estimation of Soil Salt Content (SSC) in the Ebinur Lake Wetland National Nature Reserve (ELWNNR), Northwest China, Based on a Bootstrap-BP Neural Network Model and Optimal Spectral Indices","author":"Wang, Xiaoping and Zhang, Fei and Ding, Jianli and Kung, Hsiang-te and Latif, Aamir and Johnson, Verner C.","meta_info":{"keywords":"Deep Learning,Images: HJ-1,Images: Landsat,Labels: Field survey,Model: MLP,Salinity prediction,Satellite","abstract":"Soil salinity is recognized worldwide as a major threat to agriculture, particularly in arid regions. Producers and decision-makers thus require updated and accurate maps of salinity in agronomical and environmentally relevant regions. The goals of this study were to test various regression models for estimating soil salt content based on hyperspectral data, HJ-CCD images, and Landsat OLI data using; develop optimal band Difference Index (DI), Ratio Index (RI), and Normalization Index (NDI) algorithms for monitoring soil salt content using image and spectral data; and to compare the performances of the proposed models using a Bootstrap-BP neural network model (Bootstrap-BPNN) from different data sources. The results showed that previously published optimal remote sensing parameters can be applied to estimate the soil salt content in the Ebinur Lake Wetland National Nature Reserve (ELWNNR). Optimal band combination indices based on DI, RI, and NDI were developed for different data sources. Then, the Bootstrap-BP neural network model was built using 1000 groups of Bootstrap samples of remote sensing indices (DI, RI and NDI) and soil salt content. When verifying the accuracy of hyperspectral data, the model yields an R-2 value of 0.95, a root mean square error (RMSE) of 4.38 g\/kg, and a residual predictive deviation (RPD) of 3.36. The optimal model for remote sensing images was the first derivative model of Landsat OLI, which yielded R2 value of 0.91, RMSE of 4.82 g\/kg, and RPD of 3.32; these data indicated that this model has a high predictive ability. When comparing the salinization monitoring accuracy of satellite images to that of ground hyperspectral data, the accuracy of the first derivative of the Landsat OLI model was close to that of the hyperspectral parameter model. Soil salt content was inverted using the first derivative of the Landsat OLI model in the study area. (C) 2017 Elsevier B.V. All rights reserved.","doi":"10.1016\/j.scitotenv.2017.10.025","issn":"0048-9697","pages":"918--930","volume":"615","journal":"SCIENCE OF THE TOTAL ENVIRONMENT","month":"February","year":"2018"}}
{"bib_id":"wang_evaluating_2022","title":"Evaluating the Effectiveness of Machine Learning and Deep Learning Models Combined Time-Series Satellite Data for Multiple Crop Types Classification over a Large-Scale Region","author":"Wang, Xue and Zhang, Jiahua and Xun, Lan and Wang, Jingwen and Wu, Zhenjiang and Henchiri, Malak and Zhang, Shichao and Zhang, Sha and Bai, Yun and Yang, Shanshan and Li, Shuaishuai and Yu, Xiang","meta_info":{"keywords":"Agriculture,Deep Learning,Images: MODIS,Labels: Model-based,Model: 1DCNN,Model: LSTM,Model: RF,Model: SVM,Satellite","unique-id":"WOS:000801957800001","orcid-numbers":"Zhang, Shichao\/0000-0002-5972-5474 Yu, Xiang\/0000-0002-7387-1603 Zhang, Jiahua\/0000-0002-2894-9627","eissn":"2072-4292","article-number":"2341","doi":"10.3390\/rs14102341","number":"10","volume":"14","journal":"REMOTE SENSING","month":"May","year":"2022"}}
{"bib_id":"wang_exploring_2022","title":"Exploring the Potential of Multispectral Satellite Images for Estimating the Contents of Cadmium and Lead in Cropland: The Effect of the Dimidiate Pixel Model and Random Forest","author":"Wang, Li and Zhou, Yong and Liu, Jingyi and Liu, Yujie and Zuo, Qian and Li, Qing","meta_info":{"keywords":"Agriculture,Best Model: RF,Deep Learning,Heavy metal pollution regression,Heavy metal pollution regression direct,Images: Sentinel,Labels: Field survey,Model comparison,Model: MLP,Model: RF,Satellite,Used VI","unique-id":"WOS:000830813500001","orcid-numbers":"Zuo, Qian\/0000-0001-7055-3645","eissn":"1879-1786","article-number":"132922","doi":"10.1016\/j.jclepro.2022.132922","issn":"0959-6526","volume":"367","journal":"JOURNAL OF CLEANER PRODUCTION","month":"September","year":"2022"}}
{"bib_id":"wang_mapping_2020","title":"Mapping Crop Types in Southeast India with Smartphone Crowdsourcing and Deep Learning","author":"Wang, Sherrie and Di Tommaso, Stefania and Faulkner, Joey and Friedel, Thomas and Kennepohl, Alexander and Strey, Rob and Lobell, David B.","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Sentinel,Labels: crowdsourcing,Model comparison,Model: 2DCNN,Model: RF,Satellite,Used VI","abstract":"High resolution satellite imagery and modern machine learning methods hold the potential to fill existing data gaps in where crops are grown around the world at a sub-field level. However, high resolution crop type maps have remained challenging to create in developing regions due to a lack of ground truth labels for model development. In this work, we explore the use of crowdsourced data, Sentinel-2 and DigitalGlobe imagery, and convolutional neural networks (CNNs) for crop type mapping in India. Plantix, a free app that uses image recognition to help farmers diagnose crop diseases, logged 9 million geolocated photos from 2017-2019 in India, 2 million of which are in the states of Andhra Pradesh and Telangana in India. Crop type labels based on farmer-submitted images were added by domain experts and deep CNNs. The resulting dataset of crop type at coordinates is high in volume, but also high in noise due to location inaccuracies, submissions from out-of-field, and labeling errors. We employed a number of steps to clean the dataset, which included training a CNN on very high resolution DigitalGlobe imagery to filter for points that are within a crop field. With this cleaned dataset, we extracted Sentinel time series at each point and trained another CNN to predict the crop type at each pixel. When evaluated on the highest quality subset of crowdsourced data, the CNN distinguishes rice, cotton, and ``other'' crops with 74% accuracy in a 3-way classification and outperforms a random forest trained on harmonic regression features. Furthermore, model performance remains stable when low quality points are introduced into the training set. Our results illustrate the potential of non-traditional, high-volume\/high-noise datasets for crop type mapping, some improvements that neural networks can achieve over random forests, and the robustness of such methods against moderate levels of training set noise. Lastly, we caution that obstacles like the lack of good Sentinel-2 cloud mask, imperfect mobile device location accuracy, and preservation of privacy while improving data access will need to be addressed before crowdsourcing can widely and reliably be used to map crops in smallholder systems.","doi":"10.3390\/rs12182957","number":"18","volume":"12","journal":"REMOTE SENSING","month":"September","year":"2020"}}
{"bib_id":"wang_weakly_2020","title":"Weakly Supervised Deep Learning for Segmentation of Remote Sensing Imagery","author":"Wang, Sherrie and Chen, William and Xie, Sang Michael and Xie, Sang Michael and Azzari, George and Lobell, David B.","meta_info":{"keywords":"Dataset: CDL,Deep Learning,Images: Landsat,Labels: Dataset,LULCiA,Model: 2DCNN,Satellite","pmid":"null","pmcid":"null","abstract":"Accurate automated segmentation of remote sensing data could benefit applications from land cover mapping and agricultural monitoring to urban development surveyal and disaster damage assessment. While convolutional neural networks (CNNs) achieve state-of-the-art accuracy when segmenting natural images with huge labeled datasets, their successful translation to remote sensing tasks has been limited by low quantities of ground truth labels, especially fully segmented ones, in the remote sensing domain. In this work, we perform cropland segmentation using two types of labels commonly found in remote sensing datasets that can be considered sources of ``weak supervision'': (1) labels comprised of single geotagged points and (2) image-level labels. We demonstrate that (1) a U-Net trained on a single labeled pixel per image and (2) a U-Net image classifier transferred to segmentation can outperform pixel-level algorithms such as logistic regression, support vector machine, and random forest. While the high performance of neural networks is well-established for large datasets, our experiments indicate that U-Nets trained on weak labels outperform baseline methods with as few as 100 labels. Neural networks, therefore, can combine superior classification performance with efficient label usage, and allow pixel-level labels to be obtained from image labels.","doi":"10.3390\/rs12020207","journal":"Remote Sensing","year":"2020"}}
{"bib_id":"watson-hernandez_oil_2022","title":"Oil Palm Yield Estimation Based on Vegetation and Humidity Indices Generated from Satellite Images and Machine Learning Techniques","author":"Watson-Hernandez, Fernando and Gomez-Calderon, Natalia and da Silva, Rouverson Pereira","meta_info":{"keywords":"Agriculture,Deep Learning,Images: Landsat,Labels: Business,Model: MLP,Model: RF,Model: XGB,Satellite,Yield prediction,Yield: County-level","unique-id":"WOS:000775673200001","researcherid-numbers":"SILVA, ROUVERSON\/M-2254-2018","orcid-numbers":"Gomez-Calderon, Natalia\/0000-0001-7961-7529 SILVA, ROUVERSON\/0000-0001-8852-2548 Watson-Hernandez, Fernando\/0000-0001-8258-4668","eissn":"2624-7402","doi":"10.3390\/agriengineering4010019","pages":"279--291","number":"1","volume":"4","journal":"AGRIENGINEERING","month":"March","year":"2022"}}
{"bib_id":"weiss_remote_2020","title":"Remote Sensing for Agricultural Applications: A Meta-Review","author":"Weiss, M. and Jacob, F. and Duveiller, G.","meta_info":{"langid":"english","abstract":"Agriculture provides humanity with food, fibers, fuel, and raw materials that are paramount for human livelihood. Today, this role must be satisfied within a context of environmental sustainability and climate change, combined with an unprecedented and still-expanding human population size, while maintaining the viability of agricultural activities to ensure both subsistence and livelihoods. Remote sensing has the capacity to assist the adaptive evolution of agricultural practices in order to face this major challenge, by providing repetitive information on crop status throughout the season at different scales and for different actors. We start this review by making an overview of the current remote sensing techniques relevant for the agricultural context. We present the agronomical variables and plant traits that can be estimated by remote sensing, and we describe the empirical and deterministic approaches to retrieve them. A second part of this review illustrates recent research developments that permit to strengthen applicative capabilities in remote sensing according to specific requirements for different types of stakeholders. Such agricultural applications include crop breeding, agricultural land use monitoring, crop yield forecasting, as well as ecosystem services in relation to soil and water resources or biodiversity loss. Finally, we provide a synthesis of the emerging opportunities that should strengthen the role of remote sensing in providing operational, efficient and long-term services for agricultural applications.","urldate":"2022-05-19","doi":"10.1016\/j.rse.2019.111402","issn":"0034-4257","pages":"111402","volume":"236","journal":"Remote Sensing of Environment","month":"January","year":"2020","shorttitle":"Remote Sensing for Agricultural Applications"}}
{"bib_id":"wolanin_estimating_2019","title":"Estimating Crop Primary Productivity with Sentinel-2 and Landsat 8 Using Machine Learning Methods Trained with Radiative Transfer Simulations","author":"Wolanin, Aleksandra and Camps-Valls, Gustau and Gomez-Chova, Luis and Mateo-Garcia, Gonzalo and van der Tol, Christiaan and Zhang, Yongguang and Guanter, Luis","meta_info":{"keywords":"Agriculture,Deep Learning,Extra data: climate,GPP prediction,Images: Landsat,Images: Sentinel,Labels: Model-based,Model: MLP,Model: RF,Satellite,Used VI","abstract":"Satellite remote sensing has been widely used in the last decades for agricultural applications, both for assessing vegetation condition and for subsequent yield prediction. Existing remote sensing-based methods to estimate gross primary productivity (GPP), which is an important variable to indicate crop photosynthetic function and stress, typically rely on empirical or semi-empirical approaches, which tend to over-simplify photosynthetic mechanisms. In this work, we take advantage of all parallel developments in mechanistic photosynthesis modeling and satellite data availability for an advanced monitoring of crop productivity. In particular, we combine process-based modeling with the soil-canopy energy balance radiative transfer model (SCOPE) with Sentinel-2 and Landsat 8 optical remote sensing data and machine learning methods in order to estimate crop GPP. With this approach, we by-pass the need for an intermediate step to retrieve the set of vegetation biophysical parameters needed to accurately model photosynthesis, while still accounting for the complex processes of the original physically-based model. Several implementations of the machine learning models are tested and validated using simulated and flux tower-based GPP data. Our final neural network model is able to estimate GPP at the tested flux tower sites with r(2) of 0.92 and RMSE of 1.38 gC d(-1) m(-2), which outperforms empirical models based on vegetation indices. The first test of applicability of this model to Landsat 8 data showed good results (r(2) of 0.82 and RMSE of 1.97 gC d(-1) m(-2)), which suggests that our approach can be further applied to other sensors. Modeling and testing is restricted to C3 crops in this study, but can be extended to C4 crops by producing a new training dataset with SCOPE that accounts for the different photosynthetic pathways. Our model successfully estimates GPP across a variety of C3 crop types and environmental conditions even though it does not use any local information from the corresponding sites. This highlights its potential to map crop productivity from new satellite sensors at a global scale with the help of current Earth observation cloud computing platforms.","doi":"10.1016\/j.rse.2019.03.002","issn":"0034-4257","pages":"441--457","volume":"225","journal":"REMOTE SENSING OF ENVIRONMENT","month":"May","year":"2019"}}
{"bib_id":"wolanin_estimating_2020","title":"Estimating and Understanding Crop Yields with Explainable Deep Learning in the Indian Wheat Belt","author":"Wolanin, Aleksandra and Mateo-Garcia, Gonzalo and Camps-Valls, Gustau and Gomez-Chova, Luis and Meroni, Michele and Duveiller, Gregory and Liangzhi, You and Guanter, Luis","meta_info":{"keywords":"Agriculture,Best Model: 1DCNN,Deep Learning,Extra data: climate,Images: MODIS,Labels: Public government data,Model comparison,Model: 1DCNN,Model: RF,Satellite,Yield prediction,Yield: County-level","abstract":"Forecasting crop yields is becoming increasingly important under the current context in which food security needs to be ensured despite the challenges brought by climate change, an expanding world population accompanied by rising incomes, increasing soil erosion, and decreasing water resources. Temperature, radiation, water availability and other environmental conditions influence crop growth, development, and final grain yield in a complex nonlinear manner. Machine learning (ML) techniques, and deep learning (DL) methods in particular, can account for such nonlinear relations between yield and its covariates. However, they typically lack transparency and interpretability, since the way the predictions are derived is not directly evident. Yet, in the context of yield forecasting, understanding which are the underlying factors behind both a predicted loss or gain is of great relevance. Here, we explore how to benefit from the increased predictive performance of DL methods while maintaining the ability to interpret how the models achieve their results. To do so, we applied a deep neural network to multivariate time series of vegetation and meteorological data to estimate the wheat yield in the Indian Wheat Belt. Then, we visualized and analyzed the features and yield drivers learned by the model with the use of regression activation maps. The DL model outperformed other tested models (ridge regression and random forest) and facilitated the interpretation of variables and processes that lead to yield variability. The learned features were mostly related to the length of the growing season, and temperature and light conditions during this time. For example, our results showed that high yields in 2012 were associated with low temperatures accompanied by sunny conditions during the growing period. The proposed methodology can be used for other crops and regions in order to facilitate application of DL models in agriculture.","doi":"10.1088\/1748-9326\/ab68ac","issn":"1748-9326","number":"2","volume":"15","journal":"ENVIRONMENTAL RESEARCH LETTERS","month":"February","year":"2020"}}
{"bib_id":"wu_comparison_2015","title":"Comparison of Two Inversion Methods for Leaf Area Index Using HJ-1 Satellite Data in a Temperate Meadow Steppe","author":"Wu, Qiong and Jin, Yunxiang and Bao, Yuhai and Hai, Quansheng and Yan, Ruirui and Chen, Baorui and Zhang, Hongbin and Zhang, Baohui and Li, Zhenwang and Li, Xiaoyu and Xin, Xiaoping","meta_info":{"keywords":"Agriculture,Canopy cover prediction,Deep Learning,Images: HJ-1,Labels: Field survey,Model: MLP,Satellite","abstract":"Leaf area index (LAI) is one of the most important parameters for determining grassland canopy conditions. LAI controls numerous biological and physical processes in grassland ecosystems. Remote-sensing techniques are effective for estimating grassland LAI at a regional scale. Comparison of LAI inversion methods based on remote sensing is significant for accurate estimation of LAI in particular areas. In this study, we developed and compared two inversion models to estimate the LAI of a temperate meadow steppe in Hulunbuir, Inner Mongolia, China, based on HJ-1 satellite data and field-measured LAI data. LAI was measured from early June to late August in 2013, obtained from 326 sampling data. The back propagation (BP) neural network method proved better than the statistical regression model for estimating grassland LAI, the accuracy of the former being 82.8%. We then explored the spatio-temporal distribution in LAI of Stipa baicalensis Roshev. in the meadow steppe of Hulunbuir, including cut, grazed, and fenced plots. The LAI in the cut and grazed plots reflected the growth variations in S. baicalensis Roshev. However, because of the obvious litter layer, the LAI in the fenced plots was underestimated.","doi":"10.1080\/01431161.2015.1040135","issn":"0143-1161","publisher":"Global Change Unit Univ Valencia; City Council Torrent; European Space Agcy; Inst Nacl Tecn Aeroesp; Minist Def Spain; Airbus Def and Space; Elecnor Deimos Imaging EOLAB SL; SM GEODIM","pages":"5192--5207","number":"19-20, SI","volume":"36","journal":"INTERNATIONAL JOURNAL OF REMOTE SENSING","month":"October","year":"2015"}}
{"bib_id":"wu_winter_2021","title":"Winter Wheat Planting Area Extraction Using SAR Change Detection","author":"Wu, Lin and Qi, Wenwen and Guo, Zhengwei and Zhao, Jianhui and Yang, Huijin and Li, Ning","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Model-based,Model: 2DCNN,Satellite","abstract":"With its all-day and all-weather imaging capability, Synthetic Aperture Radar (SAR) has shown great potential in crop identification. This letter puts forward a novel method of extracting winter wheat planting area by means of SAR change detection. Based on the phenological differences between winter wheat and other crops, the Difference Image (DI) is generated firstly by the different temporal SAR images. Then, Object Markov Random Field (OMRF) model is used to DI pre-classification. Finally, Convolutional Neural Network (CNN) is utilized to obtain the better area extraction result of winter wheat. The area extraction accuracy is proved by the field survey data, with an accuracy of 90.53%. This research can provide a new idea and method for agricultural remote sensing monitoring.","doi":"10.1080\/2150704X.2021.1951873","issn":"2150-704X","pages":"951--960","number":"10","volume":"12","journal":"REMOTE SENSING LETTERS","month":"October","year":"2021"}}
{"bib_id":"xie_combining_2022","title":"Combining CERES-Wheat Model, Sentinel-2 Data, and Deep Learning Method for Winter Wheat Yield Estimation","author":"Xie, Yi","meta_info":{"keywords":"Agriculture,Deep Learning,Extra data: climate,Images: Sentinel,Labels: Model-based,Labels: Public government data,Model: LSTM,Satellite,Yield prediction,Yield: County-level","abstract":"Timely and accurate regional wheat yield estimates is crucial to food security and sustainable development in the agricultural sector. In this study, a novel long short-term memory network (LSTM) model was developed to estimate wheat yield in Henan Province of China by combining field-measured yields, the time series of leaf area index (LAI) and yields simulated from CERES-Wheat model, and the LAI retrieved from Sentinel-2 imagery. The LSTM model was pretrained using the simulated LAI and yields at the agro-meteorological stations, and was retrained by the Sentinel-2 LAI and measured yields, hereafter referred to as retrained LSTM model. The yield estimation accuracy of the retrained LSTM model was compared with that of the LSTM model trained by the simulations alone (hereafter referred to as CGM-trained LSTM model) and that of the LSTM model trained by the Sentinel-2 LAI and measured yields alone (hereafter referred to as RS-trained LSTM model). The results showed that, at both the site and county levels, the retrained LSTM model provided improved accuracies compared with the CGM-trained and RS-trained LSTM models. It was because the accurate estimates of wheat yield at field scales were extended to regional scales through a combination of the advantages of both the crop growth models and satellite imagery. This study portrays the benefits of integrating crop growth models, satellite data and LSTM model in order to perform more reliable crop yield estimations over large areas.","urldate":"2022-03-07","doi":"10.1080\/01431161.2022.2026521","issn":"0143-1161","publisher":"Taylor & Francis","pages":"630--648","number":"2","volume":"43","journal":"International Journal of Remote Sensing","month":"January","year":"2022"}}
{"bib_id":"xie_deep_2019","title":"Deep Convolutional Neural Network for Mapping Smallholder Agriculture Using High Spatial Resolution Satellite Image","author":"Xie, Bin and Zhang, Hankui K. and Xue, Jie","meta_info":{"keywords":"Agriculture,Best Model: CNN,Crop segmentation,Deep Learning,Images: GF1,Labels: Image survey,Model comparison,Model: 2DCNN,Model: RF,Satellite","abstract":"In classification of satellite images acquired over smallholder agricultural landscape with complex spectral profiles of various crop types, exploring image spatial information is important. The deep convolutional neural network (CNN), originally designed for natural image recognition in the computer vision field, can automatically explore high level spatial information and thus is promising for such tasks. This study tried to evaluate different CNN structures for classification of four smallholder agricultural landscapes in Heilongjiang, China using pan-sharpened 2 m GaoFen-1 (meaning high resolution in Chinese) satellite images. CNN with three pooling strategies: without pooling, with max pooling and with average pooling, were evaluated and compared with random forest. Two different numbers (70,000 and 290,000) of CNN learnable parameters were examined for each pooling strategy. The training and testing samples were systematically sampled from reference land cover maps to ensure sample distribution proportional to the reference land cover occurrence and included 60,000-400,000 pixels to ensure effective training. Testing sample classification results in the four study areas showed that the best pooling strategy was the average pooling CNN and that the CNN significantly outperformed random forest (2.4-3.3% higher overall accuracy and 0.05-0.24 higher kappa coefficient). Visual examination of CNN classification maps showed that CNN can discriminate better the spectrally similar crop types by effectively exploring spatial information. CNN was still significantly outperformed random forest using training samples that were evenly distributed among classes. Furthermore, future research to improve CNN performance was discussed.","doi":"10.3390\/s19102398","number":"10","volume":"19","journal":"SENSORS","month":"May","year":"2019"}}
{"bib_id":"xie_integration_2021","title":"Integration of a Crop Growth Model and Deep Learning Methods to Improve Satellite-Based Yield Estimation of Winter Wheat in Henan Province, China","author":"Xie, Yi and Huang, Jianxi","meta_info":{"keywords":"Agriculture,Best Model: LSTM,Crop segmentation,Deep Learning,Extra data: climate,Extra data: soil,Images: MODIS,Labels: Model-based,Labels: Public government data,Model: 1DCNN,Model: LSTM,Model: RF,Satellite,Yield prediction,Yield: County-level","abstract":"Timely and accurate regional crop-yield estimates are crucial for guiding agronomic practices and policies to improve food security. In this study, a crop-growth model was integrated with time series of remotely sensed data through deep learning (DL) methods to improve the accuracy of regional wheat-yield estimations in Henan Province, China. Firstly, the time series of moderate-resolution imaging spectroradiometer (MODIS) normalized difference vegetation index (NDVI) were input into the long short-term memory network (LSTM) model to identify the wheat-growing region, which was further used to estimate wheat areas at the municipal and county levels. Then, the leaf area index (LAI) and grain-yield time series simulated by the Crop Environment REsource Synthesis for Wheat (CERES-Wheat) model were used to train and evaluate the LSTM, one-dimensional convolutional neural network (1-D CNN) and random forest (RF) models, respectively. Finally, an exponential model of the relationship between the field-measured LAI and MODIS NDVI was applied to obtain the regional LAI, which was input into the trained LSTM, 1-D CNN and RF models to estimate wheat yields within the wheat-growing region. The results showed that the linear correlations between the estimated wheat areas and the statistical areas were significant at both the municipal and county levels. The LSTM model provided more accurate estimates of wheat yields, with higher R-2 values and lower root mean square error (RMSE) and mean relative error (MRE) values than the 1-D CNN and RF models. The LSTM model has an inherent advantage in capturing phenological information contained in the time series of the MODIS-derived LAI, which is important for satellite-based crop-yield estimates.","doi":"10.3390\/rs13214372","number":"21","volume":"13","journal":"REMOTE SENSING","month":"November","year":"2021"}}
{"bib_id":"xu_deepcropmapping_2020","title":"DeepCropMapping: A Multi-Temporal Deep Learning Approach with Improved Spatial Generalizability for Dynamic Corn and Soybean Mapping","author":"Xu, Jinfan and Zhu, Yue and Zhong, Renhai and Lin, Zhixian and Xu, Jialu and Jiang, Hao and Huang, Jingfeng and Li, Haifeng and Lin, Tao","meta_info":{"keywords":"Agriculture,Best Model: LSTM,Crop segmentation,Deep Learning,Images: Landsat,Labels: CDL,Model comparison,Model: LSTM,Model: MLP,Model: RF,Model: Transformer,Multitemporal,Satellite","abstract":"Accurate crop mapping provides important and timely information for decision support on the estimation of crop production at large scale. Most existing crop-specific cover products based on remote sensing data and machine learning algorithms cannot serve large agriculture production areas as a result of poor model transfer capabilities. Developing a generalizable crop classification model for spatial transfer across regions is greatly needed. A deep learning approach, named DeepCropMapping (DCM), has been developed based on long short-term memory structure with attention mechanisms through integrating multi-temporal and multi-spectral remote sensing data for large-scale dynamic corn and soybean mapping. Full cross validation of classification experiments were conducted in six sites each covering 2,890,000 pixels at 30 m resolution in the U.S. corn belt from Year 2015 to 2018. Landsat Analysis Ready Data (ARD) and Cropland Data Layer (CDL) were adopted as the input satellite observations and ground reference, respectively. Transformer, Random Forest (RF), and Multilayer Perceptron (MLP) models were built for comparison. The DCM model produced a mean kappa score of 85.8% in base sites and a mean average kappa score of 82.0% in transfer sites at the end of the growing season. It yielded a comparable performance to Transformer and better than RF and MLP at the local test. The DCM model significantly outperformed other three models with a 95% confidence interval in the spatial transfer analysis. The results demonstrated the capability of learning generalizable features by the DCM model from ARD time series. The computational complexity analysis suggested that the DCM model required a shorter training time than Transformer but longer than MLP and RF. The results of the in-season classification experiment indicated the DCM model captured critical information from key growth phases and achieved higher accuracy than other models after the beginning of July. By monitoring the classification confidence in each time step, the results showed that the increased length of seasonal remote sensing time series would reduce the classification uncertainty in all sites. This study provided a viable option toward large-scale dynamic crop mapping through the integration of deep learning and remote sensing time series.","doi":"10.1016\/j.rse.2020.111946","issn":"0034-4257","volume":"247","journal":"REMOTE SENSING OF ENVIRONMENT","month":"September","year":"2020"}}
{"bib_id":"xu_downscaling_2022","title":"Downscaling SMAP Soil Moisture Using a Wide & Deep Learning Method over the Continental United States","author":"Xu, Mengyuan and Yao, Ning and Yang, Haoxuan and Xu, Jia and Hu, Annan and de Goncalves, Luis Gustavo Goncalves and Liu, Gang","meta_info":{"keywords":"Deep Learning,Images: MODIS,Images: SMAP,Labels: Model-based,Labels: Public government data,Model: MLP,Satellite,Soil moisture prediction","unique-id":"WOS:000794990400002","orcid-numbers":"Yang, Haoxuan\/0000-0001-7389-1447","eissn":"1879-2707","article-number":"127784","doi":"10.1016\/j.jhydrol.2022.127784","issn":"0022-1694","volume":"609","journal":"JOURNAL OF HYDROLOGY","month":"June","year":"2022"}}
{"bib_id":"yang_fully_2022","title":"Fully Automated Classification Method for Crops Based on Spatiotemporal Deep-Learning Fusion Technology","author":"Yang, Shuting and Gu, Lingjia and Li, Xiaofeng and Gao, Fang and Jiang, Tao","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Image survey,Model: 1DCNN,Model: 3DCNN,Multitemporal,Satellite,Used VI","abstract":"Accurate and timely crop mapping is essential for agricultural applications, and deep-learning methods have been applied on a range of remotely sensed data sources to classify crops. In this article, we develop a novel crop classification method based on spatiotemporal deep-learning fusion technology. However, for crop mapping, the selection and labeling of training samples is expensive and time consuming. Therefore, we propose a fully automated training-sample-selection method. First, we design the method according to image processing algorithms and the concept of a sliding window. Second, we develop the Geo-3D convolutional neural network (CNN) and Geo-Conv1D for crop classification using time-series Sentinel-2 imagery. Specifically, we integrate geographic information of crops into the structure of deep-learning networks. Finally, we apply an active learning strategy to integrate the classification advantages of Geo-3D CNN and Geo-Conv1D. Experiments conducted in Northeast China show that the proposed sampling method can reliably provide and label a large number of samples and achieve satisfactory results for different deep-learning networks. Based on the automatic selection and labeling of training samples, the crop classification method based on spatiotemporal deep-learning fusion technology can achieve the highest overall accuracy (OA) with approximately 92.50% as compared with Geo-Conv1D (91.89%) and Geo-3D CNN (91.27%) in the three study areas, indicating that the proposed method is effective and efficient in multi-temporal crop classification.","doi":"10.1109\/TGRS.2021.3113014","issn":"1558-0644","pages":"1--16","volume":"60","journal":"IEEE Transactions on Geoscience and Remote Sensing","year":"2022"}}
{"bib_id":"ye_resnet-locust-bn_2020","title":"ResNet-Locust-BN Network-Based Automatic Identification of East Asian Migratory Locust Species and Instars from RGB Images","author":"Ye, Sijing and Lu, Shuhan and Bai, Xuesong and Gu, Jinfeng","meta_info":{"keywords":"Agriculture,Deep Learning","abstract":"Locusts are agricultural pests found in many parts of the world. Developing efficient and accurate locust information acquisition techniques helps in understanding the relation between locust distribution density and structural changes in locust communities. It also helps in understanding the hydrothermal and vegetation growth conditions that affect locusts in their habitats in various parts of the world as well as in providing rapid and accurate warnings on locust plague outbreak. This study is a preliminary attempt to explore whether the batch normalization-based convolutional neural network (CNN) model can be applied used to perform automatic classification of East Asian migratory locust (AM locust),Oxya chinensis(rice locusts), and cotton locusts. In this paper, we present a way of applying the CNN technique to identify species and instars of locusts using the proposed ResNet-Locust-BN model. This model is based on the ResNet architecture and involves introduction of a BatchNorm function before each convolution layer to improve the network's stability, convergence speed, and classification accuracy. Subsequently, locust image data collected in the field were used as input to train the model. By performing comparison experiments of the activation function, initial learning rate, and batch size, we selected ReLU as the preferred activation function. The initial learning rate and batch size were set to 0.1 and 32, respectively. Experiments performed to evaluate the accuracy of the proposed ResNet-Locust-BN model show that the model can effectively distinguish AM locust from rice locusts (93.60% accuracy) and cotton locusts (97.80% accuracy). The model also performed well in identifying the growth status information of AM locusts (third-instar (77.20% accuracy), fifth-instar (88.40% accuracy), and adult (93.80% accuracy)) with an overall accuracy of 90.16%. This is higher than the accuracy scores obtained by using other typical models: AlexNet (73.68%), GoogLeNet (69.12%), ResNet 18 (67.60%), ResNet 50 (80.84%), and VggNet (81.70%). Further, the model has good robustness and fast convergence rate.","doi":"10.3390\/insects11080458","number":"8","volume":"11","journal":"INSECTS","month":"August","year":"2020"}}
{"bib_id":"yuan_damage_2014","title":"Damage Mapping of Powdery Mildew in Winter Wheat with High-Resolution Satellite Image","author":"Yuan, Lin and Zhang, Jingcheng and Shi, Yeyin and Nie, Chenwei and Wei, Liguang and Wang, Jihua","meta_info":{"keywords":"Agriculture,Deep Learning,Disease detection,Images: SPOT,Labels: Field survey,Model: MLP,Satellite","abstract":"Powdery mildew, caused by the fungus Blumeria graminis, is a major winter wheat disease in China. Accurate delineation of powdery mildew infestations is necessary for site-specific disease management. In this study, high-resolution multispectral imagery of a 25 km(2) typical outbreak site in Shaanxi, China, taken by a newly-launched satellite, SPOT-6, was analyzed for mapping powdery mildew disease. Two regions with high representation were selected for conducting a field survey of powdery mildew. Three supervised classification methods-artificial neural network, mahalanobis distance, and maximum likelihood classifier-were implemented and compared for their performance on disease detection. The accuracy assessment showed that the ANN has the highest overall accuracy of 89%, following by MD and MLC with overall accuracies of 84% and 79%, respectively. These results indicated that the high-resolution multispectral imagery with proper classification techniques incorporated with the field investigation can be a useful tool for mapping powdery mildew in winter wheat.","doi":"10.3390\/rs6053611","pages":"3611--3623","number":"5","volume":"6","journal":"REMOTE SENSING","month":"May","year":"2014"}}
{"bib_id":"zambrano_prediction_2018","title":"Prediction of Drought-Induced Reduction of Agricultural Productivity in Chile from MODIS, Rainfall Estimates, and Climate Oscillation Indices","author":"Zambrano, Francisco and Vrieling, Anton and Nelson, Andy and Meroni, Michele and Tadesse, Tsegaye","meta_info":{"keywords":"Agriculture,Deep Learning,Images: MODIS,Labels: Public government data,Model: MLP,Multitemporal,Satellite,Yield prediction,Yield: County-level","langid":"english","abstract":"Global food security is negatively affected by drought. Climate projections show that drought frequency and intensity may increase in different parts of the globe. These increases are particularly hazardous for developing countries. Early season forecasts on drought occurrence and severity could help to better mitigate the negative consequences of drought. The objective of this study was to assess if interannual variability in agricultural productivity in Chile can be accurately predicted from freely-available, near real-time data sources. As the response variable, we used the standard score of seasonal cumulative NDVI (zcNDVI), based on 2000-2017 data from Moderate Resolution Imaging Spectroradiometer (MODIS), as a proxy for anomalies of seasonal primary productivity. The predictions were performed with forecast lead times from one- to six-month before the end of the growing season, which varied between census units in Chile. Predictor variables included the zcNDVI obtained by cumulating NDVI from season start up to prediction time; standardised precipitation indices derived from satellite rainfall estimates, for time-scales of 1, 3, 6, 12 and 24 months; the Pacific Decadal Oscillation and the Multivariate ENSO oscillation indices; the length of the growing season, and latitude and longitude. For each of the 758 census units considered, the time series of the response and the predictor variables were averaged for agricultural areas resulting in a 17-season time series per unit for each variable. We used two prediction approaches: (i) optimal linear regression (OLR) whereby for each census unit the single predictor was selected that best explained the interannual zcNDVI variability, and (ii) a multi-layer feedforward neural network architecture, often called deep learning (DL), where all predictors for all units were combined in a single spatio-temporal model. Both approaches were evaluated with a leave-one-year-out cross-validation procedure. Both methods showed good prediction accuracies for small lead times and similar values for all lead times. The mean R-cv(2) values for OLR were 0.95, 0.83, 0.68, 0.56, 0.46 and 0.37, against 0.96, 0.84, 0.65, 0.54, 0.46 and 0.38 for DL, for one, two, three, four, five, and six months lead time, respectively. Given the wide range of climates and vegetation types covered within the study area, we expect that the presented models can contribute to an improved early warning system for agricultural drought in different geographical settings around the globe.","doi":"10.1016\/j.rse.2018.10.006","issn":"0034-4257","address":"STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA","publisher":"ELSEVIER SCIENCE INC","pages":"15--30","volume":"219","journal":"REMOTE SENSING OF ENVIRONMENT","month":"December","year":"2018","type":"Article"}}
{"bib_id":"zeynoddin_structural-optimized_2022","title":"Structural-Optimized Sequential Deep Learning Methods for Surface Soil Moisture Forecasting, Case Study Quebec, Canada","author":"Zeynoddin, Mohammad and Bonakdari, Hossein","meta_info":{"keywords":"Agriculture,Deep Learning,Images: SMAP,Labels: Self-labelled,Model: LSTM,Satellite,Soil moisture prediction","unique-id":"WOS:000823386700002","eissn":"1433-3058","earlyaccessdate":"JUL 2022","doi":"10.1007\/s00521-022-07529-2","issn":"0941-0643","journal":"NEURAL COMPUTING & APPLICATIONS","year":"2022"}}
{"bib_id":"zhang_automatic_2018","title":"Automatic Identification of Center Pivot Irrigation Systems from Landsat Images Using Convolutional Neural Networks","author":"Zhang, Chenxiao and Yue, Peng and Di, Liping and Wu, Zhaoyan","meta_info":{"keywords":"Agriculture,Center pivot irrigation detection,Dataset: CDL,Deep Learning,Images: Landsat,Labels: Image survey,Model: AlexNet,Model: LeNet,Model: VGG,Satellite","abstract":"Being hailed as the greatest mechanical innovation in agriculture since the replacement of draft animals by the tractor, center pivot irrigation systems irrigate crops with a significant reduction in both labor and water needs compared to traditional irrigation methods, such as flood irrigation. In the last few decades, the deployment of center pivot irrigation systems has increased dramatically throughout the United States. Monitoring the installment and operation of the center pivot systems can help: (i) Water resource management agencies to objectively assess water consumption and properly allocate water resources, (ii) Agro-businesses to locate potential customers, and (iii) Researchers to investigate land use change. However, few studies have been carried out on the automatic identification and location of center pivot irrigation systems from satellite images. Growing rapidly in recent years, machine learning techniques have been widely applied on image recognition, and they provide a possible solution for identification of center pivot systems. In this study, a Convolutional Neural Networks (CNNs) approach was proposed for identification of center pivot irrigation systems. CNNs with different structures were constructed and compared for the task. A sampling approach was presented for training data augmentation. The CNN with the best performance and less training time was used in the testing area. A variance-based approach was proposed to further locate the center of each center pivot system. The experiment was applied to a 30-m resolution Landsat image, covering an area of 20,000 km(2) in North Colorado. A precision of 95.85% and a recall of 93.33% of the identification results indicated that the proposed approach performed well in the center pivot irrigation systems identification task.","doi":"10.3390\/agriculture8100147","number":"10","volume":"8","journal":"AGRICULTURE-BASEL","month":"October","year":"2018"}}
{"bib_id":"zhang_combining_2020","title":"Combining Optical, Fluorescence, Thermal Satellite, and Environmental Data to Predict County-Level Maize Yield in China Using Machine Learning Approaches","author":"Zhang, Liangliang and Zhang, Zhao and Luo, Yuchuan and Cao, Juan and Tao, Fulu","meta_info":{"keywords":"Agriculture,Best Model: XGB,Deep Learning,Extra data: climate,Extra data: soil,Images: MODIS,Labels: Public government data,Model comparison,Model: LSTM,Model: RF,Model: XGB,Satellite,Yield prediction,Yield: County-level","abstract":"Maize is an extremely important grain crop, and the demand has increased sharply throughout the world. China contributes nearly one-fifth of the total production alone with its decreasing arable land. Timely and accurate prediction of maize yield in China is critical for ensuring global food security. Previous studies primarily used either visible or near-infrared (NIR) based vegetation indices (VIs), or climate data, or both to predict crop yield. However, other satellite data from different spectral bands have been underutilized, which contain unique information on crop growth and yield. In addition, although a joint application of multi-source data significantly improves crop yield prediction, the combinations of input variables that could achieve the best results have not been well investigated. Here we integrated optical, fluorescence, thermal satellite, and environmental data to predict county-level maize yield across four agro-ecological zones (AEZs) in China using a regression-based method (LASSO), two machine learning (ML) methods (RF and XGBoost), and deep learning (DL) network (LSTM). The results showed that combining multi-source data explained more than 75% of yield variation. Satellite data at the silking stage contributed more information than other variables, and solar-induced chlorophyll fluorescence (SIF) had an almost equivalent performance with the enhanced vegetation index (EVI) largely due to the low signal to noise ratio and coarse spatial resolution. The extremely high temperature and vapor pressure deficit during the reproductive period were the most important climate variables affecting maize production in China. Soil properties and management factors contained extra information on crop growth conditions that cannot be fully captured by satellite and climate data. We found that ML and DL approaches definitely outperformed regression-based methods, and ML had more computational efficiency and easier generalizations relative to DL. Our study is an important effort to combine multi-source remote sensed and environmental data for large-scale yield prediction. The proposed methodology provides a paradigm for other crop yield predictions and in other regions.","doi":"10.3390\/rs12010021","number":"1","volume":"12","journal":"REMOTE SENSING","month":"January","year":"2020"}}
{"bib_id":"zhang_estimation_2020","title":"Estimation of Surface Soil Moisture during Corn Growth Stage from SAR and Optical Data Using a Combined Scattering Model","author":"Zhang, Li and Lv, Xiaolei and Chen, Qi and Sun, Guangcai and Yao, Jingchuan","meta_info":{"keywords":"Agriculture,Deep Learning,Images: Landsat,Images: Terra-SAR,Labels: Model-based,Model: MLP,Satellite,Soil moisture prediction,Used VI","abstract":"As an indispensable ecological parameter, surface soil moisture (SSM) is of great significance for understanding the growth status of vegetation. The cooperative use of synthetic aperture radar (SAR) and optical data has the advantage of considering both vegetation and underlying soil scattering information, which is suitable for SSM monitoring of vegetation areas. The main purpose of this paper is to establish an inversion approach using Terra-SAR and Landsat-7 data to estimate SSM at three different stages of corn growth in the irrigated area. A combined scattering model that can adequately represent the scattering characteristics of the vegetation coverage area is proposed by modifying the water cloud model (WCM) to reduce the effect of vegetation on the total SAR backscattering. The backscattering from the underlying soil is expressed by an empirical model with good performance in X-band. The modified water cloud model (MWCM) as a function of normalized differential vegetation index (NDVI) considers the contribution of vegetation to the backscattering signal. An inversion technique based on artificial neural network (ANN) is used to invert the combined scattering model for SSM estimation. The inversion method is established and verified using datasets of three different growth stages of corn. Using the proposed method, we estimate the SSM with a correlation coefficient R $>$= 0.72 and root-mean-square error RMSE $<$= 0.043 cm(3)\/cm(3) at the emergence stage, with R $>$= 0.87 and RMSE $<$= 0.046 cm(3)\/cm(3) at the trefoil stage and with R $>$= 0.70 and RMSE $<$= 0.064 cm(3)\/cm(3) at the jointing stage. The results suggest that the method proposed in this paper has operational potential in estimating SSM from Terra-SAR and Landsat-7 data at different stages of early corn growth.","doi":"10.3390\/rs12111844","number":"11","volume":"12","journal":"REMOTE SENSING","month":"June","year":"2020"}}
{"bib_id":"zhang_high-resolution_2021","title":"High-Resolution Boundary Refined Convolutional Neural Network for Automatic Agricultural Greenhouses Extraction from GaoFen-2 Satellite Imageries","author":"Zhang, Xiaoping and Cheng, Bo and Chen, Jinfen and Liang, Chenbin","meta_info":{"keywords":"Agriculture,Deep Learning,Greenhouse detection,Images: GF2,Labels: Image survey,Model: 2DCNN,Satellite","abstract":"Agricultural greenhouses (AGs) are an important component of modern facility agriculture, and accurately mapping and dynamically monitoring their distribution are necessary for agricultural scientific management and planning. Semantic segmentation can be adopted for AG extraction from remote sensing images. However, the feature maps obtained by traditional deep convolutional neural network (DCNN)-based segmentation algorithms blur spatial details and insufficient attention is usually paid to contextual representation. Meanwhile, the maintenance of the original morphological characteristics, especially the boundaries, is still a challenge for precise identification of AGs. To alleviate these problems, this paper proposes a novel network called high-resolution boundary refined network (HBRNet). In this method, we design a new backbone with multiple paths based on HRNetV2 aiming to preserve high spatial resolution and improve feature extraction capability, in which the Pyramid Cross Channel Attention (PCCA) module is embedded to residual blocks to strengthen the interaction of multiscale information. Moreover, the Spatial Enhancement (SE) module is employed to integrate the contextual information of different scales. In addition, we introduce the Spatial Gradient Variation (SGV) unit in the Boundary Refined (BR) module to couple the segmentation task and boundary learning task, so that they can share latent high-level semantics and interact with each other, and combine this with the joint loss to refine the boundary. In our study, GaoFen-2 remote sensing images in Shouguang City, Shandong Province, China are selected to make the AG dataset. The experimental results show that HBRNet demonstrates a significant improvement in segmentation performance up to an IoU score of 94.89%, implying that this approach has advantages and potential for precise identification of AGs.","doi":"10.3390\/rs13214237","number":"21","volume":"13","journal":"REMOTE SENSING","month":"November","year":"2021"}}
{"bib_id":"zhang_integrating_2021","title":"Integrating Satellite-Derived Climatic and Vegetation Indices to Predict Smallholder Maize Yield Using Deep Learning","author":"Zhang, Liangliang and Zhang, Zhao and Luo, Yuchuan and Cao, Juan and Xie, Ruizhi and Li, Shaokun","meta_info":{"keywords":"Agriculture,Deep Learning,Extra data: climate,Extra data: soil,Images: Landsat,Labels: Private government data,Model: LightGBM,Model: LSTM,Satellite,Used VI,Yield prediction,Yield: Field-level","abstract":"Timely and accurately estimating smallholder crop yield is essential for optimizing agronomic management, guiding investment and policy-making to reduce poverty and improve food security. However, the productivity of most smallholder farms around the world is still poorly estimated due to absence of technologies and field-scale data, especially for the largest smallholders across China. Here, we integrated 11,857 of field-surveyed yields across maize cultivation areas in China and heterogeneous geospatial data to predict field-level maize yield using three data-driven approaches, i.e., Least Absolute Shrinkage and Selection Operator (LASSO), Light Gradient Boosting Machine (LightGBM) and Long Short-Term Memory (LSTM). We determined the most suitable vegetation index (VI), compared the performances of satellite-derived and ground-observed climate data, and identified the optimal combination of input variables and the best method for maize yield estimation. We found that the green chlorophyll vegetation index (GCVI) outperformed the traditional visible and near-infrared-based VIs. Combining Land Surface Temperature (LST), cumulative precipitation (Pgs) and standardized precipitation index (SPI) explained about 70% of the yield variation, which was comparable to ground-observed indices. Integrating GCVI improved R-2 by 0.01-0.20 depending on the methods, suggesting valuable information on biotic or abiotic stress contained by GCVI. Maize yield could be predicted 1-2-month ahead before harvesting in all agro-ecological zones. The data collected during silking period contributed more information. The LSTM model did better than LightGBM and LASSO, because of its neural network characterizing the cumulative effects of environmental factors on yield. Our study demonstrates an effective mean for large-scale crop yield estimation using publicly available data, particularly for smallholder systems where ground observations are currently limited and sparse.","doi":"10.1016\/j.agrformet.2021.108666","issn":"0168-1923","volume":"311","journal":"AGRICULTURAL AND FOREST METEOROLOGY","month":"December","year":"2021"}}
{"bib_id":"zhang_rapid_2021","title":"Rapid In-Season Mapping of Corn and Soybeans Using Machine-Learned Trusted Pixels from Cropland Data Layer","author":"Zhang, Chen and Di, Liping and Hao, Pengyu and Yang, Zhengwei and Lin, Li and Zhao, Haoteng and Guo, Liying","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Landsat,Images: Sentinel,Labels: Field survey,Labels: Public government data,Model: MLP,Satellite,Used VI","abstract":"A timely and detailed crop-specific land cover map can support many agricultural applications and decision makings. However, in-season crop mapping over a large area is still challenging due to the insufficiency of ground truth in the early stage of a growing season. To address this issue, this paper presents an efficient machine-learning workflow for the rapid in-season mapping of corn and soybeans fields without ground truth data for the current year. We use trusted pixels, a set of pixels that are predicted from the historical Cropland Data Layer (CDL) data with high confidence in the current year's crop type, to label training samples on multitemporal satellite images for crop type classification. The entire mapping process only involves a limited number of satellite images acquired within the growing season (normally 3-4 images per scene) and no field data needs to be collected. According to the investigation on 12 states of the U.S. Corn Belt, it is found that a considerable number of trusted pixels can be identified from the historical CDL data by the trusted pixel prediction model based on artificial neural network. According to the experiment on 49 Landsat-8 scenes and 31 Sentinel-2 tiles, the in-season maps of corn and soybeans are expected to reach 85%-95% agreement with CDL as well as field data by mid-July. Once the in-season satellite imagery becomes available, the crop cover map can be rapidly created even with limited computational resources. This study provides a new perspective and detailed guidance for rapid in-season mapping of corn and soybeans, which can be potentially applied to identify more diverse crop types and scaled up to the entire United States.","doi":"10.1016\/j.jag.2021.102374","issn":"1569-8432","volume":"102","journal":"INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION","month":"October","year":"2021"}}
{"bib_id":"zhang_retrieving_2022","title":"Retrieving Soil Heavy Metals Concentrations Based on GaoFen-5 Hyperspectral Satellite Image at an Opencast Coal Mine, Inner Mongolia, China","author":"Zhang, Bo and Guo, Bin and Zou, Bin and Wei, Wei and Lei, Yongzhi and Li, Tianqi","meta_info":{"keywords":"Deep Learning,Heavy metal pollution regression,Heavy metal pollution regression direct,Images: GF5,Labels: Field survey,Model: MLP,Model: RF,Model: SVM,Satellite","unique-id":"WOS:000758457600006","orcid-numbers":"Guo, Bin\/0000-0001-9786-7644","eissn":"1873-6424","article-number":"118981","doi":"10.1016\/j.envpol.2022.118981","issn":"0269-7491","volume":"300","journal":"ENVIRONMENTAL POLLUTION","month":"May","year":"2022"}}
{"bib_id":"zhang_temporal_2020","title":"Temporal Paradox in Soil Potassium Estimations Using Spaceborne Multispectral Imagery","author":"Zhang, Jing and Ji, Dongli and Du, Dong and Miao, Jinjie and Liu, Hongwei and Bai, Yaonan","meta_info":{"keywords":"Agriculture,Deep Learning,Images: Landsat,Labels: Field survey,Model: MLP,Satellite,Soil potassium prediction","abstract":"The time difference between the field sampling and acquired spaceborne imagery has always been ignored in satellite-based soil analyses. In this study, the impacts of the time difference on soil nutrient predictions and the underlying mechanism for these predictions were investigated using a case study from the North China Plain. Soil total potassium (TK) was sampled in 2016 and was subsequently analyzed, with the soil TK content then predicted using the original reflectances from eight Landsat TM\/OLI images that spanned the 1986-2016 period as inputs to multiple linear regression (MLR) and artificial neural network (ANN) models. The results reveal a temporal paradox, where earlier satellite imagery yields higher accuracy in the predictions than does the more recent imagery. Historical soil nutrient data sets were used to explain this temporal paradox, which indicated that both an internal and external factor influenced the soil TK predictions. The internal factor, the deposition pattern across the study region, was found to strongly control the spatial distribution of potassium and exhibited minimal changes over the past 30 years, which influenced the good soil TK predictions using the early satellite imagery. The external factor, the soil organic matter (SOM), which has a stronger impact on the spectral reflectances than the soil TK, indicated that the increase and regional uniformization of SOM contents caused by Chinese agricultural development from the 1980s to the early 2000s masked the true spectral response of soil TK and explained the decline in the prediction accuracy of soil TK with time. This study reveals a potential limitation in remote-sensing-based soil TK predictions, and indicates that early satellite imagery should be considered as a potentially important factor in future research in order to accurately assess soil nutrient.","doi":"10.1016\/j.catena.2020.104771","issn":"0341-8162","volume":"194","journal":"CATENA","month":"November","year":"2020"}}
{"bib_id":"zhao_evaluation_2019","title":"Evaluation of Three Deep Learning Models for Early Crop Classification Using Sentinel-1A Imagery Time Series-A Case Study in Zhanjiang, China","author":"Zhao, Hongwei and Chen, Zhongxin and Jiang, Hao and Jing, Wenlong and Sun, Liang and Feng, Min","meta_info":{"keywords":"Agriculture,Best Model: 1DCNN,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Field survey,Model comparison,Model: 1DCNN,Model: GRU,Model: LSTM,Model: RF,Satellite","abstract":"Timely and accurate estimation of the area and distribution of crops is vital for food security. Optical remote sensing has been a key technique for acquiring crop area and conditions on regional to global scales, but great challenges arise due to frequent cloudy days in southern China. This makes optical remote sensing images usually unavailable. Synthetic aperture radar (SAR) could bridge this gap since it is less affected by clouds. The recent availability of Sentinel-1A (S1A) SAR imagery with a 12-day revisit period at a high spatial resolution of about 10 m makes it possible to fully utilize phenological information to improve early crop classification. In deep learning methods, one-dimensional convolutional neural networks (1D CNNs), long short-term memory recurrent neural networks (LSTM RNNs), and gated recurrent unit RNNs (GRU RNNs) have been shown to efficiently extract temporal features for classification tasks. However, due to the complexity of training, these three deep learning methods have been less used in early crop classification. In this work, we attempted to combine them with an incremental classification method to avoid the need for training optimal architectures and hyper-parameters for data from each time series. First, we trained 1D CNNs, LSTM RNNs, and GRU RNNs based on the full images' time series to attain three classifiers with optimal architectures and hyper-parameters. Then, starting at the first time point, we performed an incremental classification process to train each classifier using all of the previous data, and obtained a classification network with all parameter values (including the hyper-parameters) at each time point. Finally, test accuracies of each time point were assessed for each crop type to determine the optimal time series length. A case study was conducted in Suixi and Leizhou counties of Zhanjiang City, China. To verify the effectiveness of this method, we also implemented the classic random forest (RF) approach. The results were as follows: (i) 1D CNNs achieved the highest Kappa coefficient (0.942) of the four classifiers, and the highest value (0.934) in the GRU RNNs time series was attained earlier than with other classifiers; (ii) all three deep learning methods and the RF achieved F measures above 0.900 before the end of growth seasons of banana, eucalyptus, second-season paddy rice, and sugarcane; while, the 1D CNN classifier was the only one that could obtain an F-measure above 0.900 for pineapple before harvest. All results indicated the effectiveness of the solution combining the deep learning models with the incremental classification approach for early crop classification. This method is expected to provide new perspectives for early mapping of croplands in cloudy areas.","doi":"10.3390\/rs11222673","number":"22","volume":"11","journal":"REMOTE SENSING","month":"November","year":"2019"}}
{"bib_id":"zhao_evaluation_2021","title":"Evaluation of Five Deep Learning Models for Crop Type Mapping Using Sentinel-2 Time Series Images with Missing Information","author":"Zhao, Hongwei and Duan, Sibo and Liu, Jia and Sun, Liang and Reymondin, Louis","meta_info":{"keywords":"Agriculture,Crop segmentation,Deep Learning,Images: Sentinel,Labels: Field survey,Labels: Image survey,Model: 1DCNN,Model: ConvGRU,Model: ConvLSTM,Model: GRU,Model: LSTM,Satellite","abstract":"Accurate crop type maps play an important role in food security due to their widespread applicability. Optical time series data (TSD) have proven to be significant for crop type mapping. However, filling in missing information due to clouds in optical imagery is always needed, which will increase the workload and the risk of error transmission, especially for imagery with high spatial resolution. The development of optical imagery with high temporal and spatial resolution and the emergence of deep learning algorithms provide solutions to this problem. Although the one-dimensional convolutional neural network (1D CNN), long short-term memory (LSTM), and gate recurrent unit (GRU) models have been used to classify crop types in previous studies, their ability to identify crop types using optical TSD with missing information needs to be further explored due to their different mechanisms for handling invalid values in TSD. In this research, we designed two groups of experiments to explore the performances and characteristics of the 1D CNN, LSTM, GRU, LSTM-CNN, and GRU-CNN models for crop type mapping using unfilled Sentinel-2 (Sentinel-2) TSD and to discover the differences between unfilled and filled Sentinel-2 TSD based on the same algorithm. A case study was conducted in Hengshui City, China, of which 70.3% is farmland. The results showed that the 1D CNN, LSTM-CNN, and GRU-CNN models achieved acceptable classification accuracies (above 85%) using unfilled TSD, even though the total missing rate of the sample values was 43.5%; these accuracies were higher and more stable than those obtained using filled TSD. Furthermore, the models recalled more samples on crop types with small parcels when using unfilled TSD. Although LSTM and GRU models did not attain accuracies as high as the other three models using unfilled TSD, their results were almost close to those with filled TSD. This research showed that crop types could be identified by deep learning features in Sentinel-2 dense time series images with missing information due to clouds or cloud shadows randomly, which avoided spending a lot of time on missing information reconstruction.","doi":"10.3390\/rs13142790","number":"14","volume":"13","journal":"REMOTE SENSING","month":"July","year":"2021"}}
{"bib_id":"zhao_spatial-aware_2022","title":"Spatial-Aware SAR-optical Time-Series Deep Integration for Crop Phenology Tracking","author":"Zhao, Wenzhi and Qu, Yang and Zhang, Liqiang and Li, Kaiyuan","meta_info":{"keywords":"Agriculture,Deep Learning,Growth stage prediction,Images: Sentinel,Labels: Field survey,Labels: Model-based,Model: 2DCNN,Model: Transformer,Satellite,Used VI","unique-id":"WOS:000798976600001","eissn":"1879-0704","article-number":"113046","doi":"10.1016\/j.rse.2022.113046","issn":"0034-4257","volume":"276","journal":"REMOTE SENSING OF ENVIRONMENT","month":"July","year":"2022"}}
{"bib_id":"zhou_long-short-term-memory-based_2019","title":"Long-Short-Term-Memory-Based Crop Classification Using High-Resolution Optical Images and Multi-Temporal SAR Data","author":"Zhou, Ya'nan and Luo, Jiancheng and Feng, Li and Yang, Yingpin and Chen, Yuehong and Wu, Wei","meta_info":{"keywords":"Agriculture,Best Model: LSTM,Crop segmentation,Deep Learning,Images: Sentinel,Images: Ziyuan,Labels: Model-assisted survey,Model comparison,Model: LSTM,Model: RF,Model: SVM,Multitemporal,Satellite","abstract":"Farmland parcel-based crop classification using satellite data plays an important role in precision agriculture. In this study, a deep-learning-based time-series analysis method employing optical images and synthetic aperture radar (SAR) data is presented for crop classification for cloudy and rainy regions. Central to this method is the spatial-temporal incorporation of high-resolution optical images and multi-temporal SAR data and deep-learning-based time-series analysis. First, a precise farmland parcel map is delineated from high-resolution optical images. Second, pre-processed SAR intensity images are overlaid onto the parcel map to construct time series of crop growth for each parcel. Third, a deep-learning-based (using the long short-term memory, LSTM, network) classifier is employed to learn time-series features of crops and to classify parcels to produce a final classification map. The method was applied to two datasets of high-resolution ZY-3 images and multi-temporal Sentinel-1A SAR data to classify crop types in Hunan and Guizhou of China. The classification results, with an 5.0% improvement in overall accuracy compared to those of traditional methods, illustrate the effectiveness of the proposed framework for parcel-based crop classification for southern China. A further analysis of the relationship between crop calendars and change patterns of time-series intensity indicates that the LSTM model could learn and extract useful features for time-series crop classification.","doi":"10.1080\/15481603.2019.1628412","issn":"1548-1603","pages":"1170--1191","number":"8","volume":"56","journal":"GISCIENCE & REMOTE SENSING","month":"November","year":"2019"}}
{"bib_id":"zhu_benefits_2019","title":"Benefits of the Free and Open Landsat Data Policy","author":"Zhu, Zhe and Wulder, Michael A. and Roy, David P. and Woodcock, Curtis E. and Hansen, Matthew C. and Radeloff, Volker C. and Healey, Sean P. and Schaaf, Crystal and Hostert, Patrick and Strobl, Peter and Pekel, Jean-Francois and Lymburner, Leo and Pahlevan, Nima and Scambos, Ted A.","meta_info":{"langid":"english","abstract":"The United States (U.S.) federal government provides imagery obtained by federally funded Earth Observation satellites typically at no cost. For many years Landsat was an exception to this trend, until 2008 when the United States Geological Survey (USGS) made Landsat data accessible via the internet for free. Substantial increases in downloads of Landsat imagery ensued and led to a rapid expansion of science and operational applications, serving government, private sector, and civil society. The Landsat program hence provides an example to space agencies worldwide on the value of open access for Earth Observation data and has spurred the adaption of similar policies globally, including the European Copernicus Program. Here, we describe important aspects of the Landsat free and open data policy and highlight the importance and continued relevance of this policy.","urldate":"2022-07-28","doi":"10.1016\/j.rse.2019.02.016","issn":"0034-4257","pages":"382--385","volume":"224","journal":"Remote Sensing of Environment","month":"April","year":"2019"}}
