{"bib_id":"krizhevsky2012imagenet","title":"ImageNet classification with deep convolutional neural networks","author":"Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E","meta_info":{"year":"2012","pages":"1097--1105","booktitle":"Proc. NeurIPS"}}
{"bib_id":"redmon2016you","title":"You only look once: Unified, real-time object detection","author":"Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali","meta_info":{"year":"2016","pages":"779--788","booktitle":"Proc. CVPR"}}
{"bib_id":"zhang2016deep","title":"Deep learning over multi-field categorical data","author":"Zhang, Weinan and Du, Tianming and Wang, Jun","meta_info":{"year":"2016","pages":"45--57","booktitle":"Proc. ECIR"}}
{"bib_id":"pang2017deeprank","title":"Deeprank: A new deep architecture for relevance ranking in information retrieval","author":"Pang, Liang and Lan, Yanyan and Guo, Jiafeng and Xu, Jun and Xu, Jingfang and Cheng, Xueqi","meta_info":{"year":"2017","pages":"257--266","booktitle":"Proc. CIKM"}}
{"bib_id":"onal2018neural","title":"Neural information retrieval: At the end of the early years","author":"Onal, Kezban Dilek and Zhang, Ye and Altingovde, Ismail Sengor and Rahman, Md Mustafizur and Karagoz, Pinar and Braylan, Alex and Dang, Brandon and Chang, Heng-Lu and Kim, Henna and McNamara, Quinten and others","meta_info":{"year":"2018","pages":"111--182","number":"2-3","volume":"21","journal":"Information Retrieval Journal"}}
{"bib_id":"howard2018universal","title":"Universal Language Model Fine-tuning for Text Classification","author":"Howard, Jeremy and Ruder, Sebastian","meta_info":{"year":"2018","pages":"328--339","booktitle":"Proc. ACL"}}
{"bib_id":"devlin2019bert","title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding","author":"Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina","meta_info":{"year":"2019","pages":"4171--4186","booktitle":"Proc. ACL"}}
{"bib_id":"severyn2015twitter","title":"Twitter sentiment analysis with deep convolutional neural networks","author":"Severyn, Aliaksei and Moschitti, Alessandro","meta_info":{"year":"2015","pages":"959--962","booktitle":"Proc. ACL"}}
{"bib_id":"paolacci2010running","title":"Running experiments on amazon mechanical turk","author":"Paolacci, Gabriele and Chandler, Jesse and Ipeirotis, Panagiotis G","meta_info":{"year":"2010","pages":"411--419","number":"5","volume":"5","journal":"Judgment and Decision Making"}}
{"bib_id":"cothey2004web","title":"Web-crawling reliability","author":"Cothey, Viv","meta_info":{"year":"2004","pages":"1228--1238","number":"14","volume":"55","journal":"Journal of the American Society for Information Science and Technology"}}
{"bib_id":"menon2020can","title":"Can gradient clipping mitigate label noise?","author":"Menon, Aditya Krishna and Rawat, Ankit Singh and Reddi, Sashank J and Kumar, Sanjiv","meta_info":{"year":"2020","booktitle":"Proc. ICLR"}}
{"bib_id":"mason2012conducting","title":"Conducting behavioral research on Amazon’s Mechanical Turk","author":"Mason, Winter and Suri, Siddharth","meta_info":{"year":"2012","pages":"1--23","number":"1","volume":"44","journal":"Behavior Research Methods"}}
{"bib_id":"xiao2012adversarial","title":"Adversarial Label Flips Attack on Support Vector Machines.","author":"Xiao, Han and Xiao, Huang and Eckert, Claudia","meta_info":{"year":"2012","pages":"870--875","booktitle":"Proc. ECAI"}}
{"bib_id":"akhtar2018threat","title":"Threat of adversarial attacks on deep learning in computer vision: A survey","author":"Akhtar, Naveed and Mian, Ajmal","meta_info":{"year":"2018","pages":"14410--14430","volume":"6","journal":"Access"}}
{"bib_id":"lloyd2004observer","title":"Observer variation in the diagnosis of follicular variant of papillary thyroid carcinoma","author":"Lloyd, Ricardo V and Erickson, Lori A and Casey, Mary B and Lam, King Y and Lohse, Christine M and Asa, Sylvia L and Chan, John KC and DeLellis, Ronald A and Harach, H Ruben and Kakudo, Kennichi and others","meta_info":{"year":"2004","pages":"1336--1340","number":"10","volume":"28","journal":"The American Journal of Surgical Pathology"}}
{"bib_id":"han2020survey","title":"A survey of label-noise representation learning: Past, present and future","author":"Han, Bo and Yao, Quanming and Liu, Tongliang and Niu, Gang and Tsang, Ivor W and Kwok, James T and Sugiyama, Masashi","meta_info":{"year":"2020","journal":"arXiv preprint arXiv:2011.04406"}}
{"bib_id":"frenay2013classification","title":"Classification in the presence of label noise: A survey","author":"Frénay, Benoı̂t and Verleysen, Michel","meta_info":{"year":"2013","pages":"845--869","number":"5","volume":"25","journal":"IEEE Transaction on Neural Networks and Learning Systems"}}
{"bib_id":"zhang2016understanding","title":"Understanding deep learning requires rethinking generalization","author":"Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol","meta_info":{"year":"2017","booktitle":"Proc. ICLR"}}
{"bib_id":"arpit2017closer","title":"A Closer Look at Memorization in Deep Networks","author":"Arpit, Devansh and Jastrzebski, Stanislaw and Ballas, Nicolas and Krueger, David and Bengio, Emmanuel and Kanwal, Maxinder S and Maharaj, Tegan and Fischer, Asja and Courville, Aaron and Bengio, Yoshua and others","meta_info":{"year":"2017","pages":"233--242","booktitle":"Proc. ICML"}}
{"bib_id":"krogh1992simple","title":"A simple weight decay can improve generalization","author":"Krogh, Anders and Hertz, John A","meta_info":{"year":"1992","pages":"950--957","booktitle":"Proc, NeurIPS"}}
{"bib_id":"ioffe2015batch","title":"Batch normalization: Accelerating deep network training by reducing internal covariate shift","author":"Ioffe, Sergey and Szegedy, Christian","meta_info":{"year":"2015","pages":"448-456","booktitle":"Proc. ICML"}}
{"bib_id":"shorten2019survey","title":"A survey on image data augmentation for deep learning","author":"Shorten, Connor and Khoshgoftaar, Taghi M","meta_info":{"year":"2019","pages":"60","number":"1","volume":"6","journal":"Journal of Big Data"}}
{"bib_id":"srivastava2014dropout","title":"Dropout: A simple way to prevent neural networks from overfitting","author":"Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan","meta_info":{"year":"2014","pages":"1929--1958","number":"1","volume":"15","journal":"The Journal of Machine Learning Research"}}
{"bib_id":"song2019selfie","title":"SELFIE: Refurbishing Unclean Samples for Robust Deep Learning","author":"Song, Hwanjun and Kim, Minseok and Lee, Jae-Gil","meta_info":{"year":"2019","pages":"5907--5915","booktitle":"Proc. ICML"}}
{"bib_id":"menon2018learning","title":"Learning from binary labels with instance-dependent noise","author":"Menon, Aditya Krishna and Van Rooyen, Brendan and Natarajan, Nagarajan","meta_info":{"year":"2018","pages":"1561--1595","number":"8","volume":"107","journal":"Machine Learning"}}
{"bib_id":"kumar2020robust","title":"Robust Learning of Multi-Label Classifiers under Label Noise","author":"Kumar, Himanshu and Manwani, Naresh and Sastry, PS","meta_info":{"year":"2020","pages":"90--97","booktitle":"Proc. CODS-COMAD"}}
{"bib_id":"xiao2015learning","title":"Learning from massive noisy labeled data for image classification","author":"Xiao, Tong and Xia, Tian and Yang, Yi and Huang, Chang and Wang, Xiaogang","meta_info":{"year":"2015","pages":"2691--2699","booktitle":"Proc. CVPR"}}
{"bib_id":"lee2018cleannet","title":"CleanNet: Transfer learning for scalable image classifier training with label noise","author":"Lee, Kuang-Huei and He, Xiaodong and Zhang, Lei and Yang, Linjun","meta_info":{"year":"2018","pages":"5447--5456","booktitle":"Proc. CVPR"}}
{"bib_id":"zhu2004class","title":"Class noise vs. attribute noise: A quantitative study","author":"Zhu, Xingquan and Wu, Xindong","meta_info":{"year":"2004","pages":"177--210","number":"3","volume":"22","journal":"Artificial Intelligence Review"}}
{"bib_id":"zhang2016learning","title":"Learning from crowdsourced labeled data: A survey","author":"Zhang, Jing and Wu, Xindong and Sheng, Victor S","meta_info":{"year":"2016","pages":"543--576","number":"4","volume":"46","journal":"Artificial Intelligence Review"}}
{"bib_id":"nigam2020impact","title":"Impact of Noisy Labels in Learning Techniques: A Survey","author":"Nigam, Nitika and Dutta, Tanima and Gupta, Hari Prabhat","meta_info":{"year":"2020","pages":"403--411","booktitle":"Proc. ICDIS"}}
{"bib_id":"bishop2006pattern","title":"Pattern recognition and machine learning","author":"Bishop, Christopher M","meta_info":{"publisher":"Springer","year":"2006"}}
{"bib_id":"natarajan2013learning","title":"Learning with noisy labels","author":"Natarajan, Nagarajan and Dhillon, Inderjit S and Ravikumar, Pradeep K and Tewari, Ambuj","meta_info":{"year":"2013","pages":"1196--1204","booktitle":"Proc. NeurIPS"}}
{"bib_id":"shalev2014understanding","title":"Understanding machine learning: From theory to algorithms","author":"Shalev-Shwartz, Shai and Ben-David, Shai","meta_info":{"publisher":"Cambridge university press","year":"2014"}}
{"bib_id":"csaji2001approximation","title":"Approximation with artificial neural networks","author":"Csáji, Balázs Csanád and others","meta_info":{"year":"2001","pages":"7","number":"48","volume":"24","journal":"Faculty of Sciences, Etvs Lornd University, Hungary"}}
{"bib_id":"goldberger2016training","title":"Training deep neural-networks using a noise adaptation layer","author":"Goldberger, Jacob and Ben-Reuven, Ehud","meta_info":{"year":"2017","booktitle":"Proc. ICLR"}}
{"bib_id":"mnih2012learning","title":"Learning to label aerial images from noisy data","author":"Mnih, Volodymyr and Hinton, Geoffrey E","meta_info":{"year":"2012","pages":"567--574","booktitle":"Proc. ICML"}}
{"bib_id":"manwani2013noise","title":"Noise tolerance under risk minimization","author":"Manwani, Naresh and Sastry, PS","meta_info":{"year":"2013","pages":"1146--1151","number":"3","volume":"43","journal":"IEEE Transactions on Cybernetics"}}
{"bib_id":"ghosh2015making","title":"Making risk minimization tolerant to label noise","author":"Ghosh, Aritra and Manwani, Naresh and Sastry, PS","meta_info":{"year":"2015","pages":"93--107","volume":"160","journal":"Neurocomputing"}}
{"bib_id":"van2015learning","title":"Learning with symmetric label noise: The importance of being unhinged","author":"Van Rooyen, Brendan and Menon, Aditya and Williamson, Robert C","meta_info":{"year":"2015","pages":"10--18","booktitle":"Proc. NeurIPS"}}
{"bib_id":"patrini2016loss","title":"Loss factorization, weakly supervised learning and label noise robustness","author":"Patrini, Giorgio and Nielsen, Frank and Nock, Richard and Carioni, Marcello","meta_info":{"year":"2016","pages":"708--717","booktitle":"Proc. ICML"}}
{"bib_id":"wheway2000using","title":"Using boosting to detect noisy data","author":"Wheway, Virginia","meta_info":{"year":"2000","pages":"123--130","booktitle":"Proc. PRICAI"}}
{"bib_id":"sluban2014ensemble","title":"Ensemble-based noise detection: Noise ranking and visual performance evaluation","author":"Sluban, Borut and Gamberger, Dragan and Lavrač, Nada","meta_info":{"year":"2014","pages":"265--303","number":"2","volume":"28","journal":"Data Mining and Knowledge Discovery"}}
{"bib_id":"delany2012profiling","title":"Profiling instances in noise reduction","author":"Delany, Sarah Jane and Segata, Nicola and Mac Namee, Brian","meta_info":{"year":"2012","pages":"28--40","volume":"31","journal":"Knowledge-Based Systems"}}
{"bib_id":"gamberger2000noise","title":"Noise detection and elimination in data preprocessing: Experiments in medical domains","author":"Gamberger, Dragan and Lavrac, Nada and Dzeroski, Saso","meta_info":{"year":"2000","pages":"205--223","number":"2","volume":"14","journal":"Applied Artificial Intelligence"}}
{"bib_id":"thongkam2008support","title":"Support vector machine for outlier detection in breast cancer survivability prediction","author":"Thongkam, Jaree and Xu, Guandong and Zhang, Yanchun and Huang, Fuchun","meta_info":{"year":"2008","pages":"99--109","booktitle":"Proc. APWeb"}}
{"bib_id":"xu2005survey","title":"Survey of clustering algorithms","author":"Xu, Rui and Wunsch, Donald","meta_info":{"year":"2005","pages":"645--678","number":"3","volume":"16","journal":"IEEE Transactions on Neural Networks"}}
{"bib_id":"rebbapragada2007class","title":"Class noise mitigation through instance weighting","author":"Rebbapragada, Umaa and Brodley, Carla E","meta_info":{"year":"2007","pages":"708--715","booktitle":"Proc. ECML"}}
{"bib_id":"liu2017soft","title":"A soft-label method for noise-tolerant distantly supervised relation extraction","author":"Liu, Tianyu and Wang, Kexiang and Chang, Baobao and Sui, Zhifang","meta_info":{"year":"2017","pages":"1790--1795","booktitle":"Proc. EMNLP"}}
{"bib_id":"kaster2010comparative","title":"Comparative validation of graphical models for learning tumor segmentations from noisy manual annotations","author":"Kaster, Frederik O and Menze, Bjoern H and Weber, Marc-André and Hamprecht, Fred A","meta_info":{"year":"2010","pages":"74--85","booktitle":"Proc. MICCAI"}}
{"bib_id":"ganapathiraju2000support","title":"Support vector machines for automatic data cleanup","author":"Ganapathiraju, Aravind and Picone, Joseph","meta_info":{"year":"2000","booktitle":"Proc. ICSLP"}}
{"bib_id":"biggio2011support","title":"Support vector machines under adversarial label noise","author":"Biggio, Battista and Nelson, Blaine and Laskov, Pavel","meta_info":{"year":"2011","pages":"97--112","booktitle":"Proc. ACML"}}
{"bib_id":"mantas2014credal","title":"Credal-C4. 5: Decision tree based on imprecise probabilities to classify noisy data","author":"Mantas, Carlos J and Abellán, Joaquı́n","meta_info":{"year":"2014","pages":"4625--4637","number":"10","volume":"41","journal":"Expert Systems with Applications"}}
{"bib_id":"sastry2017robust","title":"Robust learning of classifiers in the presence of label noise","author":"Sastry, PS and Manwani, Naresh","meta_info":{"year":"2017","pages":"167--197","booktitle":"Pattern Recognition and Big Data"}}
{"bib_id":"ghosh2017robustness","title":"On the robustness of decision tree learning under label noise","author":"Ghosh, Aritra and Manwani, Naresh and Sastry, PS","meta_info":{"year":"2017","pages":"685--697","booktitle":"Proc. PAKDD"}}
{"bib_id":"ghosh2017robust","title":"Robust loss functions under label noise for deep neural networks","author":"Ghosh, Aritra and Kumar, Himanshu and Sastry, PS","meta_info":{"year":"2017","booktitle":"Proc. AAAI"}}
{"bib_id":"malach2017decoupling","title":"Decoupling\" when to update\" from\" how to update\"","author":"Malach, Eran and Shalev-Shwartz, Shai","meta_info":{"year":"2017","pages":"960--970","booktitle":"Proc. NeurIPS"}}
{"bib_id":"garcia2016noise","title":"Noise detection in the meta-learning level","author":"Garcia, Luı́s PF and de Carvalho, André CPLF and Lorena, Ana C","meta_info":{"year":"2016","pages":"14--25","volume":"176","journal":"Neurocomputing"}}
{"bib_id":"yan2016robust","title":"Robust semi-supervised learning through label aggregation","author":"Yan, Yan and Xu, Zhongwen and Tsang, Ivor W and Long, Guodong and Yang, Yi","meta_info":{"year":"2016","booktitle":"Proc. AAAI"}}
{"bib_id":"zhang2018generalized","title":"Generalized cross entropy loss for training deep neural networks with noisy labels","author":"Zhang, Zhilu and Sabuncu, Mert","meta_info":{"year":"2018","pages":"8778--8788","booktitle":"Proc. NeurIPS"}}
{"bib_id":"wang2019symmetric","title":"Symmetric cross entropy for robust learning with noisy labels","author":"Wang, Yisen and Ma, Xingjun and Chen, Zaiyi and Luo, Yuan and Yi, Jinfeng and Bailey, James","meta_info":{"year":"2019","pages":"322--330","booktitle":"Proc. ICCV"}}
{"bib_id":"lyu2020curriculum","title":"Curriculum Loss: Robust Learning and Generalization against Label Corruption","author":"Lyu, Yueming and Tsang, Ivor W","meta_info":{"year":"2020","booktitle":"Proc. ICLR"}}
{"bib_id":"sukhbaatar2014training","title":"Training convolutional networks with noisy labels","author":"Sukhbaatar, Sainbayar and Bruna, Joan and Paluri, Manohar and Bourdev, Lubomir and Fergus, Rob","meta_info":{"year":"2015","booktitle":"Proc. ICLRW"}}
{"bib_id":"jindal2016learning","title":"Learning deep networks from noisy labels with dropout regularization","author":"Jindal, Ishan and Nokleby, Matthew and Chen, Xuewen","meta_info":{"year":"2016","pages":"967--972","booktitle":"Proc. ICDM"}}
{"bib_id":"han2018masking","title":"Masking: A new perspective of noisy supervision","author":"Han, Bo and Yao, Jiangchao and Niu, Gang and Zhou, Mingyuan and Tsang, Ivor and Zhang, Ya and Sugiyama, Masashi","meta_info":{"year":"2018","pages":"5836--5846","booktitle":"Proc. NeurIPS"}}
{"bib_id":"yao2018deep","title":"Deep learning from noisy image labels with quality embedding","author":"Yao, Jiangchao and Wang, Jiajie and Tsang, Ivor W and Zhang, Ya and Sun, Jun and Zhang, Chengqi and Zhang, Rui","meta_info":{"year":"2018","pages":"1909--1922","number":"4","volume":"28","journal":"IEEE Transactions on Image Processing"}}
{"bib_id":"goldberger2017training","title":"Training deep neural-networks using a noise adaptation layer","author":"Goldberger, Jacob and Ben-Reuven, Ehud","meta_info":{"year":"2017","booktitle":"Proc. ICLR"}}
{"bib_id":"chen2015webly","title":"Webly supervised learning of convolutional networks","author":"Chen, Xinlei and Gupta, Abhinav","meta_info":{"year":"2015","pages":"1431--1439","booktitle":"Proc. ICCV"}}
{"bib_id":"bekker2016training","title":"Training deep neural-networks based on unreliable labels","author":"Bekker, Alan Joseph and Goldberger, Jacob","meta_info":{"year":"2016","pages":"2682--2686","booktitle":"Proc. ICASSP"}}
{"bib_id":"goodfellow2014explaining","title":"Explaining and harnessing adversarial examples","author":"Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian","meta_info":{"year":"2014","booktitle":"Proc. ICLR"}}
{"bib_id":"pereyra2017regularizing","title":"Regularizing neural networks by penalizing confident output distributions","author":"Pereyra, Gabriel and Tucker, George and Chorowski, Jan and Kaiser, Łukasz and Hinton, Geoffrey","meta_info":{"year":"2017","booktitle":"Proc. ICLRW"}}
{"bib_id":"zhang2018mixup","title":"Mixup: Beyond empirical risk minimization","author":"Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David","meta_info":{"year":"2018","booktitle":"Proc. ICLR"}}
{"bib_id":"jenni2018deep","title":"Deep bilevel learning","author":"Jenni, Simon and Favaro, Paolo","meta_info":{"year":"2018","pages":"618--633","booktitle":"Proc. ECCV"}}
{"bib_id":"tanno2019learning","title":"Learning from noisy labels by regularized estimation of annotator confusion","author":"Tanno, Ryutaro and Saeedi, Ardavan and Sankaranarayanan, Swami and Alexander, Daniel C and Silberman, Nathan","meta_info":{"year":"2019","pages":"11244--11253","booktitle":"Proc. CVPR"}}
{"bib_id":"hendrycks2019using","title":"Using pre-training can improve model robustness and uncertainty","author":"Hendrycks, Dan and Lee, Kimin and Mazeika, Mantas","meta_info":{"year":"2019","booktitle":"Proc. ICML"}}
{"bib_id":"xia2019anchor","title":"Are anchor points really indispensable in label-noise learning?","author":"Xia, Xiaobo and Liu, Tongliang and Wang, Nannan and Han, Bo and Gong, Chen and Niu, Gang and Sugiyama, Masashi","meta_info":{"year":"2019","booktitle":"Proc. NeurIPS"}}
{"bib_id":"scott2013classification","title":"Classification with asymmetric label noise: Consistency and maximal denoising","author":"Scott, Clayton and Blanchard, Gilles and Handy, Gregory","meta_info":{"year":"2013","pages":"489--511","booktitle":"Proc. COLT"}}
{"bib_id":"amid2019two","title":"Two-temperature logistic regression based on the Tsallis divergence","author":"Amid, Ehsan and Warmuth, Manfred K and Srinivasan, Sriram","meta_info":{"year":"2019","pages":"2388--2396","booktitle":"Proc. AISTATS"}}
{"bib_id":"amidrobust","title":"Robust Bi-Tempered Logistic Loss Based on Bregman Divergences","author":"Amid, Ehsan and Warmuth, Manfred K and Anil, Rohan and Koren, Tomer","meta_info":{"year":"2019","pages":"14987--14996","booktitle":"Proc. NeurIPS"}}
{"bib_id":"reed2015training","title":"Training deep neural networks on noisy labels with bootstrapping","author":"Reed, Scott and Lee, Honglak and Anguelov, Dragomir and Szegedy, Christian and Erhan, Dumitru and Rabinovich, Andrew","meta_info":{"year":"2015","booktitle":"Proc. ICLR"}}
{"bib_id":"patrini2017making","title":"Making deep neural networks robust to label noise: A loss correction approach","author":"Patrini, Giorgio and Rozza, Alessandro and Krishna Menon, Aditya and Nock, Richard and Qu, Lizhen","meta_info":{"year":"2017","pages":"1944--1952","booktitle":"Proc. CVPR"}}
{"bib_id":"chang2017active","title":"Active Bias: Training more accurate neural networks by emphasizing high variance samples","author":"Chang, Haw-Shiuan and Learned-Miller, Erik and McCallum, Andrew","meta_info":{"year":"2017","pages":"1002--1012","booktitle":"Proc. NeurIPS"}}
{"bib_id":"liu2015classification","title":"Classification with noisy labels by importance reweighting","author":"Liu, Tongliang and Tao, Dacheng","meta_info":{"year":"2015","pages":"447--461","number":"3","volume":"38","journal":"IEEE Transactions on Pattern Analysis and Machine Intelligence"}}
{"bib_id":"scott2015rate","title":"A rate of convergence for mixture proportion estimation, with application to learning from noisy labels","author":"Scott, Clayton","meta_info":{"year":"2015","pages":"838--846","booktitle":"AISTATS"}}
{"bib_id":"wang2017multiclass","title":"Multiclass learning with partially corrupted labels","author":"Wang, Ruxin and Liu, Tongliang and Tao, Dacheng","meta_info":{"year":"2017","pages":"2568--2580","number":"6","volume":"29","journal":"IEEE Transactions on Neural Networks and Learning Systems"}}
{"bib_id":"ren2018learning","title":"Learning to reweight examples for robust deep learning","author":"Ren, Mengye and Zeng, Wenyuan and Yang, Bin and Urtasun, Raquel","meta_info":{"year":"2018","booktitle":"Proc. ICML"}}
{"bib_id":"ma2018dimensionality","title":"Dimensionality-driven learning with noisy labels","author":"Ma, Xingjun and Wang, Yisen and Houle, Michael E and Zhou, Shuo and Erfani, Sarah M and Xia, Shu-Tao and Wijewickrema, Sudanthi and Bailey, James","meta_info":{"year":"2018","booktitle":"Proc. ICML"}}
{"bib_id":"hendrycks2018using","title":"Using trusted data to train deep networks on labels corrupted by severe noise","author":"Hendrycks, Dan and Mazeika, Mantas and Wilson, Duncan and Gimpel, Kevin","meta_info":{"year":"2018","pages":"10456--10465","booktitle":"Proc. NeurIPS"}}
{"bib_id":"arazo2019unsupervised","title":"Unsupervised label noise modeling and loss correction","author":"Arazo, Eric and Ortego, Diego and Albert, Paul and O'Connor, Noel E and McGuinness, Kevin","meta_info":{"year":"2019","booktitle":"Proc. ICML"}}
{"bib_id":"wang2018iterative","title":"Iterative learning with open-set noisy labels","author":"Wang, Yisen and Liu, Weiyang and Ma, Xingjun and Bailey, James and Zha, Hongyuan and Song, Le and Xia, Shu-Tao","meta_info":{"year":"2018","pages":"8688--8696","booktitle":"Proc. CVPR"}}
{"bib_id":"jiang2018mentornet","title":"MentorNet: Learning data-driven curriculum for very deep neural networks on corrupted labels","author":"Jiang, Lu and Zhou, Zhengyuan and Leung, Thomas and Li, Li-Jia and Fei-Fei, Li","meta_info":{"year":"2018","booktitle":"Proc. ICML"}}
{"bib_id":"han2018co","title":"Co-teaching: Robust training of deep neural networks with extremely noisy labels","author":"Han, Bo and Yao, Quanming and Yu, Xingrui and Niu, Gang and Xu, Miao and Hu, Weihua and Tsang, Ivor and Sugiyama, Masashi","meta_info":{"year":"2018","pages":"8527--8537","booktitle":"Proc. NeurIPS"}}
{"bib_id":"yu2019does","title":"How does disagreement help generalization against label corruption?","author":"Yu, Xingrui and Han, Bo and Yao, Jiangchao and Niu, Gang and Tsang, Ivor W and Sugiyama, Masashi","meta_info":{"year":"2019","booktitle":"Proc. ICML"}}
{"bib_id":"shen2019learning","title":"Learning with bad training data via iterative trimmed loss minimization","author":"Shen, Yanyao and Sanghavi, Sujay","meta_info":{"year":"2019","booktitle":"Proc. ICML"}}
{"bib_id":"chen2019understanding","title":"Understanding and utilizing deep neural networks trained with noisy labels","author":"Chen, Pengfei and Liao, Benben and Chen, Guangyong and Zhang, Shengyu","meta_info":{"year":"2019","booktitle":"Proc. ICML"}}
{"bib_id":"nguyen2020self","title":"SELF: Learning to filter noisy labels with self-ensembling","author":"Nguyen, Duc Tam and Mummadi, Chaithanya Kumar and Ngo, Thi Phuong Nhung and Nguyen, Thi Hoai Phuong and Beggel, Laura and Brox, Thomas","meta_info":{"year":"2020","booktitle":"Proc. ICLR"}}
{"bib_id":"li2017learning","title":"Learning from noisy labels with distillation","author":"Li, Yuncheng and Yang, Jianchao and Song, Yale and Cao, Liangliang and Luo, Jiebo and Li, Li-Jia","meta_info":{"year":"2017","pages":"1910--1918","booktitle":"Proc. ICCV"}}
{"bib_id":"dehghani2017learning","title":"Learning to learn from weak supervision by full supervision","author":"Dehghani, Mostafa and Severyn, Aliaksei and Rothe, Sascha and Kamps, Jaap","meta_info":{"year":"2017","booktitle":"Proc. NeurIPSW"}}
{"bib_id":"dehghani2017avoiding","title":"Avoiding your teacher's mistakes: Training neural networks with controlled weak supervision","author":"Dehghani, Mostafa and Severyn, Aliaksei and Rothe, Sascha and Kamps, Jaap","meta_info":{"year":"2017","journal":"arXiv preprint arXiv:1711.00313"}}
{"bib_id":"li2019learning","title":"Learning to learn from noisy labeled data","author":"Li, Junnan and Wong, Yongkang and Zhao, Qi and Kankanhalli, Mohan S","meta_info":{"year":"2019","pages":"5051--5059","booktitle":"Proc. CVPR"}}
{"bib_id":"shu2019meta","title":"Meta-Weight-Net: Learning an explicit mapping for sample weighting","author":"Shu, Jun and Xie, Qi and Yi, Lixuan and Zhao, Qian and Zhou, Sanping and Xu, Zongben and Meng, Deyu","meta_info":{"year":"2019","pages":"1917--1928","booktitle":"Proc. NeurIPS"}}
{"bib_id":"ding2018semi","title":"A semi-supervised two-stage approach to learning from noisy labels","author":"Ding, Yifan and Wang, Liqiang and Fan, Deliang and Gong, Boqing","meta_info":{"year":"2018","pages":"1215--1224","booktitle":"Proc. WACV"}}
{"bib_id":"li2020dividemix","title":"DivideMix: Learning with Noisy Labels as Semi-supervised Learning","author":"Li, Junnan and Socher, Richard and Hoi, Steven CH","meta_info":{"year":"2020","booktitle":"Proc. ICLR"}}
{"bib_id":"goodfellow2014generative","title":"Generative adversarial nets","author":"Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua","meta_info":{"year":"2014","pages":"2672--2680","booktitle":"Proc. NeurIPS"}}
{"bib_id":"xia2020extended","title":"Extended T: Learning with Mixed Closed-set and Open-set Noisy Labels","author":"Xia, Xiaobo and Liu, Tongliang and Han, Bo and Wang, Nannan and Deng, Jiankang and Li, Jiatong and Mao, Yinian","meta_info":{"year":"2020","journal":"arXiv preprint arXiv:2012.00932"}}
{"bib_id":"lukasik2020does","title":"Does label smoothing mitigate label noise?","author":"Lukasik, Michal and Bhojanapalli, Srinadh and Menon, Aditya and Kumar, Sanjiv","meta_info":{"year":"2020","pages":"6448--6458","booktitle":"Proc. ICLR"}}
{"bib_id":"garg2020robust","title":"Robust Deep Ordinal Regression under Label Noise","author":"Garg, Bhanu and Manwani, Naresh","meta_info":{"year":"2020","pages":"782--796","booktitle":"Proc. ACML"}}
{"bib_id":"houle2017local","title":"Local intrinsic dimensionality I: An extreme-value-theoretic foundation for similarity applications","author":"Houle, Michael E","meta_info":{"year":"2017","pages":"64--79","booktitle":"Proc. SISAP"}}
{"bib_id":"torgo1997regression","title":"Regression using classification algorithms","author":"Torgo, Luis and Gama, Joao","meta_info":{"year":"1997","pages":"275--292","number":"4","volume":"1","journal":"Intelligent Data Analysis"}}
{"bib_id":"song2019prestopping","title":"How does Early Stopping Help Generalization against Label Noise?","author":"Song, Hwanjun and Kim, Minseok and Park, Dongmin and Lee, Jae-Gil","meta_info":{"year":"2019","journal":"arXiv preprint arXiv:1911.08059"}}
{"bib_id":"li2020gradient","title":"Gradient descent with early stopping is provably robust to label noise for overparameterized neural networks","author":"Li, Mingchen and Soltanolkotabi, Mahdi and Oymak, Samet","meta_info":{"year":"2020","pages":"4313--4324","booktitle":"Proc. AISTATS"}}
{"bib_id":"li2021provably","title":"Provably end-to-end label-noise learning without anchor points","author":"Li, Xuefeng and Liu, Tongliang and Han, Bo and Niu, Gang and Sugiyama, Masashi","meta_info":{"year":"2021","pages":"6403--6413","booktitle":"Proc. ICML"}}
{"bib_id":"breunig2000lof","title":"LOF: Identifying density-based local outliers","author":"Breunig, Markus M and Kriegel, Hans-Peter and Ng, Raymond T and Sander, Jörg","meta_info":{"year":"2000","pages":"93--104","number":"2","volume":"29","journal":"ACM SIGMOD Record"}}
{"bib_id":"tarvainen2017mean","title":"Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results","author":"Tarvainen, Antti and Valpola, Harri","meta_info":{"year":"2017","pages":"1195--1204","booktitle":"Proc. NeurIPS"}}
{"bib_id":"berthelot2019mixmatch","title":"MixMatch: A holistic approach to semi-supervised learning","author":"Berthelot, David and Carlini, Nicholas and Goodfellow, Ian and Papernot, Nicolas and Oliver, Avital and Raffel, Colin A","meta_info":{"year":"2019","pages":"5050--5060","booktitle":"Proc. NeurIPS"}}
{"bib_id":"wu2021ngc","title":"NGC: A unified framework for learning with open-world noisy data","author":"Wu, Zhi-Fan and Wei, Tong and Jiang, Jianwen and Mao, Chaojie and Tang, Mingqian and Li, Yu-Feng","meta_info":{"year":"2021","pages":"62--71","booktitle":"Proc. ICCV"}}
{"bib_id":"wei2021open","title":"Open-set Label Noise Can Improve Robustness Against Inherent Label Noise","author":"Wei, Hongxin and Tao, Lue and Xie, Renchunzi and An, Bo","meta_info":{"year":"2021","booktitle":"Proc. NeurIPS"}}
{"bib_id":"zhang2021approximating","title":"Approximating Instance-Dependent Noise via Instance-Confidence Embedding","author":"Zhang, Yivan and Sugiyama, Masashi","meta_info":{"year":"2021","journal":"arXiv preprint arXiv:2103.13569"}}
{"bib_id":"yang2021estimating","title":"Estimating Instance-dependent Label-noise Transition Matrix using DNNs","author":"Yang, Shuo and Yang, Erkun and Han, Bo and Liu, Yang and Xu, Min and Niu, Gang and Liu, Tongliang","meta_info":{"year":"2021","journal":"arXiv preprint arXiv:2105.13001"}}
{"bib_id":"wei2021learning","title":"Learning with Noisy Labels Revisited: A Study Using Real-World Human Annotations","author":"Wei, Jiaheng and Zhu, Zhaowei and Cheng, Hao and Liu, Tongliang and Niu, Gang and Liu, Yang","meta_info":{"year":"2021","journal":"arXiv preprint arXiv:2110.12088"}}
{"bib_id":"song2020two","title":"Robust Learning by Self-Transition for Handling Noisy Labels","author":"Song, Hwanjun and Kim, Minseok and Park, Dongmin and Shin, Yooju and Lee, Jae-Gil","meta_info":{"year":"2021","booktitle":"KDD"}}
{"bib_id":"finn2017model","title":"Model-agnostic meta-learning for fast adaptation of deep networks","author":"Finn, Chelsea and Abbeel, Pieter and Levine, Sergey","meta_info":{"year":"2017","pages":"1126--1135","booktitle":"Proc. ICML"}}
{"bib_id":"krueger2017deep","title":"Deep nets don't learn via memorization","author":"Krueger, David and Ballas, Nicolas and Jastrzebski, Stanislaw and Arpit, Devansh and Kanwal, Maxinder S and Maharaj, Tegan and Bengio, Emmanuel and Fischer, Asja and Courville, Aaron","meta_info":{"year":"2017","booktitle":"Proc. ICLRW"}}
{"bib_id":"yao2020searching","title":"Searching to exploit memorization effect in learning with noisy labels","author":"Yao, Quanming and Yang, Hansi and Han, Bo and Niu, Gang and Kwok, James Tin-Yau","meta_info":{"year":"2020","pages":"10789--10798","booktitle":"Proc. ICML"}}
{"bib_id":"zhang2019identity","title":"Identity Crisis: Memorization and generalization under extreme overparameterization","author":"Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Mozer, Michael C and Singer, Yoram","meta_info":{"year":"2020","booktitle":"Proc. ICLR"}}
{"bib_id":"lee2019robust","title":"Robust inference via generative classifiers for handling noisy labels","author":"Lee, Kimin and Yun, Sukmin and Lee, Kibok and Lee, Honglak and Li, Bo and Shin, Jinwoo","meta_info":{"year":"2019","pages":"3763--3772","booktitle":"Proc. ICML"}}
{"bib_id":"krizhevsky2014cifar","title":"CIFAR-10 and CIFAR-100 datasets","author":"Krizhevsky, Alex and Nair, Vinod and Hinton, Geoffrey","meta_info":{"year":"2014","note":"r̆lhttps:\/\/www.cs.toronto.edu\/~kriz\/cifar.html"}}
{"bib_id":"lecun1998mnist","title":"The MNIST database of handwritten digits, 1998","author":"LeCun, Yann and Cortes, Corinna and Burges, Christopher JC","meta_info":{"year":"1998","pages":"34","volume":"10","journal":"URL http:\/\/yann. lecun. com\/exdb\/mnist"}}
{"bib_id":"xiao2017fashion","title":"Fashion-MNIST: A novel image dataset for benchmarking machine learning algorithms","author":"Xiao, Han and Rasul, Kashif and Vollgraf, Roland","meta_info":{"year":"2017","journal":"arXiv preprint arXiv:1708.07747"}}
{"bib_id":"netzer2011reading","title":"Reading digits in natural images with unsupervised feature learning","author":"Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y","meta_info":{"year":"2011","booktitle":"Proc. NeurIPSW"}}
{"bib_id":"bossard2014food","title":"Food-101--mining discriminative components with random forests","author":"Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc","meta_info":{"year":"2014","pages":"446--461","booktitle":"Proc. ECCV"}}
{"bib_id":"li2017webvision","title":"Webvision database: Visual learning and understanding from web data","author":"Li, Wen and Wang, Limin and Li, Wei and Agustsson, Eirikur and Van Gool, Luc","meta_info":{"year":"2017","journal":"arXiv preprint arXiv:1708.02862"}}
{"bib_id":"tsoumakas2007multi","title":"Multi-label classification: An overview","author":"Tsoumakas, Grigorios and Katakis, Ioannis","meta_info":{"year":"2007","pages":"1--13","number":"3","volume":"3","journal":"International Journal of Data Warehousing and Mining"}}
{"bib_id":"boutell2004learning","title":"Learning multi-label scene classification","author":"Boutell, Matthew R and Luo, Jiebo and Shen, Xipeng and Brown, Christopher M","meta_info":{"year":"2004","pages":"1757--1771","number":"9","volume":"37","journal":"Pattern Recognition"}}
{"bib_id":"karpathy2016cs231n","title":"Cs231n convolutional neural networks for visual recognition","author":"Karpathy, Andrej and others","meta_info":{"year":"2016","pages":"1","volume":"1","journal":"Neural Networks"}}
{"bib_id":"fawzi2016robustness","title":"Robustness of classifiers: from adversarial to random noise","author":"Fawzi, Alhussein and Moosavi-Dezfooli, Seyed-Mohsen and Frossard, Pascal","meta_info":{"year":"2016","pages":"1632--1640","booktitle":"Proc. NeurIPS"}}
{"bib_id":"mahloujifar2019curse","title":"The curse of concentration in robust learning: Evasion and poisoning attacks from concentration of measure","author":"Mahloujifar, Saeed and Diochnos, Dimitrios I and Mahmoody, Mohammad","meta_info":{"year":"2019","pages":"4536--4543","number":"01","volume":"33","booktitle":"Proc. AAAI"}}
{"bib_id":"huang2019o2u","title":"O2U-Net: A simple noisy label detection approach for deep neural networks","author":"Huang, Jinchi and Qu, Lie and Jia, Rongfei and Zhao, Binqiang","meta_info":{"year":"2019","pages":"3326--3334","booktitle":"Proc. ICCV"}}
{"bib_id":"dohmatob2018limitations","title":"Limitations of adversarial robustness: strong no free lunch theorem","author":"Dohmatob, Elvis","meta_info":{"year":"2019","booktitle":"Proc. ICML"}}
{"bib_id":"gilmer2019adversarial","title":"Adversarial examples are a natural consequence of test error in noise","author":"Gilmer, Justin and Ford, Nicolas and Carlini, Nicholas and Cubuk, Ekin","meta_info":{"year":"2019","pages":"2280--2289","booktitle":"Proc. ICML"}}
{"bib_id":"rubin1976inference","title":"Inference and missing data","author":"Rubin, Donald B","meta_info":{"year":"1976","pages":"581--592","number":"3","volume":"63","journal":"Biometrika"}}
{"bib_id":"yoon2018gain","title":"Gain: Missing data imputation using generative adversarial nets","author":"Yoon, Jinsung and Jordon, James and Schaar, Mihaela","meta_info":{"year":"2018","pages":"5689--5698","booktitle":"Proc. ICML"}}
{"bib_id":"pleiss2020detecting","title":"Detecting Noisy Training Data with Loss Curves","author":"Pleiss, Geoff and Zhang, Tianyi and R. Elenberg, Ethan and Q. Weinberger, Kilian","meta_info":{"url":"https:\/\/openreview.net\/forum?id=HyenUkrtDB","year":"2020"}}
{"bib_id":"cheng2020learning","title":"Learning with Bounded Instance and Label-dependent Label Noise","author":"Cheng, Jiacheng and Liu, Tongliang and Ramamohanarao, Kotagiri and Tao, Dacheng","meta_info":{"year":"2020","pages":"1789--1799","booktitle":"Proc. ICML"}}
{"bib_id":"hu2019simple","title":"Simple and effective regularization methods for training on noisily labeled data with generalization guarantee","author":"Hu, Wei and Li, Zhiyuan and Yu, Dingli","meta_info":{"year":"2020","booktitle":"Proc. ICLR"}}
{"bib_id":"chen2021noise","title":"Noise against noise: stochastic label noise helps combat inherent label noise","author":"Pengfei Chen and Guangyong Chen and Junjie Ye and jingwei zhao and Pheng-Ann Heng","meta_info":{"year":"2021","booktitle":"Proc. ICLR"}}
{"bib_id":"feng2020can","title":"Can cross entropy loss be robust to label noise","author":"Feng, Lei and Shu, Senlin and Lin, Zhuoyi and Lv, Fengmao and Li, Li and An, Bo","meta_info":{"year":"2020","pages":"2206--2212","booktitle":"Proc. IJCAI"}}
{"bib_id":"ma2020normalized","title":"Normalized loss functions for deep learning with noisy labels","author":"Ma, Xingjun and Huang, Hanxun and Wang, Yisen and Romano, Simone and Erfani, Sarah and Bailey, James","meta_info":{"year":"2020","pages":"6543--6553","booktitle":"Proc. ICML"}}
{"bib_id":"liu2020peer","title":"Peer loss functions: Learning from noisy labels without knowing noise rates","author":"Liu, Yang and Guo, Hongyi","meta_info":{"year":"2020","pages":"6226--6236","booktitle":"Proc. ICML"}}
{"bib_id":"cheng2020weakly","title":"Weakly Supervised Learning with Side Information for Noisy Labeled Images","author":"Cheng, Lele and Zhou, Xiangzeng and Zhao, Liming and Li, Dangwei and Shang, Hong and Zheng, Yun and Pan, Pan and Xu, Yinghui","meta_info":{"year":"2020","pages":"306--321","booktitle":"Proc. ECCV"}}
{"bib_id":"huang2020self","title":"Self-adaptive training: beyond Empirical Risk Minimization","author":"Huang, Lang and Zhang, Chao and Zhang, Hongyang","meta_info":{"year":"2020","booktitle":"Proc. NeurIPS"}}
{"bib_id":"zhang2020distilling","title":"Distilling effective supervision from severe label noise","author":"Zhang, Zizhao and Zhang, Han and Arik, Sercan O and Lee, Honglak and Pfister, Tomas","meta_info":{"year":"2020","pages":"9294--9303","booktitle":"Proc. CVPR"}}
{"bib_id":"zheng2020error","title":"Error-bounded correction of noisy labels","author":"Zheng, Songzhu and Wu, Pengxiang and Goswami, Aman and Goswami, Mayank and Metaxas, Dimitris and Chen, Chao","meta_info":{"year":"2020","pages":"11447--11457","booktitle":"Proc. ICML"}}
{"bib_id":"zhang2021dualgraph","title":"DualGraph: A Graph-Based Method for Reasoning About Label Noise","author":"Zhang, HaiYang and Xing, XiMing and Liu, Liang","meta_info":{"year":"2021","pages":"9654--9663","booktitle":"Proc. CVPR"}}
{"bib_id":"yao2020dual","title":"Dual T: Reducing estimation error for transition matrix in label-noise learning","author":"Yao, Yu and Liu, Tongliang and Han, Bo and Gong, Mingming and Deng, Jiankang and Niu, Gang and Sugiyama, Masashi","meta_info":{"year":"2020","booktitle":"Proc. NeurIPS"}}
{"bib_id":"wang2020training","title":"Training Noise-Robust Deep Neural Networks via Meta-Learning","author":"Wang, Zhen and Hu, Guosheng and Hu, Qinghua","meta_info":{"year":"2020","pages":"4524--4533","booktitle":"Proc. CVPR"}}
{"bib_id":"harutyunyan2020improving","title":"Improving generalization by controlling label-noise information in neural network weights","author":"Harutyunyan, Hrayr and Reing, Kyle and Ver Steeg, Greg and Galstyan, Aram","meta_info":{"year":"2020","pages":"4071--4081","booktitle":"Proc. ICML"}}
{"bib_id":"zheng2021meta","title":"Meta Label Correction for Noisy Label Learning","author":"Zheng, Guoqing and Awadallah, Ahmed Hassan and Dumais, Susan","meta_info":{"year":"2021","booktitle":"Proc. AAAI"}}
{"bib_id":"wu2020topological","title":"A Topological Filter for Learning with Label Noise","author":"Wu, Pengxiang and Zheng, Songzhu and Goswami, Mayank and Metaxas, Dimitris and Chen, Chao","meta_info":{"year":"2020","booktitle":"Proc. NeurIPS"}}
{"bib_id":"zhou2021robust","title":"Robust Curriculum Learning: from clean label detection to noisy label self-correction","author":"Tianyi Zhou and Shengjie Wang and Jeff Bilmes","meta_info":{"year":"2021","booktitle":"Proc. ICLR"}}
{"bib_id":"wei2020combating","title":"Combating noisy labels by agreement: A joint training method with co-regularization","author":"Wei, Hongxin and Feng, Lei and Chen, Xiangyu and An, Bo","meta_info":{"year":"2020","pages":"13726--13735","booktitle":"Proc. CVPR"}}
{"bib_id":"liu2020early","title":"Early-Learning Regularization Prevents Memorization of Noisy Labels","author":"Liu, Sheng and Niles-Weed, Jonathan and Razavian, Narges and Fernandez-Granda, Carlos","meta_info":{"year":"2020","volume":"33","booktitle":"Proc. NeurIPS"}}
{"bib_id":"wang2020robust","title":"Robust optimization for fairness with noisy protected groups","author":"Wang, Serena and Guo, Wenshuo and Narasimhan, Harikrishna and Cotter, Andrew and Gupta, Maya and Jordan, Michael I","meta_info":{"year":"2020","booktitle":"Proc. NeurIPS"}}
{"bib_id":"wang2021fair","title":"Fair classification with group-dependent label noise","author":"Wang, Jialu and Liu, Yang and Levy, Caleb","meta_info":{"year":"2021","pages":"526--536","booktitle":"Proc. FAccT"}}
{"bib_id":"xia2021robust","title":"Robust early-learning: Hindering the memorization of noisy labels","author":"Xia, Xiaobo and Liu, Tongliang and Han, Bo and Gong, Chen and Wang, Nannan and Ge, Zongyuan and Chang, Yi","meta_info":{"year":"2021","booktitle":"Proc. ICLR"}}
{"bib_id":"chen2021beyond","title":"Beyond Class-Conditional Assumption: A Primary Attempt to Combat Instance-Dependent Label Noise","author":"Chen, Pengfei and Ye, Junjie and Chen, Guangyong and Zhao, Jingwei and Heng, Pheng-Ann","meta_info":{"year":"2021","booktitle":"Proc. AAAI"}}
{"bib_id":"zhu2021understanding","title":"Understanding the Interaction of Adversarial Training with Noisy Labels","author":"Zhu, Jianing and Zhang, Jingfeng and Han, Bo and Liu, Tongliang and Niu, Gang and Yang, Hongxia and Kankanhalli, Mohan and Sugiyama, Masashi","meta_info":{"year":"2021","journal":"arXiv preprint arXiv:2102.03482"}}
{"bib_id":"bootkrajang2020towards","title":"Towards instance-dependent label noise-tolerant classification: a probabilistic approach","author":"Bootkrajang, Jakramate and Chaijaruwanich, Jeerayut","meta_info":{"year":"2020","pages":"95--111","number":"1","volume":"23","journal":"Pattern Analysis and Applications"}}
{"bib_id":"krasin2017openimages","title":"OpenImages: A public dataset for large-scale multi-label and multi-class image classification","author":"Krasin, Ivan and Duerig, Tom and Alldrin, Neil and Ferrari, Vittorio and Abu-El-Haija, Sami and Kuznetsova, Alina and Rom, Hassan and Uijlings, Jasper and Popov, Stefan and Veit, Andreas and others","meta_info":{"year":"2017","pages":"18","number":"3","volume":"2","journal":"Dataset available from https:\/\/github. com\/openimages"}}
{"bib_id":"zhao2021evaluating","title":"Evaluating Multi-label Classifiers with Noisy Labels","author":"Zhao, Wenting and Gomes, Carla","meta_info":{"year":"2021","journal":"arXiv preprint arXiv:2102.08427"}}
{"bib_id":"hardt2016equality","title":"Equality of Opportunity in Supervised Learning","author":"Hardt, Moritz and Price, Eric and Srebro, Nati","meta_info":{"year":"2016","booktitle":"Proc. NeurIPS"}}
{"bib_id":"johnson2019survey","title":"Survey on deep learning with class imbalance","author":"Johnson, Justin M and Khoshgoftaar, Taghi M","meta_info":{"year":"2019","pages":"1--54","number":"1","volume":"6","journal":"Journal of Big Data"}}
{"bib_id":"jiang2020identifying","title":"Identifying and correcting label bias in machine learning","author":"Jiang, Heinrich and Nachum, Ofir","meta_info":{"year":"2020","pages":"702--712","booktitle":"Proc. AISTATS"}}
{"bib_id":"nguyen2019machine","title":"Machine learning and deep learning frameworks and libraries for large-scale data mining: a survey","author":"Nguyen, Giang and Dlugolinsky, Stefan and Bobák, Martin and Tran, Viet and Garcı́a, Álvaro López and Heredia, Ignacio and Mal\\ḱ, Peter and Hluchỳ, Ladislav","meta_info":{"year":"2019","pages":"77--124","number":"1","volume":"52","journal":"Artificial Intelligence Review"}}
{"bib_id":"krause2016unreasonable","title":"The unreasonable effectiveness of noisy data for fine-grained recognition","author":"Krause, Jonathan and Sapp, Benjamin and Howard, Andrew and Zhou, Howard and Toshev, Alexander and Duerig, Tom and Philbin, James and Fei-Fei, Li","meta_info":{"year":"2016","pages":"301--320","booktitle":"Proc. ECCV"}}
{"bib_id":"uesato2019labels","title":"Are labels required for improving adversarial robustness?","author":"Uesato, Jonathan and Alayrac, Jean-Baptiste and Huang, Po-Sen and Stanforth, Robert and Fawzi, Alhussein and Kohli, Pushmeet","meta_info":{"year":"2019","pages":"12192--12202","booktitle":"Proc. NeurIPS"}}
{"bib_id":"damodaran2020wasserstein","title":"Wasserstein Adversarial Regularization (WAR) on label noise","author":"Damodaran, Bharath Bhushan and Fatras, Kilian and Lobry, Sylvain and Flamary, Rémi and Tuia, Devis and Courty, Nicolas","meta_info":{"year":"2020","booktitle":"Proc. ICLR"}}
