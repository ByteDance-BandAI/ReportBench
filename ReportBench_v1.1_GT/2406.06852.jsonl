{"bib_id":"huang2023training","title":"Training-free Lexical Backdoor Attacks on Language Models","author":"Huang, Yujin and Zhuo, Terry Yue and Xu, Qiongkai and Hu, Han and Yuan, Xingliang and Chen, Chunyang","meta_info":{"year":"2023","pages":"2198--2208","booktitle":"Proceedings of the ACM Web Conference 2023"}}
{"bib_id":"zhao2024universal","title":"Universal Vulnerabilities in Large Language Models: Backdoor Attacks for In-context Learning","author":"Zhao, Shuai and Jia, Meihuizi and Tuan, Luu Anh and Pan, Fengjun and Wen, Jinming","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2401.05949"}}
{"bib_id":"xiang2023badchain","title":"BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models","author":"Xiang, Zhen and Jiang, Fengqing and Xiong, Zidi and Ramasubramanian, Bhaskar and Poovendran, Radha and Li, Bo","meta_info":{"year":"2023","booktitle":"The Twelfth International Conference on Learning Representations"}}
{"bib_id":"liu2024loraasanattack","title":"LoRA-as-an-Attack! Piercing LLM Safety Under The Share-and-Play Scenario","author":"Hongyi Liu and Zirui Liu and Ruixiang Tang and Jiayi Yuan and Shaochen Zhong and Yu-Neng Chuang and Li Li and Rui Chen and Xia Hu","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2403.00108"}}
{"bib_id":"hu2021lora","title":"LoRA: Low-Rank Adaptation of Large Language Models","author":"Hu, Edward J and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others","meta_info":{"year":"2021","booktitle":"International Conference on Learning Representations"}}
{"bib_id":"achiam2023gpt","title":"Gpt-4 technical report","author":"Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2303.08774"}}
{"bib_id":"wang2023decodingtrust","title":"DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models","author":"Boxin Wang and Weixin Chen and Hengzhi Pei and Chulin Xie and Mintong Kang and Chenhui Zhang and Chejian Xu and Zidi Xiong and Ritik Dutta and Rylan Schaeffer and Sang T. Truong and Simran Arora and Mantas Mazeika and Dan Hendrycks and Zinan Lin and Yu Cheng and Sanmi Koyejo and Dawn Song and Bo Li","meta_info":{"year":"2023","booktitle":"Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track"}}
{"bib_id":"mccloskey1989catastrophic","title":"Catastrophic interference in connectionist networks: The sequential learning problem","author":"McCloskey, Michael and Cohen, Neal J","meta_info":{"year":"1989","pages":"109--165","volume":"24","journal":"Psychology of learning and motivation"}}
{"bib_id":"du2022ppt","title":"PPT: Backdoor Attacks on Pre-trained Models via Poisoned Prompt Tuning.","author":"Du, Wei and Zhao, Yichun and Li, Boqun and Liu, Gongshen and Wang, Shilin","meta_info":{"year":"2022","pages":"680--686","booktitle":"IJCAI"}}
{"bib_id":"jiang2023forcing","title":"Forcing Generative Models to Degenerate Ones: The Power of Data Poisoning Attacks","author":"Jiang, Shuli and Kadhe, Swanand Ravindra and Zhou, Yi and Cai, Ling and Baracaldo, Nathalie","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2312.04748"}}
{"bib_id":"wan2023poisoning","title":"Poisoning language models during instruction tuning","author":"Wan, Alexander and Wallace, Eric and Shen, Sheng and Klein, Dan","meta_info":{"organization":"PMLR","year":"2023","pages":"35413--35425","booktitle":"International Conference on Machine Learning"}}
{"bib_id":"yan2023backdooring","title":"Backdooring instruction-tuned large language models with virtual prompt injection","author":"Yan, Jun and Yadav, Vikas and Li, Shiyang and Chen, Lichang and Tang, Zheng and Wang, Hai and Srinivasan, Vijay and Ren, Xiang and Jin, Hongxia","meta_info":{"year":"2023","booktitle":"NeurIPS 2023 Workshop on Backdoors in Deep Learning-The Good, the Bad, and the Ugly"}}
{"bib_id":"xu2023instructions","title":"Instructions as backdoors: Backdoor vulnerabilities of instruction tuning for large language models","author":"Xu, Jiashu and Ma, Mingyu Derek and Wang, Fei and Xiao, Chaowei and Chen, Muhao","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2305.14710"}}
{"bib_id":"du2023uor","title":"Uor: Universal backdoor attacks on pre-trained language models","author":"Du, Wei and Li, Peixuan and Li, Boqun and Zhao, Haodong and Liu, Gongshen","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2305.09574"}}
{"bib_id":"gu2023gradient","title":"A gradient control method for backdoor attacks on parameter-efficient tuning","author":"Gu, Naibin and Fu, Peng and Liu, Xiyu and Liu, Zhengxiao and Lin, Zheng and Wang, Weiping","meta_info":{"year":"2023","pages":"3508--3520","booktitle":"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)"}}
{"bib_id":"xue2024trojllm","title":"Trojllm: A black-box trojan prompt attack on large language models","author":"Xue, Jiaqi and Zheng, Mengxin and Hua, Ting and Shen, Yilin and Liu, Yepeng and Bölöni, Ladislau and Lou, Qian","meta_info":{"year":"2024","volume":"36","journal":"Advances in Neural Information Processing Systems"}}
{"bib_id":"qiang2024learning","title":"Learning to Poison Large Language Models During Instruction Tuning","author":"Qiang, Yao and Zhou, Xiangyu and Zade, Saleh Zare and Roshani, Mohammad Amin and Zytko, Douglas and Zhu, Dongxiao","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2402.13459"}}
{"bib_id":"zhang2024rapid","title":"Rapid Adoption, Hidden Risks: The Dual Impact of Large Language Model Customization","author":"Zhang, Rui and Li, Hongwei and Wen, Rui and Jiang, Wenbo and Zhang, Yuan and Backes, Michael and Shen, Yun and Zhang, Yang","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2402.09179"}}
{"bib_id":"dong2024philosophers","title":"The Philosopher's Stone: Trojaning Plugins of Large Language Models","author":"Tian Dong and Minhui Xue and Guoxing Chen and Rayne Holland and Shaofeng Li and Yan Meng and Zhen Liu and Haojin Zhu","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2312.00374"}}
{"bib_id":"you2023large","title":"Large Language Models Are Better Adversaries: Exploring Generative Clean-Label Backdoor Attacks Against Text Classifiers","author":"You, Wencong and Hammoudeh, Zayd and Lowd, Daniel","meta_info":{"year":"2023","pages":"12499--12527","booktitle":"Findings of the Association for Computational Linguistics: EMNLP 2023"}}
{"bib_id":"huang2023composite","title":"Composite backdoor attacks against large language models","author":"Huang, Hai and Zhao, Zhengyu and Backes, Michael and Shen, Yun and Zhang, Yang","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2310.07676"}}
{"bib_id":"cao2023stealthy","title":"Stealthy and persistent unalignment on large language models via backdoor injections","author":"Cao, Yuanpu and Cao, Bochuan and Chen, Jinghui","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2312.00027"}}
{"bib_id":"zhang2022fine","title":"Fine-mixing: Mitigating Backdoors in Fine-tuned Language Models","author":"Zhang, Zhiyuan and Lyu, Lingjuan and Ma, Xingjun and Wang, Chenguang and Sun, Xu","meta_info":{"year":"2022","pages":"355--372","booktitle":"Findings of the Association for Computational Linguistics: EMNLP 2022"}}
{"bib_id":"qi2021onion","title":"ONION: A Simple and Effective Defense Against Textual Backdoor Attacks","author":"Qi, Fanchao and Chen, Yangyi and Li, Mukai and Yao, Yuan and Liu, Zhiyuan and Sun, Maosong","meta_info":{"year":"2021","pages":"9558--9566","booktitle":"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing"}}
{"bib_id":"chen2021badnl","title":"Badnl: Backdoor attacks against nlp models with semantic-preserving improvements","author":"Chen, Xiaoyi and Salem, Ahmed and Chen, Dingfan and Backes, Michael and Ma, Shiqing and Shen, Qingni and Wu, Zhonghai and Zhang, Yang","meta_info":{"year":"2021","pages":"554--569","booktitle":"Proceedings of the 37th Annual Computer Security Applications Conference"}}
{"bib_id":"kandpal2023backdoor","title":"Backdoor Attacks for In-Context Learning with Language Models","author":"Kandpal, Nikhil and Jagielski, Matthew and Tramèr, Florian and Carlini, Nicholas","meta_info":{"year":"2023","booktitle":"The Second Workshop on New Frontiers in Adversarial Machine Learning"}}
{"bib_id":"shi2023poster","title":"Poster: BadGPT: Exploring Security Vulnerabilities of ChatGPT via Backdoor Attacks to InstructGPT","author":"Shi, Jiawen and Liu, Yixin and Zhou, Pan and Sun, Lichao","meta_info":{"booktitle":"NDSS","year":"2023"}}
{"bib_id":"li2023chatgpt","title":"Chatgpt as an attack tool: Stealthy textual backdoor attack via blackbox generative model trigger","author":"Li, Jiazhao and Yang, Yijin and Wu, Zhuofeng and Vydiswaran, VG and Xiao, Chaowei","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2304.14475"}}
{"bib_id":"zhao2023prompt","title":"Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models","author":"Zhao, Shuai and Wen, Jinming and Luu, Anh and Zhao, Junbo and Fu, Jie","meta_info":{"year":"2023","pages":"12303--12317","booktitle":"Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing"}}
{"bib_id":"qi2023fine","title":"Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!","author":"Qi, Xiangyu and Zeng, Yi and Xie, Tinghao and Chen, Pin-Yu and Jia, Ruoxi and Mittal, Prateek and Henderson, Peter","meta_info":{"year":"2023","booktitle":"The Twelfth International Conference on Learning Representations"}}
{"bib_id":"kirkpatrick2017overcoming","title":"Overcoming catastrophic forgetting in neural networks","author":"Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others","meta_info":{"publisher":"National Acad Sciences","year":"2017","pages":"3521--3526","number":"13","volume":"114","journal":"Proceedings of the national academy of sciences"}}
{"bib_id":"luo2023empirical","title":"An empirical study of catastrophic forgetting in large language models during continual fine-tuning","author":"Luo, Yun and Yang, Zhen and Meng, Fandong and Li, Yafu and Zhou, Jie and Zhang, Yue","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2308.08747"}}
{"bib_id":"wang2023backdoor","title":"Backdoor activation attack: Attack large language models using activation steering for safety-alignment","author":"Wang, Haoran and Shu, Kai","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2311.09433"}}
{"bib_id":"wang2023exploitability","title":"On the exploitability of reinforcement learning with human feedback for large language models","author":"Wang, Jiongxiao and Wu, Junlin and Chen, Muhao and Vorobeychik, Yevgeniy and Xiao, Chaowei","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2311.09641"}}
{"bib_id":"tan2023target","title":"TARGET: Template-Transferable Backdoor Attack Against Prompt-based NLP Models via GPT4","author":"Tan, Zihao and Chen, Qingliang and Huang, Yongjian and Liang, Chen","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2311.17429"}}
{"bib_id":"li2023watermarking","title":"Watermarking LLMs with Weight Quantization","author":"Li, Linyang and Jiang, Botian and Wang, Pengyu and Ren, Ke and Yan, Hang and Qiu, Xipeng","meta_info":{"year":"2023","pages":"3368--3378","booktitle":"Findings of the Association for Computational Linguistics: EMNLP 2023"}}
{"bib_id":"peng2023you","title":"Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark","author":"Peng, Wenjun and Yi, Jingwei and Wu, Fangzhao and Wu, Shangxi and Zhu, Bin Bin and Lyu, Lingjuan and Jiao, Binxing and Xu, Tong and Sun, Guangzhong and Xie, Xing","meta_info":{"year":"2023","pages":"7653--7668","booktitle":"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)"}}
{"bib_id":"zou2024poisonedrag","title":"PoisonedRAG: Knowledge Poisoning Attacks to Retrieval-Augmented Generation of Large Language Models","author":"Zou, Wei and Geng, Runpeng and Wang, Binghui and Jia, Jinyuan","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2402.07867"}}
{"bib_id":"long2024backdoor","title":"Backdoor Attacks on Dense Passage Retrievers for Disseminating Misinformation","author":"Long, Quanyu and Deng, Yue and Gan, LeiLei and Wang, Wenya and Pan, Sinno Jialin","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2402.13532"}}
{"bib_id":"li2024badedit","title":"BadEdit: Backdooring large language models by model editing","author":"Li, Yanzhou and Li, Tianlin and Chen, Kangjie and Zhang, Jian and Liu, Shangqing and Wang, Wenhan and Zhang, Tianwei and Liu, Yang","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2403.13355"}}
{"bib_id":"yang2024watch","title":"Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based Agents","author":"Yang, Wenkai and Bi, Xiaohan and Lin, Yankai and Chen, Sishuo and Zhou, Jie and Sun, Xu","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2402.11208"}}
{"bib_id":"chen2021badpre","title":"BadPre: Task-agnostic Backdoor Attacks to Pre-trained NLP Foundation Models","author":"Chen, Kangjie and Meng, Yuxian and Sun, Xiaofei and Guo, Shangwei and Zhang, Tianwei and Li, Jiwei and Fan, Chun","meta_info":{"year":"2021","booktitle":"International Conference on Learning Representations"}}
{"bib_id":"zhou2023backdoor","title":"Backdoor attacks with input-unique triggers in nlp","author":"Zhou, Xukun and Li, Jiwei and Zhang, Tianwei and Lyu, Lingjuan and Yang, Muqiao and He, Jun","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2303.14325"}}
{"bib_id":"lou2022trojtext","title":"TrojText: Test-time Invisible Textual Trojan Insertion","author":"Lou, Qian and Liu, Yepeng and Feng, Bo","meta_info":{"year":"2022","booktitle":"The Eleventh International Conference on Learning Representations"}}
{"bib_id":"zhao2024taslp","title":"Exploring Clean Label Backdoor Attacks and Defense in Language Models","author":"Zhao, Shuai and Luu, Anh Tuan and Fu, Jie and Wen, Jinming and Luo, Weiqi","meta_info":{"year":"2024","booktitle":"IEEE\/ACM Transactions on Audio, Speech and Language Processing"}}
{"bib_id":"xi2024defending","title":"Defending pre-trained language models as few-shot learners against backdoor attacks","author":"Xi, Zhaohan and Du, Tianyu and Li, Changjiang and Pang, Ren and Ji, Shouling and Chen, Jinghui and Ma, Fenglong and Wang, Ting","meta_info":{"year":"2024","volume":"36","journal":"Advances in Neural Information Processing Systems"}}
{"bib_id":"mo2023test","title":"Test-time backdoor mitigation for black-box large language models with defensive demonstrations","author":"Mo, Wenjie and Xu, Jiashu and Liu, Qin and Wang, Jiongxiao and Yan, Jun and Xiao, Chaowei and Chen, Muhao","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2311.09763"}}
{"bib_id":"pei2023textguard","title":"Textguard: Provable defense against backdoor attacks on text classification","author":"Pei, Hengzhi and Jia, Jinyuan and Guo, Wenbo and Li, Bo and Song, Dawn","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2311.11225"}}
{"bib_id":"li2023defending","title":"Defending against Insertion-based Textual Backdoor Attacks via Attribution","author":"Li, Jiazhao and Wu, Zhuofeng and Ping, Wei and Xiao, Chaowei and Vydiswaran, VG Vinod","meta_info":{"year":"2023","pages":"8818--8833","booktitle":"Findings of the Association for Computational Linguistics: ACL 2023"}}
{"bib_id":"xiang2024nlpsweep","title":"NLPSweep: A comprehensive defense scheme for mitigating NLP backdoor attacks","author":"Xiang, Tao and Ouyang, Fei and Zhang, Di and Xie, Chunlong and Wang, Hao","meta_info":{"publisher":"Elsevier","year":"2024","pages":"120176","volume":"661","journal":"Information Sciences"}}
{"bib_id":"guo2024artwork","title":"Artwork Protection Against Neural Style Transfer Using Locally Adaptive Adversarial Color Attack","author":"Guo, Zhongliang and Wang, Kaixuan and Li, Weiye and Qian, Yifei and Arandjelović, Ognjen and Fang, Lei","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2401.09673"}}
{"bib_id":"dai2019backdoor","title":"A backdoor attack against lstm-based text classification systems","author":"Dai, Jiazhu and Chen, Chuanshuai and Li, Yufeng","meta_info":{"publisher":"IEEE","year":"2019","pages":"138872--138878","volume":"7","journal":"IEEE Access"}}
{"bib_id":"kwon2021textual","title":"Textual backdoor attack for the text classification system","author":"Kwon, Hyun and Lee, Sanghyun","meta_info":{"publisher":"Hindawi Limited","year":"2021","pages":"1--11","volume":"2021","journal":"Security and Communication Networks"}}
{"bib_id":"li2021backdoor","title":"Backdoor Attacks on Pre-trained Models by Layerwise Weight Poisoning","author":"Li, Linyang and Song, Demin and Li, Xiaonan and Zeng, Jiehang and Ma, Ruotian and Qiu, Xipeng","meta_info":{"year":"2021","pages":"3023--3032","booktitle":"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing"}}
{"bib_id":"zhang2021trojaning","title":"Trojaning language models for fun and profit","author":"Zhang, Xinyang and Zhang, Zheng and Ji, Shouling and Wang, Ting","meta_info":{"organization":"IEEE","year":"2021","pages":"179--197","booktitle":"2021 IEEE European Symposium on Security and Privacy (EuroS&P)"}}
{"bib_id":"shao2022triggers","title":"The triggers that open the NLP model backdoors are hidden in the adversarial samples","author":"Shao, Kun and Zhang, Yu and Yang, Junan and Li, Xiaoshuai and Liu, Hui","meta_info":{"publisher":"Elsevier","year":"2022","pages":"102730","volume":"118","journal":"Computers & Security"}}
{"bib_id":"yang2021rethinking","title":"Rethinking stealthiness of backdoor attack against nlp models","author":"Yang, Wenkai and Lin, Yankai and Li, Peng and Zhou, Jie and Sun, Xu","meta_info":{"year":"2021","pages":"5543--5557","booktitle":"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)"}}
{"bib_id":"wallace2021concealed","title":"Concealed Data Poisoning Attacks on NLP Models","author":"Wallace, Eric and Zhao, Tony and Feng, Shi and Singh, Sameer","meta_info":{"year":"2021","pages":"139--150","booktitle":"Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"}}
{"bib_id":"li2021hidden","title":"Hidden backdoors in human-centric language models","author":"Li, Shaofeng and Liu, Hui and Dong, Tian and Zhao, Benjamin Zi Hao and Xue, Minhui and Zhu, Haojin and Lu, Jialiang","meta_info":{"year":"2021","pages":"3123--3140","booktitle":"Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security"}}
{"bib_id":"qi2021hidden","title":"Hidden Killer: Invisible Textual Backdoor Attacks with Syntactic Trigger","author":"Qi, Fanchao and Li, Mukai and Chen, Yangyi and Zhang, Zhengyan and Liu, Zhiyuan and Wang, Yasheng and Sun, Maosong","meta_info":{"year":"2021","pages":"443--453","booktitle":"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)"}}
{"bib_id":"pan2022hidden","title":"Hidden trigger backdoor attack on $\\$NLP$\\$ models via linguistic style manipulation","author":"Pan, Xudong and Zhang, Mi and Sheng, Beina and Zhu, Jiaming and Yang, Min","meta_info":{"year":"2022","pages":"3611--3628","booktitle":"31st USENIX Security Symposium (USENIX Security 22)"}}
{"bib_id":"kurita2020weight","title":"Weight Poisoning Attacks on Pretrained Models","author":"Kurita, Keita and Michel, Paul and Neubig, Graham","meta_info":{"year":"2020","pages":"2793--2806","booktitle":"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics"}}
{"bib_id":"yang2021careful","title":"Be Careful about Poisoned Word Embeddings: Exploring the Vulnerability of the Embedding Layers in NLP Models","author":"Yang, Wenkai and Li, Lei and Zhang, Zhiyuan and Ren, Xuancheng and Sun, Xu and He, Bin","meta_info":{"year":"2021","pages":"2048--2058","booktitle":"Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"}}
{"bib_id":"shen2021backdoor","title":"Backdoor Pre-trained Models Can Transfer to All","author":"Shen, Lujia and Ji, Shouling and Zhang, Xuhong and Li, Jinfeng and Chen, Jing and Shi, Jie and Fang, Chengfang and Yin, Jianwei and Wang, Ting","meta_info":{"year":"2021","pages":"3141--3158","booktitle":"Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security"}}
{"bib_id":"gan2022triggerless","title":"Triggerless Backdoor Attack for NLP Tasks with Clean Labels","author":"Gan, Leilei and Li, Jiwei and Zhang, Tianwei and Li, Xiaoya and Meng, Yuxian and Wu, Fei and Yang, Yi and Guo, Shangwei and Fan, Chun","meta_info":{"year":"2022","pages":"2942--2952","booktitle":"Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"}}
{"bib_id":"gupta2023adversarial","title":"Adversarial Clean Label Backdoor Attacks and Defenses on Text Classification Systems","author":"Gupta, Ashim and Krishna, Amrith","meta_info":{"year":"2023","pages":"1--12","booktitle":"Proceedings of the 8th Workshop on Representation Learning for NLP (RepL4NLP 2023)"}}
{"bib_id":"garg2020can","title":"Can adversarial weight perturbations inject neural backdoors","author":"Garg, Siddhant and Kumar, Adarsh and Goel, Vibhor and Liang, Yingyu","meta_info":{"year":"2020","pages":"2029--2032","booktitle":"Proceedings of the 29th ACM International Conference on Information & Knowledge Management"}}
{"bib_id":"li2020open","title":"Open-sourced dataset protection via backdoor watermarking","author":"Li, Yiming and Zhang, Ziqi and Bai, Jiawang and Wu, Baoyuan and Jiang, Yong and Xia, Shu-Tao","meta_info":{"year":"2020","journal":"arXiv preprint arXiv:2010.05821"}}
{"bib_id":"yao2024poisonprompt","title":"Poisonprompt: Backdoor attack on prompt-based large language models","author":"Yao, Hongwei and Lou, Jian and Qin, Zhan","meta_info":{"organization":"IEEE","year":"2024","pages":"7745--7749","booktitle":"ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"}}
{"bib_id":"bagdasaryan2022spinning","title":"Spinning language models: Risks of propaganda-as-a-service and countermeasures","author":"Bagdasaryan, Eugene and Shmatikov, Vitaly","meta_info":{"organization":"IEEE","year":"2022","pages":"769--786","booktitle":"2022 IEEE Symposium on Security and Privacy (SP)"}}
{"bib_id":"chen2023backdoor","title":"Backdoor learning on sequence to sequence models","author":"Chen, Lichang and Cheng, Minhao and Huang, Heng","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2305.02424"}}
{"bib_id":"papineni2002bleu","title":"Bleu: a method for automatic evaluation of machine translation","author":"Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing","meta_info":{"year":"2002","pages":"311--318","booktitle":"Proceedings of the 40th annual meeting of the Association for Computational Linguistics"}}
{"bib_id":"lin2004rouge","title":"Rouge: A package for automatic evaluation of summaries","author":"Lin, Chin-Yew","meta_info":{"year":"2004","pages":"74--81","booktitle":"Text summarization branches out"}}
{"bib_id":"reimers2019sentence","title":"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks","author":"Reimers, Nils and Gurevych, Iryna","meta_info":{"year":"2019","pages":"3982--3992","booktitle":"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)"}}
{"bib_id":"radford4language","title":"Language Models are Unsupervised Multitask Learners","author":"Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and Dean, Jeffrey and Ghemawat, Sanjay","meta_info":{"year":"2019","pages":"137--150","booktitle":"OSDI'04: Sixth Symposium on Operating System Design and Implementation"}}
{"bib_id":"naber2003rule","title":"A rule-based style and grammar checker","author":"Naber, Daniel and others","meta_info":{"journal":"GRIN Verlag Munich, Germnay","year":"2003"}}
{"bib_id":"socher2013recursive","title":"Recursive deep models for semantic compositionality over a sentiment treebank","author":"Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher","meta_info":{"year":"2013","pages":"1631--1642","booktitle":"Proceedings of the 2013 conference on empirical methods in natural language processing"}}
{"bib_id":"maas2011learning","title":"Learning word vectors for sentiment analysis","author":"Maas, Andrew and Daly, Raymond E and Pham, Peter T and Huang, Dan and Ng, Andrew Y and Potts, Christopher","meta_info":{"year":"2011","pages":"142--150","booktitle":"Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies"}}
{"bib_id":"zhang2015character","title":"Character-level convolutional networks for text classification","author":"Zhang, Xiang and Zhao, Junbo and LeCun, Yann","meta_info":{"year":"2015","volume":"28","journal":"Advances in neural information processing systems"}}
{"bib_id":"blitzer2007biographies","title":"Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification","author":"Blitzer, John and Dredze, Mark and Pereira, Fernando","meta_info":{"year":"2007","pages":"440--447","booktitle":"Proceedings of the 45th annual meeting of the association of computational linguistics"}}
{"bib_id":"zampieri2019predicting","title":"Predicting the Type and Target of Offensive Posts in Social Media","author":"Zampieri, Marcos and Malmasi, Shervin and Nakov, Preslav and Rosenthal, Sara and Farra, Noura and Kumar, Ritesh","meta_info":{"year":"2019","pages":"1415--1420","booktitle":"Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)"}}
{"bib_id":"de2018hate","title":"Hate Speech Dataset from a White Supremacy Forum","author":"De Gibert, Ona and Perez, Naiara and Garcıa-Pablos, Aitor and Cuadros, Montse","meta_info":{"year":"2018","pages":"11","journal":"EMNLP 2018"}}
{"bib_id":"wang2018glue","title":"GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding","author":"Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel","meta_info":{"year":"2018","pages":"353--355","booktitle":"Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP"}}
{"bib_id":"cettolo2014report","title":"Report on the 11th IWSLT evaluation campaign","author":"Cettolo, Mauro and Niehues, Jan and Stüker, Sebastian and Bentivogli, Luisa and Federico, Marcello","meta_info":{"year":"2014","pages":"2--17","booktitle":"Proceedings of the 11th International Workshop on Spoken Language Translation: Evaluation Campaign"}}
{"bib_id":"cettolo2016iwslt","title":"The IWSLT 2016 evaluation campaign","author":"Cettolo, Mauro and Niehues, Jan and Stüker, Sebastian and Bentivogli, Luisa and Cattoni, Rolando and Federico, Marcello","meta_info":{"year":"2016","booktitle":"Proceedings of the 13th International Conference on Spoken Language Translation"}}
{"bib_id":"bojar2016findings","title":"Findings of the 2016 conference on machine translation (wmt16)","author":"Bojar, Ondrej and Chatterjee, Rajen and Federmann, Christian and Graham, Yvette and Haddow, Barry and Huck, Matthias and Yepes, Antonio Jimeno and Koehn, Philipp and Logacheva, Varvara and Monz, Christof and others","meta_info":{"organization":"Association for Computational Linguistics","year":"2016","pages":"131--198","booktitle":"First conference on machine translation"}}
{"bib_id":"narayan2018don","title":"Don’t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization","author":"Narayan, Shashi and Cohen, Shay B and Lapata, Mirella","meta_info":{"year":"2018","pages":"1797--1807","booktitle":"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing"}}
{"bib_id":"hermann2015teaching","title":"Teaching machines to read and comprehend","author":"Hermann, Karl Moritz and Kocisky, Tomas and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil","meta_info":{"year":"2015","volume":"28","journal":"Advances in neural information processing systems"}}
{"bib_id":"grusky2018newsroom","title":"Newsroom: A Dataset of 1.3 Million Summaries with Diverse Extractive Strategies","author":"Grusky, Max and Naaman, Mor and Artzi, Yoav","meta_info":{"year":"2018","pages":"708--719","booktitle":"Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)"}}
{"bib_id":"mackenzie2020cc","title":"CC-News-En: A large English news corpus","author":"Mackenzie, Joel and Benham, Rodger and Petri, Matthias and Trippas, Johanne R and Culpepper, J Shane and Moffat, Alistair","meta_info":{"year":"2020","pages":"3077--3084","booktitle":"Proceedings of the 29th ACM International Conference on Information & Knowledge Management"}}
{"bib_id":"danescu2011chameleons","title":"Chameleons in imagined conversations: A new approach to understanding coordination of linguistic style in dialogs","author":"Danescu-Niculescu-Mizil, Cristian and Lee, Lillian","meta_info":{"year":"2011","pages":"76","journal":"ACL HLT 2011"}}
{"bib_id":"rajpurkar2016squad","title":"SQuAD: 100,000+ Questions for Machine Comprehension of Text","author":"Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy","meta_info":{"year":"2016","pages":"2383--2392","booktitle":"Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing"}}
{"bib_id":"yatskar2019qualitative","title":"A Qualitative Comparison of CoQA, SQuAD 2.0 and QuAC","author":"Yatskar, Mark","meta_info":{"year":"2019","pages":"2318--2323","booktitle":"Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)"}}
{"bib_id":"sang2003introduction","title":"Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition","author":"Sang, Erik Tjong Kim and De Meulder, Fien","meta_info":{"year":"2003","pages":"142--147","booktitle":"Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003"}}
{"bib_id":"kenton2019bert","title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding","author":"Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina","meta_info":{"year":"2019","pages":"4171--4186","booktitle":"Proceedings of NAACL-HLT"}}
{"bib_id":"touvron2023llama","title":"Llama: Open and efficient foundation language models","author":"Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timothée and Rozière, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2302.13971\n\n"}}
{"bib_id":"touvron2023llama2","title":"Llama 2: Open foundation and fine-tuned chat models","author":"Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2307.09288\n\n"}}
{"bib_id":"liu2019roberta","title":"Roberta: A robustly optimized bert pretraining approach","author":"Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin","meta_info":{"year":"2019","journal":"arXiv preprint arXiv:1907.11692\n\n"}}
{"bib_id":"lan2019albert","title":"ALBERT: A Lite BERT for Self-supervised Learning of Language Representations","author":"Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu","meta_info":{"year":"2019","booktitle":"International Conference on Learning Representations"}}
{"bib_id":"snell2017prototypical","title":"Prototypical networks for few-shot learning","author":"Snell, Jake and Swersky, Kevin and Zemel, Richard","meta_info":{"year":"2017","volume":"30","journal":"Advances in neural information processing systems"}}
{"bib_id":"wang2020generalizing","title":"Generalizing from a few examples: A survey on few-shot learning","author":"Wang, Yaqing and Yao, Quanming and Kwok, James T and Ni, Lionel M","meta_info":{"publisher":"ACM New York, NY, USA","year":"2020","pages":"1--34","number":"3","volume":"53","journal":"ACM computing surveys (csur)"}}
{"bib_id":"xian2018zero","title":"Zero-shot learning—a comprehensive evaluation of the good, the bad and the ugly","author":"Xian, Yongqin and Lampert, Christoph H and Schiele, Bernt and Akata, Zeynep","meta_info":{"publisher":"IEEE","year":"2018","pages":"2251--2265","number":"9","volume":"41","journal":"IEEE transactions on pattern analysis and machine intelligence"}}
{"bib_id":"robey2023smoothllm","title":"SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks","author":"Robey, Alexander and Wong, Eric and Hassani, Hamed and Pappas, George","meta_info":{"year":"2023","booktitle":"R0-FoMo: Robustness of Few-shot and Zero-shot Learning in Large Foundation Models"}}
{"bib_id":"niu2024jailbreaking","title":"Jailbreaking attack against multimodal large language model","author":"Niu, Zhenxing and Ren, Haodong and Gao, Xinbo and Hua, Gang and Jin, Rong","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2402.02309\n\n"}}
{"bib_id":"formento2023using","title":"Using punctuation as an adversarial attack on deep learning-based NLP systems: An empirical study","author":"Formento, Brian and Foo, Chuan Sheng and Tuan, Luu Anh and Ng, See Kiong","meta_info":{"year":"2023","pages":"1--34","booktitle":"Findings of the Association for Computational Linguistics: EACL 2023"}}
{"bib_id":"minh2022textual","title":"Textual manifold-based defense against natural language adversarial examples","author":"Minh, Dang Nguyen and Luu, Anh Tuan","meta_info":{"year":"2022","pages":"6612--6625","booktitle":"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing"}}
{"bib_id":"dong2021should","title":"How should pre-trained language models be fine-tuned towards adversarial robustness?","author":"Dong, Xinshuai and Luu, Anh Tuan and Lin, Min and Yan, Shuicheng and Zhang, Hanwang","meta_info":{"year":"2021","pages":"4356--4369","volume":"34","journal":"Advances in Neural Information Processing Systems"}}
{"bib_id":"nguyen2024backdoor","title":"Backdoor attacks and defenses in federated learning: Survey, challenges and future research directions","author":"Nguyen, Thuy Dung and Nguyen, Tuan and Le Nguyen, Phi and Pham, Hieu H and Doan, Khoa D and Wong, Kok-Seng","meta_info":{"publisher":"Elsevier","year":"2024","pages":"107166","volume":"127","journal":"Engineering Applications of Artificial Intelligence"}}
{"bib_id":"cheng2023backdoor","title":"Backdoor attacks and countermeasures in natural language processing models: A comprehensive security review","author":"Cheng, Pengzhou and Wu, Zongru and Du, Wei and Liu, Gongshen","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2309.06055"}}
{"bib_id":"mengara2024backdoor","title":"Backdoor Attacks to Deep Neural Networks: A Survey of the Literature, Challenges, and Future Research Directions","author":"Mengara, Orson and Avila, Anderson and Falk, Tiago H","meta_info":{"publisher":"IEEE","year":"2024","journal":"IEEE Access"}}
{"bib_id":"sun2023defending","title":"Defending against backdoor attacks in natural language generation","author":"Sun, Xiaofei and Li, Xiaoya and Meng, Yuxian and Ao, Xiang and Lyu, Lingjuan and Li, Jiwei and Zhang, Tianwei","meta_info":{"year":"2023","pages":"5257--5265","booktitle":"Proceedings of the AAAI Conference on Artificial Intelligence"}}
{"bib_id":"fan2021text","title":"Text backdoor detection using an interpretable rnn abstract model","author":"Fan, Ming and Si, Ziliang and Xie, Xiaofei and Liu, Yang and Liu, Ting","meta_info":{"publisher":"IEEE","year":"2021","pages":"4117--4132","volume":"16","journal":"IEEE Transactions on Information Forensics and Security"}}
{"bib_id":"shao2021bddr","title":"Bddr: An effective defense against textual backdoor attacks","author":"Shao, Kun and Yang, Junan and Ai, Yang and Liu, Hui and Zhang, Yu","meta_info":{"publisher":"Elsevier","year":"2021","pages":"102433","volume":"110","journal":"Computers & Security"}}
{"bib_id":"yang2021rap","title":"RAP: Robustness-Aware Perturbations for Defending against Backdoor Attacks on NLP Models","author":"Yang, Wenkai and Lin, Yankai and Li, Peng and Zhou, Jie and Sun, Xu","meta_info":{"year":"2021","pages":"8365--8381","booktitle":"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing"}}
{"bib_id":"wei2024bdmmt","title":"Bdmmt: Backdoor sample detection for language models through model mutation testing","author":"Wei, Jiali and Fan, Ming and Jiao, Wenjing and Jin, Wuxia and Liu, Ting","meta_info":{"publisher":"IEEE","year":"2024","journal":"IEEE Transactions on Information Forensics and Security"}}
{"bib_id":"li2021bfclass","title":"BFClass: A Backdoor-free Text Classification Framework","author":"Li, Zichao and Mekala, Dheeraj and Dong, Chengyu and Shang, Jingbo","meta_info":{"year":"2021","pages":"444--453","booktitle":"Findings of the Association for Computational Linguistics: EMNLP 2021"}}
{"bib_id":"zhai2023ncl","title":"NCL: Textual backdoor defense using noise-augmented contrastive learning","author":"Zhai, Shengfang and Shen, Qingni and Chen, Xiaoyi and Wang, Weilong and Li, Cong and Fang, Yuejian and Wu, Zhonghai","meta_info":{"organization":"IEEE","year":"2023","pages":"1--5","booktitle":"ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"}}
{"bib_id":"jin2022wedef","title":"WeDef: Weakly Supervised Backdoor Defense for Text Classification","author":"Jin, Lesheng and Wang, Zihan and Shang, Jingbo","meta_info":{"year":"2022","pages":"11614--11626","booktitle":"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing"}}
{"bib_id":"li2020neural","title":"Neural Attention Distillation: Erasing Backdoor Triggers from Deep Neural Networks","author":"Li, Yige and Lyu, Xixiang and Koren, Nodens and Lyu, Lingjuan and Li, Bo and Ma, Xingjun","meta_info":{"year":"2020","booktitle":"International Conference on Learning Representations"}}
{"bib_id":"liu2018fine","title":"Fine-pruning: Defending against backdooring attacks on deep neural networks","author":"Liu, Kang and Dolan-Gavitt, Brendan and Garg, Siddharth","meta_info":{"organization":"Springer","year":"2018","pages":"273--294","booktitle":"International symposium on research in attacks, intrusions, and defenses"}}
{"bib_id":"shen2022constrained","title":"Constrained optimization with dynamic bound-scaling for effective nlp backdoor defense","author":"Shen, Guangyu and Liu, Yingqi and Tao, Guanhong and Xu, Qiuling and Zhang, Zhuo and An, Shengwei and Ma, Shiqing and Zhang, Xiangyu","meta_info":{"organization":"PMLR","year":"2022","pages":"19879--19892","booktitle":"International Conference on Machine Learning"}}
{"bib_id":"lyu2022study","title":"A Study of the Attention Abnormality in Trojaned BERTs","author":"Lyu, Weimin and Zheng, Songzhu and Ma, Tengfei and Chen, Chao","meta_info":{"year":"2022","pages":"4727--4741","booktitle":"Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies"}}
{"bib_id":"xian2023unified","title":"A unified detection framework for inference-stage backdoor defenses","author":"Xian, Xun and Wang, Ganghua and Srinivasa, Jayanth and Kundu, Ashish and Bi, Xuan and Hong, Mingyi and Ding, Jie","meta_info":{"year":"2023","pages":"7867--7894","volume":"36","journal":"Advances in Neural Information Processing Systems"}}
{"bib_id":"liu2023shortcuts","title":"From shortcuts to triggers: Backdoor defense with denoised poe","author":"Liu, Qin and Wang, Fei and Xiao, Chaowei and Chen, Muhao","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2305.14910\n"}}
{"bib_id":"azizi2021t","title":"T-Miner: A generative approach to defend against trojan attacks on DNN-based text classification","author":"Azizi, Ahmadreza and Tahmid, Ibrahim Asadullah and Waheed, Asim and Mangaokar, Neal and Pu, Jiameng and Javed, Mobin and Reddy, Chandan K and Viswanath, Bimal","meta_info":{"year":"2021","pages":"2255--2272","booktitle":"30th USENIX Security Symposium (USENIX Security 21)"}}
{"bib_id":"wang2024rlhf","title":"Is RLHF More Difficult than Standard RL? A Theoretical Perspective","author":"Wang, Yuanhao and Liu, Qinghua and Jin, Chi","meta_info":{"year":"2024","volume":"36","journal":"Advances in Neural Information Processing Systems"}}
{"bib_id":"lester2021power","title":"The Power of Scale for Parameter-Efficient Prompt Tuning","author":"Lester, Brian and Al-Rfou, Rami and Constant, Noah","meta_info":{"year":"2021","pages":"3045--3059","booktitle":"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing"}}
{"bib_id":"ma2016tag","title":"Tag correlation and user social relation based microblog recommendation","author":"Ma, Huifang and Jia, Meihuizi and Lin, Xianghong and Zhuang, Fuzhen","meta_info":{"organization":"IEEE","year":"2016","pages":"2424--2430","booktitle":"2016 International Joint Conference on Neural Networks (IJCNN)"}}
{"bib_id":"li2024embedding","title":"Embedding Compression in Recommender Systems: A Survey","author":"Li, Shiwei and Guo, Huifeng and Tang, Xing and Tang, Ruiming and Hou, Lu and Li, Ruixuan and Zhang, Rui","meta_info":{"publisher":"ACM New York, NY","year":"2024","pages":"1--21","number":"5","volume":"56","journal":"ACM Computing Surveys"}}
{"bib_id":"zhao2022ap","title":"AP-BERT: enhanced pre-trained model through average pooling","author":"Zhao, Shuai and Zhang, Tianyu and Hu, Man and Chang, Wen and You, Fucheng","meta_info":{"publisher":"Springer","year":"2022","pages":"15929--15937","number":"14","volume":"52","journal":"Applied Intelligence"}}
{"bib_id":"zhao2023softmax","title":"From softmax to nucleusmax: A novel sparse language model for chinese radiology report summarization","author":"Zhao, Shuai and Li, Qing and Yang, Yuer and Wen, Jinming and Luo, Weiqi","meta_info":{"publisher":"ACM New York, NY","year":"2023","pages":"1--21","number":"6","volume":"22","journal":"ACM Transactions on Asian and Low-Resource Language Information Processing"}}
{"bib_id":"wu2020short","title":"Short Text Topic Modeling with Topic Distribution Quantization and Negative Sampling Decoder","author":"Wu, Xiaobao  and Li, Chunping  and Zhu, Yan  and Miao, Yishu","meta_info":{"pages":"1772--1782","booktitle":"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)","year":"2020"}}
{"bib_id":"pan2024fallacy","title":"Are LLMs Good Zero-Shot Fallacy Classifiers?","author":"Pan, Fengjun  and Wu, Xiaobao  and Li, Zongrui  and Luu, Anh Tuan","meta_info":{"pages":"14338--14364","publisher":"Association for Computational Linguistics","address":"Miami, Florida, USA","year":"2024","month":"November","booktitle":"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing","editor":"Al-Onaizan, Yaser  and Bansal, Mohit  and Chen, Yun-Nung"}}
{"bib_id":"wu2022mitigating","title":"Mitigating Data Sparsity for Short Text Topic Modeling by Topic-Semantic Contrastive Learning","author":"Wu, Xiaobao  and Luu, Anh Tuan  and Dong, Xinshuai","meta_info":{"pages":"2748--2760","address":"Abu Dhabi, United Arab Emirates","publisher":"Association for Computational Linguistics","booktitle":"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing","month":"December","year":"2022"}}
{"bib_id":"pan2023fact","title":"Fact-Checking Complex Claims with Program-Guided Reasoning","author":"Pan, Liangming and Wu, Xiaobao and Lu, Xinyuan and Luu, Anh Tuan and Wang, William Yang and Kan, Min-Yen and Nakov, Preslav","meta_info":{"pages":"6981--7004","booktitle":"Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","year":"2023"}}
{"bib_id":"wu2024antileak","title":"AntiLeak-Bench: Preventing Data Contamination by Automatically Constructing Benchmarks with Updated Real-World Knowledge","author":"Wu, Xiaobao and Pan, Liangming and Xie, Yuxi and Zhou, Ruiwen and Zhao, Shuai and Ma, Yubo and Du, Mingzhe and Mao, Rui and Luu, Anh Tuan and Wang, William Yang","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2412.13670"}}
{"bib_id":"wu2024akew","title":"AKEW: Assessing Knowledge Editing in the Wild","author":"Wu, Xiaobao  and Pan, Liangming  and Wang, William Yang  and Luu, Anh Tuan","meta_info":{"pages":"15118--15133","publisher":"Association for Computational Linguistics","address":"Miami, Florida, USA","year":"2024","month":"November","booktitle":"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing","editor":"Al-Onaizan, Yaser  and Bansal, Mohit  and Chen, Yun-Nung"}}
{"bib_id":"wu2024topmost","title":"Towards the TopMost: A Topic Modeling System Toolkit","author":"Wu, Xiaobao  and Pan, Fengjun  and Luu, Anh Tuan","meta_info":{"pages":"31--41","year":"2024","booktitle":"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)"}}
{"bib_id":"zhang2023prompting","title":"Prompting large language model for machine translation: A case study","author":"Zhang, Biao and Haddow, Barry and Birch, Alexandra","meta_info":{"organization":"PMLR","year":"2023","pages":"41092--41110","booktitle":"International Conference on Machine Learning"}}
{"bib_id":"garcia2023unreasonable","title":"The unreasonable effectiveness of few-shot learning for machine translation","author":"Garcia, Xavier and Bansal, Yamini and Cherry, Colin and Foster, George and Krikun, Maxim and Johnson, Melvin and Firat, Orhan","meta_info":{"organization":"PMLR","year":"2023","pages":"10867--10878","booktitle":"International Conference on Machine Learning"}}
{"bib_id":"chiang2023vicuna","title":"Judging llm-as-a-judge with mt-bench and chatbot arena","author":"Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others","meta_info":{"year":"2024","volume":"36","journal":"Advances in Neural Information Processing Systems"}}
{"bib_id":"liu2023zero","title":"Zero-Shot Text Classification via Self-Supervised Tuning","author":"Liu, Chaoqun and Zhang, Wenxuan and Chen, Guizhen and Wu, Xiaobao and Luu, Anh Tuan and Chang, Chip Hong and Bing, Lidong","meta_info":{"year":"2023","pages":"1743--1761","booktitle":"Findings of the Association for Computational Linguistics: ACL 2023"}}
{"bib_id":"zhao2024defending","title":"Defending Against Weight-Poisoning Backdoor Attacks for Parameter-Efficient Fine-Tuning","author":"Zhao, Shuai and Gan, Leilei and Tuan, Luu Anh and Fu, Jie and Lyu, Lingjuan and Jia, Meihuizi and Wen, Jinming","meta_info":{"year":"2024","pages":"3421--3438","booktitle":"Findings of the Association for Computational Linguistics: NAACL 2024"}}
{"bib_id":"nguyen2021enriching","title":"Enriching and Controlling Global Semantics for Text Summarization","author":"Nguyen, Thong and Luu, Anh Tuan and Lu, Truc and Quan, Tho","meta_info":{"year":"2021","pages":"9443--9456","booktitle":"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing"}}
{"bib_id":"nguyen2022improving","title":"Improving neural cross-lingual abstractive summarization via employing optimal transport distance for knowledge distillation","author":"Nguyen, Thong Thanh and Luu, Anh Tuan","meta_info":{"year":"2022","pages":"11103--11111","booktitle":"Proceedings of the AAAI Conference on Artificial Intelligence"}}
{"bib_id":"guo2024white","title":"A White-Box False Positive Adversarial Attack Method on Contrastive Loss Based Offline Handwritten Signature Verification Models","author":"Guo, Zhongliang and Li, Weiye and Qian, Yifei and Arandjelovic, Ognjen and Fang, Lei","meta_info":{"organization":"PMLR","year":"2024","pages":"901--909","booktitle":"International Conference on Artificial Intelligence and Statistics"}}
{"bib_id":"gu2024light","title":"Light-PEFT: Lightening Parameter-Efficient Fine-Tuning via Early Pruning","author":"Gu, Naibin and Fu, Peng and Liu, Xiyu and Shen, Bowen and Lin, Zheng and Wang, Weiping","meta_info":{"year":"2024","pages":"arXiv--2406","journal":"arXiv e-prints"}}
{"bib_id":"xiao2024atlantis","title":"Atlantis: Aesthetic-oriented multiple granularities fusion network for joint multimodal aspect-based sentiment analysis","author":"Xiao, Luwei and Wu, Xingjiao and Xu, Junjie and Li, Weijie and Jin, Cheng and He, Liang","meta_info":{"publisher":"Elsevier","year":"2024","pages":"102304","journal":"Information Fusion"}}
{"bib_id":"xiao2022exploring","title":"Exploring fine-grained syntactic information for aspect-based sentiment classification with dual graph neural networks","author":"Xiao, Luwei and Xue, Yun and Wang, Hua and Hu, Xiaohui and Gu, Donghong and Zhu, Yongsheng","meta_info":{"publisher":"Elsevier","year":"2022","pages":"48--59","volume":"471","journal":"Neurocomputing"}}
{"bib_id":"li2024chain","title":"Chain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models","author":"Li, Xi and Zhang, Yusen and Lou, Renze and Wu, Chen and Wang, Jiaqi","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2406.05948"}}
{"bib_id":"lyu2024cross","title":"Cross-Context Backdoor Attacks against Graph Prompt Learning","author":"Lyu, Xiaoting and Han, Yufei and Wang, Wei and Qian, Hangwei and Tsang, Ivor and Zhang, Xiangliang","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2405.17984"}}
{"bib_id":"yuan2024sage","title":"E-SAGE: Explainability-based Defense Against Backdoor Attacks on Graph Neural Networks","author":"Yuan, Dingqiang and Xu, Xiaohua and Yu, Lei and Han, Tongchang and Li, Rongchang and Han, Meng","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2406.10655"}}
{"bib_id":"jiao2024exploring","title":"Exploring Backdoor Attacks against Large Language Model-based Decision Making","author":"Jiao, Ruochen and Xie, Shaoyuan and Yue, Justin and Sato, Takami and Wang, Lixu and Wang, Yixuan and Chen, Qi Alfred and Zhu, Qi","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2405.20774"}}
{"bib_id":"li2024cleangen","title":"CleanGen: Mitigating Backdoor Attacks for Generation Tasks in Large Language Models","author":"Li, Yuetai and Xu, Zhangchen and Jiang, Fengqing and Niu, Luyao and Sahabandu, Dinuka and Ramasubramanian, Bhaskar and Poovendran, Radha","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2406.12257"}}
{"bib_id":"wei2023lmsanitator","title":"Lmsanitator: Defending prompt-tuning against task-agnostic backdoors","author":"Wei, Chengkun and Meng, Wenlong and Zhang, Zhikun and Chen, Min and Zhao, Minghu and Fang, Wenjing and Wang, Lei and Zhang, Zihui and Chen, Wenzhi","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2308.13904"}}
{"bib_id":"zeng2024beear","title":"BEEAR: Embedding-based Adversarial Removal of Safety Backdoors in Instruction-tuned Language Models","author":"Zeng, Yi and Sun, Weiyu and Huynh, Tran Ngoc and Song, Dawn and Li, Bo and Jia, Ruoxi","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2406.17092"}}
{"bib_id":"zhaodefense","title":"Defense against Backdoor Attack on Pre-trained Language Models via Head Pruning and Attention Normalization","author":"Zhao, Xingyi and Xu, Depeng and Yuan, Shuhan","meta_info":{"year":"2024","booktitle":"Forty-first International Conference on Machine Learning"}}
{"bib_id":"liucausality","title":"Causality Based Front-door Defense Against Backdoor Attack on Language Models","author":"Liu, Yiran and Xu, Xiaoang and Hou, Zhiyi and Yu, Yang","meta_info":{"year":"2024","booktitle":"Forty-first International Conference on Machine Learning"}}
{"bib_id":"luo2023chatkbqa","title":"Chatkbqa: A generate-then-retrieve framework for knowledge base question answering with fine-tuned large language models","author":"Luo, Haoran and Tang, Zichen and Peng, Shiyao and Guo, Yikai and Zhang, Wentai and Ma, Chenghao and Dong, Guanting and Song, Meina and Lin, Wei and others","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2310.08975"}}
{"bib_id":"wang2024symbolic","title":"Symbolic Knowledge Reasoning on Hyper-Relational Knowledge Graphs","author":"Wang, Zikang and Li, Linjing and Zeng, Daniel Dajun","meta_info":{"publisher":"IEEE","year":"2024","journal":"IEEE Transactions on Big Data"}}
{"bib_id":"liang2024revisiting","title":"Revisiting Backdoor Attacks against Large Vision-Language Models","author":"Liang, Siyuan and Liang, Jiawei and Pang, Tianyu and Du, Chao and Liu, Aishan and Chang, Ee-Chien and Cao, Xiaochun","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2406.18844"}}
{"bib_id":"zhao2024w2sattack","title":"Weak-to-Strong Backdoor Attack for Large Language Models","author":"Shuai Zhao and Leilei Gan and Zhongliang Guo and Xiaobao Wu and Luwei Xiao and Xiaoyu Xu and Cong-Duy Nguyen and Luu Anh Tuan","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2409.17946"}}
{"bib_id":"zhao2024w2sdefense","title":"Unlearning Backdoor Attacks for LLMs with Weak-to-Strong Knowledge Distillation","author":"Shuai Zhao and Xiaobao Wu and Cong-Duy Nguyen and Meihuizi Jia and Yichao Feng and Luu Anh Tuan","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2410.14425"}}
{"bib_id":"he2024cbas","title":"CBAs: Character-level Backdoor Attacks against Chinese Pre-trained Language Models","author":"He, Xinyu and Hao, Fengrui and Gu, Tianlong and Chang, Liang","meta_info":{"publisher":"ACM New York, NY","year":"2024","journal":"ACM Transactions on Privacy and Security"}}
{"bib_id":"hayase2021spectre","title":"Spectre: Defending against backdoor attacks using robust statistics","author":"Hayase, Jonathan and Kong, Weihao and Somani, Raghav and Oh, Sewoong","meta_info":{"organization":"PMLR","year":"2021","pages":"4129--4139","booktitle":"International Conference on Machine Learning"}}
{"bib_id":"sheshadri2024targeted","title":"Targeted Latent Adversarial Training Improves Robustness to Persistent Harmful Behaviors in LLMs","author":"Sheshadri, Abhay and Ewart, Aidan and Guo, Phillip and Lynch, Aengus and Wu, Cindy and Hebbar, Vivek and Sleight, Henry and Stickland, Asa Cooper and Perez, Ethan and Hadfield-Menell, Dylan and others","meta_info":{"year":"2024","journal":"CoRR"}}
{"bib_id":"rando2024competition","title":"Competition report: Finding universal jailbreak backdoors in aligned llms","author":"Rando, Javier and Croce, Francesco and Mitka, Kryštof and Shabalin, Stepan and Andriushchenko, Maksym and Flammarion, Nicolas and Tramèr, Florian","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2404.14461"}}
{"bib_id":"chen2024bathe","title":"BaThe: Defense against the Jailbreak Attack in Multimodal Large Language Models by Treating Harmful Instruction as Backdoor Trigger","author":"Chen, Yulin and Li, Haoran and Zheng, Zihao and Song, Yangqiu","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2408.09093"}}
{"bib_id":"wang2024mitigating","title":"Mitigating fine-tuning jailbreak attack with backdoor enhanced alignment","author":"Wang, Jiongxiao and Li, Jiazhao and Li, Yiquan and Qi, Xiangyu and Chen, Muhao and Hu, Junjie and Li, Yixuan and Li, Bo and Xiao, Chaowei","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2402.14968"}}
{"bib_id":"liu2024backdoor","title":"Backdoor attacks via machine unlearning","author":"Liu, Zihao and Wang, Tianhao and Huai, Mengdi and Miao, Chenglin","meta_info":{"year":"2024","pages":"14115--14123","booktitle":"Proceedings of the AAAI Conference on Artificial Intelligence"}}
{"bib_id":"liu2022backdoor","title":"Backdoor defense with machine unlearning","author":"Liu, Yang and Fan, Mingyuan and Chen, Cen and Liu, Ximeng and Ma, Zhuo and Wang, Li and Ma, Jianfeng","meta_info":{"organization":"IEEE","year":"2022","pages":"280--289","booktitle":"IEEE INFOCOM 2022-IEEE conference on computer communications"}}
{"bib_id":"li2024expose","title":"Expose Before You Defend: Unifying and Enhancing Backdoor Defenses via Exposed Models","author":"Li, Yige and Huang, Hanxun and Zhang, Jiaming and Ma, Xingjun and Jiang, Yu-Gang","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2410.19427"}}
{"bib_id":"mu2024codepurify","title":"CodePurify: Defend Backdoor Attacks on Neural Code Models via Entropy-based Purification","author":"Mu, Fangwen and Wang, Junjie and Yu, Zhuohao and Shi, Lin and Wang, Song and Li, Mingyang and Wang, Qing","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2410.20136"}}
{"bib_id":"sui2024dmgnn","title":"DMGNN: Detecting and Mitigating Backdoor Attacks in Graph Neural Networks","author":"Sui, Hao and Chen, Bing and Zhang, Jiale and Zhu, Chengcheng and Wu, Di and Lu, Qinghua and Long, Guodong","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2410.14105"}}
{"bib_id":"tang2021demon","title":"Demon in the variant: Statistical analysis of $\\$DNNs$\\$ for robust backdoor contamination detection","author":"Tang, Di and Wang, XiaoFeng and Tang, Haixu and Zhang, Kehuan","meta_info":{"year":"2021","pages":"1541--1558","booktitle":"30th USENIX Security Symposium (USENIX Security 21)"}}
{"bib_id":"liu2024rethinking","title":"Rethinking machine unlearning for large language models","author":"Liu, Sijia and Yao, Yuanshun and Jia, Jinghan and Casper, Stephen and Baracaldo, Nathalie and Hase, Peter and Yao, Yuguang and Liu, Chris Yuhao and Xu, Xiaojun and Li, Hang and others","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2402.08787"}}
{"bib_id":"cao2023defending","title":"Defending against alignment-breaking attacks via robustly aligned llm","author":"Cao, Bochuan and Cao, Yuanpu and Lin, Lu and Chen, Jinghui","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2309.14348"}}
{"bib_id":"huang2024vaccine","title":"Vaccine: Perturbation-aware alignment for large language model","author":"Huang, Tiansheng and Hu, Sihao and Liu, Ling","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2402.01109"}}
{"bib_id":"tamirisa2024tamper","title":"Tamper-resistant safeguards for open-weight llms","author":"Tamirisa, Rishub and Bharathi, Bhrugu and Phan, Long and Zhou, Andy and Gatti, Alice and Suresh, Tarun and Lin, Maxwell and Wang, Justin and Wang, Rowan and Arel, Ron and others","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2408.00761"}}
{"bib_id":"liu-etal-2022-p","title":"P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks","author":"Liu, Xiao  and\nJi, Kaixuan  and\nFu, Yicheng  and\nTam, Weng  and\nDu, Zhengxiao  and\nYang, Zhilin  and\nTang, Jie","meta_info":{"pages":"61--68","year":"2022","booktitle":"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)"}}
{"bib_id":"zhao2024clean","title":"Clean-label backdoor attack and defense: An examination of language model vulnerability","author":"Zhao, Shuai and Xu, Xiaoyu and Xiao, Luwei and Wen, Jinming and Tuan, Luu Anh","meta_info":{"publisher":"Elsevier","year":"2024","pages":"125856","journal":"Expert Systems with Applications"}}
