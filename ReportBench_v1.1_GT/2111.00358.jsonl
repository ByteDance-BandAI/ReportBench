{"bib_id":"dominguez2022adversarial","title":"On the adversarial robustness of causal algorithmic recourse","author":"Dominguez-Olmedo, Ricardo and Karimi, Amir H and Schölkopf, Bernhard","meta_info":{"organization":"PMLR","year":"2022","pages":"5324--5342","booktitle":"International Conference on Machine Learning"}}
{"bib_id":"black_consistent_2021","title":"Consistent Counterfactuals for Deep Models","author":"Black, Emily and Wang, Zifan and Fredrikson, Matt and Datta, Anupam","meta_info":{"file":"Black et al. - 2021 - Consistent Counterfactuals for Deep Models.pdf:\/Users\/saumitramishra\/Zotero\/storage\/MPSBQ5ID\/Black et al. - 2021 - Consistent Counterfactuals for Deep Models.pdf:application\/pdf","keywords":"Computer Science - Machine Learning","note":"arXiv: 2110.03109","year":"2021","month":"October","journal":"arXiv:2110.03109 [cs]","urldate":"2022-03-21","language":"en","url":"http:\/\/arxiv.org\/abs\/2110.03109"}}
{"bib_id":"dutta2022robust","title":"Robust Counterfactual Explanations for Tree-Based Ensembles","author":"Dutta, Sanghamitra and Long, Jason and Mishra, Saumitra and Tilli, Cecilia and Magazzeni, Daniele","meta_info":{"organization":"PMLR","year":"2022","pages":"5742--5756","booktitle":"International Conference on Machine Learning"}}
{"bib_id":"verma2020counterfactual","title":"Counterfactual explanations for machine learning: A review","author":"Verma, Sahil and Dickerson, John and Hines, Keegan","meta_info":{"year":"2020","journal":"arXiv preprint arXiv:2010.10596"}}
{"bib_id":"wachter2017counterfactual","title":"Counterfactual explanations without opening the black box: Automated decisions and the GDPR","author":"Wachter, Sandra and Mittelstadt, Brent and Russell, Chris","meta_info":{"publisher":"HeinOnline","year":"2017","pages":"841","volume":"31","journal":"Harv. JL & Tech."}}
{"bib_id":"upadhyay2021towards","title":"Towards Robust and Reliable Algorithmic Recourse","author":"Upadhyay, Sohini and Joshi, Shalmali and Lakkaraju, Himabindu","meta_info":{"year":"2021","journal":"arXiv preprint arXiv:2102.13620"}}
{"bib_id":"rawal2020can","title":"Can I Still Trust You?: Understanding the Impact of Distribution Shifts on Algorithmic Recourses","author":"Rawal, Kaivalya and Kamar, Ece and Lakkaraju, Himabindu","meta_info":{"year":"2020","journal":"arXiv preprint arXiv:2012.11788"}}
{"bib_id":"slack2021counterfactual","title":"Counterfactual Explanations Can Be Manipulated","author":"Slack, Dylan and Hilgard, Sophie and Lakkaraju, Himabindu and Singh, Sameer","meta_info":{"year":"2021","journal":"arXiv preprint arXiv:2106.02666"}}
{"bib_id":"multiobjective","title":"Multi-Objective Counterfactual Explanations","author":"Dandl, Susanne and Molnar, Christoph and Binder, Martin and Bischl, Bernd","meta_info":{"year":"2020","journal":"International Conference on Parallel Problem Solving from Nature"}}
{"bib_id":"konig2021causal","title":"A Causal Perspective on Meaningful and Robust Algorithmic Recourse","author":"König, Gunnar and Freiesleben, Timo and Grosse-Wentrup, Moritz","meta_info":{"year":"2021","journal":"arXiv preprint arXiv:2107.07853"}}
{"bib_id":"pawelczyk2020learning","title":"Learning model-agnostic counterfactual explanations for tabular data","author":"Pawelczyk, Martin and Broelemann, Klaus and Kasneci, Gjergji","meta_info":{"year":"2020","pages":"3126--3132","booktitle":"Proceedings of The Web Conference 2020"}}
{"bib_id":"poyiadzi2020face","title":"FACE: Feasible and actionable counterfactual explanations","author":"Poyiadzi, Rafael and Sokol, Kacper and Santos-Rodriguez, Raul and De Bie, Tijl and Flach, Peter","meta_info":{"year":"2020","pages":"344--350","booktitle":"Proceedings of the AAAI\/ACM Conference on AI, Ethics, and Society"}}
{"bib_id":"Bracke_boe_2019","title":"Machine learning explainability in finance:\nan application to default risk analysis","author":"Philippe Bracke and\nAnupam Datta and\nCarsten Jung and\nShayak Sen","meta_info":{"url":"https:\/\/www.bankofengland.co.uk\/-\/media\/boe\/files\/working-paper\/2019\/machine-learning-explainability-in-finance-an-application-to-default-risk-analysis.pdf","year":"2019","journal":"Bank of England Working Paper"}}
{"bib_id":"Karimi_arXiv_2020","title":"A survey of algorithmic recourse: definitions, formulations, solutions,\nand prospects","author":"Amir-Hossein Karimi and\nGilles Barthe and\nBernhard Schölkopf and\nIsabel Valera","meta_info":{"bibsource":"dblp computer science bibliography, https:\/\/dblp.org","biburl":"https:\/\/dblp.org\/rec\/journals\/corr\/abs-2010-04050.bib","timestamp":"Tue, 13 Oct 2020 15:25:23 +0200","eprint":"2010.04050","eprinttype":"arXiv","url":"https:\/\/arxiv.org\/abs\/2010.04050","year":"2020","volume":"abs\/2010.04050","journal":"CoRR"}}
{"bib_id":"Pawelczyk_arXiv_2021","title":"CARLA: A Python Library to Benchmark Algorithmic Recourse and\nCounterfactual Explanation Algorithms","author":"Martin Pawelczyk and\nSascha Bielawski and\nJohannes van den Heuvel and\nTobias Richter and\nGjergji Kasneci","meta_info":{"bibsource":"dblp computer science bibliography, https:\/\/dblp.org","biburl":"https:\/\/dblp.org\/rec\/journals\/corr\/abs-2108-00783.bib","timestamp":"Thu, 05 Aug 2021 14:27:08 +0200","eprint":"2108.00783","eprinttype":"arXiv","url":"https:\/\/arxiv.org\/abs\/2108.00783","year":"2021","volume":"abs\/2108.00783","journal":"CoRR"}}
{"bib_id":"Dombrowski_pr_2022","title":"Towards robust explanations for deep neural networks","author":"Ann-Kathrin Dombrowski and\nChristopher J. Anders and\nKlaus-Robert Müller and\nPan Kessel","meta_info":{"bibsource":"dblp computer science bibliography, https:\/\/dblp.org","biburl":"https:\/\/dblp.org\/rec\/journals\/pr\/DombrowskiAMK22.bib","timestamp":"Thu, 30 Sep 2021 09:12:06 +0200","doi":"10.1016\/j.patcog.2021.108194","url":"https:\/\/doi.org\/10.1016\/j.patcog.2021.108194","year":"2022","pages":"108194","volume":"121","journal":"Pattern Recognition"}}
{"bib_id":"Jacovi_acl_2020","title":"Towards Faithfully Interpretable NLP Systems: How Should We Define and Evaluate Faithfulness?","author":"Alon Jacovi and Yoav Goldberg","meta_info":{"year":"2020","pages":"4198--4205","organization":"Online","month":"July 5--10","date-modified":"2020-08-25 23:02:49 +0100","date-added":"2020-08-25 23:00:46 +0100","booktitle":"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL)"}}
{"bib_id":"Hancox-Li_fat_2020","title":"Robustness in Machine Learning Explanations: Does It Matter?","author":"Leif Hancox-Li","meta_info":{"year":"2020","pages":"640--647","organization":"Barcelona, Spain","month":"January 27--30","date-modified":"2020-08-25 23:00:07 +0100","date-added":"2020-08-25 22:58:31 +0100","booktitle":"Proceedings of the 3rd ACM Conference on Fairness, Accountability, and Transparency (FAT*)"}}
{"bib_id":"Bansal_cvpr_2020","title":"SAM: The Sensitivity of Attribution Methods to Hyperparameters","author":"Naman Bansal and Chirag Agarwal and Anh Nguyen","meta_info":{"year":"2020","pages":"8670--8680","organization":"Seattle, USA","month":"June 13--19","date-modified":"2020-08-25 22:42:25 +0100","date-added":"2020-08-25 22:40:54 +0100","booktitle":"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"}}
{"bib_id":"Warnecke_arXiv_2020","title":"Evaluating Explanation Methods for Deep Learning in Security","author":"Alexander Warnecke and Daniel Arp and Christian Wressnegger and Konrad Rieck","meta_info":{"year":"2020","volume":"arXiv: 1906.02108","journal":"arXiv e-prints","date-modified":"2020-08-20 02:38:51 +0100","date-added":"2020-08-20 02:35:52 +0100"}}
{"bib_id":"Bhatt_ijcai_2020","title":"Evaluating and Aggregating Feature-based Model Explanations","author":"Umang Bhatt and Adrian Weller and José M. F. Moura","meta_info":{"year":"2020","pages":"3016--3022","organization":"Yokohama, Japan","month":"July","date-modified":"2020-08-20 02:19:35 +0100","date-added":"2020-08-20 02:17:11 +0100","booktitle":"Proceedings of the 29th International Joint Conference on Artificial Intelligence (IJCAI)"}}
{"bib_id":"Yang_arXiv_2019","title":"Benchmarking Attribution Methods with Relative Feature Importance","author":"Mengjiao Yang and Been Kim","meta_info":{"year":"2019","volume":"arXiv:1907.09701","journal":"arXiv e-prints","date-modified":"2020-08-20 02:15:20 +0100","date-added":"2020-08-20 02:13:48 +0100"}}
{"bib_id":"Lakkaraju_icml_2020","title":"Robust and Stable Black Box Explanations","author":"Himabindu Lakkaraju and Nino Arsov and Osbert Bastani","meta_info":{"year":"2020","organization":"Vienna, Austria","date-modified":"2020-08-20 01:58:03 +0100","date-added":"2020-08-20 01:56:33 +0100","booktitle":"Proceedings of the 37th International Conference on Machine Learning (ICML)"}}
{"bib_id":"Zhang_arXiv_2019","title":"Why should you trust my interpretation? Understanding uncertainty in LIME predictions","author":"Yujia Zhang and Kuangyan Song and Yiming Sun and Sarah Tan and Madeilene Udell","meta_info":{"year":"2019","volume":"arXiv: 1904.12991","journal":"arXiv e-prints","date-modified":"2020-08-20 01:54:22 +0100","date-added":"2020-08-20 01:52:16 +0100"}}
{"bib_id":"Melis_arXiv_2018","title":"On the Robustness of Interpretability Methods","author":"David Alvarez-Melis and Tommi S. Jaakkola","meta_info":{"year":"2018","volume":"arXiv: 1806.08049","journal":"arXiv e-prints","date-modified":"2020-08-20 01:50:36 +0100","date-added":"2020-08-20 01:49:46 +0100"}}
{"bib_id":"Anders_arXiv_2020","title":"Fairwashing Explanations with Off-Manifold Detergent","author":"Christopher J. Anders and Plamen Pasliev and Ann-Kathrin Dombrowski and Klaus-Robert Müller and Pan Kessel","meta_info":{"year":"2020","volume":"arXiv:2007.09969","journal":"arXiv e-prints","date-modified":"2020-08-20 01:46:45 +0100","date-added":"2020-08-20 01:45:27 +0100"}}
{"bib_id":"Dimanov_aaai_ws_2020","title":"You Shouldn't Trust Me: Learning Models Which Conceal Unfairness From Multiple Explanation Methods","author":"Botty Dimanov and Umang Bhatt and Mateja Jamnik and Adrian Weller","meta_info":{"year":"2020","organization":"New York, USA","number":"63--73","month":"February 7","date-modified":"2020-08-20 01:44:42 +0100","date-added":"2020-08-20 01:42:13 +0100","booktitle":"Proceedings of the Workshop on Artificial Intelligence Safety 2020 co-located with the 34th AAAI Conference on Artificial Intelligence 2020 (AAAI)"}}
{"bib_id":"Heo_neurips_2019","title":"Fooling Neural Network Interpretations via Adversarial Model Manipulation","author":"Juyeon Heo and Sunghwan Joo and Taesup Moon","meta_info":{"year":"2019","organization":"Vancouver, Canada","number":"2921--2932","month":"December 8--14","date-modified":"2020-08-20 01:41:43 +0100","date-added":"2020-08-20 01:40:24 +0100","booktitle":"Proceedings of the 32nd Conference on Neural Information Processing Systems (NeurIPS)"}}
{"bib_id":"Slack_aies_2020","title":"Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods","author":"Dylan Slack and Sophie Hilgard and Emily Jia and Sameer Singh and Himabindu Lakkaraju","meta_info":{"year":"2020","organization":"New York, USA","number":"180--186","month":"February 7--8","date-modified":"2020-08-20 01:18:06 +0100","date-added":"2020-08-20 01:16:04 +0100","booktitle":"Proceedings of the AAAI\/ACM Conference on AI, Ethics, and Society (AIES)"}}
{"bib_id":"Lakkaraju_aies_2020","title":"\"How do I fool you?\": Manipulating User Trust via Misleading BlackBox Explanations","author":"Himabindu Lakkaraju and Osbert Bastani","meta_info":{"year":"2020","organization":"New York, USA","number":"79--85","month":"February 7--8","date-modified":"2020-08-20 01:18:12 +0100","date-added":"2020-08-20 01:13:52 +0100","booktitle":"Proceedings of the AAAI\/ACM Conference on AI, Ethics, and Society (AIES)"}}
{"bib_id":"Dombrowski_neurips_2019","title":"Explanations can be manipulated and geometry is to blame","author":"Ann-Kathrin Dombrowski and Maximilian Alber and Christopher J. Anders and Marcel Ackermann and Klaus-Robert Müller and Pan Kessel","meta_info":{"year":"2019","pages":"13567--13578","organization":"Vancouver, Canada","month":"December 8--14","date-modified":"2020-08-20 01:17:57 +0100","date-added":"2020-08-20 01:05:58 +0100","booktitle":"Proceedings of the 32nd Conference on Neural Information Processing Systems (NeurIPS)"}}
{"bib_id":"Ghorbani_aaai_2019","title":"Interpretation of Neural Networks Is Fragile","author":"Amirata Ghorbani and Abubakar Abid and James Y. Zou","meta_info":{"year":"2019","organization":"Honolulu, Hawaii, USA","number":"3681--3688","month":"January 27-- February 1","date-modified":"2020-08-20 01:18:36 +0100","date-added":"2020-08-20 00:59:38 +0100","booktitle":"Proceedings of the 33rd AAAI Conference on Artificial Intelligence"}}
{"bib_id":"Mishra_ijcnn_2020","title":"Reliable Local Explanations for Machine Listening","author":"Saumitra Mishra and Emmanouil Benetos and Bob L. Sturm and Simon Dixon","meta_info":{"year":"2020","organization":"Glasgow, Scotland","month":"July 19--24","date-modified":"2020-08-09 23:48:14 +0100","date-added":"2020-08-09 23:45:48 +0100","booktitle":"Proceedings of the International Joint Conference on Neural Networks (IJCNN) Special Session on Explainable Computational\/Artificial Intelligence"}}
{"bib_id":"Adebayo_neurips_2018","title":"Sanity Checks for Saliency Maps","author":"Julius Adebayo and Justin Gilmer and Michael Muelly and Ian J. Goodfellow and Moritz Hardt and Been Kim","meta_info":{"year":"2018","pages":"9525--9536","organization":"Montréal, Canada","month":"December 3--8","date-modified":"2020-01-04 13:44:34 +0000","date-added":"2020-01-02 22:33:19 +0000","booktitle":"Proceedings of the 32nd Conference on Neural Information Processing Systems (NeurIPS)"}}
{"bib_id":"Lundberg_neurips_2017","title":"A Unified Approach to Interpreting Model Predictions","author":"Scott M. Lundberg and Su-In Lee","meta_info":{"year":"2017","pages":"4765--4774","organization":"Long Beach, California, USA","month":"December 4--9","date-modified":"2020-01-04 15:29:23 +0000","date-added":"2019-10-29 20:05:33 +0000","booktitle":"Proceedings of the 31st Conference on Neural Information Processing Systems (NeurIPS)"}}
{"bib_id":"Angwin_web_2016","title":"Machine Bias","author":"Julia Angwin and Jeff Larson and Surya Mattu and Lauren Kirchner","meta_info":{"bdsk-url-1":"https:\/\/www.propublica.org\/article\/machine-bias-risk-assessments-in-criminal-sentencing","year":"2016","url":"https:\/\/www.propublica.org\/article\/machine-bias-risk-assessments-in-criminal-sentencing","note":"Accessed October 8, 2019","month":"May","date-modified":"2020-01-04 16:03:47 +0000","date-added":"2019-10-08 20:49:50 +0100"}}
{"bib_id":"Gilpin_dsaa_2018","title":"Explaining Explanations: An Overview of Interpretability of Machine Learning","author":"Leilani H. Gilpin and David Bau and Ben Z. Yuan and Ayesha Bajwa and Michael Specter and Lalana Kagal","meta_info":{"year":"2018","pages":"80--89","organization":"Turin, Italy","month":"October 1--3","date-modified":"2020-01-04 14:33:28 +0000","date-added":"2019-10-04 17:27:54 +0100","booktitle":"Proceedings of the 5th IEEE International Conference on Data Science and Advanced Analytics (DSAA)"}}
{"bib_id":"Sundarrajan_icml_2017","title":"Axiomatic Attribution for Deep Networks","author":"Mukund Sundararajan and Ankur Taly and Qiqi Yan","meta_info":{"year":"2017","pages":"3319--3328","organization":"Sydney, Australia","month":"August 6--11","date-modified":"2020-01-04 17:11:34 +0000","date-added":"2017-12-27 15:05:14 +0000","booktitle":"Proceedings of the 34th International Conference on Machine Learning (ICML)"}}
{"bib_id":"Kindermans_arXiv_2017","title":"The (Un)reliability of Saliency Methods","author":"Pieter-Jan Kindermans and Sara Hooker and Julius Adebayo and Maximilian Alber and Kristof T. Schütt and Sven Dähne and Dumitru Erhan and Been Kim","meta_info":{"year":"2017","volume":"arXiv:1711.00867","journal":"arXiv e-prints","date-modified":"2019-12-30 22:18:22 +0000","date-added":"2017-12-27 10:15:58 +0000"}}
{"bib_id":"Montavon_dsp_2018","title":"Methods for Interpreting and Understanding Deep Neural Networks","author":"Grégoire Montavon and Wojciech Samek and Klaus-Robert Müller","meta_info":{"year":"2018","volume":"73","pages":"1-15","journal":"Digital Signal Processing","date-modified":"2019-10-05 01:11:40 +0100","date-added":"2017-12-24 23:18:43 +0000"}}
{"bib_id":"Ribeiro_kdd_2016","title":"``Why Should I Trust You?'': Explaining the Predictions of Any Classifier","author":"Marco Túlio Ribeiro and Sameer Singh and Carlos Guestrin","meta_info":{"year":"2016","pages":"1135-1144","organization":"San Francisco, USA","month":"August","date-modified":"2020-01-04 16:35:44 +0000","date-added":"2016-09-11 09:17:41 +0000","booktitle":"Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)"}}
{"bib_id":"Sturm_ieeetmm_2014","title":"A Simple Method to Determine if a Music Information Retrieval System is a ``Horse''","author":"Bob L. Sturm","meta_info":{"year":"2014","volume":"16","pages":"1636-1644","number":"6","journal":"IEEE Transactions on Multimedia","date-modified":"2020-01-04 17:09:50 +0000","date-added":"2016-09-11 09:17:41 +0000"}}
