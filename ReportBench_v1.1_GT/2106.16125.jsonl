{"bib_id":"schuller2010mister","title":"‘Mister DJ, Cheer Me Up!’: Musical and textual features for automatic mood classification","author":"Schuller, Björn and Hage, Clemens and Schuller, Dagmar and Rigoll, Gerhard","meta_info":{"year":"2010","pages":"13--34","number":"1","volume":"39","journal":"JNMR"}}
{"bib_id":"gunes201716","title":"16 Automatic Analysis of Social Emotions","author":"Gunes, Hatice and Schüller, Björn","meta_info":{"year":"2017","pages":"213","journal":"SSP"}}
{"bib_id":"gunes2013categorical","title":"Categorical and dimensional affect analysis in continuous input: Current trends and future directions","author":"Gunes, Hatice and Schuller, Björn","meta_info":{"year":"2013","pages":"120--136","number":"2","volume":"31","journal":"IVC"}}
{"bib_id":"pantic2006dynamics","title":"Dynamics of facial expression: recognition of facial actions and their temporal segments from face profile image sequences","author":"Pantic, Maja and Patras, Ioannis","meta_info":{"year":"2006","pages":"433--449","number":"2","volume":"36","journal":"IEEE TCYB"}}
{"bib_id":"keren2017end","title":"End-to-end learning for dimensional emotion recognition from physiological signals","author":"Keren, Gil and Kirschstein, Tobias and Marchi, Erik and Ringeval, Fabien and Schuller, Björn","meta_info":{"year":"2017","pages":"985--990","booktitle":"ICME"}}
{"bib_id":"schuller2002multimodal","title":"Multimodal emotion recognition in audiovisual communication","author":"Schuller, Björn and Lang, Manfred and Rigoll, Gerhard","meta_info":{"year":"2002","pages":"745--748","volume":"1","booktitle":"ICME"}}
{"bib_id":"schuller2018speech","title":"Speech emotion recognition: two decades in a nutshell, benchmarks, and ongoing trends","author":"Schuller, Björn W","meta_info":{"year":"2018","pages":"90--99","number":"5","volume":"61","journal":"CACM"}}
{"bib_id":"metze2010emotion","title":"Emotion recognition using imperfect speech recognition","author":"Metze, Florian and Batliner, Anton and Eyben, Florian and Polzehl, Tim and Schuller, Björn and Steidl, Stefan","meta_info":{"year":"2010","pages":"478--481","booktitle":"INTERSPEECH"}}
{"bib_id":"schuller2012automatic","title":"Automatic recognition of emotion evoked by general sound events","author":"Schuller, Björn and Hantke, Simone and Weninger, Felix and Han, Wenjing and Zhang, Zixing and Narayanan, Shrikanth","meta_info":{"year":"2012","pages":"341--344","booktitle":"ICASSP"}}
{"bib_id":"williamson1979speech","title":"Speech analyzer for analyzing frequency perturbations in a speech pattern to determine the emotional state of a person","author":"Williamson, John D","meta_info":{"note":"US Patent 4,142,067","publisher":"Google Patents","month":"February~27","year":"1979"}}
{"bib_id":"cahn1990generation","title":"The generation of affect in synthesized speech","author":"Cahn, Janet E","meta_info":{"year":"1990","pages":"1--1","number":"1","volume":"8","journal":"Journal of the American Voice I\/O Society"}}
{"bib_id":"kobayashi1992recognition","title":"Recognition of six basic facial expression and their strength by neural network","author":"Kobayashi, Hiroshi and Hara, Fumio","meta_info":{"year":"1992","pages":"381--386","booktitle":"ROMAN"}}
{"bib_id":"schlosberg1954three","title":"Three dimensions of emotion","author":"Schlosberg, Harold","meta_info":{"year":"1954","pages":"81","number":"2","volume":"61","journal":"Psychological Review"}}
{"bib_id":"plutchik1980emotion","title":"Emotion: A psychoevolutionary synthesis","author":"Plutchik, Robert","meta_info":{"publisher":"Harpercollins College Division","year":"1980"}}
{"bib_id":"warriner2013norms","title":"Norms of valence, arousal, and dominance for 13,915 English lemmas","author":"Warriner, Amy Beth and Kuperman, Victor and Brysbaert, Marc","meta_info":{"year":"2013","pages":"1191--1207","number":"4","volume":"45","journal":"BRM"}}
{"bib_id":"soleymani2017survey","title":"A survey of multimodal sentiment analysis","author":"Soleymani, Mohammad and Garcia, David and Jou, Brendan and Schuller, Björn and Chang, Shih-Fu and Pantic, Maja","meta_info":{"year":"2017","pages":"3--14","volume":"65","journal":"IVC"}}
{"bib_id":"zhao2019affective","title":"Affective Computing for Large-scale Heterogeneous Multimedia Data: A Survey","author":"Zhao, Sicheng and Wang, Shangfei and Soleymani, Mohammad and Joshi, Dhiraj and Ji, Qiang","meta_info":{"year":"2019","pages":"93","number":"3s","volume":"15","journal":"ACM TOMM"}}
{"bib_id":"sariyanidi2014automatic","title":"Automatic analysis of facial affect: A survey of registration, representation, and recognition","author":"Sariyanidi, Evangelos and Gunes, Hatice and Cavallaro, Andrea","meta_info":{"year":"2014","pages":"1113--1133","number":"6","volume":"37","journal":"IEEE TPAMI"}}
{"bib_id":"li2018deep","title":"Deep facial expression recognition: A survey","author":"Li, Shan and Deng, Weihong","meta_info":{"year":"2018","journal":"arXiv:1804.08348"}}
{"bib_id":"poria2017review","title":"A review of affective computing: From unimodal analysis to multimodal fusion","author":"Poria, Soujanya and Cambria, Erik and Bajpai, Rajiv and Hussain, Amir","meta_info":{"year":"2017","pages":"98--125","volume":"37","journal":"INF"}}
{"bib_id":"zhao2018affective","title":"Affective Image Content Analysis: A Comprehensive Survey.","author":"Zhao, Sicheng and Ding, Guiguang and Huang, Qingming and Chua, Tat-Seng and Schuller, Björn W and Keutzer, Kurt","meta_info":{"year":"2018","pages":"5534--5541","booktitle":"IJCAI"}}
{"bib_id":"wang2015video","title":"Video affective content analysis: a survey of state-of-the-art methods","author":"Wang, Shangfei and Ji, Qiang","meta_info":{"year":"2015","pages":"410--430","number":"4","volume":"6","journal":"IEEE TAFFC"}}
{"bib_id":"zhao2019personalized","title":"Personalized emotion recognition by personality-aware high-order learning of physiological signals","author":"Zhao, Sicheng and Gholaminejad, Amir and Ding, Guiguang and Gao, Yue and Han, Jungong and Keutzer, Kurt","meta_info":{"year":"2019","pages":"14","number":"1s","volume":"15","journal":"ACM TOMM"}}
{"bib_id":"sun2009improved","title":"An improved valence-arousal emotion space for video affective content representation and recognition","author":"Sun, Kai and Yu, Junqing and Huang, Yue and Hu, Xiaoqiang","meta_info":{"year":"2009","pages":"566--569","booktitle":"ICME"}}
{"bib_id":"el2011survey","title":"Survey on speech emotion recognition: Features, classification schemes, and databases","author":"El Ayadi, Moataz and Kamel, Mohamed S and Karray, Fakhri","meta_info":{"year":"2011","pages":"572--587","number":"3","volume":"44","journal":"PR"}}
{"bib_id":"yang2012machine","title":"Machine recognition of music emotion: A review","author":"Yang, Yi-Hsuan and Chen, Homer H","meta_info":{"year":"2012","pages":"40","number":"3","volume":"3","journal":"ACM TIST"}}
{"bib_id":"alarcao2017emotions","title":"Emotions recognition using EEG signals: A survey","author":"Alarcao, Soraia M and Fonseca, Manuel J","meta_info":{"year":"2017","journal":"IEEE TAFFC"}}
{"bib_id":"ekman1992argument","title":"An argument for basic emotions","author":"Ekman, Paul","meta_info":{"year":"1992","pages":"169--200","number":"3-4","volume":"6","journal":"Cognition & Emotion"}}
{"bib_id":"hanjalic2006extracting","title":"Extracting moods from pictures and sounds: Towards truly personalized TV","author":"Hanjalic, Alan","meta_info":{"year":"2006","pages":"90--100","number":"2","volume":"23","journal":"IEEE SPM"}}
{"bib_id":"lang1997international","title":"International affective picture system (IAPS): Technical manual and affective ratings","author":"Lang, Peter J and Bradley, Margaret M and Cuthbert, Bruce N","meta_info":{"year":"1997","pages":"39--58","journal":"NIMH Center for the Study of Emotion and Attention"}}
{"bib_id":"mikels2005emotional","title":"Emotional category data on images from the International Affective Picture System","author":"Mikels, Joseph A and Fredrickson, Barbara L and Larkin, Gregory R and Lindberg, Casey M and Maglio, Sam J and Reuter-Lorenz, Patricia A","meta_info":{"year":"2005","pages":"626--630","number":"4","volume":"37","journal":"BRM"}}
{"bib_id":"machajdik2010affective","title":"Affective image classification using features inspired by psychology and art theory","author":"Machajdik, Jana and Hanbury, Allan","meta_info":{"year":"2010","pages":"83--92","booktitle":"ACM MM"}}
{"bib_id":"dan2011geneva","title":"The Geneva affective picture database (GAPED): a new 730-picture database focusing on valence and normative significance","author":"Dan-Glauser, Elise S and Scherer, Klaus R","meta_info":{"year":"2011","pages":"468--477","number":"2","volume":"43","journal":"BRM"}}
{"bib_id":"alameda2016recognizing","title":"Recognizing emotions from abstract paintings using non-linear matrix completion","author":"Alameda-Pineda, Xavier and Ricci, Elisa and Yan, Yan and Sebe, Nicu","meta_info":{"year":"2016","pages":"5240--5248","booktitle":"CVPR"}}
{"bib_id":"sartori2015s","title":"Who's afraid of itten: Using the art theory of color combination to analyze emotions in abstract paintings","author":"Sartori, Andreza and Culibrk, Dubravko and Yan, Yan and Sebe, Nicu","meta_info":{"year":"2015","pages":"311--320","booktitle":"ACM MM"}}
{"bib_id":"borth2013large","title":"Large-scale visual sentiment ontology and detectors using adjective noun pairs","author":"Borth, Damian and Ji, Rongrong and Chen, Tao and Breuel, Thomas and Chang, Shih-Fu","meta_info":{"year":"2013","pages":"223--232","booktitle":"ACM MM"}}
{"bib_id":"yang2014your","title":"How Do Your Friends on Social Media Disclose Your Emotions?","author":"Yang, Yang and Jia, Jia and Zhang, Shumei and Wu, Boya and Chen, Qicong and Li, Juanzi and Xing, Chunxiao and Tang, Jie","meta_info":{"year":"2014","pages":"306--312","booktitle":"AAAI"}}
{"bib_id":"lin2020multi","title":"Multi-source Domain Adaptation for Visual Sentiment Classification","author":"Lin, Chuang and Zhao, Sicheng and Meng, Lei and Chua, Tat-Seng","meta_info":{"year":"2020","booktitle":"AAAI"}}
{"bib_id":"you2016building","title":"Building a large scale dataset for image emotion recognition: The fine print and the benchmark","author":"You, Quanzeng and Luo, Jiebo and Jin, Hailin and Yang, Jianchao","meta_info":{"year":"2016","pages":"308--314","booktitle":"AAAI"}}
{"bib_id":"zhao2016predicting","title":"Predicting personalized emotion perceptions of social images","author":"Zhao, Sicheng and Yao, Hongxun and Gao, Yue and Ji, Rongrong and Xie, Wenlong and Jiang, Xiaolei and Chua, Tat-Seng","meta_info":{"year":"2016","pages":"1385--1394","booktitle":"ACM MM"}}
{"bib_id":"peng2015mixed","title":"A Mixed Bag of Emotions: Model, Predict, and Transfer Emotion Distributions","author":"Peng, Kuan-Chuan and Sadovnik, Amir and Gallagher, Andrew and Chen, Tsuhan","meta_info":{"year":"2015","pages":"860--868","booktitle":"CVPR"}}
{"bib_id":"yang2013user","title":"User interest and social influence based emotion prediction for individuals","author":"Yang, Yun and Cui, Peng and Zhu, Wenwu and Yang, Shiqiang","meta_info":{"year":"2013","pages":"785--788","booktitle":"ACM MM"}}
{"bib_id":"rui2017joint","title":"Joint user-interest and social-influence emotion prediction for individuals","author":"Rui, Ting and Cui, Peng and Zhu, Wenwu","meta_info":{"year":"2017","pages":"66--76","volume":"230","journal":"Neurocomputing"}}
{"bib_id":"parrott2001emotions","title":"Emotions in social psychology: Essential readings","author":"Parrott, W Gerrod","meta_info":{"publisher":"Psychology Press","year":"2001"}}
{"bib_id":"ortony1988cognitive","title":"The cognitive structure of emotions","author":"Ortony, Andrew and Clore, Gerald L and Collins, Allan","meta_info":{"publisher":"Cambridge university press","year":"1988"}}
{"bib_id":"scherer2001appraisal","title":"Appraisal processes in emotion: Theory, methods, research","author":"Scherer, Klaus R and Schorr, Angela and Johnstone, Tom","meta_info":{"publisher":"Oxford University Press","year":"2001"}}
{"bib_id":"munezero2014they","title":"Are they different? Affect, feeling, emotion, sentiment, and opinion detection in text","author":"Munezero, Myriam D and Montero, Calkin Suero and Sutinen, Erkki and Pajunen, John","meta_info":{"year":"2014","pages":"101--111","number":"2","volume":"5","journal":"IEEE TAFFC"}}
{"bib_id":"zhao2018emotiongan","title":"EmotionGAN: unsupervised domain adaptation for learning discrete probability distributions of image emotions","author":"Zhao, Sicheng and Zhao, Xin and Ding, Guiguang and Keutzer, Kurt","meta_info":{"year":"2018","pages":"1319--1327","booktitle":"ACM MM"}}
{"bib_id":"zhan2019zero","title":"Zero-shot emotion recognition via affective structural embedding","author":"Zhan, Chi and She, Dongyu and Zhao, Sicheng and Cheng, Ming-Ming and Yang, Jufeng","meta_info":{"year":"2019","pages":"1151--1160","booktitle":"ICCV"}}
{"bib_id":"yang2017learning","title":"Learning Visual Sentiment Distributions via Augmented Conditional Probability Neural Network","author":"Yang, Jufeng and Sun, Ming and Sun, Xiaoxiao","meta_info":{"year":"2017","pages":"224--230","booktitle":"AAAI"}}
{"bib_id":"zhao2014affective","title":"Affective image retrieval via multi-graph learning","author":"Zhao, Sicheng and Yao, Hongxun and Yang, You and Zhang, Yanhao","meta_info":{"year":"2014","pages":"1025--1028","booktitle":"ACM MM"}}
{"bib_id":"lee2011fuzzy","title":"Fuzzy similarity-based emotional classification of color images","author":"Lee, Joonwhoan and Park, EunJong","meta_info":{"year":"2011","pages":"1031--1039","number":"5","volume":"13","journal":"IEEE TMM"}}
{"bib_id":"giachanou2016like","title":"Like it or not: A survey of twitter sentiment analysis methods","author":"Giachanou, Anastasia and Crestani, Fabio","meta_info":{"year":"2016","pages":"28","number":"2","volume":"49","journal":"CSUR"}}
{"bib_id":"zhang2018deep","title":"Deep learning for sentiment analysis: A survey","author":"Zhang, Lei and Wang, Shuai and Liu, Bing","meta_info":{"year":"2018","pages":"e1253","number":"4","volume":"8","journal":"Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery"}}
{"bib_id":"lu2012shape","title":"On shape and the computability of emotions","author":"Lu, Xin and Suryanarayan, Poonam and Adams Jr, Reginald B and Li, Jia and Newman, Michelle G and Wang, James Z","meta_info":{"year":"2012","pages":"229--238","booktitle":"ACM MM"}}
{"bib_id":"yuan2013sentribute","title":"Sentribute: image sentiment analysis from a mid-level perspective","author":"Yuan, Jianbo and Mcdonough, Sean and You, Quanzeng and Luo, Jiebo","meta_info":{"year":"2013","pages":"10","booktitle":"WISDOM"}}
{"bib_id":"yang2010exploring","title":"Exploring facial expressions with compositional features","author":"Yang, Peng and Liu, Qingshan and Metaxas, Dimitris N","meta_info":{"year":"2010","pages":"2638--2644","booktitle":"CVPR"}}
{"bib_id":"patterson2012sun","title":"Sun attribute database: Discovering, annotating, and recognizing scene attributes","author":"Patterson, Genevieve and Hays, James","meta_info":{"year":"2012","pages":"2751--2758","booktitle":"CVPR"}}
{"bib_id":"zhao2014exploring","title":"Exploring principles-of-art features for image emotion recognition","author":"Zhao, Sicheng and Gao, Yue and Jiang, Xiaolei and Yao, Hongxun and Chua, Tat-Seng and Sun, Xiaoshuai","meta_info":{"year":"2014","pages":"47--56","booktitle":"ACM MM"}}
{"bib_id":"li2012context","title":"Context-aware affective images classification based on bilayer sparse representation","author":"Li, Bing and Xiong, Weihua and Hu, Weiming and Ding, Xinmiao","meta_info":{"year":"2012","pages":"721--724","booktitle":"ACM MM"}}
{"bib_id":"rao2016multi","title":"Multi-scale blocks based image emotion classification using multiple instance learning","author":"Rao, Tianrong and Xu, Min and Liu, Huiying and Wang, Jinqiao and Burnett, Ian","meta_info":{"year":"2016","pages":"634--638","booktitle":"ICIP"}}
{"bib_id":"wang2013interpretable","title":"Interpretable aesthetic features for affective image classification","author":"Wang, Xiaohui and Jia, Jia and Yin, Jiaming and Cai, Lianhong","meta_info":{"year":"2013","pages":"3230--3234","booktitle":"ICIP"}}
{"bib_id":"kipf2017semi","title":"Semi-supervised classification with graph convolutional networks","author":"Kipf, Thomas N and Welling, Max","meta_info":{"year":"2017","booktitle":"ICLR"}}
{"bib_id":"feng2019hypergraph","title":"Hypergraph neural networks","author":"Feng, Yifan and You, Haoxuan and Zhang, Zizhao and Ji, Rongrong and Gao, Yue","meta_info":{"year":"2019","pages":"3558--3565","booktitle":"AAAI"}}
{"bib_id":"wang2015modeling","title":"Modeling emotion influence in image social networks","author":"Wang, Xiaohui and Jia, Jia and Tang, Jie and Wu, Boya and Cai, Lianhong and Xie, Lexing","meta_info":{"year":"2015","pages":"286--297","number":"3","volume":"6","journal":"IEEE TAFFC"}}
{"bib_id":"you2015robust","title":"Robust Image Sentiment Analysis Using Progressively Trained and Domain Transferred Deep Networks.","author":"You, Quanzeng and Luo, Jiebo and Jin, Hailin and Yang, Jianchao","meta_info":{"year":"2015","pages":"381--388","booktitle":"AAAI"}}
{"bib_id":"rao2016learning","title":"Learning multi-level deep representations for image emotion classification","author":"Rao, Tianrong and Xu, Min and Xu, Dong","meta_info":{"year":"2020","pages":"2043--2061","number":"3","volume":"51","journal":"NPL"}}
{"bib_id":"zhu2017dependency","title":"Dependency exploitation: a unified CNN-RNN approach for visual emotion recognition","author":"Zhu, Xinge and Li, Liang and Zhang, Weigang and Rao, Tianrong and Xu, Min and Huang, Qingming and Xu, Dong","meta_info":{"year":"2017","pages":"3595--3601","booktitle":"IJCAI"}}
{"bib_id":"zhao2015continuous","title":"Predicting continuous probability distribution of image emotions in valence-arousal space","author":"Zhao, Sicheng and Yao, Hongxun and Jiang, Xiaolei","meta_info":{"year":"2015","pages":"879--882","booktitle":"ACM MM"}}
{"bib_id":"yang2018retrieving","title":"Retrieving and classifying affective Images via deep metric learning","author":"Yang, Jufeng and She, Dongyu and Lai, Yukun and Yang, Ming-Hsuan","meta_info":{"year":"2018","pages":"491--498","booktitle":"AAAI"}}
{"bib_id":"zhao2017continuous","title":"Continuous Probability Distribution Prediction of Image Emotions via Multi-Task Shared Sparse Regression","author":"Zhao, Sicheng and Yao, Hongxun and Gao, Yue and Ji, Rongrong and Ding, Guiguang","meta_info":{"year":"2017","pages":"632--645","number":"3","volume":"19","journal":"IEEE TMM"}}
{"bib_id":"zhao2015predicting","title":"Predicting discrete probability distribution of image emotions","author":"Zhao, Sicheng and Yao, Hongxun and Jiang, Xiaolei and Sun, Xiaoshuai","meta_info":{"year":"2015","pages":"2459--2463","booktitle":"ICIP"}}
{"bib_id":"zhao2017approximating","title":"Approximating Discrete Probability Distribution of Image Emotions by Multi-Modal Features Fusion","author":"Zhao, Sicheng and Ding, Guiguang and Gao, Yue and Han, Jungong","meta_info":{"year":"2017","pages":"4669--4675","booktitle":"IJCAI"}}
{"bib_id":"zhao2018personality","title":"Personality-Aware Personalized Emotion Recognition from Physiological Signals","author":"Zhao, Sicheng and Ding, Guiguang and Han, Jungong and Gao, Yue","meta_info":{"year":"2018","pages":"1660--1667","booktitle":"IJCAI"}}
{"bib_id":"geng2013facial","title":"Facial age estimation by learning from label distributions","author":"Geng, Xin and Yin, Chao and Zhou, Zhi-Hua","meta_info":{"year":"2013","pages":"2401--2412","number":"10","volume":"35","journal":"IEEE TPAMI"}}
{"bib_id":"zhao2017learning","title":"Learning Visual Emotion Distributions via Multi-Modal Features Fusion","author":"Zhao, Sicheng and Ding, Guiguang and Gao, Yue and Han, Jungong","meta_info":{"year":"2017","pages":"369--377","booktitle":"ACM MM"}}
{"bib_id":"yang2017joint","title":"Joint image emotion classification and distribution learning via deep convolutional neural network","author":"Yang, Jufeng and She, Dongyu and Sun, Ming","meta_info":{"year":"2017","pages":"3266--3272","booktitle":"IJCAI"}}
{"bib_id":"zhao2018predicting","title":"Predicting personalized image emotion perceptions in social networks","author":"Zhao, Sicheng and Yao, Hongxun and Gao, Yue and Ding, Guiguang and Chua, Tat-Seng","meta_info":{"year":"2018","pages":"526--540","number":"4","volume":"9","journal":"IEEE TAFFC"}}
{"bib_id":"chen2014object","title":"Object-based visual sentiment concept analysis and application","author":"Chen, Tao and Yu, Felix X and Chen, Jiawei and Cui, Yin and Chen, Yan-Ying and Chang, Shih-Fu","meta_info":{"year":"2014","pages":"367--376","booktitle":"ACM MM"}}
{"bib_id":"zhao2018discrete","title":"Discrete Probability Distribution Prediction of Image Emotions With Shared Sparse Learning","author":"Zhao, Sicheng and Ding, Guiguang and Gao, Yue and Zhao, Xin and Tang, Youbao and Han, Jungong and Yao, Hongxun and Huang, Qingming","meta_info":{"year":"2018","journal":"IEEE TAFFC"}}
{"bib_id":"you2016robust","title":"Robust visual-textual sentiment analysis: When attention meets tree-structured recursive neural networks","author":"You, Quanzeng and Cao, Liangliang and Jin, Hailin and Luo, Jiebo","meta_info":{"year":"2016","pages":"1008--1017","booktitle":"ACM MM"}}
{"bib_id":"chen2018predicting","title":"Predicting Microblog Sentiments via Weakly Supervised Multimodal Deep Learning","author":"Chen, Fuhai and Ji, Rongrong and Su, Jinsong and Cao, Donglin and Gao, Yue","meta_info":{"year":"2018","pages":"997--1007","number":"4","volume":"20","journal":"IEEE TMM"}}
{"bib_id":"katsurai2016image","title":"Image sentiment analysis using latent correlations among visual, textual, and sentiment views","author":"Katsurai, Marie and Satoh, Shin'ichi","meta_info":{"year":"2016","pages":"2837--2841","booktitle":"ICASSP"}}
{"bib_id":"panda2018contemplating","title":"Contemplating Visual Emotions: Understanding and Overcoming Dataset Bias","author":"Panda, Rameswar and Zhang, Jianming and Li, Haoxiang and Lee, Joon-Young and Lu, Xin and Roy-Chowdhury, Amit K","meta_info":{"year":"2018","pages":"579--595","booktitle":"ECCV"}}
{"bib_id":"balouchian2019lucfer","title":"LUCFER: A Large-Scale Context-Sensitive Image Dataset for Deep Learning of Visual Emotions","author":"Balouchian, Pooyan and Safaei, Marjaneh and Foroosh, Hassan","meta_info":{"year":"2019","pages":"1645--1654","booktitle":"WACV"}}
{"bib_id":"kosti2017emotion","title":"Emotion recognition in context","author":"Kosti, Ronak and Alvarez, Jose M and Recasens, Adria and Lapedriza, Agata","meta_info":{"year":"2017","pages":"1667--1675","booktitle":"CVPR"}}
{"bib_id":"Vadicamo_2017_ICCVW","title":"Cross-Media Learning for Image Sentiment Analysis in the Wild","author":"Vadicamo, Lucia and Carrara, Fabio and Cimino, Andrea and Cresci, Stefano and Dell'Orletta, Felice and Falchi, Fabrizio and Tesconi, Maurizio","meta_info":{"year":"2017","pages":"308--317","booktitle":"ICCVW"}}
{"bib_id":"jou2015visual","title":"Visual affect around the world: A large-scale multilingual visual sentiment ontology","author":"Jou, Brendan and Chen, Tao and Pappas, Nikolaos and Redi, Miriam and Topkara, Mercan and Chang, Shih-Fu","meta_info":{"year":"2015","pages":"159--168","booktitle":"ACM MM"}}
{"bib_id":"fan2018emotional","title":"Emotional attention: A study of image sentiment and visual attention","author":"Fan, Shaojing and Shen, Zhiqi and Jiang, Ming and Koenig, Bryan L and Xu, Juan and Kankanhalli, Mohan S and Zhao, Qi","meta_info":{"year":"2018","pages":"7521--7531","booktitle":"CVPR"}}
{"bib_id":"lin2014microsoft","title":"Microsoft coco: Common objects in context","author":"Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Dollár, Piotr and Zitnick, C Lawrence","meta_info":{"year":"2014","pages":"740--755","booktitle":"ECCV"}}
{"bib_id":"zhou2019semantic","title":"Semantic understanding of scenes through the ade20k dataset","author":"Zhou, Bolei and Zhao, Hang and Puig, Xavier and Xiao, Tete and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio","meta_info":{"year":"2019","pages":"302--321","number":"3","volume":"127","journal":"IJCV"}}
{"bib_id":"wei2006image","title":"Image retrieval by emotional semantics: A study of emotional space and feature extraction","author":"Wang, Wei-ning and Yu, Ying-lin and Jiang, Sheng-ming","meta_info":{"year":"2006","pages":"3534--3539","volume":"4","booktitle":"SMC"}}
{"bib_id":"wei2004image","title":"Image emotional classification: static vs. dynamic","author":"Wang, Wei-ning and Yu, Ying-lin and Zhang, Jian-chao","meta_info":{"year":"2004","pages":"6407--6411","volume":"7","booktitle":"SMC"}}
{"bib_id":"yanulevskaya2008emotional","title":"Emotional valence categorization using holistic image features","author":"Yanulevskaya, Victoria and van Gemert, Jan C and Roth, Katharina and Herbold, Ann-KatYanulevskayarin and Sebe, Nicu and Geusebroek, Jan-Mark","meta_info":{"year":"2008","pages":"101--104","booktitle":"ICIP"}}
{"bib_id":"salovey1990emotional","title":"Emotional intelligence","author":"Salovey, Peter and Mayer, John D","meta_info":{"year":"1990","pages":"185--211","number":"3","volume":"9","journal":"Imagination, Cognition and Personality"}}
{"bib_id":"zhang2011analyzing","title":"Analyzing emotional semantics of abstract art using low-level image features","author":"Zhang, He and Augilius, Eimontas and Honkela, Timo and Laaksonen, Jorma and Gamper, Hannes and Alene, Henok","meta_info":{"year":"2011","pages":"413--423","booktitle":"IDA"}}
{"bib_id":"lu2017investigation","title":"An investigation into three visual characteristics of complex scenes that evoke human emotion","author":"Lu, Xin and Adams, Reginald B and Li, Jia and Newman, Michelle G and Wang, James Z","meta_info":{"year":"2017","pages":"440--447","booktitle":"ACII"}}
{"bib_id":"xu5731visual","title":"Visual Sentiment Prediction with Deep Convolutional Neural Networks","author":"Xu, Can and Cetintas, Suleyman and Lee, Kuang-Chih and Li, Li-Jia","meta_info":{"year":"2014","journal":"arXiv:1411.5731"}}
{"bib_id":"chen2014deepsentibank","title":"Deepsentibank: Visual sentiment concept classification with deep convolutional neural networks","author":"Chen, Tao and Borth, Damian and Darrell, Trevor and Chang, Shih-Fu","meta_info":{"year":"2014","journal":"arXiv:1410.8586"}}
{"bib_id":"chen2015learning","title":"Learning deep features for image emotion classification","author":"Chen, Ming and Zhang, Lu and Allebach, Jan P","meta_info":{"year":"2015","pages":"4491--4495","booktitle":"ICIP"}}
{"bib_id":"ali2017high","title":"High-level concepts for affective understanding of images","author":"Ali, Afsheen Rafaqat and Shahid, Usman and Ali, Mohsen and Ho, Jeffrey","meta_info":{"year":"2017","pages":"679--687","booktitle":"WACV"}}
{"bib_id":"lu2016identifying","title":"Identifying Emotions Aroused from Paintings","author":"Lu, Xin and Sawant, Neela and Newman, Michelle G and Adams, Reginald B and Wang, James Z and Li, Jia","meta_info":{"year":"2016","pages":"48--63","booktitle":"ECCV"}}
{"bib_id":"gatys2015texture","title":"Texture synthesis using convolutional neural networks","author":"Gatys, Leon and Ecker, Alexander S and Bethge, Matthias","meta_info":{"year":"2015","pages":"262--270","booktitle":"NeurIPS"}}
{"bib_id":"liu2016improving","title":"Improving visual saliency computing with emotion intensity","author":"Liu, Huiying and Xu, Min and Wang, Jinqiao and Rao, Tianrong and Burnett, Ian","meta_info":{"year":"2016","pages":"1201--1213","number":"6","volume":"27","journal":"IEEE TNNLS"}}
{"bib_id":"you2017visual","title":"Visual sentiment analysis by attending on local image regions","author":"You, Quanzeng and Jin, Hailin and Luo, Jiebo","meta_info":{"year":"2017","pages":"231--237","booktitle":"AAAI"}}
{"bib_id":"yang2018visual","title":"Visual sentiment prediction based on automatic discovery of affective regions","author":"Yang, Jufeng and She, Dongyu and Sun, Ming and Cheng, Ming-Ming and Rosin, Paul L and Wang, Liang","meta_info":{"year":"2018","pages":"2513--2525","number":"9","volume":"20","journal":"IEEE TMM"}}
{"bib_id":"yang2018weakly","title":"Weakly supervised coupled networks for visual sentiment analysis","author":"Yang, Jufeng and She, Dongyu and Lai, Yu-Kun and Rosin, Paul L and Yang, Ming-Hsuan","meta_info":{"year":"2018","pages":"7584--7592","booktitle":"CVPR"}}
{"bib_id":"zhao2019pdanet","title":"PDANet: Polarity-consistent Deep Attention Network for Fine-grained Visual Emotion Regression","author":"Zhao, Sicheng and Jia, Zizhou and Chen, Hui and Li, Leida and Ding, Guiguang and Keutzer, Kurt","meta_info":{"year":"2019","pages":"192--201","booktitle":"ACM MM"}}
{"bib_id":"rao2019multi","title":"Multi-level region-based Convolutional Neural Network for image emotion classification","author":"Rao, Tianrong and Li, Xiaoxu and Zhang, Haimin and Xu, Min","meta_info":{"year":"2019","pages":"429--439","volume":"333","journal":"Neurocomputing"}}
{"bib_id":"wu2019visual","title":"Visual Sentiment Analysis by Combining Global and Local Information","author":"Wu, Lifang and Qi, Mingchao and Jian, Meng and Zhang, Heng","meta_info":{"year":"2019","pages":"1--13","journal":"NPL"}}
{"bib_id":"yao2019attention","title":"Attention-aware Polarity Sensitive Embedding for Affective Image Retrieval","author":"Yao, Xingxu and She, Dongyu and Zhao, Sicheng and Liang, Jie and Lai, Yu-Kun and Yang, Jufeng","meta_info":{"year":"2019","pages":"1140--1150","booktitle":"ICCV"}}
{"bib_id":"geusebroek2006compact","title":"Compact Object Descriptors from Local Colour Invariant Histograms","author":"Geusebroek, Jan-Mark","meta_info":{"year":"2006","pages":"1029--1038","booktitle":"BMVC"}}
{"bib_id":"dellandrea2010classification","title":"Classification of affective semantics in images based on discrete and dimensional models of emotions","author":"Dellandrea, Emmanuel and Liu, Ningning and Chen, Liming","meta_info":{"year":"2010","pages":"1--6","booktitle":"CBMI"}}
{"bib_id":"zhang2013affective","title":"Affective abstract image classification and retrieval using multiple kernel learning","author":"Zhang, He and Yang, Zhirong and Gönen, Mehmet and Koskela, Markus and Laaksonen, Jorma and Honkela, Timo and Oja, Erkki","meta_info":{"year":"2013","pages":"166--175","booktitle":"ICONIP"}}
{"bib_id":"campos2015diving","title":"Diving deep into sentiment: Understanding fine-tuned CNNs for visual sentiment prediction","author":"Campos, Victor and Salvador, Amaia and Giro-i-Nieto, Xavier and Jou, Brendan","meta_info":{"year":"2015","pages":"57--62","booktitle":"ASM"}}
{"bib_id":"wang2016beyond","title":"Beyond Object Recognition: Visual Sentiment Analysis with Deep Coupled Adjective and Noun Neural Networks","author":"Wang, Jingwen and Fu, Jianlong and Xu, Yong and Mei, Tao","meta_info":{"year":"2016","pages":"3484--3490","booktitle":"IJCAI"}}
{"bib_id":"ahsan2017towards","title":"Towards using visual attributes to infer image sentiment of social events","author":"Ahsan, Unaiza and De Choudhury, Munmun and Essa, Irfan","meta_info":{"year":"2017","pages":"1372--1379","booktitle":"IJCNN"}}
{"bib_id":"schroff2015facenet","title":"Facenet: A unified embedding for face recognition and clustering","author":"Schroff, Florian and Kalenichenko, Dmitry and Philbin, James","meta_info":{"year":"2015","pages":"815--823","booktitle":"CVPR"}}
{"bib_id":"he2018emotion","title":"Emotion recognition by assisted learning with convolutional neural networks","author":"He, Xuanyu and Zhang, Wei","meta_info":{"year":"2018","pages":"187--194","volume":"291","journal":"Neurocomputing"}}
{"bib_id":"liu2019affective","title":"Affective image classification by jointly using interpretable art features and semantic annotations","author":"Liu, Xuan and Li, Na and Xia, Yong","meta_info":{"year":"2019","pages":"576--588","volume":"58","journal":"JVCIR"}}
{"bib_id":"sun2016discovering","title":"Discovering affective regions in deep convolutional neural networks for visual sentiment prediction","author":"Sun, Ming and Yang, Jufeng and Wang, Kai and Shen, Hui","meta_info":{"year":"2016","pages":"1--6","booktitle":"ICME"}}
{"bib_id":"fan2017role","title":"The role of visual attention in sentiment prediction","author":"Fan, Shaojing and Jiang, Ming and Shen, Zhiqi and Koenig, Bryan L and Kankanhalli, Mohan S and Zhao, Qi","meta_info":{"year":"2017","pages":"217--225","booktitle":"ACM MM"}}
{"bib_id":"zhao2019cycleemotiongan","title":"Cycleemotiongan: Emotional semantic consistency preserved cyclegan for adapting image emotions","author":"Zhao, Sicheng and Lin, Chuang and Xu, Pengfei and Zhao, Sendong and Guo, Yuchen and Krishna, Ravi and Ding, Guiguang and Keutzer, Kurt","meta_info":{"year":"2019","pages":"2620--2627","booktitle":"AAAI"}}
{"bib_id":"wang2018visual","title":"Visual Sentiment Analysis with Noisy Labels by Reweighting Loss","author":"Wang, Lin and Xu, Xiangmin and Guo, Kailing and Cai, Bolun","meta_info":{"year":"2018","pages":"1873--1878","booktitle":"SMC"}}
{"bib_id":"song2018boosting","title":"Boosting image sentiment analysis with visual attention","author":"Song, Kaikai and Yao, Ting and Ling, Qiang and Mei, Tao","meta_info":{"year":"2018","pages":"218--228","volume":"312","journal":"Neurocomputing"}}
{"bib_id":"he2019image","title":"Image Emotion Distribution Learning with Graph Convolutional Networks","author":"He, Tao and Jin, Xiaoming","meta_info":{"year":"2019","pages":"382--390","booktitle":"ICMR"}}
{"bib_id":"liu2018structured","title":"Structured low-rank inverse-covariance estimation for visual sentiment distribution prediction","author":"Liu, Anan and Shi, Yingdi and Jing, Peiguang and Liu, Jing and Su, Yuting","meta_info":{"year":"2018","pages":"206--216","volume":"152","journal":"SP"}}
{"bib_id":"minsky1988society","title":"The Society of mind","author":"Minsky, Marvin","meta_info":{"publisher":"Simon and Schuster","year":"1986"}}
{"bib_id":"hossain2019emotion","title":"Emotion recognition using deep learning approach from audio--visual emotional big data","author":"Hossain, M Shamim and Muhammad, Ghulam","meta_info":{"year":"2019","pages":"69--78","volume":"49","journal":"INF"}}
{"bib_id":"szegedy2016rethinking","title":"Rethinking the inception architecture for computer vision","author":"Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew","meta_info":{"year":"2016","pages":"2818--2826","booktitle":"CVPR"}}
{"bib_id":"he2016deep","title":"Deep residual learning for image recognition","author":"He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian","meta_info":{"year":"2016","pages":"770--778","booktitle":"CVPR"}}
{"bib_id":"torralba2011unbiased","title":"Unbiased look at dataset bias","author":"Torralba, Antonio and Efros, Alexei A","meta_info":{"year":"2011","pages":"1521--1528","booktitle":"CVPR"}}
{"bib_id":"picard1997affective","title":"Affective computing","author":"Picard, Rosalind W","meta_info":{"publisher":"MIT press","year":"1997"}}
{"bib_id":"d2015review","title":"A review and meta-analysis of multimodal affect detection systems","author":"D'mello, Sidney K and Kory, Jacqueline","meta_info":{"year":"2015","pages":"43","number":"3","volume":"47","journal":"CSUR"}}
{"bib_id":"garg2007influence","title":"The influence of incidental affect on consumers’ food intake","author":"Garg, Nitika and Wansink, Brian and Inman, J Jeffrey","meta_info":{"year":"2007","pages":"194--206","number":"1","volume":"71","journal":"Journal of Marketing"}}
{"bib_id":"tan2008entertainment","title":"Entertainment is emotion: The functional architecture of the entertainment experience","author":"Tan, Eduard Sioe-Hao","meta_info":{"year":"2008","pages":"28--51","number":"1","volume":"11","journal":"Media Psychology"}}
{"bib_id":"xing2015emotion","title":"Emotion-driven Chinese folk music-image retrieval based on DE-SVM","author":"Xing, Baixi and Zhang, Kejun and Sun, Shouqian and Zhang, Lekai and Gao, Zenggui and Wang, Jiaxi and Chen, Shi","meta_info":{"year":"2015","pages":"619--627","volume":"148","journal":"Neurocomputing"}}
{"bib_id":"lin2014psychological","title":"Psychological stress detection from cross-media microblog data using deep sparse neural network","author":"Lin, Huijie and Jia, Jia and Guo, Quan and Xue, Yuanyuan and Huang, Jie and Cai, Lianhong and Feng, Ling","meta_info":{"year":"2014","pages":"1--6","booktitle":"ICME"}}
{"bib_id":"wu2015understanding","title":"Understanding the emotions behind social images: Inferring with user demographics","author":"Wu, Boya and Jia, Jia and Yang, Yang and Zhao, Peijun and Tang, Jie","meta_info":{"year":"2015","pages":"1--6","booktitle":"ICME"}}
{"bib_id":"wu2017inferring","title":"Inferring emotional tags from social images with user demographics","author":"Wu, Boya and Jia, Jia and Yang, Yang and Zhao, Peijun and Tang, Jie and Tian, Qi","meta_info":{"year":"2017","pages":"1670--1684","number":"7","volume":"19","journal":"IEEE TMM"}}
{"bib_id":"truong2017visual","title":"Visual sentiment analysis for review images with item-oriented and user-oriented CNN","author":"Truong, Quoc-Tuan and Lauw, Hady W","meta_info":{"year":"2017","pages":"1274--1282","booktitle":"ACM MM"}}
{"bib_id":"goodfellow2014generative","title":"Generative adversarial nets","author":"Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua","meta_info":{"year":"2014","pages":"2672--2680","booktitle":"NeurIPS"}}
{"bib_id":"zhu2017unpaired","title":"Unpaired image-to-image translation using cycle-consistent adversarial networks","author":"Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A","meta_info":{"year":"2017","pages":"2223--2232","booktitle":"ICCV"}}
{"bib_id":"wu2017reducing","title":"Reducing noisy labels in weakly labeled data for visual sentiment analysis","author":"Wu, Lifang and Liu, Shuang and Jian, Meng and Luo, Jiebo and Zhang, Xiuzhen and Qi, Mingchao","meta_info":{"year":"2017","pages":"1322--1326","booktitle":"ICIP"}}
{"bib_id":"wang2019robust","title":"Robust Emotion Navigation: Few-shot Visual Sentiment Analysis by Auxiliary Noisy Data","author":"Wang, Lin and Xu, Xiangmin and Liu, Fang and Xing, Xiaofen and Cai, Bolun and Lu, Weirui","meta_info":{"year":"2019","pages":"121--127","booktitle":"ACII Workshops and Demos"}}
{"bib_id":"wang2015unsupervised","title":"Unsupervised Sentiment Analysis for Social Media Images","author":"Wang, Yilin and Wang, Suhang and Tang, Jiliang and Liu, Huan and Li, Baoxin","meta_info":{"year":"2015","pages":"2378--2379","booktitle":"IJCAI"}}
{"bib_id":"muandet2013domain","title":"Domain generalization via invariant feature representation","author":"Muandet, Krikamol and Balduzzi, David and Schölkopf, Bernhard","meta_info":{"year":"2013","pages":"10--18","booktitle":"ICML"}}
{"bib_id":"tobin2017domain","title":"Domain randomization for transferring deep neural networks from simulation to the real world","author":"Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas and Zaremba, Wojciech and Abbeel, Pieter","meta_info":{"year":"2017","pages":"23--30","booktitle":"IROS"}}
{"bib_id":"he2019deep","title":"Deep Transfer Learning for Image Emotion Analysis: Reducing Marginal and Joint Distribution Discrepancies Together","author":"He, Yuwei and Ding, Guiguang","meta_info":{"year":"2019","pages":"1--10","journal":"NPL"}}
{"bib_id":"dhall2018emotiw","title":"Emotiw 2018: Audio-video, student engagement and group-level affect prediction","author":"Dhall, Abhinav and Kaur, Amanjot and Goecke, Roland and Gedeon, Tom","meta_info":{"year":"2018","pages":"653--656","booktitle":"ICMI"}}
{"bib_id":"guo2018group","title":"Group-Level Emotion Recognition using Hybrid Deep Models based on Faces, Scenes, Skeletons and Visual Attentions","author":"Guo, Xin and Zhu, Bin and Polanı́a, Luisa F and Boncelet, Charles and Barner, Kenneth E","meta_info":{"year":"2018","pages":"635--639","booktitle":"ICMI"}}
{"bib_id":"soleymani2011multimodal","title":"A multimodal database for affect recognition and implicit tagging","author":"Soleymani, Mohammad and Lichtenauer, Jeroen and Pun, Thierry and Pantic, Maja","meta_info":{"year":"2011","pages":"42--55","number":"1","volume":"3","journal":"IEEE TAFFC"}}
{"bib_id":"koelstra2013fusion","title":"Fusion of facial expressions and EEG for implicit affective tagging","author":"Koelstra, Sander and Patras, Ioannis","meta_info":{"year":"2013","pages":"164--174","number":"2","volume":"31","journal":"IVC"}}
{"bib_id":"wang2013affective","title":"Affective image adjustment with a single word","author":"Wang, Xiaohui and Jia, Jia and Cai, Lianhong","meta_info":{"year":"2013","pages":"1121--1133","number":"11","volume":"29","journal":"TVC"}}
{"bib_id":"ye2019visual","title":"Visual-Textual Sentiment Analysis in Product Reviews","author":"Ye, Jin and Peng, Xiaojiang and Qiao, Yu and Xing, Hao and Li, Junli and Ji, Rongrong","meta_info":{"year":"2019","pages":"869--873","booktitle":"ICIP"}}
{"bib_id":"bao2014thupis","title":"ThuPIS: A new affective image system for psychological analysis","author":"Bao, Shurui and Ma, Huimin and Li, Wenyu","meta_info":{"year":"2014","pages":"1--4","booktitle":"BIBM"}}
{"bib_id":"helmes1993perspective","title":"A perspective on developments in assessing psychopathology: a critical review of the MMPI and MMPI-2.","author":"Helmes, Edward and Reddon, John R","meta_info":{"year":"1993","pages":"453","number":"3","volume":"113","journal":"Psychological Bulletin"}}
{"bib_id":"holbrook1984role","title":"The role of emotion in advertising","author":"Holbrook, Morris B and O'Shaughnessy, John","meta_info":{"year":"1984","pages":"45--64","number":"2","volume":"1","journal":"Psychology & Marketing"}}
{"bib_id":"poels2006capture","title":"How to capture the heart? Reviewing 20 years of emotion measurement in advertising","author":"Poels, Karolien and Dewitte, Siegfried","meta_info":{"year":"2006","pages":"18--37","number":"1","volume":"46","journal":"JAR"}}
{"bib_id":"pan2014travel","title":"Travel photos: Motivations, image dimensions, and affective qualities of places","author":"Pan, Steve and Lee, Jinsoo and Tsai, Henry","meta_info":{"year":"2014","pages":"59--69","volume":"40","journal":"Tourism Management"}}
{"bib_id":"toyama2016categorization","title":"Categorization of Destinations Based on Tourists’ Emotional Responses","author":"Toyama, Masaki and Yamada, Yuichi","meta_info":{"year":"2013","booktitle":"TTRA International Conference"}}
{"bib_id":"hosany2013patterns","title":"Patterns of tourists' emotional responses, satisfaction, and intention to recommend","author":"Hosany, Sameer and Prayag, Girish","meta_info":{"year":"2013","pages":"730--737","number":"6","volume":"66","journal":"Journal of Business Research"}}
{"bib_id":"hosany2010measuring","title":"Measuring tourists’ emotional experiences toward hedonic holiday destinations","author":"Hosany, Sameer and Gilbert, David","meta_info":{"year":"2010","pages":"513--526","number":"4","volume":"49","journal":"Journal of Travel Research"}}
{"bib_id":"ahmad2012emotion","title":"Emotion as a Key Role in Successful Acceptance of Japanese Manga by Indonesian Readers","author":"Ahmad, Hafiz Aziz and Koyama, Shinichi and Hibino, Haruo","meta_info":{"year":"2012","booktitle":"KEER"}}
{"bib_id":"she2019learning","title":"Learning Discriminative Sentiment Representation from Strongly-and Weakly Supervised CNNs","author":"She, Dongyu and Sun, Ming and Yang, Jufeng","meta_info":{"year":"2019","pages":"1--19","number":"3s","volume":"15","journal":"ACM TOMM"}}
{"bib_id":"xiong2019structured","title":"Structured and Sparse Annotations for Image Emotion Distribution Learning","author":"Xiong, Haitao and Liu, Hongfu and Zhong, Bineng and Fu, Yun","meta_info":{"year":"2019","booktitle":"AAAI"}}
{"bib_id":"zhao2013video","title":"Video classification and recommendation based on affective analysis of viewers","author":"Zhao, Sicheng and Yao, Hongxun and Sun, Xiaoshuai","meta_info":{"year":"2013","pages":"101--110","volume":"119","journal":"Neurocomputing"}}
{"bib_id":"joho2011looking","title":"Looking at the viewer: analysing facial activity to detect personal highlights of multimedia contents","author":"Joho, Hideo and Staiano, Jacopo and Sebe, Nicu and Jose, Joemon M","meta_info":{"year":"2011","pages":"505--523","number":"2","volume":"51","journal":"MTA"}}
{"bib_id":"liu2018low","title":"Low-rank regularized multi-view inverse-covariance estimation for visual sentiment distribution prediction","author":"Liu, Anan and Shi, Yingdi and Jing, Peiguang and Liu, Jing and Su, Yuting","meta_info":{"year":"2018","pages":"243--252","volume":"57","journal":"JVCIR"}}
{"bib_id":"campos2017pixels","title":"From pixels to sentiment: Fine-tuning CNNs for visual sentiment prediction","author":"Campos, Victor and Jou, Brendan and Giro-i-Nieto, Xavier","meta_info":{"year":"2017","pages":"15--22","volume":"65","journal":"IVC"}}
{"bib_id":"kang2018method","title":"A method for extracting emotion using colors comprise the painting image","author":"Kang, Dongwann and Shim, Hyounoh and Yoon, Kyunghyun","meta_info":{"year":"2018","pages":"4985--5002","number":"4","volume":"77","journal":"MTA"}}
{"bib_id":"alarcao2018identifying","title":"Identifying emotions in images from valence and arousal ratings","author":"Alarcão, Soraia M and Fonseca, Manuel J","meta_info":{"year":"2018","pages":"17413--17435","number":"13","volume":"77","journal":"MTA"}}
{"bib_id":"hassan2019sentiment","title":"Sentiment Analysis from Images of Natural Disasters","author":"Hassan, Syed Zohaib and Ahmad, Kashif and Al-Fuqaha, Ala and Conci, Nicola","meta_info":{"year":"2019","pages":"104--113","booktitle":"CIAP"}}
{"bib_id":"he2019multi","title":"A Multi-Attentive Pyramidal Model for Visual Sentiment Analysis","author":"He, Xiaohao and Zhang, Huijun and Li, Ningyun and Feng, Ling and Zheng, Feng","meta_info":{"year":"2019","pages":"1--8","booktitle":"IJCNN"}}
{"bib_id":"zhang2019another","title":"Another Dimension: Towards Multi-subnet Neural Network for Image Sentiment Analysis","author":"Zhang, Jing and Sun, Han and Wang, Zhe and Ruan, Tong","meta_info":{"year":"2019","pages":"1126--1131","booktitle":"ICME"}}
{"bib_id":"yu2019towards","title":"Towards Unified Aesthetics and Emotion Prediction in Images","author":"Yu, Jun and Cui, Chaoran and Geng, LeiLei and Ma, Yuling and Yin, Yilong","meta_info":{"year":"2019","pages":"2526--2530","booktitle":"ICIP"}}
{"bib_id":"guntuku2019twitter","title":"What Twitter profile and posted images reveal about depression and anxiety","author":"Guntuku, Sharath Chandra and Preotiuc-Pietro, Daniel and Eichstaedt, Johannes C and Ungar, Lyle H","meta_info":{"year":"2019","booktitle":"AAAI"}}
{"bib_id":"al2019smile","title":"Smile, be Happy:) Emoji Embedding for Visual Sentiment Analysis","author":"Al-Halah, Ziad and Aitken, Andrew and Shi, Wenzhe and Caballero, Jose","meta_info":{"year":"2019","booktitle":"ICCVW"}}
{"bib_id":"jindal2015image","title":"Image sentiment analysis using deep convolutional neural networks with domain specific fine tuning","author":"Jindal, Stuti and Singh, Sanjay","meta_info":{"year":"2015","pages":"447--451","booktitle":"IPSN"}}
{"bib_id":"zhao2020endtoend","title":"An End-to-End Visual-Audio Attention Network for Emotion Recognition in User-Generated Videos","author":"Zhao, Sicheng and Ma, Yunsheng and Gu, Yang and Yang, Jufeng and Xing, Tengfei and Xu, Pengfei and Hu, Runbo and Chai, Hua and Keutzer, Kurt","meta_info":{"year":"2020","pages":"303--311","booktitle":"AAAI"}}
{"bib_id":"zhang2019exploring","title":"Exploring Discriminative Representations for Image Emotion Recognition with CNNs","author":"Zhang, Wei and He, Xuanyu and Lu, Weizhi","meta_info":{"year":"2020","pages":"515--523","number":"2","volume":"22","journal":"IEEE TMM"}}
{"bib_id":"zhang2019object","title":"Object semantics sentiment correlation analysis enhanced image sentiment classification","author":"Zhang, Jing and Chen, Mei and Sun, Han and Li, Dongdong and Wang, Zhe","meta_info":{"year":"2020","pages":"105245","volume":"191","journal":"KBS"}}
{"bib_id":"cordel2019emotion","title":"Emotion-Aware Human Attention Prediction","author":"Cordel, Macario O and Fan, Shaojing and Shen, Zhiqi and Kankanhalli, Mohan S","meta_info":{"year":"2019","pages":"4026--4035","booktitle":"CVPR"}}
{"bib_id":"bovik1990multichannel","title":"Multichannel texture analysis using localized spatial filters","author":"Bovik, Alan C. and Clark, Marianna and Geisler, Wilson S.","meta_info":{"year":"1990","pages":"55--73","number":"1","volume":"12","journal":"IEEE TPAMI"}}
{"bib_id":"hassan2019automatic","title":"Automatic detection of pain from facial expressions: a survey","author":"Hassan, Teena and Seuß, Dominik and Wollenberg, Johannes and Weitz, Katharina and Kunz, Miriam and Lautenbacher, Stefan and Garbas, Jens-Uwe and Schmid, Ute","meta_info":{"year":"2019","journal":"IEEE TPAMI"}}
{"bib_id":"kosti2020context","title":"Context Based Emotion Recognition Using EMOTIC Dataset","author":"Kosti, Ronak and Alvarez, Jose and Recasens, Adria and Lapedriza, Agata","meta_info":{"pages":"2755--2766","number":"11","volume":"42","year":"2020","journal":"IEEE TPAMI"}}
{"bib_id":"zhao2020review","title":"A Review of Single-Source Deep Unsupervised Visual Domain Adaptation","author":"Zhao, Sicheng and Yue, Xiangyu and Zhang, Shanghang and Li, Bo and Zhao, Han and Wu, Bichen and Krishna, Ravi and Gonzalez, Joseph E and Sangiovanni-Vincentelli, Alberto L and Seshia, Sanjit A and others","meta_info":{"year":"2020","journal":"IEEE TNNLS"}}
{"bib_id":"zhao2020end","title":"An End-to-End visual-audio attention network for emotion recognition in user-generated videos","author":"Zhao, Sicheng and Ma, Yunsheng and Gu, Yang and Yang, Jufeng and Xing, Tengfei and Xu, Pengfei and Hu, Runbo and Chai, Hua and Keutzer, Kurt","meta_info":{"year":"2020","pages":"303--311","booktitle":"AAAI"}}
{"bib_id":"wei2020learning","title":"Learning Visual Emotion Representations From Web Data","author":"Wei, Zijun and Zhang, Jianming and Lin, Zhe and Lee, Joon-Young and Balasubramanian, Niranjan and Hoai, Minh and Samaras, Dimitris","meta_info":{"year":"2020","pages":"13106--13115","booktitle":"CVPR"}}
{"bib_id":"simonyan2015very","title":"Very deep convolutional networks for large-scale image recognition","author":"Simonyan, Karen and Zisserman, Andrew","meta_info":{"year":"2015","booktitle":"ICLR"}}
{"bib_id":"zhao2020emotion","title":"Emotion-Based End-to-End Matching Between Image and Music in Valence-Arousal Space","author":"Zhao, Sicheng and Li, Yaxian and Yao, Xingxu and Nie, Weizhi and Xu, Pengfei and Yang, Jufeng and Keutzer, Kurt","meta_info":{"year":"2020","pages":"2945--2954","booktitle":"ACM MM"}}
{"bib_id":"zhao2021madan","title":"MADAN: multi-source adversarial domain aggregation network for domain adaptation","author":"Zhao, Sicheng and Li, Bo and Xu, Pengfei and Yue, Xiangyu and Ding, Guiduang and Keutzer, Kurt","meta_info":{"year":"2021","journal":"IJCV"}}
{"bib_id":"liu2015classification","title":"Classification with noisy labels by importance reweighting","author":"Liu, Tongliang and Tao, Dacheng","meta_info":{"year":"2015","pages":"447--461","number":"3","volume":"38","journal":"IEEE TPAMI"}}
{"bib_id":"compton2003interface","title":"The interface between emotion and attention: A review of evidence from psychology and neuroscience","author":"Compton, Rebecca J","meta_info":{"year":"2003","pages":"115--129","number":"2","volume":"2","journal":"BCN"}}
{"bib_id":"zhao2021emotional","title":"Emotional semantics-preserved and feature-aligned cyclegan for visual emotion adaptation","author":"Zhao, Sicheng and Chen, Xuanbai and Yue, Xiangyu and Lin, Chuang and Xu, Pengfei and Krishna, Ravi and Yang, Jufeng and Ding, Guiguang and Sangiovanni-Vincentelli, Alberto L and Keutzer, Kurt","meta_info":{"year":"2021","journal":"IEEE TCYB"}}
{"bib_id":"krizhevsky2012imagenet","title":"Imagenet classification with deep convolutional neural networks","author":"Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E","meta_info":{"year":"2012","pages":"1097--1105","journal":"NIPS"}}
{"bib_id":"schuller2010mister","title":"‘Mister DJ, Cheer Me Up!’: Musical and textual features for automatic mood classification","author":"Schuller, Björn and Hage, Clemens and Schuller, Dagmar and Rigoll, Gerhard","meta_info":{"year":"2010","pages":"13--34","number":"1","volume":"39","journal":"JNMR"}}
{"bib_id":"gunes201716","title":"16 Automatic Analysis of Social Emotions","author":"Gunes, Hatice and Schüller, Björn","meta_info":{"year":"2017","pages":"213","journal":"SSP"}}
{"bib_id":"gunes2013categorical","title":"Categorical and dimensional affect analysis in continuous input: Current trends and future directions","author":"Gunes, Hatice and Schuller, Björn","meta_info":{"year":"2013","pages":"120--136","number":"2","volume":"31","journal":"IVC"}}
{"bib_id":"pantic2006dynamics","title":"Dynamics of facial expression: recognition of facial actions and their temporal segments from face profile image sequences","author":"Pantic, Maja and Patras, Ioannis","meta_info":{"year":"2006","pages":"433--449","number":"2","volume":"36","journal":"IEEE TCYB"}}
{"bib_id":"keren2017end","title":"End-to-end learning for dimensional emotion recognition from physiological signals","author":"Keren, Gil and Kirschstein, Tobias and Marchi, Erik and Ringeval, Fabien and Schuller, Björn","meta_info":{"year":"2017","pages":"985--990","booktitle":"ICME"}}
{"bib_id":"schuller2002multimodal","title":"Multimodal emotion recognition in audiovisual communication","author":"Schuller, Björn and Lang, Manfred and Rigoll, Gerhard","meta_info":{"year":"2002","pages":"745--748","volume":"1","booktitle":"ICME"}}
{"bib_id":"schuller2018speech","title":"Speech emotion recognition: two decades in a nutshell, benchmarks, and ongoing trends","author":"Schuller, Björn W","meta_info":{"year":"2018","pages":"90--99","number":"5","volume":"61","journal":"CACM"}}
{"bib_id":"metze2010emotion","title":"Emotion recognition using imperfect speech recognition","author":"Metze, Florian and Batliner, Anton and Eyben, Florian and Polzehl, Tim and Schuller, Björn and Steidl, Stefan","meta_info":{"year":"2010","pages":"478--481","booktitle":"INTERSPEECH"}}
{"bib_id":"schuller2012automatic","title":"Automatic recognition of emotion evoked by general sound events","author":"Schuller, Björn and Hantke, Simone and Weninger, Felix and Han, Wenjing and Zhang, Zixing and Narayanan, Shrikanth","meta_info":{"year":"2012","pages":"341--344","booktitle":"ICASSP"}}
{"bib_id":"williamson1979speech","title":"Speech analyzer for analyzing frequency perturbations in a speech pattern to determine the emotional state of a person","author":"Williamson, John D","meta_info":{"note":"US Patent 4,142,067","publisher":"Google Patents","month":"February~27","year":"1979"}}
{"bib_id":"cahn1990generation","title":"The generation of affect in synthesized speech","author":"Cahn, Janet E","meta_info":{"year":"1990","pages":"1--1","number":"1","volume":"8","journal":"Journal of the American Voice I\/O Society"}}
{"bib_id":"kobayashi1992recognition","title":"Recognition of six basic facial expression and their strength by neural network","author":"Kobayashi, Hiroshi and Hara, Fumio","meta_info":{"year":"1992","pages":"381--386","booktitle":"ROMAN"}}
{"bib_id":"schlosberg1954three","title":"Three dimensions of emotion","author":"Schlosberg, Harold","meta_info":{"year":"1954","pages":"81","number":"2","volume":"61","journal":"Psychological Review"}}
{"bib_id":"plutchik1980emotion","title":"Emotion: A psychoevolutionary synthesis","author":"Plutchik, Robert","meta_info":{"publisher":"Harpercollins College Division","year":"1980"}}
{"bib_id":"warriner2013norms","title":"Norms of valence, arousal, and dominance for 13,915 English lemmas","author":"Warriner, Amy Beth and Kuperman, Victor and Brysbaert, Marc","meta_info":{"year":"2013","pages":"1191--1207","number":"4","volume":"45","journal":"BRM"}}
{"bib_id":"soleymani2017survey","title":"A survey of multimodal sentiment analysis","author":"Soleymani, Mohammad and Garcia, David and Jou, Brendan and Schuller, Björn and Chang, Shih-Fu and Pantic, Maja","meta_info":{"year":"2017","pages":"3--14","volume":"65","journal":"IVC"}}
{"bib_id":"zhao2019affective","title":"Affective Computing for Large-scale Heterogeneous Multimedia Data: A Survey","author":"Zhao, Sicheng and Wang, Shangfei and Soleymani, Mohammad and Joshi, Dhiraj and Ji, Qiang","meta_info":{"year":"2019","pages":"93","number":"3s","volume":"15","journal":"ACM TOMM"}}
{"bib_id":"sariyanidi2014automatic","title":"Automatic analysis of facial affect: A survey of registration, representation, and recognition","author":"Sariyanidi, Evangelos and Gunes, Hatice and Cavallaro, Andrea","meta_info":{"year":"2014","pages":"1113--1133","number":"6","volume":"37","journal":"IEEE TPAMI"}}
{"bib_id":"li2018deep","title":"Deep facial expression recognition: A survey","author":"Li, Shan and Deng, Weihong","meta_info":{"year":"2018","journal":"arXiv:1804.08348"}}
{"bib_id":"poria2017review","title":"A review of affective computing: From unimodal analysis to multimodal fusion","author":"Poria, Soujanya and Cambria, Erik and Bajpai, Rajiv and Hussain, Amir","meta_info":{"year":"2017","pages":"98--125","volume":"37","journal":"INF"}}
{"bib_id":"zhao2018affective","title":"Affective Image Content Analysis: A Comprehensive Survey.","author":"Zhao, Sicheng and Ding, Guiguang and Huang, Qingming and Chua, Tat-Seng and Schuller, Björn W and Keutzer, Kurt","meta_info":{"year":"2018","pages":"5534--5541","booktitle":"IJCAI"}}
{"bib_id":"wang2015video","title":"Video affective content analysis: a survey of state-of-the-art methods","author":"Wang, Shangfei and Ji, Qiang","meta_info":{"year":"2015","pages":"410--430","number":"4","volume":"6","journal":"IEEE TAFFC"}}
{"bib_id":"zhao2019personalized","title":"Personalized emotion recognition by personality-aware high-order learning of physiological signals","author":"Zhao, Sicheng and Gholaminejad, Amir and Ding, Guiguang and Gao, Yue and Han, Jungong and Keutzer, Kurt","meta_info":{"year":"2019","pages":"14","number":"1s","volume":"15","journal":"ACM TOMM"}}
{"bib_id":"sun2009improved","title":"An improved valence-arousal emotion space for video affective content representation and recognition","author":"Sun, Kai and Yu, Junqing and Huang, Yue and Hu, Xiaoqiang","meta_info":{"year":"2009","pages":"566--569","booktitle":"ICME"}}
{"bib_id":"el2011survey","title":"Survey on speech emotion recognition: Features, classification schemes, and databases","author":"El Ayadi, Moataz and Kamel, Mohamed S and Karray, Fakhri","meta_info":{"year":"2011","pages":"572--587","number":"3","volume":"44","journal":"PR"}}
{"bib_id":"yang2012machine","title":"Machine recognition of music emotion: A review","author":"Yang, Yi-Hsuan and Chen, Homer H","meta_info":{"year":"2012","pages":"40","number":"3","volume":"3","journal":"ACM TIST"}}
{"bib_id":"alarcao2017emotions","title":"Emotions recognition using EEG signals: A survey","author":"Alarcao, Soraia M and Fonseca, Manuel J","meta_info":{"year":"2017","journal":"IEEE TAFFC"}}
{"bib_id":"ekman1992argument","title":"An argument for basic emotions","author":"Ekman, Paul","meta_info":{"year":"1992","pages":"169--200","number":"3-4","volume":"6","journal":"Cognition & Emotion"}}
{"bib_id":"hanjalic2006extracting","title":"Extracting moods from pictures and sounds: Towards truly personalized TV","author":"Hanjalic, Alan","meta_info":{"year":"2006","pages":"90--100","number":"2","volume":"23","journal":"IEEE SPM"}}
{"bib_id":"lang1997international","title":"International affective picture system (IAPS): Technical manual and affective ratings","author":"Lang, Peter J and Bradley, Margaret M and Cuthbert, Bruce N","meta_info":{"year":"1997","pages":"39--58","journal":"NIMH Center for the Study of Emotion and Attention"}}
{"bib_id":"mikels2005emotional","title":"Emotional category data on images from the International Affective Picture System","author":"Mikels, Joseph A and Fredrickson, Barbara L and Larkin, Gregory R and Lindberg, Casey M and Maglio, Sam J and Reuter-Lorenz, Patricia A","meta_info":{"year":"2005","pages":"626--630","number":"4","volume":"37","journal":"BRM"}}
{"bib_id":"machajdik2010affective","title":"Affective image classification using features inspired by psychology and art theory","author":"Machajdik, Jana and Hanbury, Allan","meta_info":{"year":"2010","pages":"83--92","booktitle":"ACM MM"}}
{"bib_id":"dan2011geneva","title":"The Geneva affective picture database (GAPED): a new 730-picture database focusing on valence and normative significance","author":"Dan-Glauser, Elise S and Scherer, Klaus R","meta_info":{"year":"2011","pages":"468--477","number":"2","volume":"43","journal":"BRM"}}
{"bib_id":"alameda2016recognizing","title":"Recognizing emotions from abstract paintings using non-linear matrix completion","author":"Alameda-Pineda, Xavier and Ricci, Elisa and Yan, Yan and Sebe, Nicu","meta_info":{"year":"2016","pages":"5240--5248","booktitle":"CVPR"}}
{"bib_id":"sartori2015s","title":"Who's afraid of itten: Using the art theory of color combination to analyze emotions in abstract paintings","author":"Sartori, Andreza and Culibrk, Dubravko and Yan, Yan and Sebe, Nicu","meta_info":{"year":"2015","pages":"311--320","booktitle":"ACM MM"}}
{"bib_id":"borth2013large","title":"Large-scale visual sentiment ontology and detectors using adjective noun pairs","author":"Borth, Damian and Ji, Rongrong and Chen, Tao and Breuel, Thomas and Chang, Shih-Fu","meta_info":{"year":"2013","pages":"223--232","booktitle":"ACM MM"}}
{"bib_id":"yang2014your","title":"How Do Your Friends on Social Media Disclose Your Emotions?","author":"Yang, Yang and Jia, Jia and Zhang, Shumei and Wu, Boya and Chen, Qicong and Li, Juanzi and Xing, Chunxiao and Tang, Jie","meta_info":{"year":"2014","pages":"306--312","booktitle":"AAAI"}}
{"bib_id":"lin2020multi","title":"Multi-source Domain Adaptation for Visual Sentiment Classification","author":"Lin, Chuang and Zhao, Sicheng and Meng, Lei and Chua, Tat-Seng","meta_info":{"year":"2020","booktitle":"AAAI"}}
{"bib_id":"you2016building","title":"Building a large scale dataset for image emotion recognition: The fine print and the benchmark","author":"You, Quanzeng and Luo, Jiebo and Jin, Hailin and Yang, Jianchao","meta_info":{"year":"2016","pages":"308--314","booktitle":"AAAI"}}
{"bib_id":"zhao2016predicting","title":"Predicting personalized emotion perceptions of social images","author":"Zhao, Sicheng and Yao, Hongxun and Gao, Yue and Ji, Rongrong and Xie, Wenlong and Jiang, Xiaolei and Chua, Tat-Seng","meta_info":{"year":"2016","pages":"1385--1394","booktitle":"ACM MM"}}
{"bib_id":"peng2015mixed","title":"A Mixed Bag of Emotions: Model, Predict, and Transfer Emotion Distributions","author":"Peng, Kuan-Chuan and Sadovnik, Amir and Gallagher, Andrew and Chen, Tsuhan","meta_info":{"year":"2015","pages":"860--868","booktitle":"CVPR"}}
{"bib_id":"yang2013user","title":"User interest and social influence based emotion prediction for individuals","author":"Yang, Yun and Cui, Peng and Zhu, Wenwu and Yang, Shiqiang","meta_info":{"year":"2013","pages":"785--788","booktitle":"ACM MM"}}
{"bib_id":"rui2017joint","title":"Joint user-interest and social-influence emotion prediction for individuals","author":"Rui, Ting and Cui, Peng and Zhu, Wenwu","meta_info":{"year":"2017","pages":"66--76","volume":"230","journal":"Neurocomputing"}}
{"bib_id":"parrott2001emotions","title":"Emotions in social psychology: Essential readings","author":"Parrott, W Gerrod","meta_info":{"publisher":"Psychology Press","year":"2001"}}
{"bib_id":"ortony1988cognitive","title":"The cognitive structure of emotions","author":"Ortony, Andrew and Clore, Gerald L and Collins, Allan","meta_info":{"publisher":"Cambridge university press","year":"1988"}}
{"bib_id":"scherer2001appraisal","title":"Appraisal processes in emotion: Theory, methods, research","author":"Scherer, Klaus R and Schorr, Angela and Johnstone, Tom","meta_info":{"publisher":"Oxford University Press","year":"2001"}}
{"bib_id":"munezero2014they","title":"Are they different? Affect, feeling, emotion, sentiment, and opinion detection in text","author":"Munezero, Myriam D and Montero, Calkin Suero and Sutinen, Erkki and Pajunen, John","meta_info":{"year":"2014","pages":"101--111","number":"2","volume":"5","journal":"IEEE TAFFC"}}
{"bib_id":"zhao2018emotiongan","title":"EmotionGAN: unsupervised domain adaptation for learning discrete probability distributions of image emotions","author":"Zhao, Sicheng and Zhao, Xin and Ding, Guiguang and Keutzer, Kurt","meta_info":{"year":"2018","pages":"1319--1327","booktitle":"ACM MM"}}
{"bib_id":"zhan2019zero","title":"Zero-shot emotion recognition via affective structural embedding","author":"Zhan, Chi and She, Dongyu and Zhao, Sicheng and Cheng, Ming-Ming and Yang, Jufeng","meta_info":{"year":"2019","pages":"1151--1160","booktitle":"ICCV"}}
{"bib_id":"yang2017learning","title":"Learning Visual Sentiment Distributions via Augmented Conditional Probability Neural Network","author":"Yang, Jufeng and Sun, Ming and Sun, Xiaoxiao","meta_info":{"year":"2017","pages":"224--230","booktitle":"AAAI"}}
{"bib_id":"zhao2014affective","title":"Affective image retrieval via multi-graph learning","author":"Zhao, Sicheng and Yao, Hongxun and Yang, You and Zhang, Yanhao","meta_info":{"year":"2014","pages":"1025--1028","booktitle":"ACM MM"}}
{"bib_id":"lee2011fuzzy","title":"Fuzzy similarity-based emotional classification of color images","author":"Lee, Joonwhoan and Park, EunJong","meta_info":{"year":"2011","pages":"1031--1039","number":"5","volume":"13","journal":"IEEE TMM"}}
{"bib_id":"giachanou2016like","title":"Like it or not: A survey of twitter sentiment analysis methods","author":"Giachanou, Anastasia and Crestani, Fabio","meta_info":{"year":"2016","pages":"28","number":"2","volume":"49","journal":"CSUR"}}
{"bib_id":"zhang2018deep","title":"Deep learning for sentiment analysis: A survey","author":"Zhang, Lei and Wang, Shuai and Liu, Bing","meta_info":{"year":"2018","pages":"e1253","number":"4","volume":"8","journal":"Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery"}}
{"bib_id":"lu2012shape","title":"On shape and the computability of emotions","author":"Lu, Xin and Suryanarayan, Poonam and Adams Jr, Reginald B and Li, Jia and Newman, Michelle G and Wang, James Z","meta_info":{"year":"2012","pages":"229--238","booktitle":"ACM MM"}}
{"bib_id":"yuan2013sentribute","title":"Sentribute: image sentiment analysis from a mid-level perspective","author":"Yuan, Jianbo and Mcdonough, Sean and You, Quanzeng and Luo, Jiebo","meta_info":{"year":"2013","pages":"10","booktitle":"WISDOM"}}
{"bib_id":"yang2010exploring","title":"Exploring facial expressions with compositional features","author":"Yang, Peng and Liu, Qingshan and Metaxas, Dimitris N","meta_info":{"year":"2010","pages":"2638--2644","booktitle":"CVPR"}}
{"bib_id":"patterson2012sun","title":"Sun attribute database: Discovering, annotating, and recognizing scene attributes","author":"Patterson, Genevieve and Hays, James","meta_info":{"year":"2012","pages":"2751--2758","booktitle":"CVPR"}}
{"bib_id":"zhao2014exploring","title":"Exploring principles-of-art features for image emotion recognition","author":"Zhao, Sicheng and Gao, Yue and Jiang, Xiaolei and Yao, Hongxun and Chua, Tat-Seng and Sun, Xiaoshuai","meta_info":{"year":"2014","pages":"47--56","booktitle":"ACM MM"}}
{"bib_id":"li2012context","title":"Context-aware affective images classification based on bilayer sparse representation","author":"Li, Bing and Xiong, Weihua and Hu, Weiming and Ding, Xinmiao","meta_info":{"year":"2012","pages":"721--724","booktitle":"ACM MM"}}
{"bib_id":"rao2016multi","title":"Multi-scale blocks based image emotion classification using multiple instance learning","author":"Rao, Tianrong and Xu, Min and Liu, Huiying and Wang, Jinqiao and Burnett, Ian","meta_info":{"year":"2016","pages":"634--638","booktitle":"ICIP"}}
{"bib_id":"wang2013interpretable","title":"Interpretable aesthetic features for affective image classification","author":"Wang, Xiaohui and Jia, Jia and Yin, Jiaming and Cai, Lianhong","meta_info":{"year":"2013","pages":"3230--3234","booktitle":"ICIP"}}
{"bib_id":"kipf2017semi","title":"Semi-supervised classification with graph convolutional networks","author":"Kipf, Thomas N and Welling, Max","meta_info":{"year":"2017","booktitle":"ICLR"}}
{"bib_id":"feng2019hypergraph","title":"Hypergraph neural networks","author":"Feng, Yifan and You, Haoxuan and Zhang, Zizhao and Ji, Rongrong and Gao, Yue","meta_info":{"year":"2019","pages":"3558--3565","booktitle":"AAAI"}}
{"bib_id":"wang2015modeling","title":"Modeling emotion influence in image social networks","author":"Wang, Xiaohui and Jia, Jia and Tang, Jie and Wu, Boya and Cai, Lianhong and Xie, Lexing","meta_info":{"year":"2015","pages":"286--297","number":"3","volume":"6","journal":"IEEE TAFFC"}}
{"bib_id":"you2015robust","title":"Robust Image Sentiment Analysis Using Progressively Trained and Domain Transferred Deep Networks.","author":"You, Quanzeng and Luo, Jiebo and Jin, Hailin and Yang, Jianchao","meta_info":{"year":"2015","pages":"381--388","booktitle":"AAAI"}}
{"bib_id":"rao2016learning","title":"Learning multi-level deep representations for image emotion classification","author":"Rao, Tianrong and Xu, Min and Xu, Dong","meta_info":{"year":"2020","pages":"2043--2061","number":"3","volume":"51","journal":"NPL"}}
{"bib_id":"zhu2017dependency","title":"Dependency exploitation: a unified CNN-RNN approach for visual emotion recognition","author":"Zhu, Xinge and Li, Liang and Zhang, Weigang and Rao, Tianrong and Xu, Min and Huang, Qingming and Xu, Dong","meta_info":{"year":"2017","pages":"3595--3601","booktitle":"IJCAI"}}
{"bib_id":"zhao2015continuous","title":"Predicting continuous probability distribution of image emotions in valence-arousal space","author":"Zhao, Sicheng and Yao, Hongxun and Jiang, Xiaolei","meta_info":{"year":"2015","pages":"879--882","booktitle":"ACM MM"}}
{"bib_id":"yang2018retrieving","title":"Retrieving and classifying affective Images via deep metric learning","author":"Yang, Jufeng and She, Dongyu and Lai, Yukun and Yang, Ming-Hsuan","meta_info":{"year":"2018","pages":"491--498","booktitle":"AAAI"}}
{"bib_id":"zhao2017continuous","title":"Continuous Probability Distribution Prediction of Image Emotions via Multi-Task Shared Sparse Regression","author":"Zhao, Sicheng and Yao, Hongxun and Gao, Yue and Ji, Rongrong and Ding, Guiguang","meta_info":{"year":"2017","pages":"632--645","number":"3","volume":"19","journal":"IEEE TMM"}}
{"bib_id":"zhao2015predicting","title":"Predicting discrete probability distribution of image emotions","author":"Zhao, Sicheng and Yao, Hongxun and Jiang, Xiaolei and Sun, Xiaoshuai","meta_info":{"year":"2015","pages":"2459--2463","booktitle":"ICIP"}}
{"bib_id":"zhao2017approximating","title":"Approximating Discrete Probability Distribution of Image Emotions by Multi-Modal Features Fusion","author":"Zhao, Sicheng and Ding, Guiguang and Gao, Yue and Han, Jungong","meta_info":{"year":"2017","pages":"4669--4675","booktitle":"IJCAI"}}
{"bib_id":"zhao2018personality","title":"Personality-Aware Personalized Emotion Recognition from Physiological Signals","author":"Zhao, Sicheng and Ding, Guiguang and Han, Jungong and Gao, Yue","meta_info":{"year":"2018","pages":"1660--1667","booktitle":"IJCAI"}}
{"bib_id":"geng2013facial","title":"Facial age estimation by learning from label distributions","author":"Geng, Xin and Yin, Chao and Zhou, Zhi-Hua","meta_info":{"year":"2013","pages":"2401--2412","number":"10","volume":"35","journal":"IEEE TPAMI"}}
{"bib_id":"zhao2017learning","title":"Learning Visual Emotion Distributions via Multi-Modal Features Fusion","author":"Zhao, Sicheng and Ding, Guiguang and Gao, Yue and Han, Jungong","meta_info":{"year":"2017","pages":"369--377","booktitle":"ACM MM"}}
{"bib_id":"yang2017joint","title":"Joint image emotion classification and distribution learning via deep convolutional neural network","author":"Yang, Jufeng and She, Dongyu and Sun, Ming","meta_info":{"year":"2017","pages":"3266--3272","booktitle":"IJCAI"}}
{"bib_id":"zhao2018predicting","title":"Predicting personalized image emotion perceptions in social networks","author":"Zhao, Sicheng and Yao, Hongxun and Gao, Yue and Ding, Guiguang and Chua, Tat-Seng","meta_info":{"year":"2018","pages":"526--540","number":"4","volume":"9","journal":"IEEE TAFFC"}}
{"bib_id":"chen2014object","title":"Object-based visual sentiment concept analysis and application","author":"Chen, Tao and Yu, Felix X and Chen, Jiawei and Cui, Yin and Chen, Yan-Ying and Chang, Shih-Fu","meta_info":{"year":"2014","pages":"367--376","booktitle":"ACM MM"}}
{"bib_id":"zhao2018discrete","title":"Discrete Probability Distribution Prediction of Image Emotions With Shared Sparse Learning","author":"Zhao, Sicheng and Ding, Guiguang and Gao, Yue and Zhao, Xin and Tang, Youbao and Han, Jungong and Yao, Hongxun and Huang, Qingming","meta_info":{"year":"2018","journal":"IEEE TAFFC"}}
{"bib_id":"you2016robust","title":"Robust visual-textual sentiment analysis: When attention meets tree-structured recursive neural networks","author":"You, Quanzeng and Cao, Liangliang and Jin, Hailin and Luo, Jiebo","meta_info":{"year":"2016","pages":"1008--1017","booktitle":"ACM MM"}}
{"bib_id":"chen2018predicting","title":"Predicting Microblog Sentiments via Weakly Supervised Multimodal Deep Learning","author":"Chen, Fuhai and Ji, Rongrong and Su, Jinsong and Cao, Donglin and Gao, Yue","meta_info":{"year":"2018","pages":"997--1007","number":"4","volume":"20","journal":"IEEE TMM"}}
{"bib_id":"katsurai2016image","title":"Image sentiment analysis using latent correlations among visual, textual, and sentiment views","author":"Katsurai, Marie and Satoh, Shin'ichi","meta_info":{"year":"2016","pages":"2837--2841","booktitle":"ICASSP"}}
{"bib_id":"panda2018contemplating","title":"Contemplating Visual Emotions: Understanding and Overcoming Dataset Bias","author":"Panda, Rameswar and Zhang, Jianming and Li, Haoxiang and Lee, Joon-Young and Lu, Xin and Roy-Chowdhury, Amit K","meta_info":{"year":"2018","pages":"579--595","booktitle":"ECCV"}}
{"bib_id":"balouchian2019lucfer","title":"LUCFER: A Large-Scale Context-Sensitive Image Dataset for Deep Learning of Visual Emotions","author":"Balouchian, Pooyan and Safaei, Marjaneh and Foroosh, Hassan","meta_info":{"year":"2019","pages":"1645--1654","booktitle":"WACV"}}
{"bib_id":"kosti2017emotion","title":"Emotion recognition in context","author":"Kosti, Ronak and Alvarez, Jose M and Recasens, Adria and Lapedriza, Agata","meta_info":{"year":"2017","pages":"1667--1675","booktitle":"CVPR"}}
{"bib_id":"Vadicamo_2017_ICCVW","title":"Cross-Media Learning for Image Sentiment Analysis in the Wild","author":"Vadicamo, Lucia and Carrara, Fabio and Cimino, Andrea and Cresci, Stefano and Dell'Orletta, Felice and Falchi, Fabrizio and Tesconi, Maurizio","meta_info":{"year":"2017","pages":"308--317","booktitle":"ICCVW"}}
{"bib_id":"jou2015visual","title":"Visual affect around the world: A large-scale multilingual visual sentiment ontology","author":"Jou, Brendan and Chen, Tao and Pappas, Nikolaos and Redi, Miriam and Topkara, Mercan and Chang, Shih-Fu","meta_info":{"year":"2015","pages":"159--168","booktitle":"ACM MM"}}
{"bib_id":"fan2018emotional","title":"Emotional attention: A study of image sentiment and visual attention","author":"Fan, Shaojing and Shen, Zhiqi and Jiang, Ming and Koenig, Bryan L and Xu, Juan and Kankanhalli, Mohan S and Zhao, Qi","meta_info":{"year":"2018","pages":"7521--7531","booktitle":"CVPR"}}
{"bib_id":"lin2014microsoft","title":"Microsoft coco: Common objects in context","author":"Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Dollár, Piotr and Zitnick, C Lawrence","meta_info":{"year":"2014","pages":"740--755","booktitle":"ECCV"}}
{"bib_id":"zhou2019semantic","title":"Semantic understanding of scenes through the ade20k dataset","author":"Zhou, Bolei and Zhao, Hang and Puig, Xavier and Xiao, Tete and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio","meta_info":{"year":"2019","pages":"302--321","number":"3","volume":"127","journal":"IJCV"}}
{"bib_id":"wei2006image","title":"Image retrieval by emotional semantics: A study of emotional space and feature extraction","author":"Wang, Wei-ning and Yu, Ying-lin and Jiang, Sheng-ming","meta_info":{"year":"2006","pages":"3534--3539","volume":"4","booktitle":"SMC"}}
{"bib_id":"wei2004image","title":"Image emotional classification: static vs. dynamic","author":"Wang, Wei-ning and Yu, Ying-lin and Zhang, Jian-chao","meta_info":{"year":"2004","pages":"6407--6411","volume":"7","booktitle":"SMC"}}
{"bib_id":"yanulevskaya2008emotional","title":"Emotional valence categorization using holistic image features","author":"Yanulevskaya, Victoria and van Gemert, Jan C and Roth, Katharina and Herbold, Ann-KatYanulevskayarin and Sebe, Nicu and Geusebroek, Jan-Mark","meta_info":{"year":"2008","pages":"101--104","booktitle":"ICIP"}}
{"bib_id":"salovey1990emotional","title":"Emotional intelligence","author":"Salovey, Peter and Mayer, John D","meta_info":{"year":"1990","pages":"185--211","number":"3","volume":"9","journal":"Imagination, Cognition and Personality"}}
{"bib_id":"zhang2011analyzing","title":"Analyzing emotional semantics of abstract art using low-level image features","author":"Zhang, He and Augilius, Eimontas and Honkela, Timo and Laaksonen, Jorma and Gamper, Hannes and Alene, Henok","meta_info":{"year":"2011","pages":"413--423","booktitle":"IDA"}}
{"bib_id":"lu2017investigation","title":"An investigation into three visual characteristics of complex scenes that evoke human emotion","author":"Lu, Xin and Adams, Reginald B and Li, Jia and Newman, Michelle G and Wang, James Z","meta_info":{"year":"2017","pages":"440--447","booktitle":"ACII"}}
{"bib_id":"xu5731visual","title":"Visual Sentiment Prediction with Deep Convolutional Neural Networks","author":"Xu, Can and Cetintas, Suleyman and Lee, Kuang-Chih and Li, Li-Jia","meta_info":{"year":"2014","journal":"arXiv:1411.5731"}}
{"bib_id":"chen2014deepsentibank","title":"Deepsentibank: Visual sentiment concept classification with deep convolutional neural networks","author":"Chen, Tao and Borth, Damian and Darrell, Trevor and Chang, Shih-Fu","meta_info":{"year":"2014","journal":"arXiv:1410.8586"}}
{"bib_id":"chen2015learning","title":"Learning deep features for image emotion classification","author":"Chen, Ming and Zhang, Lu and Allebach, Jan P","meta_info":{"year":"2015","pages":"4491--4495","booktitle":"ICIP"}}
{"bib_id":"ali2017high","title":"High-level concepts for affective understanding of images","author":"Ali, Afsheen Rafaqat and Shahid, Usman and Ali, Mohsen and Ho, Jeffrey","meta_info":{"year":"2017","pages":"679--687","booktitle":"WACV"}}
{"bib_id":"lu2016identifying","title":"Identifying Emotions Aroused from Paintings","author":"Lu, Xin and Sawant, Neela and Newman, Michelle G and Adams, Reginald B and Wang, James Z and Li, Jia","meta_info":{"year":"2016","pages":"48--63","booktitle":"ECCV"}}
{"bib_id":"gatys2015texture","title":"Texture synthesis using convolutional neural networks","author":"Gatys, Leon and Ecker, Alexander S and Bethge, Matthias","meta_info":{"year":"2015","pages":"262--270","booktitle":"NeurIPS"}}
{"bib_id":"liu2016improving","title":"Improving visual saliency computing with emotion intensity","author":"Liu, Huiying and Xu, Min and Wang, Jinqiao and Rao, Tianrong and Burnett, Ian","meta_info":{"year":"2016","pages":"1201--1213","number":"6","volume":"27","journal":"IEEE TNNLS"}}
{"bib_id":"you2017visual","title":"Visual sentiment analysis by attending on local image regions","author":"You, Quanzeng and Jin, Hailin and Luo, Jiebo","meta_info":{"year":"2017","pages":"231--237","booktitle":"AAAI"}}
{"bib_id":"yang2018visual","title":"Visual sentiment prediction based on automatic discovery of affective regions","author":"Yang, Jufeng and She, Dongyu and Sun, Ming and Cheng, Ming-Ming and Rosin, Paul L and Wang, Liang","meta_info":{"year":"2018","pages":"2513--2525","number":"9","volume":"20","journal":"IEEE TMM"}}
{"bib_id":"yang2018weakly","title":"Weakly supervised coupled networks for visual sentiment analysis","author":"Yang, Jufeng and She, Dongyu and Lai, Yu-Kun and Rosin, Paul L and Yang, Ming-Hsuan","meta_info":{"year":"2018","pages":"7584--7592","booktitle":"CVPR"}}
{"bib_id":"zhao2019pdanet","title":"PDANet: Polarity-consistent Deep Attention Network for Fine-grained Visual Emotion Regression","author":"Zhao, Sicheng and Jia, Zizhou and Chen, Hui and Li, Leida and Ding, Guiguang and Keutzer, Kurt","meta_info":{"year":"2019","pages":"192--201","booktitle":"ACM MM"}}
{"bib_id":"rao2019multi","title":"Multi-level region-based Convolutional Neural Network for image emotion classification","author":"Rao, Tianrong and Li, Xiaoxu and Zhang, Haimin and Xu, Min","meta_info":{"year":"2019","pages":"429--439","volume":"333","journal":"Neurocomputing"}}
{"bib_id":"wu2019visual","title":"Visual Sentiment Analysis by Combining Global and Local Information","author":"Wu, Lifang and Qi, Mingchao and Jian, Meng and Zhang, Heng","meta_info":{"year":"2019","pages":"1--13","journal":"NPL"}}
{"bib_id":"yao2019attention","title":"Attention-aware Polarity Sensitive Embedding for Affective Image Retrieval","author":"Yao, Xingxu and She, Dongyu and Zhao, Sicheng and Liang, Jie and Lai, Yu-Kun and Yang, Jufeng","meta_info":{"year":"2019","pages":"1140--1150","booktitle":"ICCV"}}
{"bib_id":"geusebroek2006compact","title":"Compact Object Descriptors from Local Colour Invariant Histograms","author":"Geusebroek, Jan-Mark","meta_info":{"year":"2006","pages":"1029--1038","booktitle":"BMVC"}}
{"bib_id":"dellandrea2010classification","title":"Classification of affective semantics in images based on discrete and dimensional models of emotions","author":"Dellandrea, Emmanuel and Liu, Ningning and Chen, Liming","meta_info":{"year":"2010","pages":"1--6","booktitle":"CBMI"}}
{"bib_id":"zhang2013affective","title":"Affective abstract image classification and retrieval using multiple kernel learning","author":"Zhang, He and Yang, Zhirong and Gönen, Mehmet and Koskela, Markus and Laaksonen, Jorma and Honkela, Timo and Oja, Erkki","meta_info":{"year":"2013","pages":"166--175","booktitle":"ICONIP"}}
{"bib_id":"campos2015diving","title":"Diving deep into sentiment: Understanding fine-tuned CNNs for visual sentiment prediction","author":"Campos, Victor and Salvador, Amaia and Giro-i-Nieto, Xavier and Jou, Brendan","meta_info":{"year":"2015","pages":"57--62","booktitle":"ASM"}}
{"bib_id":"wang2016beyond","title":"Beyond Object Recognition: Visual Sentiment Analysis with Deep Coupled Adjective and Noun Neural Networks","author":"Wang, Jingwen and Fu, Jianlong and Xu, Yong and Mei, Tao","meta_info":{"year":"2016","pages":"3484--3490","booktitle":"IJCAI"}}
{"bib_id":"ahsan2017towards","title":"Towards using visual attributes to infer image sentiment of social events","author":"Ahsan, Unaiza and De Choudhury, Munmun and Essa, Irfan","meta_info":{"year":"2017","pages":"1372--1379","booktitle":"IJCNN"}}
{"bib_id":"schroff2015facenet","title":"Facenet: A unified embedding for face recognition and clustering","author":"Schroff, Florian and Kalenichenko, Dmitry and Philbin, James","meta_info":{"year":"2015","pages":"815--823","booktitle":"CVPR"}}
{"bib_id":"he2018emotion","title":"Emotion recognition by assisted learning with convolutional neural networks","author":"He, Xuanyu and Zhang, Wei","meta_info":{"year":"2018","pages":"187--194","volume":"291","journal":"Neurocomputing"}}
{"bib_id":"liu2019affective","title":"Affective image classification by jointly using interpretable art features and semantic annotations","author":"Liu, Xuan and Li, Na and Xia, Yong","meta_info":{"year":"2019","pages":"576--588","volume":"58","journal":"JVCIR"}}
{"bib_id":"sun2016discovering","title":"Discovering affective regions in deep convolutional neural networks for visual sentiment prediction","author":"Sun, Ming and Yang, Jufeng and Wang, Kai and Shen, Hui","meta_info":{"year":"2016","pages":"1--6","booktitle":"ICME"}}
{"bib_id":"fan2017role","title":"The role of visual attention in sentiment prediction","author":"Fan, Shaojing and Jiang, Ming and Shen, Zhiqi and Koenig, Bryan L and Kankanhalli, Mohan S and Zhao, Qi","meta_info":{"year":"2017","pages":"217--225","booktitle":"ACM MM"}}
{"bib_id":"zhao2019cycleemotiongan","title":"Cycleemotiongan: Emotional semantic consistency preserved cyclegan for adapting image emotions","author":"Zhao, Sicheng and Lin, Chuang and Xu, Pengfei and Zhao, Sendong and Guo, Yuchen and Krishna, Ravi and Ding, Guiguang and Keutzer, Kurt","meta_info":{"year":"2019","pages":"2620--2627","booktitle":"AAAI"}}
{"bib_id":"wang2018visual","title":"Visual Sentiment Analysis with Noisy Labels by Reweighting Loss","author":"Wang, Lin and Xu, Xiangmin and Guo, Kailing and Cai, Bolun","meta_info":{"year":"2018","pages":"1873--1878","booktitle":"SMC"}}
{"bib_id":"song2018boosting","title":"Boosting image sentiment analysis with visual attention","author":"Song, Kaikai and Yao, Ting and Ling, Qiang and Mei, Tao","meta_info":{"year":"2018","pages":"218--228","volume":"312","journal":"Neurocomputing"}}
{"bib_id":"he2019image","title":"Image Emotion Distribution Learning with Graph Convolutional Networks","author":"He, Tao and Jin, Xiaoming","meta_info":{"year":"2019","pages":"382--390","booktitle":"ICMR"}}
{"bib_id":"liu2018structured","title":"Structured low-rank inverse-covariance estimation for visual sentiment distribution prediction","author":"Liu, Anan and Shi, Yingdi and Jing, Peiguang and Liu, Jing and Su, Yuting","meta_info":{"year":"2018","pages":"206--216","volume":"152","journal":"SP"}}
{"bib_id":"minsky1988society","title":"The Society of mind","author":"Minsky, Marvin","meta_info":{"publisher":"Simon and Schuster","year":"1986"}}
{"bib_id":"hossain2019emotion","title":"Emotion recognition using deep learning approach from audio--visual emotional big data","author":"Hossain, M Shamim and Muhammad, Ghulam","meta_info":{"year":"2019","pages":"69--78","volume":"49","journal":"INF"}}
{"bib_id":"szegedy2016rethinking","title":"Rethinking the inception architecture for computer vision","author":"Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew","meta_info":{"year":"2016","pages":"2818--2826","booktitle":"CVPR"}}
{"bib_id":"he2016deep","title":"Deep residual learning for image recognition","author":"He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian","meta_info":{"year":"2016","pages":"770--778","booktitle":"CVPR"}}
{"bib_id":"torralba2011unbiased","title":"Unbiased look at dataset bias","author":"Torralba, Antonio and Efros, Alexei A","meta_info":{"year":"2011","pages":"1521--1528","booktitle":"CVPR"}}
{"bib_id":"picard1997affective","title":"Affective computing","author":"Picard, Rosalind W","meta_info":{"publisher":"MIT press","year":"1997"}}
{"bib_id":"d2015review","title":"A review and meta-analysis of multimodal affect detection systems","author":"D'mello, Sidney K and Kory, Jacqueline","meta_info":{"year":"2015","pages":"43","number":"3","volume":"47","journal":"CSUR"}}
{"bib_id":"garg2007influence","title":"The influence of incidental affect on consumers’ food intake","author":"Garg, Nitika and Wansink, Brian and Inman, J Jeffrey","meta_info":{"year":"2007","pages":"194--206","number":"1","volume":"71","journal":"Journal of Marketing"}}
{"bib_id":"tan2008entertainment","title":"Entertainment is emotion: The functional architecture of the entertainment experience","author":"Tan, Eduard Sioe-Hao","meta_info":{"year":"2008","pages":"28--51","number":"1","volume":"11","journal":"Media Psychology"}}
{"bib_id":"xing2015emotion","title":"Emotion-driven Chinese folk music-image retrieval based on DE-SVM","author":"Xing, Baixi and Zhang, Kejun and Sun, Shouqian and Zhang, Lekai and Gao, Zenggui and Wang, Jiaxi and Chen, Shi","meta_info":{"year":"2015","pages":"619--627","volume":"148","journal":"Neurocomputing"}}
{"bib_id":"lin2014psychological","title":"Psychological stress detection from cross-media microblog data using deep sparse neural network","author":"Lin, Huijie and Jia, Jia and Guo, Quan and Xue, Yuanyuan and Huang, Jie and Cai, Lianhong and Feng, Ling","meta_info":{"year":"2014","pages":"1--6","booktitle":"ICME"}}
{"bib_id":"wu2015understanding","title":"Understanding the emotions behind social images: Inferring with user demographics","author":"Wu, Boya and Jia, Jia and Yang, Yang and Zhao, Peijun and Tang, Jie","meta_info":{"year":"2015","pages":"1--6","booktitle":"ICME"}}
{"bib_id":"wu2017inferring","title":"Inferring emotional tags from social images with user demographics","author":"Wu, Boya and Jia, Jia and Yang, Yang and Zhao, Peijun and Tang, Jie and Tian, Qi","meta_info":{"year":"2017","pages":"1670--1684","number":"7","volume":"19","journal":"IEEE TMM"}}
{"bib_id":"truong2017visual","title":"Visual sentiment analysis for review images with item-oriented and user-oriented CNN","author":"Truong, Quoc-Tuan and Lauw, Hady W","meta_info":{"year":"2017","pages":"1274--1282","booktitle":"ACM MM"}}
{"bib_id":"goodfellow2014generative","title":"Generative adversarial nets","author":"Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua","meta_info":{"year":"2014","pages":"2672--2680","booktitle":"NeurIPS"}}
{"bib_id":"zhu2017unpaired","title":"Unpaired image-to-image translation using cycle-consistent adversarial networks","author":"Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A","meta_info":{"year":"2017","pages":"2223--2232","booktitle":"ICCV"}}
{"bib_id":"wu2017reducing","title":"Reducing noisy labels in weakly labeled data for visual sentiment analysis","author":"Wu, Lifang and Liu, Shuang and Jian, Meng and Luo, Jiebo and Zhang, Xiuzhen and Qi, Mingchao","meta_info":{"year":"2017","pages":"1322--1326","booktitle":"ICIP"}}
{"bib_id":"wang2019robust","title":"Robust Emotion Navigation: Few-shot Visual Sentiment Analysis by Auxiliary Noisy Data","author":"Wang, Lin and Xu, Xiangmin and Liu, Fang and Xing, Xiaofen and Cai, Bolun and Lu, Weirui","meta_info":{"year":"2019","pages":"121--127","booktitle":"ACII Workshops and Demos"}}
{"bib_id":"wang2015unsupervised","title":"Unsupervised Sentiment Analysis for Social Media Images","author":"Wang, Yilin and Wang, Suhang and Tang, Jiliang and Liu, Huan and Li, Baoxin","meta_info":{"year":"2015","pages":"2378--2379","booktitle":"IJCAI"}}
{"bib_id":"muandet2013domain","title":"Domain generalization via invariant feature representation","author":"Muandet, Krikamol and Balduzzi, David and Schölkopf, Bernhard","meta_info":{"year":"2013","pages":"10--18","booktitle":"ICML"}}
{"bib_id":"tobin2017domain","title":"Domain randomization for transferring deep neural networks from simulation to the real world","author":"Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas and Zaremba, Wojciech and Abbeel, Pieter","meta_info":{"year":"2017","pages":"23--30","booktitle":"IROS"}}
{"bib_id":"he2019deep","title":"Deep Transfer Learning for Image Emotion Analysis: Reducing Marginal and Joint Distribution Discrepancies Together","author":"He, Yuwei and Ding, Guiguang","meta_info":{"year":"2019","pages":"1--10","journal":"NPL"}}
{"bib_id":"dhall2018emotiw","title":"Emotiw 2018: Audio-video, student engagement and group-level affect prediction","author":"Dhall, Abhinav and Kaur, Amanjot and Goecke, Roland and Gedeon, Tom","meta_info":{"year":"2018","pages":"653--656","booktitle":"ICMI"}}
{"bib_id":"guo2018group","title":"Group-Level Emotion Recognition using Hybrid Deep Models based on Faces, Scenes, Skeletons and Visual Attentions","author":"Guo, Xin and Zhu, Bin and Polanı́a, Luisa F and Boncelet, Charles and Barner, Kenneth E","meta_info":{"year":"2018","pages":"635--639","booktitle":"ICMI"}}
{"bib_id":"soleymani2011multimodal","title":"A multimodal database for affect recognition and implicit tagging","author":"Soleymani, Mohammad and Lichtenauer, Jeroen and Pun, Thierry and Pantic, Maja","meta_info":{"year":"2011","pages":"42--55","number":"1","volume":"3","journal":"IEEE TAFFC"}}
{"bib_id":"koelstra2013fusion","title":"Fusion of facial expressions and EEG for implicit affective tagging","author":"Koelstra, Sander and Patras, Ioannis","meta_info":{"year":"2013","pages":"164--174","number":"2","volume":"31","journal":"IVC"}}
{"bib_id":"wang2013affective","title":"Affective image adjustment with a single word","author":"Wang, Xiaohui and Jia, Jia and Cai, Lianhong","meta_info":{"year":"2013","pages":"1121--1133","number":"11","volume":"29","journal":"TVC"}}
{"bib_id":"ye2019visual","title":"Visual-Textual Sentiment Analysis in Product Reviews","author":"Ye, Jin and Peng, Xiaojiang and Qiao, Yu and Xing, Hao and Li, Junli and Ji, Rongrong","meta_info":{"year":"2019","pages":"869--873","booktitle":"ICIP"}}
{"bib_id":"bao2014thupis","title":"ThuPIS: A new affective image system for psychological analysis","author":"Bao, Shurui and Ma, Huimin and Li, Wenyu","meta_info":{"year":"2014","pages":"1--4","booktitle":"BIBM"}}
{"bib_id":"helmes1993perspective","title":"A perspective on developments in assessing psychopathology: a critical review of the MMPI and MMPI-2.","author":"Helmes, Edward and Reddon, John R","meta_info":{"year":"1993","pages":"453","number":"3","volume":"113","journal":"Psychological Bulletin"}}
{"bib_id":"holbrook1984role","title":"The role of emotion in advertising","author":"Holbrook, Morris B and O'Shaughnessy, John","meta_info":{"year":"1984","pages":"45--64","number":"2","volume":"1","journal":"Psychology & Marketing"}}
{"bib_id":"poels2006capture","title":"How to capture the heart? Reviewing 20 years of emotion measurement in advertising","author":"Poels, Karolien and Dewitte, Siegfried","meta_info":{"year":"2006","pages":"18--37","number":"1","volume":"46","journal":"JAR"}}
{"bib_id":"pan2014travel","title":"Travel photos: Motivations, image dimensions, and affective qualities of places","author":"Pan, Steve and Lee, Jinsoo and Tsai, Henry","meta_info":{"year":"2014","pages":"59--69","volume":"40","journal":"Tourism Management"}}
{"bib_id":"toyama2016categorization","title":"Categorization of Destinations Based on Tourists’ Emotional Responses","author":"Toyama, Masaki and Yamada, Yuichi","meta_info":{"year":"2013","booktitle":"TTRA International Conference"}}
{"bib_id":"hosany2013patterns","title":"Patterns of tourists' emotional responses, satisfaction, and intention to recommend","author":"Hosany, Sameer and Prayag, Girish","meta_info":{"year":"2013","pages":"730--737","number":"6","volume":"66","journal":"Journal of Business Research"}}
{"bib_id":"hosany2010measuring","title":"Measuring tourists’ emotional experiences toward hedonic holiday destinations","author":"Hosany, Sameer and Gilbert, David","meta_info":{"year":"2010","pages":"513--526","number":"4","volume":"49","journal":"Journal of Travel Research"}}
{"bib_id":"ahmad2012emotion","title":"Emotion as a Key Role in Successful Acceptance of Japanese Manga by Indonesian Readers","author":"Ahmad, Hafiz Aziz and Koyama, Shinichi and Hibino, Haruo","meta_info":{"year":"2012","booktitle":"KEER"}}
{"bib_id":"she2019learning","title":"Learning Discriminative Sentiment Representation from Strongly-and Weakly Supervised CNNs","author":"She, Dongyu and Sun, Ming and Yang, Jufeng","meta_info":{"year":"2019","pages":"1--19","number":"3s","volume":"15","journal":"ACM TOMM"}}
{"bib_id":"xiong2019structured","title":"Structured and Sparse Annotations for Image Emotion Distribution Learning","author":"Xiong, Haitao and Liu, Hongfu and Zhong, Bineng and Fu, Yun","meta_info":{"year":"2019","booktitle":"AAAI"}}
{"bib_id":"zhao2013video","title":"Video classification and recommendation based on affective analysis of viewers","author":"Zhao, Sicheng and Yao, Hongxun and Sun, Xiaoshuai","meta_info":{"year":"2013","pages":"101--110","volume":"119","journal":"Neurocomputing"}}
{"bib_id":"joho2011looking","title":"Looking at the viewer: analysing facial activity to detect personal highlights of multimedia contents","author":"Joho, Hideo and Staiano, Jacopo and Sebe, Nicu and Jose, Joemon M","meta_info":{"year":"2011","pages":"505--523","number":"2","volume":"51","journal":"MTA"}}
{"bib_id":"liu2018low","title":"Low-rank regularized multi-view inverse-covariance estimation for visual sentiment distribution prediction","author":"Liu, Anan and Shi, Yingdi and Jing, Peiguang and Liu, Jing and Su, Yuting","meta_info":{"year":"2018","pages":"243--252","volume":"57","journal":"JVCIR"}}
{"bib_id":"campos2017pixels","title":"From pixels to sentiment: Fine-tuning CNNs for visual sentiment prediction","author":"Campos, Victor and Jou, Brendan and Giro-i-Nieto, Xavier","meta_info":{"year":"2017","pages":"15--22","volume":"65","journal":"IVC"}}
{"bib_id":"kang2018method","title":"A method for extracting emotion using colors comprise the painting image","author":"Kang, Dongwann and Shim, Hyounoh and Yoon, Kyunghyun","meta_info":{"year":"2018","pages":"4985--5002","number":"4","volume":"77","journal":"MTA"}}
{"bib_id":"alarcao2018identifying","title":"Identifying emotions in images from valence and arousal ratings","author":"Alarcão, Soraia M and Fonseca, Manuel J","meta_info":{"year":"2018","pages":"17413--17435","number":"13","volume":"77","journal":"MTA"}}
{"bib_id":"hassan2019sentiment","title":"Sentiment Analysis from Images of Natural Disasters","author":"Hassan, Syed Zohaib and Ahmad, Kashif and Al-Fuqaha, Ala and Conci, Nicola","meta_info":{"year":"2019","pages":"104--113","booktitle":"CIAP"}}
{"bib_id":"he2019multi","title":"A Multi-Attentive Pyramidal Model for Visual Sentiment Analysis","author":"He, Xiaohao and Zhang, Huijun and Li, Ningyun and Feng, Ling and Zheng, Feng","meta_info":{"year":"2019","pages":"1--8","booktitle":"IJCNN"}}
{"bib_id":"zhang2019another","title":"Another Dimension: Towards Multi-subnet Neural Network for Image Sentiment Analysis","author":"Zhang, Jing and Sun, Han and Wang, Zhe and Ruan, Tong","meta_info":{"year":"2019","pages":"1126--1131","booktitle":"ICME"}}
{"bib_id":"yu2019towards","title":"Towards Unified Aesthetics and Emotion Prediction in Images","author":"Yu, Jun and Cui, Chaoran and Geng, LeiLei and Ma, Yuling and Yin, Yilong","meta_info":{"year":"2019","pages":"2526--2530","booktitle":"ICIP"}}
{"bib_id":"guntuku2019twitter","title":"What Twitter profile and posted images reveal about depression and anxiety","author":"Guntuku, Sharath Chandra and Preotiuc-Pietro, Daniel and Eichstaedt, Johannes C and Ungar, Lyle H","meta_info":{"year":"2019","booktitle":"AAAI"}}
{"bib_id":"al2019smile","title":"Smile, be Happy:) Emoji Embedding for Visual Sentiment Analysis","author":"Al-Halah, Ziad and Aitken, Andrew and Shi, Wenzhe and Caballero, Jose","meta_info":{"year":"2019","booktitle":"ICCVW"}}
{"bib_id":"jindal2015image","title":"Image sentiment analysis using deep convolutional neural networks with domain specific fine tuning","author":"Jindal, Stuti and Singh, Sanjay","meta_info":{"year":"2015","pages":"447--451","booktitle":"IPSN"}}
{"bib_id":"zhao2020endtoend","title":"An End-to-End Visual-Audio Attention Network for Emotion Recognition in User-Generated Videos","author":"Zhao, Sicheng and Ma, Yunsheng and Gu, Yang and Yang, Jufeng and Xing, Tengfei and Xu, Pengfei and Hu, Runbo and Chai, Hua and Keutzer, Kurt","meta_info":{"year":"2020","pages":"303--311","booktitle":"AAAI"}}
{"bib_id":"zhang2019exploring","title":"Exploring Discriminative Representations for Image Emotion Recognition with CNNs","author":"Zhang, Wei and He, Xuanyu and Lu, Weizhi","meta_info":{"year":"2020","pages":"515--523","number":"2","volume":"22","journal":"IEEE TMM"}}
{"bib_id":"zhang2019object","title":"Object semantics sentiment correlation analysis enhanced image sentiment classification","author":"Zhang, Jing and Chen, Mei and Sun, Han and Li, Dongdong and Wang, Zhe","meta_info":{"year":"2020","pages":"105245","volume":"191","journal":"KBS"}}
{"bib_id":"cordel2019emotion","title":"Emotion-Aware Human Attention Prediction","author":"Cordel, Macario O and Fan, Shaojing and Shen, Zhiqi and Kankanhalli, Mohan S","meta_info":{"year":"2019","pages":"4026--4035","booktitle":"CVPR"}}
{"bib_id":"bovik1990multichannel","title":"Multichannel texture analysis using localized spatial filters","author":"Bovik, Alan C. and Clark, Marianna and Geisler, Wilson S.","meta_info":{"year":"1990","pages":"55--73","number":"1","volume":"12","journal":"IEEE TPAMI"}}
{"bib_id":"hassan2019automatic","title":"Automatic detection of pain from facial expressions: a survey","author":"Hassan, Teena and Seuß, Dominik and Wollenberg, Johannes and Weitz, Katharina and Kunz, Miriam and Lautenbacher, Stefan and Garbas, Jens-Uwe and Schmid, Ute","meta_info":{"year":"2019","journal":"IEEE TPAMI"}}
{"bib_id":"kosti2020context","title":"Context Based Emotion Recognition Using EMOTIC Dataset","author":"Kosti, Ronak and Alvarez, Jose and Recasens, Adria and Lapedriza, Agata","meta_info":{"pages":"2755--2766","number":"11","volume":"42","year":"2020","journal":"IEEE TPAMI"}}
{"bib_id":"zhao2020review","title":"A Review of Single-Source Deep Unsupervised Visual Domain Adaptation","author":"Zhao, Sicheng and Yue, Xiangyu and Zhang, Shanghang and Li, Bo and Zhao, Han and Wu, Bichen and Krishna, Ravi and Gonzalez, Joseph E and Sangiovanni-Vincentelli, Alberto L and Seshia, Sanjit A and others","meta_info":{"year":"2020","journal":"IEEE TNNLS"}}
{"bib_id":"zhao2020end","title":"An End-to-End visual-audio attention network for emotion recognition in user-generated videos","author":"Zhao, Sicheng and Ma, Yunsheng and Gu, Yang and Yang, Jufeng and Xing, Tengfei and Xu, Pengfei and Hu, Runbo and Chai, Hua and Keutzer, Kurt","meta_info":{"year":"2020","pages":"303--311","booktitle":"AAAI"}}
{"bib_id":"wei2020learning","title":"Learning Visual Emotion Representations From Web Data","author":"Wei, Zijun and Zhang, Jianming and Lin, Zhe and Lee, Joon-Young and Balasubramanian, Niranjan and Hoai, Minh and Samaras, Dimitris","meta_info":{"year":"2020","pages":"13106--13115","booktitle":"CVPR"}}
{"bib_id":"simonyan2015very","title":"Very deep convolutional networks for large-scale image recognition","author":"Simonyan, Karen and Zisserman, Andrew","meta_info":{"year":"2015","booktitle":"ICLR"}}
{"bib_id":"zhao2020emotion","title":"Emotion-Based End-to-End Matching Between Image and Music in Valence-Arousal Space","author":"Zhao, Sicheng and Li, Yaxian and Yao, Xingxu and Nie, Weizhi and Xu, Pengfei and Yang, Jufeng and Keutzer, Kurt","meta_info":{"year":"2020","pages":"2945--2954","booktitle":"ACM MM"}}
{"bib_id":"zhao2021madan","title":"MADAN: multi-source adversarial domain aggregation network for domain adaptation","author":"Zhao, Sicheng and Li, Bo and Xu, Pengfei and Yue, Xiangyu and Ding, Guiduang and Keutzer, Kurt","meta_info":{"year":"2021","journal":"IJCV"}}
{"bib_id":"liu2015classification","title":"Classification with noisy labels by importance reweighting","author":"Liu, Tongliang and Tao, Dacheng","meta_info":{"year":"2015","pages":"447--461","number":"3","volume":"38","journal":"IEEE TPAMI"}}
{"bib_id":"compton2003interface","title":"The interface between emotion and attention: A review of evidence from psychology and neuroscience","author":"Compton, Rebecca J","meta_info":{"year":"2003","pages":"115--129","number":"2","volume":"2","journal":"BCN"}}
{"bib_id":"zhao2021emotional","title":"Emotional semantics-preserved and feature-aligned cyclegan for visual emotion adaptation","author":"Zhao, Sicheng and Chen, Xuanbai and Yue, Xiangyu and Lin, Chuang and Xu, Pengfei and Krishna, Ravi and Yang, Jufeng and Ding, Guiguang and Sangiovanni-Vincentelli, Alberto L and Keutzer, Kurt","meta_info":{"year":"2021","journal":"IEEE TCYB"}}
{"bib_id":"krizhevsky2012imagenet","title":"Imagenet classification with deep convolutional neural networks","author":"Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E","meta_info":{"year":"2012","pages":"1097--1105","journal":"NIPS"}}
