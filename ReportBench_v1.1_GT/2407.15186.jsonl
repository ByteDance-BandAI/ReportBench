{"bib_id":"DBLP:journals\/eswa\/ChenZD25","title":"Embedding dynamic graph attention mechanism into Clinical Knowledge\nGraph for enhanced diagnostic accuracy","author":"Deng Chen and\nWeiwei Zhang and\nZuohua Ding","meta_info":{"year":"2025","pages":"126215","volume":"267","journal":"Expert Syst. Appl."}}
{"bib_id":"YangSLLMLZ24","title":"SQL-to-Schema Enhances Schema Linking in Text-to-SQL","author":"Sun Yang and\nQiong Su and\nZhishuai Li and\nZiyue Li and\nHangyu Mao and\nChenxi Liu and\nRui Zhao","meta_info":{"year":"2024","publisher":"Springer","pages":"139--145","volume":"14910","series":"Lecture Notes in Computer Science","booktitle":"DEXA (1)"}}
{"bib_id":"OpenSearch-SQL","title":"OpenSearch-SQL: Enhancing Text-to-SQL with Dynamic Few-shot and Consistency\nAlignment","author":"Xiangjin Xie and\nGuangwei Xu and\nLingyan Zhao and\nRuijie Guo","meta_info":{"year":"2025","volume":"abs\/2502.14913","journal":"CoRR"}}
{"bib_id":"Distillery","title":"The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned\nLanguage Models","author":"Karime Maamari and\nFadhil Abubaker and\nDaniel Jaroslawicz and\nAmine Mhedhbi","meta_info":{"year":"2024","volume":"abs\/2408.07702","journal":"CoRR"}}
{"bib_id":"ReFoRCE","title":"ReFoRCE: A Text-to-SQL Agent with Self-Refinement, Format Restriction,\nand Column Exploration","author":"Minghang Deng and\nAshwin Ramachandran and\nCanwen Xu and\nLanxiang Hu and\nZhewei Yao and\nAnupam Datta and\nHao Zhang","meta_info":{"year":"2025","volume":"abs\/2502.00675","journal":"CoRR"}}
{"bib_id":"liu2019roberta","title":"Roberta: A robustly optimized bert pretraining approach","author":"Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin","meta_info":{"year":"2019","journal":"arXiv preprint arXiv:1907.11692"}}
{"bib_id":"devlin2018bert","title":"Bert: Pre-training of deep bidirectional transformers for language understanding","author":"Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina","meta_info":{"organization":"Minneapolis, Minnesota","year":"2019","number":"2","volume":"1","booktitle":"Proceedings of naacL-HLT"}}
{"bib_id":"openai2024o1preview","title":"Introducing OpenAI o1-Preview","author":"OpenAI","meta_info":{"howpublished":"r̆lhttps:\/\/openai.com\/index\/introducing-openai-o1-preview\/","year":"2024"}}
{"bib_id":"zhang2024natural","title":"Natural language interfaces for tabular data querying and visualization: A survey","author":"Zhang, Weixu and Wang, Yifei and Song, Yuanfeng and Wei, Victor Junqiu and Tian, Yuxing and Qi, Yiyan and Chan, Jonathan H and Wong, Raymond Chi-Wing and Yang, Haiqin","meta_info":{"publisher":"IEEE","year":"2024","journal":"IEEE Transactions on Knowledge and Data Engineering"}}
{"bib_id":"hong2024next","title":"Next-generation database interfaces: A survey of llm-based text-to-sql","author":"Hong, Zijin and Yuan, Zheng and Zhang, Qinggang and Chen, Hao and Dong, Junnan and Huang, Feiran and Huang, Xiao","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2406.08426"}}
{"bib_id":"liu2024survey","title":"A Survey of NL2SQL with Large Language Models: Where are we, and where are we going?","author":"Liu, Xinyu and Shen, Shuyu and Li, Boyan and Ma, Peixian and Jiang, Runzhi and Zhang, Yuxin and Fan, Ju and Li, Guoliang and Tang, Nan and Luo, Yuyu","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2408.05109"}}
{"bib_id":"zhu2024large","title":"Large language model enhanced text-to-sql generation: A survey","author":"Zhu, Xiaohu and Li, Qian and Cui, Lizhen and Liu, Yongkang","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2410.06011"}}
{"bib_id":"lester2021power","title":"The power of scale for parameter-efficient prompt tuning","author":"Lester, Brian and Al-Rfou, Rami and Constant, Noah","meta_info":{"year":"2021","journal":"arXiv preprint arXiv:2104.08691"}}
{"bib_id":"spider2","title":"Spider 2.0: Evaluating Language Models on Real-World Enterprise Text-to-SQL Workflows","author":"Fangyu Lei and\nJixuan Chen and\nYuxiao Ye and\nRuisheng Cao and\nDongchan Shin and\nHongjin Su and\nZhaoqing Suo and\nHongcheng Gao and\nWenjing Hu and\nPengcheng Yin and\nVictor Zhong and\nCaiming Xiong and\nRuoxi Sun and\nQian Liu and\nSida I. Wang and\nTao Yu","meta_info":{"year":"2024","volume":"abs\/2411.07763","journal":"CoRR"}}
{"bib_id":"liu2022few","title":"Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning","author":"Liu, Haokun and Tam, Derek and Muqeeth, Mohammed and Mohta, Jay and Huang, Tenghao and Bansal, Mohit and Raffel, Colin A","meta_info":{"year":"2022","pages":"1950--1965","volume":"35","journal":"Advances in Neural Information Processing Systems"}}
{"bib_id":"dettmers2024qlora","title":"Qlora: Efficient finetuning of quantized llms","author":"Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke","meta_info":{"year":"2024","volume":"36","journal":"Advances in Neural Information Processing Systems"}}
{"bib_id":"hu2021lora","title":"Lora: Low-rank adaptation of large language models","author":"Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu","meta_info":{"year":"2021","journal":"arXiv preprint arXiv:2106.09685"}}
{"bib_id":"P-tuning","title":"P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks","author":"Liu, Xiao and Ji, Kaixuan and Fu, Yicheng and Tam, Weng Lam and Du, Zhengxiao and Yang, Zhilin and Tang, Jie","meta_info":{"year":"2021","journal":"arXiv preprint arXiv:2110.07602"}}
{"bib_id":"liu2023gpt","title":"GPT understands, too","author":"Liu, Xiao and Zheng, Yanan and Du, Zhengxiao and Ding, Ming and Qian, Yujie and Yang, Zhilin and Tang, Jie","meta_info":{"publisher":"Elsevier","year":"2023","journal":"AI Open"}}
{"bib_id":"zhang2024benchmarking","title":"Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation","author":"Zhang, Bin and Ye, Yuxiao and Du, Guoqing and Hu, Xiaoru and Li, Zhishuai and Yang, Sun and Liu, Chi Harold and Zhao, Rui and Li, Ziyue and Mao, Hangyu","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2403.02951"}}
{"bib_id":"kahng2024llm","title":"LLM Comparator: Visual Analytics for Side-by-Side Evaluation of Large Language Models","author":"Kahng, Minsuk and Tenney, Ian and Pushkarna, Mahima and Liu, Michael Xieyang and Wexler, James and Reif, Emily and Kallarackal, Krystal and Chang, Minsuk and Terry, Michael and Dixon, Lucas","meta_info":{"year":"2024","pages":"1--7","booktitle":"Extended Abstracts of the CHI Conference on Human Factors in Computing Systems"}}
{"bib_id":"knowledgetosql","title":"Knowledge-to-SQL: Enhancing SQL Generation with Data Expert LLM","author":"Hong, Zijin and Yuan, Zheng and Chen, Hao and Zhang, Qinggang and Huang, Feiran and Huang, Xiao","meta_info":{"year":"2024","pages":"10997--11008","booktitle":"Findings of the Association for Computational Linguistics ACL 2024"}}
{"bib_id":"dtssql","title":"DTS-SQL: Decomposed Text-to-SQL with Small Large Language Models","author":"Pourreza, Mohammadreza and Rafiei, Davood","meta_info":{"year":"2024","pages":"8212--8220","booktitle":"Findings of the Association for Computational Linguistics: EMNLP 2024"}}
{"bib_id":"FinSQL","title":"FinSQL: Model-Agnostic LLMs-based Text-to-SQL Framework for Financial Analysis","author":"Chao Zhang and Yuren Mao and Yijiang Fan and Yu Mi and Yunjun Gao and Lu Chen and Dongfang Lou and Jinshu Lin","meta_info":{"url":"https:\/\/arxiv.org\/abs\/2401.10506","primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2401.10506","year":"2024"}}
{"bib_id":"DataGpt-SQL-7B","title":"DataGpt-SQL-7B: An Open-Source Language Model for Text-to-SQL","author":"Lixia Wu and Peng Li and Junhong Lou and Lei Fu","meta_info":{"url":"https:\/\/arxiv.org\/abs\/2409.15985","primaryclass":"cs.AI","archiveprefix":"arXiv","eprint":"2409.15985","year":"2024"}}
{"bib_id":"Dubo","title":"Dubo-SQL: Diverse Retrieval-Augmented Generation and Fine Tuning for Text-to-SQL","author":"Dayton G. Thorpe and Andrew J. Duberstein and Ian A. Kinsey","meta_info":{"url":"https:\/\/arxiv.org\/abs\/2404.12560","primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2404.12560","year":"2024"}}
{"bib_id":"codeS","title":"CodeS: Towards Building Open-source Language Models for Text-to-SQL","author":"Haoyang Li and Jing Zhang and Hanbing Liu and Ju Fan and Xiaokang Zhang and Jun Zhu and Renjie Wei and Hongyan Pan and Cuiping Li and Hong Chen","meta_info":{"url":"https:\/\/arxiv.org\/abs\/2402.16347","primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2402.16347","year":"2024"}}
{"bib_id":"guo2024deepseek","title":"DeepSeek-Coder: When the Large Language Model Meets Programming-The Rise of Code Intelligence","author":"Daya Guo and\nQihao Zhu and\nDejian Yang and\nZhenda Xie and\nKai Dong and\nWentao Zhang and\nGuanting Chen and\nXiao Bi and\nY. Wu and\nY. K. Li and\nFuli Luo and\nYingfei Xiong and\nWenfeng Liang","meta_info":{"year":"2024","volume":"abs\/2401.14196","journal":"CoRR"}}
{"bib_id":"nijkamp2022codegen","title":"Codegen: An open large language model for code with multi-turn program synthesis","author":"Nijkamp, Erik and Pang, Bo and Hayashi, Hiroaki and Tu, Lifu and Wang, Huan and Zhou, Yingbo and Savarese, Silvio and Xiong, Caiming","meta_info":{"year":"2022","journal":"arXiv preprint arXiv:2203.13474"}}
{"bib_id":"xu2023wizardlm","title":"Wizardlm: Empowering large language models to follow complex instructions","author":"Xu, Can and Sun, Qingfeng and Zheng, Kai and Geng, Xiubo and Zhao, Pu and Feng, Jiazhan and Tao, Chongyang and Jiang, Daxin","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2304.12244"}}
{"bib_id":"jang2023exploring","title":"Exploring the benefits of training expert language models over instruction tuning","author":"Jang, Joel and Kim, Seungone and Ye, Seonghyeon and Kim, Doyoung and Logeswaran, Lajanugen and Lee, Moontae and Lee, Kyungjae and Seo, Minjoon","meta_info":{"organization":"PMLR","year":"2023","pages":"14702--14729","booktitle":"International Conference on Machine Learning"}}
{"bib_id":"Code-llama","title":"Code llama: Open foundation models for code","author":"Roziere, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Remez, Tal and Rapin, Jérémy and others","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2308.12950"}}
{"bib_id":"Db-gpt","title":"Db-gpt: Empowering database interactions with private large language models","author":"Xue, Siqiao and Jiang, Caigao and Shi, Wenhui and Cheng, Fangyin and Chen, Keting and Yang, Hongjun and Zhang, Zhiping and He, Jianshan and Zhang, Hongyang and Wei, Ganglin and others","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2312.17449"}}
{"bib_id":"achiam2023gpt","title":"Gpt-4 technical report","author":"Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2303.08774"}}
{"bib_id":"chen2023teaching","title":"Teaching large language models to self-debug","author":"Chen, Xinyun and Lin, Maxwell and Schärli, Nathanael and Zhou, Denny","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2304.05128"}}
{"bib_id":"WikiSQL","title":"Seq2sql: Generating structured queries from natural language using reinforcement learning","author":"Zhong, Victor and Xiong, Caiming and Socher, Richard","meta_info":{"year":"2017","journal":"arXiv preprint arXiv:1709.00103"}}
{"bib_id":"chang2023dr.spider","title":"Dr. spider: A diagnostic evaluation benchmark towards text-to-sql robustness","author":"Chang, Shuaichen and Wang, Jun and Dong, Mingwen and Pan, Lin and Zhu, Henghui and Li, Alexander Hanbo and Lan, Wuwei and Zhang, Sheng and Jiang, Jiarong and Lilien, Joseph and others","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2301.08881"}}
{"bib_id":"yu2019cosql","title":"Cosql: A conversational text-to-sql challenge towards cross-domain natural language interfaces to databases","author":"Yu, Tao and Zhang, Rui and Er, He Yang and Li, Suyi and Xue, Eric and Pang, Bo and Lin, Xi Victoria and Tan, Yi Chern and Shi, Tianze and Li, Zihan and others","meta_info":{"year":"2019","journal":"arXiv preprint arXiv:1909.05378"}}
{"bib_id":"SParC","title":"Sparc: Cross-domain semantic parsing in context","author":"Yu, Tao and Zhang, Rui and Yasunaga, Michihiro and Tan, Yi Chern and Lin, Xi Victoria and Li, Suyi and Er, Heyang and Li, Irene and Pang, Bo and Chen, Tao and others","meta_info":{"year":"2019","journal":"arXiv preprint arXiv:1906.02285"}}
{"bib_id":"DuSQL","title":"DuSQL: A large-scale and pragmatic Chinese text-to-SQL dataset","author":"Wang, Lijie and Zhang, Ao and Wu, Kun and Sun, Ke and Li, Zhenghua and Wu, Hua and Zhang, Min and Wang, Haifeng","meta_info":{"year":"2020","pages":"6923--6935","booktitle":"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)"}}
{"bib_id":"yao2022react","title":"React: Synergizing reasoning and acting in language models","author":"Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan","meta_info":{"year":"2022","journal":"arXiv preprint arXiv:2210.03629"}}
{"bib_id":"CSpider","title":"A pilot study for Chinese SQL semantic parsing","author":"Min, Qingkai and Shi, Yuefeng and Zhang, Yue","meta_info":{"year":"2019","journal":"arXiv preprint arXiv:1909.13293"}}
{"bib_id":"ADVETA","title":"Towards robustness of text-to-SQL models against natural and realistic adversarial table perturbation","author":"Pi, Xinyu and Wang, Bing and Gao, Yan and Guo, Jiaqi and Li, Zhoujun and Lou, Jian-Guang","meta_info":{"year":"2022","journal":"arXiv preprint arXiv:2212.09994"}}
{"bib_id":"Spider-CG","title":"Measuring and improving compositional generalization in text-to-sql via component alignment","author":"Gan, Yujian and Chen, Xinyun and Huang, Qiuping and Purver, Matthew","meta_info":{"year":"2022","journal":"arXiv preprint arXiv:2205.02054"}}
{"bib_id":"Spider-Realistic","title":"Structure-grounded pretraining for text-to-sql","author":"Deng, Xiang and Awadallah, Ahmed Hassan and Meek, Christopher and Polozov, Oleksandr and Sun, Huan and Richardson, Matthew","meta_info":{"year":"2020","journal":"arXiv preprint arXiv:2010.12773"}}
{"bib_id":"spider-dk","title":"Exploring underexplored limitations of cross-domain text-to-SQL generalization","author":"Gan, Yujian and Chen, Xinyun and Purver, Matthew","meta_info":{"year":"2021","journal":"arXiv preprint arXiv:2109.05157"}}
{"bib_id":"brown2020language","title":"Language models are few-shot learners","author":"Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others","meta_info":{"year":"2020","pages":"1877--1901","volume":"33","journal":"Advances in neural information processing systems"}}
{"bib_id":"aroraageneric","title":"A Generic PROMPT FOR AN LLM THAT ENABLES NL-TO-SQL ACROSS DOMAINS AND COMPOSITIONS","author":"Arora, Aseem and Bhaisaheb, Shabbirhussain and Patwardhan, Manasi and Vig, Lovekesh and Shroff, Gautam","meta_info":{}}
{"bib_id":"li2024can","title":"Can llm already serve as a database interface? a big bench for large-scale database grounded text-to-sqls","author":"Li, Jinyang and Hui, Binyuan and Qu, Ge and Yang, Jiaxi and Li, Binhua and Li, Bowen and Wang, Bailin and Qin, Bowen and Geng, Ruiying and Huo, Nan and others","meta_info":{"year":"2024","volume":"36","journal":"Advances in Neural Information Processing Systems"}}
{"bib_id":"zhang2023sciencebenchmarkcomplexrealworldbenchmark","title":"ScienceBenchmark: A Complex Real-World Benchmark for Evaluating Natural Language to SQL Systems","author":"Yi Zhang and Jan Deriu and George Katsogiannis-Meimarakis and Catherine Kosten and Georgia Koutrika and Kurt Stockinger","meta_info":{"url":"https:\/\/arxiv.org\/abs\/2306.04743","primaryclass":"cs.DB","archiveprefix":"arXiv","eprint":"2306.04743","year":"2023"}}
{"bib_id":"sen:2020","title":"ATHENA++: Natural Language Querying for Complex Nested SQL Queries","author":"Sen, Jaydeep and Lei, Chuan and Quamar, Abdul and Ozcan, Fatma and Efthymiou, Vasilis and Dalmia, Ayushi and Stager, Greg and Mittal, Ashish and Saha, Diptikalyan and Sankaranarayanan, Karthik","meta_info":{"pages":"2747--2759","year":"2020","number":"11","volume":"13","journal":"Proc. VLDB Endow."}}
{"bib_id":"chen2020tabfactlargescaledatasettablebased","title":"TabFact: A Large-scale Dataset for Table-based Fact Verification","author":"Wenhu Chen and Hongmin Wang and Jianshu Chen and Yunkai Zhang and Hong Wang and Shiyang Li and Xiyou Zhou and William Yang Wang","meta_info":{"url":"https:\/\/arxiv.org\/abs\/1909.02164","primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"1909.02164","year":"2020"}}
{"bib_id":"liu2023comprehensive","title":"A comprehensive evaluation of ChatGPT's zero-shot Text-to-SQL capability","author":"Liu, Aiwei and Hu, Xuming and Wen, Lijie and Yu, Philip S","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2303.13547"}}
{"bib_id":"sun2023sql","title":"Sql-palm: Improved large language modeladaptation for text-to-sql","author":"Sun, Ruoxi and Arik, Sercan O and Nakhost, Hootan and Dai, Hanjun and Sinha, Rajarishi and Yin, Pengcheng and Pfister, Tomas","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2306.00739"}}
{"bib_id":"nan2023enhancing","title":"Enhancing text-to-SQL capabilities of large language models: A study on prompt design strategies","author":"Nan, Linyong and Zhao, Yilun and Zou, Weijin and Ri, Narutatsu and Tae, Jaesung and Zhang, Ellen and Cohan, Arman and Radev, Dragomir","meta_info":{"year":"2023","pages":"14935--14956","booktitle":"Findings of the Association for Computational Linguistics: EMNLP 2023"}}
{"bib_id":"gao2023text","title":"Text-to-sql empowered by large language models: A benchmark evaluation","author":"Gao, Dawei and Wang, Haibin and Li, Yaliang and Sun, Xiuyu and Qian, Yichen and Ding, Bolin and Zhou, Jingren","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2308.15363"}}
{"bib_id":"guo2023case","title":"A case-based reasoning framework for adaptive prompting in cross-domain text-to-sql","author":"Guo, Chunxi and Tian, Zhiliang and Tang, Jintao and Wang, Pancheng and Wen, Zhihua and Yang, Kang and Wang, Ting","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2304.13301"}}
{"bib_id":"guo2023prompting","title":"Prompting GPT-3.5 for Text-to-SQL with De-semanticization and Skeleton Retrieval","author":"Guo, Chunxi and Tian, Zhiliang and Tang, Jintao and Wang, Pancheng and Wen, Zhihua and Yang, Kang and Wang, Ting","meta_info":{"organization":"Springer","year":"2023","pages":"262--274","booktitle":"Pacific Rim International Conference on Artificial Intelligence"}}
{"bib_id":"zhang2023act","title":"Act-sql: In-context learning for text-to-sql with automatically-generated chain-of-thought","author":"Zhang, Hanchong and Cao, Ruisheng and Chen, Lu and Xu, Hongshen and Yu, Kai","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2310.17342"}}
{"bib_id":"arora2023adapt","title":"Adapt and Decompose: Efficient Generalization of Text-to-SQL via Domain Adapted Least-To-Most Prompting","author":"Arora, Aseem and Bhaisaheb, Shabbirhussain and Patwardhan, Manasi and Vig, Lovekesh and Shroff, Gautam","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2308.02582"}}
{"bib_id":"pourreza2024din","title":"Din-sql: Decomposed in-context learning of text-to-sql with self-correction","author":"Pourreza, Mohammadreza and Rafiei, Davood","meta_info":{"year":"2024","volume":"36","journal":"Advances in Neural Information Processing Systems"}}
{"bib_id":"wang2023mac","title":"Mac-sql: Multi-agent collaboration for text-to-sql","author":"Wang, Bing and Ren, Changyu and Yang, Jian and Liang, Xinnian and Bai, Jiaqi and Zhang, Qian-Wen and Yan, Zhao and Li, Zhoujun","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2312.11242"}}
{"bib_id":"cheng2022binding","title":"Binding language models in symbolic languages","author":"Cheng, Zhoujun and Xie, Tianbao and Shi, Peng and Li, Chengzu and Nadkarni, Rahul and Hu, Yushi and Xiong, Caiming and Radev, Dragomir and Ostendorf, Mari and Zettlemoyer, Luke and others","meta_info":{"year":"2022","journal":"arXiv preprint arXiv:2210.02875"}}
{"bib_id":"kothyari2023crush4sql","title":"CRUSH4SQL: Collective retrieval using schema hallucination for Text2SQL","author":"Kothyari, Mayank and Dhingra, Dhruva and Sarawagi, Sunita and Chakrabarti, Soumen","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2311.01173"}}
{"bib_id":"dong2023c3","title":"C3: Zero-shot text-to-sql with chatgpt","author":"Dong, Xuemei and Zhang, Chao and Ge, Yuhang and Mao, Yuren and Gao, Yunjun and Lin, Jinshu and Lou, Dongfang and others","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2307.07306"}}
{"bib_id":"liu2023divide","title":"Divide and prompt: Chain of thought prompting for text-to-sql","author":"Liu, Xiping and Tan, Zhao","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2304.11556"}}
{"bib_id":"wei2022chain","title":"Chain-of-thought prompting elicits reasoning in large language models","author":"Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others","meta_info":{"year":"2022","pages":"24824--24837","volume":"35","journal":"Advances in neural information processing systems"}}
{"bib_id":"zhou2022least","title":"Least-to-most prompting enables complex reasoning in large language models","author":"Zhou, Denny and Schärli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc and others","meta_info":{"year":"2022","journal":"arXiv preprint arXiv:2205.10625"}}
{"bib_id":"wang2022self","title":"Self-consistency improves chain of thought reasoning in language models","author":"Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny","meta_info":{"year":"2022","journal":"arXiv preprint arXiv:2203.11171"}}
{"bib_id":"tai2023exploring","title":"Exploring Chain of Thought Style Prompting for Text-to-SQL","author":"Tai, Chang-Yu and Chen, Ziru and Zhang, Tianshu and Deng, Xiang and Sun, Huan","meta_info":{"year":"2023","pages":"5376--5393","booktitle":"Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing"}}
{"bib_id":"yu2018spider","title":"Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task","author":"Yu, Tao and Zhang, Rui and Yang, Kai and Yasunaga, Michihiro and Wang, Dongxu and Li, Zifan and Ma, James and Li, Irene and Yao, Qingning and Roman, Shanelle and others","meta_info":{"year":"2018","journal":"arXiv preprint arXiv:1809.08887"}}
{"bib_id":"NL2SQLisnot","title":"NL2SQL is a solved problem... Not!","author":"Floratou, Avrilia and Psallidas, Fotis","meta_info":{"year":"2024","journal":"Conference on Innovative Data Systems Research"}}
{"bib_id":"NL2SQLisnot","title":"NL2SQL is a solved problem... Not!","author":"Avrilia Floratou and\nFotis Psallidas and\nFuheng Zhao and\nShaleen Deep and\nGunther Hagleither and\nWangda Tan and\nJoyce Cahoon and\nRana Alotaibi and\nJordan Henkel and\nAbhik Singla and\nothers","meta_info":{"year":"2024","publisher":"www.cidrdb.org","booktitle":"CIDR"}}
{"bib_id":"zhong2020semantic","title":"Semantic evaluation for text-to-SQL with distilled test suites","author":"Zhong, Ruiqi and Yu, Tao and Klein, Dan","meta_info":{"year":"2020","journal":"arXiv preprint arXiv:2010.02840"}}
{"bib_id":"li2023resdsql","title":"Resdsql: Decoupling schema linking and skeleton parsing for text-to-sql","author":"Li, Haoyang and Zhang, Jing and Li, Cuiping and Chen, Hong","meta_info":{"year":"2023","pages":"13067--13075","number":"11","volume":"37","booktitle":"Proceedings of the AAAI Conference on Artificial Intelligence"}}
{"bib_id":"scholak2021picard","title":"PICARD: Parsing incrementally for constrained auto-regressive decoding from language models","author":"Scholak, Torsten and Schucher, Nathan and Bahdanau, Dzmitry","meta_info":{"year":"2021","journal":"arXiv preprint arXiv:2109.05093"}}
{"bib_id":"wang2019rat","title":"Rat-sql: Relation-aware schema encoding and linking for text-to-sql parsers","author":"Wang, Bailin and Shin, Richard and Liu, Xiaodong and Polozov, Oleksandr and Richardson, Matthew","meta_info":{"year":"2019","journal":"arXiv preprint arXiv:1911.04942"}}
{"bib_id":"chen2021evaluating","title":"Evaluating large language models trained on code","author":"Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others","meta_info":{"year":"2021","journal":"arXiv preprint arXiv:2107.03374"}}
{"bib_id":"rajkumar2022evaluating","title":"Evaluating the Text-to-SQL Capabilities of Large Language Models","author":"Nitarshan Rajkumar and\nRaymond Li and\nDzmitry Bahdanau","meta_info":{"year":"2022","volume":"abs\/2204.00498","journal":"CoRR"}}
{"bib_id":"zelle1996learning","title":"Learning to parse database queries using inductive logic programming","author":"Zelle, John M and Mooney, Raymond J","meta_info":{"year":"1996","pages":"1050--1055","booktitle":"Proceedings of the national conference on artificial intelligence"}}
{"bib_id":"zhao2023survey","title":"A survey of large language models","author":"Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2303.18223"}}
{"bib_id":"wei2021finetuned","title":"Finetuned language models are zero-shot learners","author":"Wei, Jason and Bosma, Maarten and Zhao, Vincent Y and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V","meta_info":{"year":"2021","journal":"arXiv preprint arXiv:2109.01652"}}
{"bib_id":"ascoli2024esm+","title":"ESM+: Modern Insights into Perspective on Text-to-SQL Evaluation in the Age of Large Language Models","author":"Ascoli, Benjamin and Kandikonda, Ram and Choi, Jinho D","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2407.07313"}}
{"bib_id":"zhou2024db","title":"DB-GPT-Hub: Towards Open Benchmarking Text-to-SQL Empowered by Large\nLanguage Models","author":"Fan Zhou and\nSiqiao Xue and\nDanrui Qi and\nWenhui Shi and\nWang Zhao and\nGanglin Wei and\nHongyang Zhang and\nCaigai Jiang and\nGangwei Jiang and\nZhixuan Chu and\nFaqiang Chen","meta_info":{"year":"2024","volume":"abs\/2406.11434","journal":"CoRR"}}
{"bib_id":"qin2022survey","title":"A survey on text-to-sql parsing: Concepts, methods, and future directions","author":"Qin, Bowen and Hui, Binyuan and Wang, Lihan and Yang, Min and Li, Jinyang and Li, Binhua and Geng, Ruiying and Cao, Rongyu and Sun, Jian and Si, Luo and others","meta_info":{"year":"2022","journal":"arXiv preprint arXiv:2208.13629"}}
{"bib_id":"hou2023large","title":"Large language models for software engineering: A systematic literature review","author":"Hou, Xinyi and Zhao, Yanjie and Liu, Yue and Yang, Zhou and Wang, Kailong and Li, Li and Luo, Xiapu and Lo, David and Grundy, John and Wang, Haoyu","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2308.10620"}}
{"bib_id":"dam2024complete","title":"A Complete Survey on LLM-based AI Chatbots","author":"Dam, Sumit Kumar and Hong, Choong Seon and Qiao, Yu and Zhang, Chaoning","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2406.16937"}}
{"bib_id":"wang2024survey","title":"A survey on large language model based autonomous agents","author":"Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and others","meta_info":{"publisher":"Springer","year":"2024","pages":"186345","number":"6","volume":"18","journal":"Frontiers of Computer Science"}}
{"bib_id":"sutskever2014sequence","title":"Sequence to sequence learning with neural networks","author":"Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V","meta_info":{"year":"2014","volume":"27","journal":"Advances in neural information processing systems"}}
{"bib_id":"li2014constructing","title":"Constructing an interactive natural language interface for relational databases","author":"Li, Fei and Jagadish, Hosagrahar V","meta_info":{"publisher":"VLDB Endowment","year":"2014","pages":"73--84","number":"1","volume":"8","journal":"Proceedings of the VLDB Endowment"}}
{"bib_id":"sui2023reboost","title":"Reboost Large Language Model-based Text-to-SQL, Text-to-Python, and Text-to-Function--with Real Applications in Traffic Domain","author":"Sui, Guanghu and Li, Zhishuai and Li, Ziyue and Yang, Sun and Ruan, Jingqing and Mao, Hangyu and Zhao, Rui","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2310.18752"}}
{"bib_id":"lee2021kaggledbqa","title":"KaggleDBQA: Realistic evaluation of text-to-SQL parsers","author":"Lee, Chia-Hsuan and Polozov, Oleksandr and Richardson, Matthew","meta_info":{"year":"2021","journal":"arXiv preprint arXiv:2106.11455"}}
{"bib_id":"anil2023palm","title":"Palm 2 technical report","author":"Anil, Rohan and Dai, Andrew M and Firat, Orhan and Johnson, Melvin and Lepikhin, Dmitry and Passos, Alexandre and Shakeri, Siamak and Taropa, Emanuel and Bailey, Paige and Chen, Zhifeng and others","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2305.10403"}}
{"bib_id":"wang2023dbcopilot","title":"DBCopilot: Scaling Natural Language Querying to Massive Databases","author":"Wang, Tianshu and Lin, Hongyu and Han, Xianpei and Sun, Le and Chen, Xiaoyang and Wang, Hao and Zeng, Zhenyu","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2312.03463"}}
{"bib_id":"chang2023prompt","title":"How to prompt llms for text-to-sql: A study in zero-shot, single-domain, and cross-domain settings","author":"Chang, Shuaichen and Fosler-Lussier, Eric","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2305.11853"}}
{"bib_id":"li2024pet","title":"PET-SQL: A Prompt-enhanced Two-stage Text-to-SQL Framework with Cross-consistency","author":"Li, Zhishuai and Wang, Xiang and Zhao, Jingjing and Yang, Sun and Du, Guoqing and Hu, Xiaoru and Zhang, Bin and Ye, Yuxiao and Li, Ziyue and Zhao, Rui and others","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2403.09732"}}
{"bib_id":"hochreiter1997long","title":"Long short-term memory","author":"Hochreiter, Sepp and Schmidhuber, Jürgen","meta_info":{"publisher":"MIT press","year":"1997","pages":"1735--1780","number":"8","volume":"9","journal":"Neural computation"}}
{"bib_id":"vaswani2017attention","title":"Attention is all you need","author":"Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia","meta_info":{"year":"2017","volume":"30","journal":"Advances in neural information processing systems"}}
{"bib_id":"touvron2023llama","title":"Llama: Open and efficient foundation language models","author":"Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timothée and Rozière, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2302.13971"}}
{"bib_id":"llama3","title":"The llama 3 herd of models","author":"Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2407.21783"}}
{"bib_id":"kaplan2020scaling","title":"Scaling laws for neural language models","author":"Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario","meta_info":{"year":"2020","journal":"arXiv preprint arXiv:2001.08361"}}
{"bib_id":"wei2022emergent","title":"Emergent abilities of large language models","author":"Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others","meta_info":{"year":"2022","journal":"arXiv preprint arXiv:2206.07682"}}
{"bib_id":"gao2023retrieval","title":"Retrieval-augmented generation for large language models: A survey","author":"Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Haofen","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2312.10997"}}
{"bib_id":"yao2024tree","title":"Tree of thoughts: Deliberate problem solving with large language models","author":"Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik","meta_info":{"year":"2024","volume":"36","journal":"Advances in Neural Information Processing Systems"}}
{"bib_id":"zhang2023instruction","title":"Instruction tuning for large language models: A survey","author":"Zhang, Shengyu and Dong, Linfeng and Li, Xiaoya and Zhang, Sen and Sun, Xiaofei and Wang, Shuhe and Li, Jiwei and Hu, Runyi and Zhang, Tianwei and Wu, Fei and others","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2308.10792"}}
{"bib_id":"han2024parameter","title":"Parameter-efficient fine-tuning for large models: A comprehensive survey","author":"Zeyu Han and\nChao Gao and\nJinyang Liu and\nJeff Zhang and\nSai Qian Zhang","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2403.14608"}}
{"bib_id":"bai2022training","title":"Training a helpful and harmless assistant with reinforcement learning from human feedback","author":"Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others","meta_info":{"year":"2022","journal":"arXiv preprint arXiv:2204.05862"}}
{"bib_id":"chang2024survey","title":"A survey on evaluation of large language models","author":"Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and others","meta_info":{"publisher":"ACM New York, NY","year":"2024","pages":"1--45","number":"3","volume":"15","journal":"ACM Transactions on Intelligent Systems and Technology"}}
{"bib_id":"wang2022deep","title":"Deep reinforcement learning: A survey","author":"Wang, Xu and Wang, Sen and Liang, Xingxing and Zhao, Dawei and Huang, Jincai and Xu, Xin and Dai, Bin and Miao, Qiguang","meta_info":{"publisher":"IEEE","year":"2022","pages":"5064--5078","number":"4","volume":"35","journal":"IEEE Transactions on Neural Networks and Learning Systems"}}
{"bib_id":"li2021prefix","title":"Prefix-tuning: Optimizing continuous prompts for generation","author":"Li, Xiang Lisa and Liang, Percy","meta_info":{"year":"2021","journal":"arXiv preprint arXiv:2101.00190"}}
{"bib_id":"floridi2020gpt","title":"GPT-3: Its nature, scope, limits, and consequences","author":"Floridi, Luciano and Chiriatti, Massimo","meta_info":{"publisher":"Springer","year":"2020","pages":"681--694","volume":"30","journal":"Minds and Machines"}}
{"bib_id":"team2023gemini","title":"Gemini: a family of highly capable multimodal models","author":"Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others","meta_info":{"year":"2023","journal":"arXiv preprint arXiv:2312.11805"}}
{"bib_id":"katsogiannis2023survey","title":"A survey on deep learning approaches for text-to-SQL","author":"Katsogiannis-Meimarakis, George and Koutrika, Georgia","meta_info":{"publisher":"Springer","year":"2023","pages":"905--936","number":"4","volume":"32","journal":"The VLDB Journal"}}
{"bib_id":"xu2017sqlnet","title":"Sqlnet: Generating structured queries from natural language without reinforcement learning","author":"Xu, Xiaojun and Liu, Chang and Song, Dawn","meta_info":{"year":"2017","journal":"arXiv preprint arXiv:1711.04436"}}
{"bib_id":"bogin2019representing","title":"Representing schema structure with graph neural networks for text-to-SQL parsing","author":"Bogin, Ben and Gardner, Matt and Berant, Jonathan","meta_info":{"year":"2019","journal":"arXiv preprint arXiv:1905.06241"}}
{"bib_id":"jha2019irnet","title":"IRNet: A general purpose deep residual regression framework for materials discovery","author":"Jha, Dipendra and Ward, Logan and Yang, Zijiang and Wolverton, Christopher and Foster, Ian and Liao, Wei-keng and Choudhary, Alok and Agrawal, Ankit","meta_info":{"year":"2019","pages":"2385--2393","booktitle":"Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining"}}
{"bib_id":"lyu2020hybrid","title":"Hybrid ranking network for text-to-sql","author":"Lyu, Qin and Chakrabarti, Kaushik and Hathi, Shobhit and Kundu, Souvik and Zhang, Jianwen and Chen, Zheng","meta_info":{"year":"2020","journal":"arXiv preprint arXiv:2008.04759"}}
{"bib_id":"choi2021ryansql","title":"Ryansql: Recursively applying sketch-based slot fillings for complex text-to-sql in cross-domain databases","author":"Choi, DongHyun and Shin, Myeong Cheol and Kim, EungGyun and Shin, Dong Ryeol","meta_info":{"publisher":"MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…","year":"2021","pages":"309--332","number":"2","volume":"47","journal":"Computational Linguistics"}}
{"bib_id":"10.1145\/3534678.3539294","title":"Semantic Enhanced Text-to-SQL Parsing via Iteratively Learning Schema Linking Graph","author":"Liu, Aiwei and Hu, Xuming and Lin, Li and Wen, Lijie","meta_info":{"series":"KDD '22","location":"Washington DC, USA","keywords":"graph neural networks, model robustness, text-to-sql","numpages":"10","pages":"1021–1030","booktitle":"Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining","abstract":"The generalizability to new databases is of vital importance to Text-to-SQL systems which aim to parse human utterances into SQL statements. Existing works achieve this goal by leveraging the exact matching method to identify the lexical matching between the question words and the schema items. However, these methods fail in other challenging scenarios, such as the synonym substitution in which the surface form differs between the corresponding question words and schema items. In this paper, we propose a framework named ISESL-SQL to iteratively build a semantic enhanced schema-linking graph between question tokens and database schemas. First, we extract a schema linking graph from PLMs through a probing procedure in an unsupervised manner. Then the schema linking graph is further optimized during the training process through a deep graph learning method. Meanwhile, we also design an auxiliary task called graph regularization to improve the schema information mentioned in the schema-linking graph. Extensive experiments on three benchmarks demonstrate that ISESL-SQL could consistently outperform the baselines and further investigations show its generalizability and robustness.","doi":"10.1145\/3534678.3539294","url":"https:\/\/doi.org\/10.1145\/3534678.3539294","address":"New York, NY, USA","publisher":"Association for Computing Machinery","isbn":"9781450393850","year":"2022"}}
{"bib_id":"fu2024break","title":"Break the sequential dependency of llm inference using lookahead decoding","author":"Fu, Yichao and Bailis, Peter and Stoica, Ion and Zhang, Hao","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2402.02057"}}
{"bib_id":"lin-etal-2020-bridging","title":"Bridging Textual and Tabular Data for Cross-Domain Text-to-SQL Semantic Parsing","author":"Lin, Xi Victoria  and\nSocher, Richard  and\nXiong, Caiming","meta_info":{"abstract":"We present BRIDGE, a powerful sequential architecture for modeling dependencies between natural language questions and relational databases in cross-DB semantic parsing. BRIDGE represents the question and DB schema in a tagged sequence where a subset of the fields are augmented with cell values mentioned in the question. The hybrid sequence is encoded by BERT with minimal subsequent layers and the text-DB contextualization is realized via the fine-tuned deep attention in BERT. Combined with a pointer-generator decoder with schema-consistency driven search space pruning, BRIDGE attained state-of-the-art performance on the well-studied Spider benchmark (65.5% dev, 59.2% test), despite being much simpler than most recently proposed models for this task. Our analysis shows that BRIDGE effectively captures the desired cross-modal dependencies and has the potential to generalize to more text-DB related tasks. Our model implementation is available at r̆lhttps:\/\/github.com\/salesforce\/TabularSemanticParsing.","pages":"4870--4888","doi":"10.18653\/v1\/2020.findings-emnlp.438","url":"https:\/\/aclanthology.org\/2020.findings-emnlp.438","publisher":"Association for Computational Linguistics","address":"Online","year":"2020","month":"November","booktitle":"Findings of the Association for Computational Linguistics: EMNLP 2020","editor":"Cohn, Trevor  and\nHe, Yulan  and\nLiu, Yang"}}
{"bib_id":"mellah2021combine","title":"COMBINE: A Pipeline for SQL Generation from Natural Language","author":"Mellah, Youssef and Rhouati, Abdelkader and Ettifouri, El Hassane and Bouchentouf, Toumi and Belkasmi, Mohammed Ghaouth","meta_info":{"organization":"Springer","year":"2021","pages":"97--106","booktitle":"Advances in Computing and Data Sciences: 5th International Conference, ICACDS 2021, Nashik, India, April 23--24, 2021, Revised Selected Papers, Part II 5"}}
{"bib_id":"DBLP:journals\/corr\/abs-2010-12412","title":"SmBoP: Semi-autoregressive Bottom-up Semantic Parsing","author":"Ohad Rubin and\nJonathan Berant","meta_info":{"bibsource":"dblp computer science bibliography, https:\/\/dblp.org","biburl":"https:\/\/dblp.org\/rec\/journals\/corr\/abs-2010-12412.bib","timestamp":"Tue, 27 Oct 2020 11:22:08 +0100","eprint":"2010.12412","eprinttype":"arXiv","url":"https:\/\/arxiv.org\/abs\/2010.12412","year":"2020","volume":"abs\/2010.12412","journal":"CoRR"}}
{"bib_id":"qi-etal-2022-rasat","title":"RASAT: Integrating Relational Structures into Pretrained Seq2Seq Model for Text-to-SQL","author":"Qi, Jiexing  and\nTang, Jingyao  and\nHe, Ziwei  and\nWan, Xiangpeng  and\nCheng, Yu  and\nZhou, Chenghu  and\nWang, Xinbing  and\nZhang, Quanshi  and\nLin, Zhouhan","meta_info":{"abstract":"Relational structures such as schema linking and schema encoding have been validated as a key component to qualitatively translating natural language into SQL queries. However, introducing these structural relations comes with prices: they often result in a specialized model structure, which largely prohibits using large pretrained models in text-to-SQL. To address this problem, we propose RASAT: a Transformer seq2seq architecture augmented with relation-aware self-attention that could leverage a variety of relational structures while inheriting the pretrained parameters from the T5 model effectively. Our model can incorporate almost all types of existing relations in the literature, and in addition, we propose introducing co-reference relations for the multi-turn scenario. Experimental results on three widely used text-to-SQL datasets, covering both single-turn and multi-turn scenarios, have shown that RASAT could achieve competitive results in all three benchmarks, achieving state-of-the-art execution accuracy (75.5% EX on Spider, 52.6% IEX on SParC, and 37.4% IEX on CoSQL).","pages":"3215--3229","doi":"10.18653\/v1\/2022.emnlp-main.211","url":"https:\/\/aclanthology.org\/2022.emnlp-main.211","publisher":"Association for Computational Linguistics","address":"Abu Dhabi, United Arab Emirates","year":"2022","month":"December","booktitle":"Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing","editor":"Goldberg, Yoav  and\nKozareva, Zornitsa  and\nZhang, Yue"}}
{"bib_id":"gan2021natural","title":"Natural SQL: Making SQL easier to infer from natural language specifications","author":"Gan, Yujian and Chen, Xinyun and Xie, Jinxia and Purver, Matthew and Woodward, John R and Drake, John and Zhang, Qiaofu","meta_info":{"year":"2021","journal":"arXiv preprint arXiv:2109.05153"}}
{"bib_id":"r3","title":"$R^3$: \"This is My SQL, Are You With Me?\" A Consensus-Based Multi-Agent System for Text-to-SQL Tasks","author":"Hanchen Xia and Feng Jiang and Naihao Deng and Cunxiang Wang and Guojiang Zhao and Rada Mihalcea and Yue Zhang","meta_info":{"url":"https:\/\/arxiv.org\/abs\/2402.14851","primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2402.14851","year":"2024"}}
{"bib_id":"ren2024purplemakinglargelanguage","title":"PURPLE: Making a Large Language Model a Better SQL Writer","author":"Tonghui Ren and Yuankai Fan and Zhenying He and Ren Huang and Jiaqi Dai and Can Huang and Yinan Jing and Kai Zhang and Yifan Yang and X. Sean Wang","meta_info":{"url":"https:\/\/arxiv.org\/abs\/2403.20014","primaryclass":"cs.DB","archiveprefix":"arXiv","eprint":"2403.20014","year":"2024"}}
{"bib_id":"zhang2024structureguidedlargelanguage","title":"Structure Guided Large Language Model for SQL Generation","author":"Qinggang Zhang and Junnan Dong and Hao Chen and Wentao Li and Feiran Huang and Xiao Huang","meta_info":{"url":"https:\/\/arxiv.org\/abs\/2402.13284","primaryclass":"cs.DB","archiveprefix":"arXiv","eprint":"2402.13284","year":"2024"}}
{"bib_id":"coe","title":"CoE-SQL: In-Context Learning for Multi-Turn Text-to-SQL with Chain-of-Editions","author":"Hanchong Zhang and Ruisheng Cao and Hongshen Xu and Lu Chen and Kai Yu","meta_info":{"url":"https:\/\/arxiv.org\/abs\/2405.02712","primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2405.02712","year":"2024"}}
{"bib_id":"deasql","title":"Decomposition for Enhancing Attention: Improving LLM-based Text-to-SQL through Workflow Paradigm","author":"Yuanzhen Xie and Xinzhou Jin and Tao Xie and MingXiong Lin and Liang Chen and Chenyun Yu and Lei Cheng and ChengXiang Zhuo and Bo Hu and Zang Li","meta_info":{"url":"https:\/\/arxiv.org\/abs\/2402.10671","primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2402.10671","year":"2024"}}
{"bib_id":"opensql","title":"Open-SQL Framework: Enhancing Text-to-SQL on Open-source Large Language Models","author":"Xiaojun Chen and Tianle Wang and Tianhao Qiu and Jianbin Qin and Min Yang","meta_info":{"url":"https:\/\/arxiv.org\/abs\/2405.06674","primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2405.06674","year":"2024"}}
{"bib_id":"chess","title":"CHESS: Contextual Harnessing for Efficient SQL Synthesis","author":"Shayan Talaei and Mohammadreza Pourreza and Yu-Chen Chang and Azalia Mirhoseini and Amin Saberi","meta_info":{"url":"https:\/\/arxiv.org\/abs\/2405.16755","primaryclass":"cs.LG","archiveprefix":"arXiv","eprint":"2405.16755","year":"2024"}}
{"bib_id":"zhang2024sqlfuseenhancingtexttosqlperformance","title":"SQLfuse: Enhancing Text-to-SQL Performance through Comprehensive LLM Synergy","author":"Tingkai Zhang and Chaoyu Chen and Cong Liao and Jun Wang and Xudong Zhao and Hang Yu and Jianchao Wang and Jianguo Li and Wenhui Shi","meta_info":{"url":"https:\/\/arxiv.org\/abs\/2407.14568","primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2407.14568","year":"2024"}}
{"bib_id":"ni2023leverlearningverifylanguagetocode","title":"LEVER: Learning to Verify Language-to-Code Generation with Execution","author":"Ansong Ni and Srini Iyer and Dragomir Radev and Ves Stoyanov and Wen-tau Yih and Sida I. Wang and Xi Victoria Lin","meta_info":{"url":"https:\/\/arxiv.org\/abs\/2302.08468","primaryclass":"cs.LG","archiveprefix":"arXiv","eprint":"2302.08468","year":"2023"}}
{"bib_id":"fused","title":"Improving Demonstration Diversity by Human-Free Fusing for Text-to-SQL","author":"Dingzirui Wang and Longxu Dou and Xuanliang Zhang and Qingfu Zhu and Wanxiang Che","meta_info":{"url":"https:\/\/arxiv.org\/abs\/2402.10663","primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2402.10663","year":"2024"}}
{"bib_id":"retrievalandrevision","title":"Retrieval-augmented GPT-3.5-based Text-to-SQL Framework with Sample-aware Prompting and Dynamic Revision Chain","author":"Chunxi Guo and Zhiliang Tian and Jintao Tang and Shasha Li and Zhihua Wen and Kaixuan Wang and Ting Wang","meta_info":{"url":"https:\/\/arxiv.org\/abs\/2307.05074","primaryclass":"cs.IR","archiveprefix":"arXiv","eprint":"2307.05074","year":"2023"}}
{"bib_id":"metasql","title":"Metasql: A Generate-then-Rank Framework for Natural Language to SQL Translation","author":"Yuankai Fan and Zhenying He and Tonghui Ren and Can Huang and Yinan Jing and Kai Zhang and X. Sean Wang","meta_info":{"url":"https:\/\/arxiv.org\/abs\/2402.17144","primaryclass":"cs.DB","archiveprefix":"arXiv","eprint":"2402.17144","year":"2024"}}
{"bib_id":"selfcorrection","title":"Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies","author":"Liangming Pan and Michael Saxon and Wenda Xu and Deepak Nathani and Xinyi Wang and William Yang Wang","meta_info":{"url":"https:\/\/arxiv.org\/abs\/2308.03188","primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2308.03188","year":"2023"}}
{"bib_id":"settles2009activelearning","title":"Active learning literature survey","author":"Settles, Burr","meta_info":{"publisher":"University of Wisconsin-Madison Department of Computer Sciences","year":"2009"}}
{"bib_id":"khot2022decomposed","title":"Decomposed prompting: A modular approach for solving complex tasks","author":"Khot, Tushar and Trivedi, Harsh and Finlayson, Matthew and Fu, Yao and Richardson, Kyle and Clark, Peter and Sabharwal, Ashish","meta_info":{"year":"2022","journal":"arXiv preprint arXiv:2210.02406"}}
{"bib_id":"fried2022incoder","title":"Incoder: A generative model for code infilling and synthesis","author":"Fried, Daniel and Aghajanyan, Armen and Lin, Jessy and Wang, Sida and Wallace, Eric and Shi, Freda and Zhong, Ruiqi and Yih, Wen-tau and Zettlemoyer, Luke and Lewis, Mike","meta_info":{"journal":"arXiv preprint arXiv:2204.05999"}}
{"bib_id":"sqlcoder","title":"Defog SQLCoder","author":"Srivastava, Rishabh and Aw, Wendy","meta_info":{"url":"https:\/\/github.com\/defog-ai\/sqlcoder","journal":"GitHub repository","publisher":"GitHub","year":"2023"}}
{"bib_id":"alpaca","title":"Stanford Alpaca: An Instruction-following LLaMA model","author":"Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto ","meta_info":{"howpublished":"r̆lhttps:\/\/github.com\/tatsu-lab\/stanford_alpaca","journal":"GitHub repository","publisher":"GitHub","year":"2023"}}
{"bib_id":"vicuna","title":"Judging LLM-as-a-judge with MT-Bench and Chatbot Arena","author":"Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric. P Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2306.05685","year":"2023"}}
{"bib_id":"cai2024internlm2","title":"InternLM2 Technical Report","author":"Zheng Cai and\nMaosong Cao and\nHaojiong Chen and\nKai Chen and\nKeyu Chen and\nXin Chen and\nXun Chen and\nZehui Chen and\nZhi Chen and\nPei Chu and others","meta_info":{"primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2403.17297","year":"2024"}}
{"bib_id":"SenseChat","title":"SenseChat","author":"SenseTime","meta_info":{"year":"2024","url":"https:\/\/platform.sensenova.cn\/#\/doc?path=\/chat\/\nChatCompletions\/ChatCompletions.md"}}
{"bib_id":"cogsql","title":"CogSQL: A Cognitive Framework for Enhancing Large Language Models in Text-to-SQL Translation","author":"Yuan, Hongwei and Tang, Xiu and Chen, Ke and Shou, Lidan and Chen, Gang and Li, Huan","meta_info":{"year":"2025","pages":"25778--25786","number":"24","volume":"39","booktitle":"Proceedings of the AAAI Conference on Artificial Intelligence"}}
{"bib_id":"ptdsql","title":"PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL","author":"Luo, Ruilin and Wang, Liyuan and Lin, Binghuai and Lin, Zicheng and Yang, Yujiu","meta_info":{"year":"2024","pages":"3767--3799","booktitle":"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing"}}
{"bib_id":"magsql","title":"Mag-sql: Multi-agent generative approach with soft schema linking and iterative sub-sql refinement for text-to-sql","author":"Xie, Wenxuan and Wu, Gaochen and Zhou, Bowen","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2408.07930"}}
{"bib_id":"feathersql","title":"Feather-SQL: A Lightweight NL2SQL Framework with Dual-Model Collaboration Paradigm for Small Language Models","author":"Pei, Wenqi and Xu, Hailing and Zhao, Hengyuan and Hou, Shizheng and Chen, Han and Zhang, Zining and Luo, Pingyi and He, Bingsheng","meta_info":{"year":"2025","journal":"arXiv preprint arXiv:2503.17811"}}
{"bib_id":"basesql","title":"BASE-SQL: A powerful open source Text-To-SQL baseline approach","author":"Sheng, Lei and Xu, Shuai-Shuai and Xie, Wei","meta_info":{"year":"2025","journal":"arXiv preprint arXiv:2502.10739"}}
{"bib_id":"mcssql","title":"MCS-SQL: Leveraging Multiple Prompts and Multiple-Choice Selection For Text-to-SQL Generation","author":"Lee, Dongjun and Park, Choongwon and Kim, Jaehyuk and Park, Heesoo","meta_info":{"year":"2025","pages":"337--353","booktitle":"Proceedings of the 31st International Conference on Computational Linguistics"}}
{"bib_id":"chasesql","title":"Chase-sql: Multi-path reasoning and preference optimized candidate selection in text-to-sql","author":"Pourreza, Mohammadreza and Li, Hailong and Sun, Ruoxi and Chung, Yeounoh and Talaei, Shayan and Kakkar, Gaurav Tarlok and Gan, Yu and Saberi, Amin and Ozcan, Fatma and Arik, Sercan O","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2410.01943"}}
{"bib_id":"solidsql","title":"Solid-SQL: Enhanced Schema-linking based In-context Learning for Robust Text-to-SQL","author":"Liu, Geling and Tan, Yunzhi and Zhong, Ruichao and Xie, Yuanzhen and Zhao, Lingchen and Wang, Qian and Hu, Bo and Li, Zang","meta_info":{"year":"2025","pages":"9793--9803","booktitle":"Proceedings of the 31st International Conference on Computational Linguistics"}}
{"bib_id":"rslsql","title":"Rsl-sql: Robust schema linking in text-to-sql generation","author":"Cao, Zhenbiao and Zheng, Yuanlei and Fan, Zhihao and Zhang, Xiaojin and Chen, Wei and Bai, Xiang","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2411.00073"}}
{"bib_id":"esql","title":"E-sql: Direct schema linking via question enrichment in text-to-sql","author":"Caferoğlu, Hasan Alp and Ulusoy, Özgür","meta_info":{"year":"2024","journal":"arXiv preprint arXiv:2409.16751"}}
{"bib_id":"deepseekr1","title":"DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning","author":"DeepSeek-AI and\nDaya Guo and\nDejian Yang and\nHaowei Zhang and\nJunxiao Song and\nRuoyu Zhang and\nRunxin Xu and\nQihao Zhu and\nShirong Ma and\nPeiyi Wang and others","meta_info":{"url":"https:\/\/arxiv.org\/abs\/2501.12948","primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2501.12948","year":"2025"}}
{"bib_id":"qwen25","title":"Qwen2.5 Technical Report","author":"An Yang and\nBaosong Yang and\nBeichen Zhang and\nBinyuan Hui and\nBo Zheng and\nBowen Yu and\nChengyuan Li and\nDayiheng Liu and\nFei Huang and\nHaoran Wei and others","meta_info":{"url":"https:\/\/arxiv.org\/abs\/2412.15115","primaryclass":"cs.CL","archiveprefix":"arXiv","eprint":"2412.15115","year":"2025"}}
