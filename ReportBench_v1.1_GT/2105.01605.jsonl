{"bib_id":"wang_vitaa_2020","title":"ViTAA: Visual-Textual Attributes Alignment in Person Search by Natural Language","author":"Wang, Zhe and Fang, Zhiyuan and Wang, Jun and Yang, Yezhou","meta_info":{"file":"Springer Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\TMFVCHM5\\\\Wang et al. - 2020 - ViTAA Visual-Textual Attributes Alignment in Pers.pdf:application\/pdf","pages":"402--420","keywords":"Metric learning, Person re-identification, Person search by natural language, Vision and language","year":"2020","editor":"Vedaldi, Andrea and Bischof, Horst and Brox, Thomas and Frahm, Jan-Michael","publisher":"Springer International Publishing","booktitle":"Computer Vision – ECCV 2020","language":"en","abstract":"Person search by natural language aims at retrieving a specific person in a large-scale image pool that matches given textual descriptions. While most of the current methods treat the task as a holistic visual and textual feature matching one, we approach it from an attribute-aligning perspective that allows grounding specific attribute phrases to the corresponding visual regions. We achieve success as well as a performance boost by a robust feature learning that the referred identity can be accurately bundled by multiple attribute cues. To be concrete, our Visual-Textual Attribute Alignment model (dubbed as ViTAA) learns to disentangle the feature space of a person into sub-spaces corresponding to attributes using a light auxiliary attribute segmentation layer. It then aligns these visual features with the textual attributes parsed from the sentences via a novel contrastive learning loss. We validate our ViTAA framework through extensive experiments on tasks of person search by natural language and by attribute-phrase queries, on which our system achieves state-of-the-art performances. Codes and models are available at https:\/\/github.com\/Jarr0d\/ViTAA.","doi":"10.1007\/978-3-030-58610-2_24","shorttitle":"ViTAA","isbn":"978-3-030-58610-2","series":"Lecture Notes in Computer Science","address":"Cham"}}
{"bib_id":"liu_neural_2017","title":"Neural Person Search Machines","author":"Liu, Hao and Feng, Jiashi and Jie, Zequn and Jayashree, Karlekar and Zhao, Bo and Qi, Meibin and Jiang, Jianguo and Yan, Shuicheng","meta_info":{"file":"Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\KPCDUJ97\\Łiu et al. - 2017 - Neural Person Search Machines.pdf:application\/pdf;Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\3I5G7QXE\\Łiu_Neural_Person_Search_ICCV_2017_paper.html:text\/html","pages":"493--501","year":"2017","urldate":"2021-01-29","url":"https:\/\/openaccess.thecvf.com\/content_iccv_2017\/html\/Liu_Neural_Person_Search_ICCV_2017_paper.html"}}
{"bib_id":"liu_discriminatively_2018","title":"A Discriminatively Learned Feature Embedding Based on Multi-Loss Fusion For Person Search","author":"Liu, H. and Shi, W. and Huang, W. and Guan, Q.","meta_info":{"file":"IEEE Xplore Abstract Record:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\VJBDL7L3\\\\8462484.html:text\/html;IEEE Xplore Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\D5G7YKGZ\\Łiu et al. - 2018 - A Discriminatively Learned Feature Embedding Based.pdf:application\/pdf","pages":"1668--1672","keywords":"learning (artificial intelligence), object detection, Training, Monitoring, Feature extraction, feature extraction, Proposals, Solid modeling, Person Search, center loss, Convergence, discriminative feature embeddings, discriminatively learned feature embedding, Feature Embedding, image fusion, image matching, improved end-to-end person search network, improved online instance matching loss, IOIM loss, Multi-Loss, multiloss fusion strategy, pedestrian detection, pedestrians, person re- identification, person search model, pre-trained network, Urban areas","note":"ISSN: 2379-190X","year":"2018","month":"April","booktitle":"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","abstract":"Person search is a challenging task that requires to address pedestrian detection and person re- identification simultaneously. Though significant progress has been made in detection and re-identification respectively, the similar appearances of persons, pedestrian misdetections and false alarms still have adverse effects on person search. To this end, an improved end-to-end person search network with multi -loss is proposed to jointly optimize detection and re-identification. Firstly, a pre-trained network is designed to obtain proper initial state for the whole training network. Then, to enhance the person search model, an improved online instance matching (IOIM) loss is proposed by hardening the distribution of labeled identities and softening the distribution of unlabeled identities. Finally, considering the intra-class compactness of features learned by center loss, the IOIM loss is combined with center loss by the proposed multi-loss fusion strategy, which can learn more discriminative feature embeddings. Experimental results on two challenging datasets CUHK-SYSU and PRW demonstrate our approach significantly outperforms the state-of-the-arts.","doi":"10.1109\/ICASSP.2018.8462484"}}
{"bib_id":"dong_bi-directional_2020","title":"Bi-Directional Interaction Network for Person Search","author":"Dong, Wenkai and Zhang, Zhaoxiang and Song, Chunfeng and Tan, Tieniu","meta_info":{"file":"Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\KWCHE327\\\\Dong et al. - 2020 - Bi-Directional Interaction Network for Person Sear.pdf:application\/pdf;Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\N7SR45AZ\\\\Dong_Bi-Directional_Interaction_Network_for_Person_Search_CVPR_2020_paper.html:text\/html","pages":"2839--2848","year":"2020","urldate":"2021-01-29","url":"https:\/\/openaccess.thecvf.com\/content_CVPR_2020\/html\/Dong_Bi-Directional_Interaction_Network_for_Person_Search_CVPR_2020_paper.html"}}
{"bib_id":"jing_cross-modal_2020","title":"Cross-Modal Cross-Domain Moment Alignment Network for Person Search","author":"Jing, Y. and Wang, W. and Wang, L. and Tan, T.","meta_info":{"file":"IEEE Xplore Abstract Record:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\2XTSMPPQ\\\\9157071.html:text\/html;IEEE Xplore Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\69LSEFIZ\\\\Jing et al. - 2020 - Cross-Modal Cross-Domain Moment Alignment Network .pdf:application\/pdf","pages":"10675--10683","keywords":"object detection, Task analysis, Semantics, video surveillance, Visualization, Neural networks, Face, text analysis, Adaptation models, cross-modal cross-domain moment alignment network, cross-modal cross-domain person search task, CUHK Person Description dataset, Data models, domain alignment, exemplar alignment, paired image-text data, Richly Annotated Pedestrian dataset, semantic aligned cross-modal representations, text-based person search","note":"ISSN: 2575-7075","year":"2020","month":"June","booktitle":"2020 IEEE\/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","abstract":"Text-based person search has drawn increasing attention due to its wide applications in video surveillance. However, most of the existing models depend heavily on paired image-text data, which is very expensive to acquire. Moreover, they always face huge performance drop when directly exploiting them to new domains. To overcome this problem, we make the first attempt to adapt the model to new target domains in the absence of pairwise labels, which combines the challenges from both cross-modal (text-based) person search and cross-domain person search. Specially, we propose a moment alignment network (MAN) to solve the cross-modal cross-domain person search task in this paper. The idea is to learn three effective moment alignments including domain alignment (DA), cross-modal alignment (CA) and exemplar alignment (EA), which together can learn domain-invariant and semantic aligned cross-modal representations to improve model generalization. Extensive experiments are conducted on CUHK Person Description dataset (CUHK-PEDES) and Richly Annotated Pedestrian dataset (RAP). Experimental results show that our proposed model achieves the state-of-the-art performances on five transfer tasks.","doi":"10.1109\/CVPR42600.2020.01069"}}
{"bib_id":"liu_deep_2019","title":"Deep Adversarial Graph Attention Convolution Network for Text-Based Person Search","author":"Liu, Jiawei and Zha, Zheng-Jun and Hong, Richang and Wang, Meng and Zhang, Yongdong","meta_info":{"file":"Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\SEAUY5BK\\Łiu et al. - 2019 - Deep Adversarial Graph Attention Convolution Netwo.pdf:application\/pdf","pages":"665--673","keywords":"text-based person search, adversarial learning, graph model","year":"2019","month":"October","publisher":"Association for Computing Machinery","booktitle":"Proceedings of the 27th ACM International Conference on Multimedia","urldate":"2021-01-29","abstract":"The newly emerging text-based person search task aims at retrieving the target pedestrian by a query in natural language with fine-grained description of a pedestrian. It is more applicable in reality without the requirement of image\/video query of a pedestrian, as compared to image\/video based person search, i.e., person re-identification. In this work, we propose a novel deep adversarial graph attention convolution network (A-GANet) for text-based person search. The A-GANet exploits both textual and visual scene graphs, consisting of object properties and relationships, from the text queries and gallery images of pedestrians, towards learning informative textual and visual representations. It learns an effective joint textual-visual latent feature space in adversarial learning manner, bridging modality gap and facilitating pedestrian matching. Specifically, the A-GANet consists of an image graph attention network, a text graph attention network and an adversarial learning module. The image and text graph attention networks are designed with a novel graph attention convolution layer, which effectively exploits graph structure in the learning of textual and visual features, leading to precise and discriminative representations. An adversarial learning module is developed with a feature transformer and a modality discriminator, to learn a joint textual-visual feature space for cross-modality matching. Extensive experimental results on two challenging benchmarks, i.e., CUHK-PEDES and Flickr30k datasets, have demonstrated the effectiveness of the proposed method.","doi":"10.1145\/3343031.3350991","url":"https:\/\/doi.org\/10.1145\/3343031.3350991","isbn":"978-1-4503-6889-6","series":"MM '19","address":"New York, NY, USA"}}
{"bib_id":"zhang_diverse_2020","title":"Diverse Knowledge Distillation for End-to-End Person Search","author":"Zhang, Xinyu and Wang, Xinlong and Bian, Jia-Wang and Shen, Chunhua and You, Mingyu","meta_info":{"file":"arXiv Fulltext PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\2PE87AJ4\\\\Zhang et al. - 2020 - Diverse Knowledge Distillation for End-to-End Pers.pdf:application\/pdf;arXiv.org Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\GCEVQ4AE\\\\2012.html:text\/html","keywords":"Computer Science - Computer Vision and Pattern Recognition","note":"arXiv: 2012.11187","year":"2020","month":"December","journal":"arXiv:2012.11187 [cs]","urldate":"2021-01-29","abstract":"Person search aims to localize and identify a specific person from a gallery of images. Recent methods can be categorized into two groups, i.e., two-step and end-to-end approaches. The former views person search as two independent tasks and achieves dominant results using separately trained person detection and re-identification (Re-ID) models. The latter performs person search in an end-to-end fashion. Although the end-to-end approaches yield higher inference efficiency, they largely lag behind those two-step counterparts in terms of accuracy. In this paper, we argue that the gap between the two kinds of methods is mainly caused by the Re-ID sub-networks of end-to-end methods. To this end, we propose a simple yet strong end-to-end network with diverse knowledge distillation to break the bottleneck. We also design a spatial-invariant augmentation to assist model to be invariant to inaccurate detection results. Experimental results on the CUHK-SYSU and PRW datasets demonstrate the superiority of our method against existing approaches -- it achieves on par accuracy with state-of-the-art two-step methods while maintaining high efficiency due to the single joint model. Code is available at: https:\/\/git.io\/DKD-PersonSearch.","url":"http:\/\/arxiv.org\/abs\/2012.11187"}}
{"bib_id":"he_end--end_2019","title":"End-to-End Detection and Re-identification Integrated Net for Person Search","author":"He, Zhenwei and Zhang, Lei","meta_info":{"file":"Springer Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\7FFXGHDY\\e̋ and Zhang - 2019 - End-to-End Detection and Re-identification Integra.pdf:application\/pdf","pages":"349--364","keywords":"Person search, Deep learning","year":"2019","editor":"Jawahar, C. V. and Li, Hongdong and Mori, Greg and Schindler, Konrad","publisher":"Springer International Publishing","booktitle":"Computer Vision – ACCV 2018","language":"en","abstract":"This paper proposes a pedestrian detection and re-identification (re-id) integrated net (I-Net) in an end-to-end learning framework. The I-Net is used in real-world video surveillance scenarios, where the target person needs to be searched in the whole scene videos, and the annotations of pedestrian bounding boxes are unavailable. Comparing to the successful OIM method [31] for joint detection and re-id, we have three distinct contributions. First, we implement a Siamese architecture instead of one stream for an end-to-end training strategy. Second, a novel on-line pairing loss (OLP) with a feature dictionary restricts the positive pairs. Third, hard example priority softmax loss (HEP) with little computation cast is proposed to deal with the online hard example mining. We show our results on CUHK-SYSU and PRW datasets. Our method narrows the gap between detection and re-identification, and achieves a superior performance.","doi":"10.1007\/978-3-030-20890-5_23","isbn":"978-3-030-20890-5","series":"Lecture Notes in Computer Science","address":"Cham"}}
{"bib_id":"zhai_fmt_2019","title":"FMT: fusing multi-task convolutional neural network for person search","author":"Zhai, Sulan and Liu, Shunqiang and Wang, Xiao and Tang, Jin","meta_info":{"file":"Springer Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\46KHKX4R\\\\Zhai et al. - 2019 - FMT fusing multi-task convolutional neural networ.pdf:application\/pdf","pages":"31605--31616","year":"2019","month":"November","journal":"Multimedia Tools and Applications","urldate":"2021-01-29","number":"22","language":"en","abstract":"Person search is to detect all persons and identify the query persons from detected persons in the image without proposals and bounding boxes, which is different from person re-identification. In this paper, we propose a fusing multi-task convolutional neural network(FMT-CNN) to tackle the correlation and heterogeneity of detection and re-identification with a single convolutional neural network. We focus on how the interplay of person detection and person re-identification affects the overall performance. We employ person labels in region proposal network to produce features for person re-identification and person detection network, which can improve the accuracy of detection and re-identification simultaneously. We also use a multiple loss to train our re-identification network. Experiment results on CUHK-SYSU Person Search dataset show that the performance of our proposed method is superior to state-of-the-art approaches in both mAP and top-1.","doi":"10.1007\/s11042-019-07939-w","url":"https:\/\/doi.org\/10.1007\/s11042-019-07939-w","shorttitle":"FMT","issn":"1573-7721","volume":"78"}}
{"bib_id":"xiao_ian_2019","title":"IAN: The Individual Aggregation Network for Person Search","author":"Xiao, Jimin and Xie, Yanchun and Tillo, Tammam and Huang, Kaizhu and Wei, Yunchao and Feng, Jiashi","meta_info":{"file":"ScienceDirect Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\NRRXJUF8\\Ξao et al. - 2019 - IAN The Individual Aggregation Network for Person.pdf:application\/pdf;ScienceDirect Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\RNBVV6FA\\\\S0031320318303790.html:text\/html","pages":"332--340","keywords":"person search, center loss, pedestrian detection, dropout, re-identification, softmax loss","year":"2019","month":"March","journal":"Pattern Recognition","urldate":"2021-01-29","language":"en","abstract":"Person search in real-world scenarios is a new challenging computer version task with many meaningful applications. The challenge of this task mainly comes from: (1) unavailable bounding boxes for pedestrians and the model needs to search for the person over the whole gallery images; (2) huge variance of visual appearance of a particular person owing to varying poses, lighting conditions, and occlusions. To address these two critical issues in modern person search applications, we propose a novel Individual Aggregation Network (IAN) that can accurately localize persons by learning to minimize intra-person feature variations. IAN is built upon the state-of-the-art object detection framework, i.e., faster R-CNN, so that high-quality region proposals for pedestrians can be produced in an online manner. In addition, to relieve the negative effect caused by varying visual appearances of the same individual, IAN introduces a novel center loss that can increase the intra-class compactness of feature representations. The engaged center loss encourages persons with the same identity to have similar feature characteristics. Extensive experimental results on two benchmarks, i.e., CUHK-SYSU and PRW, well demonstrate the superiority of the proposed model. In particular, IAN achieves 77.23% mAP and 80.45% top-1 accuracy on CUHK-SYSU, which outperform the state-of-the-art by 1.7% and 1.85%, respectively.","doi":"10.1016\/j.patcog.2018.10.028","url":"http:\/\/www.sciencedirect.com\/science\/article\/pii\/S0031320318303790","shorttitle":"IAN","issn":"0031-3203","volume":"87"}}
{"bib_id":"dong_instance_2020","title":"Instance Guided Proposal Network for Person Search","author":"Dong, Wenkai and Zhang, Zhaoxiang and Song, Chunfeng and Tan, Tieniu","meta_info":{"file":"Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\72DTQZ4I\\\\Dong et al. - 2020 - Instance Guided Proposal Network for Person Search.pdf:application\/pdf;Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\3XYTJWCE\\\\Dong_Instance_Guided_Proposal_Network_for_Person_Search_CVPR_2020_paper.html:text\/html","pages":"2585--2594","year":"2020","urldate":"2021-01-29","url":"https:\/\/openaccess.thecvf.com\/content_CVPR_2020\/html\/Dong_Instance_Guided_Proposal_Network_for_Person_Search_CVPR_2020_paper.html"}}
{"bib_id":"xiao_joint_2017","title":"Joint Detection and Identification Feature Learning for Person Search","author":"Xiao, Tong and Li, Shuang and Wang, Bochao and Lin, Liang and Wang, Xiaogang","meta_info":{"file":"Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\MGAM6EA3\\Ξao et al. - 2017 - Joint Detection and Identification Feature Learnin.pdf:application\/pdf;Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\G7HDM5WK\\Ξao_Joint_Detection_and_CVPR_2017_paper.html:text\/html","pages":"3415--3424","year":"2017","urldate":"2021-01-29","url":"https:\/\/openaccess.thecvf.com\/content_cvpr_2017\/html\/Xiao_Joint_Detection_and_CVPR_2017_paper.html"}}
{"bib_id":"munjal_knowledge_2019","title":"Knowledge Distillation for End-to-End Person Search","author":"Munjal, Bharti and Galasso, Fabio and Amin, Sikandar","meta_info":{"file":"arXiv Fulltext PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\PUW3YEC7\\\\Munjal et al. - 2019 - Knowledge Distillation for End-to-End Person Searc.pdf:application\/pdf;arXiv.org Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\U4RYERML\\\\1909.html:text\/html","keywords":"Computer Science - Computer Vision and Pattern Recognition","note":"arXiv: 1909.01058","year":"2019","month":"September","journal":"arXiv:1909.01058 [cs]","urldate":"2021-01-29","abstract":"We introduce knowledge distillation for end-to-end person search. End-to-End methods are the current state-of-the-art for person search that solve both detection and re-identification jointly. These approaches for joint optimization show their largest drop in performance due to a sub-optimal detector. We propose two distinct approaches for extra supervision of end-to-end person search methods in a teacher-student setting. The first is adopted from state-of-the-art knowledge distillation in object detection. We employ this to supervise the detector of our person search model at various levels using a specialized detector. The second approach is new, simple and yet considerably more effective. This distills knowledge from a teacher re-identification technique via a pre-computed look-up table of ID features. It relaxes the learning of identification features and allows the student to focus on the detection task. This procedure not only helps fixing the sub-optimal detector training in the joint optimization and simultaneously improving the person search, but also closes the performance gap between the teacher and the student for model compression in this case. Overall, we demonstrate significant improvements for two recent state-of-the-art methods using our proposed knowledge distillation approach on two benchmark datasets. Moreover, on the model compression task our approach brings the performance of smaller models on par with the larger models.","url":"http:\/\/arxiv.org\/abs\/1909.01058"}}
{"bib_id":"yan_learning_2019","title":"Learning Context Graph for Person Search","author":"Yan, Yichao and Zhang, Qiang and Ni, Bingbing and Zhang, Wendong and Xu, Minghao and Yang, Xiaokang","meta_info":{"file":"Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\TCY7BVAP\\\\Yan et al. - 2019 - Learning Context Graph for Person Search.pdf:application\/pdf;Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\T9CJZBQX\\\\Yan_Learning_Context_Graph_for_Person_Search_CVPR_2019_paper.html:text\/html","pages":"2158--2167","year":"2019","urldate":"2021-01-29","url":"https:\/\/openaccess.thecvf.com\/content_CVPR_2019\/html\/Yan_Learning_Context_Graph_for_Person_Search_CVPR_2019_paper.html"}}
{"bib_id":"chen_norm-aware_2020","title":"Norm-Aware Embedding for Efficient Person Search","author":"Chen, Di and Zhang, Shanshan and Yang, Jian and Schiele, Bernt","meta_info":{"file":"Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\KMVKEAJ7\\\\Chen et al. - 2020 - Norm-Aware Embedding for Efficient Person Search.pdf:application\/pdf;Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\RNSJ3ETA\\\\Chen_Norm-Aware_Embedding_for_Efficient_Person_Search_CVPR_2020_paper.html:text\/html","pages":"12615--12624","year":"2020","urldate":"2021-01-29","url":"https:\/\/openaccess.thecvf.com\/content_CVPR_2020\/html\/Chen_Norm-Aware_Embedding_for_Efficient_Person_Search_CVPR_2020_paper.html"}}
{"bib_id":"lan_person_2018","title":"Person Search by Multi-Scale Matching","author":"Lan, Xu and Zhu, Xiatian and Gong, Shaogang","meta_info":{"file":"Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\Y7MUWAH9\\Łan et al. - 2018 - Person Search by Multi-Scale Matching.pdf:application\/pdf;Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\F5FR4WMV\\\\Xu_Lan_Person_Search_by_ECCV_2018_paper.html:text\/html","pages":"536--552","year":"2018","urldate":"2021-01-29","url":"https:\/\/openaccess.thecvf.com\/content_ECCV_2018\/html\/Xu_Lan_Person_Search_by_ECCV_2018_paper.html"}}
{"bib_id":"dong_person_2019","title":"Person Search by Text Attribute Query As Zero-Shot Learning","author":"Dong, Qi and Gong, Shaogang and Zhu, Xiatian","meta_info":{"file":"Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\F8JN6VGD\\\\Dong et al. - 2019 - Person Search by Text Attribute Query As Zero-Shot.pdf:application\/pdf;Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\4LIJDZQD\\\\Dong_Person_Search_by_Text_Attribute_Query_As_Zero-Shot_Learning_ICCV_2019_paper.html:text\/html","pages":"3652--3661","year":"2019","urldate":"2021-01-29","url":"https:\/\/openaccess.thecvf.com\/content_ICCV_2019\/html\/Dong_Person_Search_by_Text_Attribute_Query_As_Zero-Shot_Learning_ICCV_2019_paper.html"}}
{"bib_id":"chen_person_2018","title":"Person Search via A Mask-guided Two-stream CNN Model","author":"Chen, Di and Zhang, Shanshan and Ouyang, Wanli and Yang, Jian and Tai, Ying","meta_info":{"file":"Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\M2AT5JIQ\\\\Chen et al. - 2018 - Person Search via A Mask-guided Two-stream CNN Mod.pdf:application\/pdf;Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\7259Q9V3\\\\Di_Chen_Person_Search_via_ECCV_2018_paper.html:text\/html","pages":"734--750","year":"2018","urldate":"2021-01-29","url":"https:\/\/openaccess.thecvf.com\/content_ECCV_2018\/html\/Di_Chen_Person_Search_via_ECCV_2018_paper.html"}}
{"bib_id":"li_person_2017","title":"Person Search With Natural Language Description","author":"Li, Shuang and Xiao, Tong and Li, Hongsheng and Zhou, Bolei and Yue, Dayu and Wang, Xiaogang","meta_info":{"file":"Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\4CPJFLK5\\Łi et al. - 2017 - Person Search With Natural Language Description.pdf:application\/pdf;Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\J9XI8VSS\\Łi_Person_Search_With_CVPR_2017_paper.html:text\/html","pages":"1970--1979","year":"2017","urldate":"2021-01-29","url":"https:\/\/openaccess.thecvf.com\/content_cvpr_2017\/html\/Li_Person_Search_With_CVPR_2017_paper.html"}}
{"bib_id":"jing_pose-guided_2020","title":"Pose-Guided Multi-Granularity Attention Network for Text-Based Person Search","author":"Jing, Ya and Si, Chenyang and Wang, Junbo and Wang, Wei and Wang, Liang and Tan, Tieniu","meta_info":{"file":"Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\86BRN4QR\\\\Jing et al. - 2020 - Pose-Guided Multi-Granularity Attention Network fo.pdf:application\/pdf;Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\XSVNLP59\\\\6777.html:text\/html","pages":"11189--11196","note":"Number: 07","year":"2020","month":"April","journal":"Proceedings of the AAAI Conference on Artificial Intelligence","urldate":"2021-01-29","number":"07","language":"en","doi":"10.1609\/aaai.v34i07.6777","url":"https:\/\/ojs.aaai.org\/index.php\/AAAI\/article\/view\/6777","issn":"2374-3468","copyright":"Copyright (c) 2020 Association for the Advancement of Artificial Intelligence","volume":"34"}}
{"bib_id":"munjal_query-guided_2019","title":"Query-Guided End-To-End Person Search","author":"Munjal, Bharti and Amin, Sikandar and Tombari, Federico and Galasso, Fabio","meta_info":{"file":"Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\Ł6WZBZZ2\\\\Munjal et al. - 2019 - Query-Guided End-To-End Person Search.pdf:application\/pdf;Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\ZW797VNN\\\\Munjal_Query-Guided_End-To-End_Person_Search_CVPR_2019_paper.html:text\/html","pages":"811--820","year":"2019","urldate":"2021-01-29","url":"https:\/\/openaccess.thecvf.com\/content_CVPR_2019\/html\/Munjal_Query-Guided_End-To-End_Person_Search_CVPR_2019_paper.html"}}
{"bib_id":"han_re-id_2019","title":"Re-ID Driven Localization Refinement for Person Search","author":"Han, Chuchu and Ye, Jiacheng and Zhong, Yunshan and Tan, Xin and Zhang, Chi and Gao, Changxin and Sang, Nong","meta_info":{"file":"Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\IUI7D5IW\\a̋n et al. - 2019 - Re-ID Driven Localization Refinement for Person Se.pdf:application\/pdf;Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\2I865T6J\\\\n̋_Re-ID_Driven_Localization_Refinement_for_Person_Search_ICCV_2019_paper.html:text\/html","pages":"9814--9823","year":"2019","urldate":"2021-01-29","url":"https:\/\/openaccess.thecvf.com\/content_ICCV_2019\/html\/Han_Re-ID_Driven_Localization_Refinement_for_Person_Search_ICCV_2019_paper.html"}}
{"bib_id":"zhong_robust_2020","title":"Robust Partial Matching for Person Search in the Wild","author":"Zhong, Yingji and Wang, Xiaoyu and Zhang, Shiliang","meta_info":{"file":"Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\EZGSR354\\\\Zhong et al. - 2020 - Robust Partial Matching for Person Search in the W.pdf:application\/pdf;Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\TUTXGI66\\\\Zhong_Robust_Partial_Matching_for_Person_Search_in_the_Wild_CVPR_2020_paper.html:text\/html","pages":"6827--6835","year":"2020","urldate":"2021-01-29","url":"https:\/\/openaccess.thecvf.com\/content_CVPR_2020\/html\/Zhong_Robust_Partial_Matching_for_Person_Search_in_the_Wild_CVPR_2020_paper.html"}}
{"bib_id":"zheng_segmentation_2020","title":"Segmentation mask guided end-to-end person search","author":"Zheng, Dingyuan and Xiao, Jimin and Huang, Kaizhu and Zhao, Yao","meta_info":{"file":"ScienceDirect Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\ŁZVVS2HR\\\\Zheng et al. - 2020 - Segmentation mask guided end-to-end person search.pdf:application\/pdf;ScienceDirect Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\8JDKK7AI\\\\S0923596520300849.html:text\/html","pages":"115876","keywords":"Pedestrian detection, Person search, Background clutters, Re-identification, Segmentation masks","year":"2020","month":"August","journal":"Signal Processing: Image Communication","urldate":"2021-01-29","language":"en","abstract":"Person search aims to search for a target person among multiple images recorded by multiple surveillance cameras, which faces various challenges from both pedestrian detection and person re-identification. Besides the large intra-class variations owing to various illumination conditions, occlusions and varying poses, background clutters in the detected pedestrian bounding boxes further deteriorate the extracted features for each person, making them less discriminative. To tackle these problems, we develop a novel approach which guides the network with segmentation masks so that discriminative features can be learned invariant to the background clutters. We demonstrate that joint optimization of pedestrian detection, person re-identification and pedestrian segmentation enables to produce more discriminative features for pedestrian, and consequently leads to better person search performance. Extensive experiments on two widely used benchmark datasets prove the superiority of our approach. In particular, our proposed model achieves the state-of-the-art performance (86.3% mAP and 86.5% top-1 accuracy) on CUHK-SYSU dataset.","doi":"10.1016\/j.image.2020.115876","url":"http:\/\/www.sciencedirect.com\/science\/article\/pii\/S0923596520300849","issn":"0923-5965","volume":"86"}}
{"bib_id":"wang_tcts_2020","title":"TCTS: A Task-Consistent Two-Stage Framework for Person Search","author":"Wang, Cheng and Ma, Bingpeng and Chang, Hong and Shan, Shiguang and Chen, Xilin","meta_info":{"file":"Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\G5NVFW3Z\\\\Wang et al. - 2020 - TCTS A Task-Consistent Two-Stage Framework for Pe.pdf:application\/pdf;Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\JXJT7F4G\\\\Wang_TCTS_A_Task-Consistent_Two-Stage_Framework_for_Person_Search_CVPR_2020_paper.html:text\/html","pages":"11952--11961","year":"2020","urldate":"2021-01-29","url":"https:\/\/openaccess.thecvf.com\/content_CVPR_2020\/html\/Wang_TCTS_A_Task-Consistent_Two-Stage_Framework_for_Person_Search_CVPR_2020_paper.html","shorttitle":"TCTS"}}
{"bib_id":"chang_rcaa_2018","title":"RCAA: Relational Context-Aware Agents for Person Search","author":"Chang, Xiaojun and Huang, Po-Yao and Shen, Yi-Dong and Liang, Xiaodan and Yang, Yi and Hauptmann, Alexander G.","meta_info":{"file":"Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\T35XYIKI\\\\Chang et al. - 2018 - RCAA Relational Context-Aware Agents for Person S.pdf:application\/pdf;Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\BHJ7WJH6\\Ξaojun_Chang_RCAA_Relational_Context-Aware_ECCV_2018_paper.html:text\/html","pages":"84--100","year":"2018","urldate":"2021-01-29","url":"https:\/\/openaccess.thecvf.com\/content_ECCV_2018\/html\/Xiaojun_Chang_RCAA_Relational_Context-Aware_ECCV_2018_paper.html","shorttitle":"RCAA"}}
{"bib_id":"li_identity-aware_2017","title":"Identity-Aware Textual-Visual Matching With Latent Co-Attention","author":"Li, Shuang and Xiao, Tong and Li, Hongsheng and Yang, Wei and Wang, Xiaogang","meta_info":{"file":"Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\ŁKB2V38F\\Łi et al. - 2017 - Identity-Aware Textual-Visual Matching With Latent.pdf:application\/pdf;Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\J53N623F\\Łi_Identity-Aware_Textual-Visual_Matching_ICCV_2017_paper.html:text\/html","pages":"1890--1899","year":"2017","urldate":"2021-01-29","url":"https:\/\/openaccess.thecvf.com\/content_iccv_2017\/html\/Li_Identity-Aware_Textual-Visual_Matching_ICCV_2017_paper.html"}}
{"bib_id":"islam_person_2020","title":"Person search: New paradigm of person re-identification: A survey and outlook of recent works","author":"Islam, Khawar","meta_info":{"file":"ScienceDirect Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\A̋6FUDUS\\\\Islam - 2020 - Person search New paradigm of person re-identific.pdf:application\/pdf;ScienceDirect Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\R5Q8QVVZ\\\\S0262885620301025.html:text\/html","pages":"103970","keywords":"Metric learning, Person re-identification, Person search, Literature survey, Loss functions","year":"2020","month":"September","journal":"Image and Vision Computing","urldate":"2021-01-30","language":"en","abstract":"Person Search (PS) has become a major field because of its need in community and in the field of research among researchers. This task aims to find a probe person from whole scene which shows great significance in video surveillance field to track lost people, re-identification, and verification of person. In last few years, deep learning has played unremarkable role for the solution of re-identification problem. Deep learning shows incredible performance in person (re-ID) and search. Researchers experience more flexibility in proposing new methods and solve challenging issues such as low resolution, pose variation, background clutter, occlusion, viewpoints, and low illumination. Specially, convolutional neural network (CNN) achieves breakthrough performance and extracts useful patterns and characteristics. Development of new framework takes substantial efforts; hard work and computation cost are required to acquire excellent results. This survey paper includes brief discussion about feature representation learning and deep metric learning with novel loss functions. We thoroughly review datasets with performance analysis on existing datasets. Finally, we are reviewing current solutions for further consideration.","doi":"10.1016\/j.imavis.2020.103970","url":"http:\/\/www.sciencedirect.com\/science\/article\/pii\/S0262885620301025","shorttitle":"Person search","issn":"0262-8856","volume":"101"}}
{"bib_id":"xu_person_2014","title":"Person Search in a Scene by Jointly Modeling People Commonness and Person Uniqueness","author":"Xu, Yuanlu and Ma, Bingpeng and Huang, Rui and Lin, Liang","meta_info":{"file":"Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\MR2H29N6\\\\Xu et al. - 2014 - Person Search in a Scene by Jointly Modeling Peopl.pdf:application\/pdf","pages":"937--940","keywords":"person search, fisher vector, generative model, gmm","year":"2014","month":"November","publisher":"Association for Computing Machinery","booktitle":"Proceedings of the 22nd ACM international conference on Multimedia","urldate":"2021-01-29","abstract":"This paper presents a novel framework for a multimedia search task: searching a person in a scene using human body appearance. Existing works mostly focus on two independent problems related to this task, i.e., people detection and person re-identification. However, a sequential combination of these two components does not solve the person search problem seamlessly for two reasons: 1) the errors in people detection are carried into person re-identification unavoidably; 2) the setting of person re-identification is different from that of person search which is essentially a verification problem. To bridge this gap, we propose a unified framework which jointly models the commonness of people (for detection) and the uniqueness of a person (for identification). We demonstrate superior performance of our approach on public benchmarks compared with the sequential combination of the state-of-the-art detection and identification algorithms.","doi":"10.1145\/2647868.2654965","url":"https:\/\/doi.org\/10.1145\/2647868.2654965","isbn":"978-1-4503-3063-3","series":"MM '14","address":"New York, NY, USA"}}
{"bib_id":"yang_enhanced_2017","title":"Enhanced Deep Feature Representation for Person Search","author":"Yang, Jinfu and Wang, Meijie and Li, Mingai and Zhang, Jingling","meta_info":{"file":"Springer Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\IQNAX8KF\\\\Yang et al. - 2017 - Enhanced Deep Feature Representation for Person Se.pdf:application\/pdf","pages":"315--327","keywords":"Person search, CNN features, Feature representation, Hand-crafted features","year":"2017","editor":"Yang, Jinfeng and Hu, Qinghua and Cheng, Ming-Ming and Wang, Liang and Liu, Qingshan and Bai, Xiang and Meng, Deyu","publisher":"Springer","booktitle":"Computer Vision","language":"en","abstract":"Person re-identification (re-id) has attracted widespread attention due to its application and research significance. However, since the person re-id puts the cropped images as input, it is far from the real-world scenarios just like person search which aims at matching a target person from a gallery of the whole scene images. Person search is more difficult but more practical and meaningful. In this paper, we propose a new person search network with an enhanced feature representation. Our network mainly consists two parts, a pedestrian proposal net and an identification net. In the identification net, we utilize hand-crafted features and Convolutional Neural Network (CNN) features to get more discriminative and compact features. Experiments on a large-scale benchmark dataset demonstrate our network gets better performance than others counterparts.","doi":"10.1007\/978-981-10-7305-2_28","isbn":"978-981-10-7305-2","series":"Communications in Computer and Information Science","address":"Singapore"}}
{"bib_id":"gao_structure-aware_2019","title":"Structure-aware person search with self-attention and online instance aggregation matching","author":"Gao, Cunyuan and Yao, Rui and Zhao, Jiaqi and Zhou, Yong and Hu, Fuyuan and Li, Leida","meta_info":{"file":"ScienceDirect Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\YTVFC6UD\\\\Gao et al. - 2019 - Structure-aware person search with self-attention .pdf:application\/pdf;ScienceDirect Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\IRW7P62P\\\\S0925231219311762.html:text\/html","pages":"29--38","keywords":"Pedestrian detection, Person search, Re-Identification","year":"2019","month":"December","journal":"Neurocomputing","urldate":"2021-02-08","language":"en","abstract":"This paper tackles the task of person search, which is a new challenging computer version task in real-world scenarios. The challenge of this task is mainly from: i) Due to viewpoints, occlusions, etc., the visual appearance of a particular person varies greatly, making re-identification difficult; ii) the bounding box where pedestrians are not available, the model needs to search for the person in the entire gallery image. The task of person search is consisted of pedestrian detection and person re-identification (re-id). Instead of completing the two tasks separately, we put the two pieces together to address these issues. We design a more suitable end-to-end framework for person search, which both improve re-id and detection at the same time. Through the change of the anchor with structural prior, the pedestrian detection can be refined faster and better. By introducing self-attention, the framework enhances the fusion of global information. An Online Instance Aggregation Matching (OIAM) loss function is proposed to train the network, and it effectively solves the problem of many categories but few samples of the same category. Extensive experiments are conducted on the PRW and CUHK-SYSU datasets, and our proposed method can outperform other person search methods in both mAP and top-1 evaluation protocols.","doi":"10.1016\/j.neucom.2019.08.038","url":"https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0925231219311762","issn":"0925-2312","volume":"369"}}
{"bib_id":"chen_improving_2018-1","title":"Improving Text-Based Person Search by Spatial Matching and Adaptive Threshold","author":"Chen, T. and Xu, C. and Luo, J.","meta_info":{"file":"IEEE Xplore Abstract Record:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\CGVD4994\\\\8354312.html:text\/html;IEEE Xplore Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\W6BWS9ZT\\\\Chen et al. - 2018 - Improving Text-Based Person Search by Spatial Matc.pdf:application\/pdf","pages":"1879--1887","keywords":"image segmentation, Task analysis, Computational modeling, Feature extraction, Visualization, text analysis, Adaptation models, image matching, person re-identification, affinity score, creative adaptive threshold mechanism, Feeds, frameworks search, Image coding, image-word pair, language description, large-scale database, local matching details, matching degree, matching patch, patch-word matching model, person search applications, spatial matching, text description, text-based person searching, words threshold","year":"2018","month":"March","booktitle":"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)","abstract":"As an important complement to person re-identification, text-based person search in large-scale database is concerned greatly for person search applications. Given language description of a person, existing frameworks search the images in the dataset that describe the same person, by computing the affinity score between the description and each image. In this paper, we first propose an efficient patch-word matching model, which can accurately capture the local matching details between image and text. In particular, it computes the affinity between an image and a word as the affinity of the best matching patch of the image toward the word. Compared with the state-of-the-art framework, it achieves competitive performance, but yields lowcomplexity structure. In addition, we put forward a significant limitation of affinity-based model, it is overly sensitive to the matching degree of a corresponding image-word pair. For this limitation, we feed a creative adaptive threshold mechanism into the model, it automatically learns an adaptive threshold for each word, and effectively “compress” the affinity score between a word and an image when the score exceeds the words threshold. Extensive experiments on the benchmark dataset demonstrate the effectiveness of the proposed framework, which outperforms other approaches for text-based person search. To provide a deeper insight into the proposed model, we visualize the matching details between spatial patches of images and words of texts on typical examples, and illustrate how adaptive threshold mechanism compresses the affinity score and benefits the final rank of different images toward a text description.","doi":"10.1109\/WACV.2018.00208"}}
{"bib_id":"shi_instance_2018","title":"Instance Enhancing Loss: Deep Identity-Sensitive Feature Embedding for Person Search","author":"Shi, W. and Liu, H. and Meng, F. and Huang, W.","meta_info":{"file":"IEEE Xplore Abstract Record:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\GZJ4R8M9\\\\8451028.html:text\/html;IEEE Xplore Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\DQHH4VRQ\\\\Shi et al. - 2018 - Instance Enhancing Loss Deep Identity-Sensitive F.pdf:application\/pdf","pages":"4108--4112","keywords":"object detection, Training, Feature extraction, image representation, Testing, Proposals, Person Search, Feature Embedding, back propagation algorithms, backpropagation, deep identity-sensitive feature embedding, IEL, instance enhancing loss, intelligent surveillance, Loss Function, pedestrian detections, person search network, Surveillance, Table lookup","note":"ISSN: 2381-8549","year":"2018","month":"October","booktitle":"2018 25th IEEE International Conference on Image Processing (ICIP)","abstract":"Person search, which is vital for intelligent surveillance, aims at detecting and re-identifying pedestrians from whole monitoring images. However, due to the inaccurate pedestrian detections and extremely few instances per training identity, it remains challenging to learn discriminative representations only by labeled identities for person search. To this end, this paper proposes a novel loss function called instance enhancing loss (IEL) to learn deep identity-sensitive features by introducing unlabeled identity information. Specifically, the proposed IEL can selectively annotate unlabeled identities with similar appearances to labeled identities, and utilize these unlabeled identities in conjunction with labeled identities to train the person search network. The amount of unlabeled identities used as labeled instances can be quantitatively adjusted. Moreover, the proposed IEL is trainable and easy to optimize by back propagation algorithms. Extensive experiments on two benchmark datasets, namely CUHK-SYSU and PRW, show that our method outperforms state-of-the-arts for person search.","doi":"10.1109\/ICIP.2018.8451028","shorttitle":"Instance Enhancing Loss"}}
{"bib_id":"hong_scale_2019","title":"Scale Voting With Pyramidal Feature Fusion Network for Person Search","author":"Hong, Z. and Liu, B. and Lu, Y. and Yin, G. and Yu, N.","meta_info":{"file":"IEEE Xplore Abstract Record:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\A8Q68NDZ\\\\8846703.html:text\/html;IEEE Xplore Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\MMBU3LCE\\őng et al. - 2019 - Scale Voting With Pyramidal Feature Fusion Network.pdf:application\/pdf","pages":"139692--139702","keywords":"Object detection, Task analysis, Training, Feature extraction, Computer vision, feature extraction, Testing, image fusion, Person search, gallery set, image retrieval, object image scales, prevalent person search datasets, pyramidal feature fusion network, ranking algorithm, scale voting, Streaming media, top-down mid-level features","note":"Conference Name: IEEE Access","year":"2019","journal":"IEEE Access","abstract":"Person search aims to find the target person among a large gallery set of real scene images. Candidates should be detected and cropped before recognizing their identifications. The detection process results in a great variance of object image scales. To address this we propose Pyramidal Feature Fusion Network that integrates the top-down mid-level features to provide multi-level feature outputs. Furthermore, we propose to apply each of the mid-level features independently in ranking and we design a ranking algorithm named Scale Voting that votes among these ranking results from different feature levels to get the final ranking order. In this approach, we can make better use of the diversity and consistency information that is hidden in different mid-levels of features. The proposed algorithm achieves the state-of-the-art performance on prevalent person search datasets.","doi":"10.1109\/ACCESS.2019.2943112","issn":"2169-3536","volume":"7"}}
{"bib_id":"lu_dhff_2019","title":"Dhff: Robust Multi-Scale Person Search by Dynamic Hierarchical Feature Fusion","author":"Lu, Y. and Hong, Z. and Liu, B. and Li, W. and Yu, N.","meta_info":{"file":"IEEE Xplore Abstract Record:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\TYSMWMTK\\\\8803580.html:text\/html;IEEE Xplore Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\X758FR3L\\Łu et al. - 2019 - Dhff Robust Multi-Scale Person Search by Dynamic .pdf:application\/pdf","pages":"3935--3939","keywords":"Detectors, object detection, Training, Feature extraction, Person Search, image fusion, image matching, person re-identification, Search problems, Current measurement, deep object detector, dhff, DHFF, dynamic hierarchical feature fusion, Loss measurement, Multi-Scale, multilevel feature fusion, multimetric loss, multiscale person matching system, person re-ID, Person Re-Identification, person search methods, robust multiscale person search","note":"ISSN: 2381-8549","year":"2019","month":"September","booktitle":"2019 IEEE International Conference on Image Processing (ICIP)","abstract":"Person Search plays the role of the ultimate destination of person re-identification (re-ID) in real applications. It has many challenges that person re-ID doesn't need to handle, such as mis-detections, false alarms and multi-scale matching. In contrast to previous works, we show that a strong multi-scale person matching system can result in a good person search performance with a common deep object detector (e.g. Faster-RCNN). In this work, we provide a robust person search method called Dynamic Hierarchical Feature Fusion (DHFF) which is based on multi-level feature fusion to tackle with multi-scale matching. In addition, A Multi-Metric loss is proposed to train the model effectively and stably with numerous identities. We evaluate our method on two large person search benchmark data sets: CUHK-SYSU and PRW. Experiments show that the proposed algorithm outperforms other state-of-the-art person search methods.","doi":"10.1109\/ICIP.2019.8803580","shorttitle":"Dhff"}}
{"bib_id":"loesch_end--end_2019","title":"End-To-End Person Search Sequentially Trained On Aggregated Dataset","author":"Loesch, A. and Rabarisoa, J. and Audigier, R.","meta_info":{"file":"IEEE Xplore Abstract Record:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\SNPYEWQ8\\\\8803643.html:text\/html;IEEE Xplore Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\SW573PBJ\\Łoesch et al. - 2019 - End-To-End Person Search Sequentially Trained On A.pdf:application\/pdf","pages":"4574--4578","keywords":"Detectors, learning (artificial intelligence), object detection, Task analysis, Training, Computer architecture, Feature extraction, video surveillance, feature extraction, person search, person detection, Re-identification, aggregated dataset, convolutional neural nets, cross-dataset, cross-dataset scenario, feature extraction steps, feature maps, input dataset types, multi-task learning, multitask model, neural net architecture, pedestrian detection datasets, Protocols, re-ID features, re-ID precision, Runtime, single deep convolutional neural network architecture, video surveillance applications","note":"ISSN: 2381-8549","year":"2019","month":"September","booktitle":"2019 IEEE International Conference on Image Processing (ICIP)","abstract":"In video surveillance applications, person search is a challenging task consisting in detecting people and extracting features from their silhouette for re-identification (re-ID) purpose. We propose a new end-to-end model that jointly computes detection and feature extraction steps through a single deep Convolutional Neural Network architecture. Sharing feature maps between the two tasks for jointly describing people commonalities and specificities allows faster runtime, which is valuable in real-world applications. In addition to reaching state-of-the-art accuracy, this multi-task model can be sequentially trained task-by-task, which results in a broader acceptance of input dataset types. Indeed, we show that aggregating more pedestrian detection datasets without costly identity annotations makes the shared feature maps more generic, and improves re-ID precision. Moreover, these boosted shared feature maps result in re-ID features more robust to a cross-dataset scenario.","doi":"10.1109\/ICIP.2019.8803643"}}
{"bib_id":"zheng_dual-path_2020","title":"Dual-path Convolutional Image-Text Embeddings with Instance Loss","author":"Zheng, Zhedong and Zheng, Liang and Garrett, Michael and Yang, Yi and Xu, Mingliang and Shen, Yi-Dong","meta_info":{"file":"Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\9HSUAKMU\\\\Zheng et al. - 2020 - Dual-path Convolutional Image-Text Embeddings with.pdf:application\/pdf","pages":"51:1--51:23","keywords":"convolutional neural networks, cross-modal retrieval, Image-sentence retrieval, language-based person search","year":"2020","month":"May","journal":"ACM Transactions on Multimedia Computing, Communications, and Applications","urldate":"2021-02-09","number":"2","abstract":"Matching images and sentences demands a fine understanding of both modalities. In this article, we propose a new system to discriminatively embed the image and text to a shared visual-textual space. In this field, most existing works apply the ranking loss to pull the positive image\/text pairs close and push the negative pairs apart from each other. However, directly deploying the ranking loss on heterogeneous features (i.e., text and image features) is less effective, because it is hard to find appropriate triplets at the beginning. So the naive way of using the ranking loss may compromise the network from learning inter-modal relationship. To address this problem, we propose the instance loss, which explicitly considers the intra-modal data distribution. It is based on an unsupervised assumption that each image\/text group can be viewed as a class. So the network can learn the fine granularity from every image\/text group. The experiment shows that the instance loss offers better weight initialization for the ranking loss, so that more discriminative embeddings can be learned. Besides, existing works usually apply the off-the-shelf features, i.e., word2vec and fixed visual feature. So in a minor contribution, this article constructs an end-to-end dual-path convolutional network to learn the image and text representations. End-to-end learning allows the system to directly learn from the data and fully utilize the supervision. On two generic retrieval datasets (Flickr30k and MSCOCO), experiments demonstrate that our method yields competitive accuracy compared to state-of-the-art methods. Moreover, in language-based person retrieval, we improve the state of the art by a large margin. The code has been made publicly available.","doi":"10.1145\/3383184","url":"https:\/\/doi.org\/10.1145\/3383184","issn":"1551-6857","volume":"16"}}
{"bib_id":"zhang_deep_2018","title":"Deep Cross-Modal Projection Learning for Image-Text Matching","author":"Zhang, Ying and Lu, Huchuan","meta_info":{"file":"Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\NDXQ2SF2\\\\Zhang and Lu - 2018 - Deep Cross-Modal Projection Learning for Image-Tex.pdf:application\/pdf;Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\SVY8QJNY\\\\Ying_Zhang_Deep_Cross-Modal_Projection_ECCV_2018_paper.html:text\/html","pages":"686--701","year":"2018","urldate":"2021-02-09","url":"https:\/\/openaccess.thecvf.com\/content_ECCV_2018\/html\/Ying_Zhang_Deep_Cross-Modal_Projection_ECCV_2018_paper.html"}}
{"bib_id":"sarafianos_adversarial_2019","title":"Adversarial Representation Learning for Text-to-Image Matching","author":"Sarafianos, Nikolaos and Xu, Xiang and Kakadiaris, Ioannis A.","meta_info":{"file":"Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\K8VLNCPT\\\\Sarafianos et al. - 2019 - Adversarial Representation Learning for Text-to-Im.pdf:application\/pdf;Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\XWCD3U2P\\\\Sarafianos_Adversarial_Representation_Learning_for_Text-to-Image_Matching_ICCV_2019_paper.html:text\/html","pages":"5814--5824","year":"2019","urldate":"2021-02-09","url":"https:\/\/openaccess.thecvf.com\/content_ICCV_2019\/html\/Sarafianos_Adversarial_Representation_Learning_for_Text-to-Image_Matching_ICCV_2019_paper.html"}}
{"bib_id":"li_fast_2019","title":"Fast Person Search Pipeline","author":"Li, J. and Liang, F. and Li, Y. and Zheng, W.","meta_info":{"file":"IEEE Xplore Abstract Record:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\DGEXNELC\\\\8784982.html:text\/html;IEEE Xplore Full Text PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\8QYA3NM6\\Łi et al. - 2019 - Fast Person Search Pipeline.pdf:application\/pdf","pages":"1114--1119","keywords":"Detectors, fast person search pipeline, Feature extraction, FPSP, high time consumption, image recognition, Learning systems, multiscale person detector, part-based person re-identification descriptor, person detection, person re-identification, Person search, person search problem, person search system, person search task, Pipelines, real time, real-time person search, Real-time systems, search problems, Search problems, Task analysis","note":"ISSN: 1945-788X","year":"2019","month":"July","booktitle":"2019 IEEE International Conference on Multimedia and Expo (ICME)","abstract":"In this work, we study the person search problem, which incorporates both person detection and person re-identification. The high time consumption of person search system obstructs the development of this field in practice. For the purpose of real-time person search, we analyze the bottleneck of the person search task and therefore develop a more efficient method called the Fast Person Search Pipeline (FPSP), consisting of a multi-scale person detector as well as a part-based person re-identification descriptor. Extensive experiments show that our proposed method FPSP can accomplish the person search task approximately FIVE times faster than the state-of-the-art methods while achieving a competitive accuracy.","doi":"10.1109\/ICME.2019.00195"}}
{"bib_id":"lhinton_distiling_2015","title":"Distilling the Knowledge in a Neural Network","author":"Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff","meta_info":{"file":"arXiv Fulltext PDF:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\XX7W8HLM\\i̋nton et al. - 2015 - Distilling the Knowledge in a Neural Network.pdf:application\/pdf;arXiv.org Snapshot:C\\:\\\\Users\\Ξangtan\\\\Zotero\\\\storage\\\\N6TAMSZA\\\\1503.html:text\/html","keywords":"Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning","note":"arXiv: 1503.02531","year":"2015","month":"March","journal":"arXiv:1503.02531 [cs, stat]","urldate":"2021-02-21","abstract":"A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.","url":"http:\/\/arxiv.org\/abs\/1503.02531"}}
{"bib_id":"LiuCCPZYH20","title":"Pair-based Uncertainty and Diversity Promoting Early Active Learning\nfor Person Re-identification","author":"Wenhe Liu and\nXiaojun Chang and\nLing Chen and\nDinh Phung and\nXiaoqin Zhang and\nYi Yang and\nAlexander G. Hauptmann","meta_info":{"year":"2020","pages":"21:1--21:15","number":"2","volume":"11","journal":"ACM Trans. Intell. Syst. Technol."}}
{"bib_id":"LiuCS20","title":"Unity Style Transfer for Person Re-Identification","author":"Chong Liu and\nXiaojun Chang and\nYi-Dong Shen","meta_info":{"year":"2020","booktitle":"CVPR"}}
{"bib_id":"LiLCYPZ19","title":"Domain-Aware Unsupervised Cross-dataset Person Re-identification","author":"Zhihui Li and\nWenhe Liu and\nXiaojun Chang and\nLina Yao and\nMahesh Prakash and\nHuaxiang Zhang","meta_info":{"year":"2019","booktitle":"ADMA"}}
{"bib_id":"ChengGCSHZ18","title":"Deep feature learning via structured graph Laplacian embedding for\nperson re-identification","author":"De Cheng and\nYihong Gong and\nXiaojun Chang and\nWeiwei Shi and\nAlexander G. Hauptmann and\nNanning Zheng","meta_info":{"year":"2018","pages":"94--104","volume":"82","journal":"Pattern Recognit."}}
{"bib_id":"LiuCCY18","title":"Semi-Supervised Bayesian Attribute Learning for Person Re-Identification","author":"Wenhe Liu and\nXiaojun Chang and\nLing Chen and\nYi Yang","meta_info":{"year":"2018","booktitle":"AAAI","editor":"Sheila A. McIlraith and\nKilian Q. Weinberger"}}
{"bib_id":"ChengCLHGZ17","title":"Discriminative Dictionary Learning With Ranking Metric Embedded for\nPerson Re-Identification","author":"De Cheng and\nXiaojun Chang and\nLi Liu and\nAlexander G. Hauptmann and\nYihong Gong and\nNanning Zheng","meta_info":{"year":"2017","booktitle":"IJCAI"}}
{"bib_id":"LiuC0Y17","title":"Early Active Learning with Pairwise Constraint for Person Re-identification","author":"Wenhe Liu and\nXiaojun Chang and\nLing Chen and\nYi Yang","meta_info":{"year":"2017","booktitle":"ECML PKDD"}}
{"bib_id":"zheng_person_2017","title":"Person Re-Identification in the Wild","author":"Zheng, Liang and Zhang, Hengheng and Sun, Shaoyan and Chandraker, Manmohan and Yang, Yi and Tian, Qi","meta_info":{"file":"Full Text PDF:H\\:\\\\Zotero\\\\storage\\\\QXM8Y47X\\\\Zheng et al. - 2017 - Person Re-Identification in the Wild.pdf:application\/pdf;Snapshot:H\\:\\\\Zotero\\\\storage\\\\W5QMYHEF\\\\Zheng_Person_Re-Identification_in_CVPR_2017_paper.html:text\/html","pages":"1367--1376","year":"2017","urldate":"2021-04-20","url":"https:\/\/openaccess.thecvf.com\/content_cvpr_2017\/html\/Zheng_Person_Re-Identification_in_CVPR_2017_paper.html"}}
