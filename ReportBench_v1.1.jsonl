{"arxiv_id":"2312.04861","submitter":"Shanliang Yao","authors":"Shanliang Yao, Runwei Guan, Zitian Peng, Chenhang Xu, Yilu Shi, Weiping Ding, Eng Gee Lim, Yong Yue, Hyungjoon Seo, Ka Lok Man, Jieming Ma, Xiaohui Zhu, Yutao Yue","title":"Exploring Radar Data Representations in Autonomous Driving: A Comprehensive Review","comments":"Accepted by TITS","journal-ref":"IEEE Transactions on Intelligent Transportation Systems 2025","doi":"10.1109\/TITS.2025.3554781","report-no":null,"categories":"cs.CV cs.AI","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"With the rapid advancements of sensor technology and deep learning, autonomous driving systems are providing safe and efficient access to intelligent vehicles as well as intelligent transportation. Among these equipped sensors, the radar sensor plays a crucial role in providing robust perception information in diverse environmental conditions. This review focuses on exploring different radar data representations utilized in autonomous driving systems. Firstly, we introduce the capabilities and limitations of the radar sensor by examining the working principles of radar perception and signal processing of radar measurements. Then, we delve into the generation process of five radar representations, including the ADC signal, radar tensor, point cloud, grid map, and micro-Doppler signature. For each radar representation, we examine the related datasets, methods, advantages and limitations. Furthermore, we discuss the challenges faced in these data representations and propose potential research directions. Above all, this comprehensive review offers an in-depth insight into how these representations enhance autonomous system capabilities, providing guidance for radar perception researchers. To facilitate retrieval and comparison of different data representations, datasets and methods, we provide an interactive website at https:\/\/radar-camera-fusion.github.io\/radar.","versions":[{"version":"v1","created":"Fri, 8 Dec 2023 06:31:19 GMT"},{"version":"v2","created":"Fri, 19 Apr 2024 08:55:34 GMT"},{"version":"v3","created":"Mon, 21 Apr 2025 08:37:24 GMT"}],"update_date":"2025-04-22","authors_parsed":[["Yao","Shanliang"],["Guan","Runwei"],["Peng","Zitian"],["Xu","Chenhang"],["Shi","Yilu"],["Ding","Weiping"],["Lim","Eng Gee"],["Yue","Yong"],["Seo","Hyungjoon"],["Man","Ka Lok"],["Ma","Jieming"],["Zhu","Xiaohui"],["Yue","Yutao"]],"application_domain":"Transportation and Intelligent Mobility","prompt":"Please help me research the academic advancements in different radar data representation methods in the field of autonomous driving, and ensure only papers published before April 2025 are referenced."}
{"arxiv_id":"2308.06419","submitter":"Mahsa Golchoubian","authors":"Mahsa Golchoubian, Moojan Ghafurian, Kerstin Dautenhahn, Nasser Lashgarian Azad","title":"Pedestrian Trajectory Prediction in Pedestrian-Vehicle Mixed Environments: A Systematic Review","comments":"Published in IEEE Transactions on Intelligent Transportation Systems","journal-ref":null,"doi":"10.1109\/TITS.2023.3291196","report-no":null,"categories":"cs.RO cs.AI cs.HC cs.LG cs.SY eess.SY","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Planning an autonomous vehicle's (AV) path in a space shared with pedestrians requires reasoning about pedestrians' future trajectories. A practical pedestrian trajectory prediction algorithm for the use of AVs needs to consider the effect of the vehicle's interactions with the pedestrians on pedestrians' future motion behaviours. In this regard, this paper systematically reviews different methods proposed in the literature for modelling pedestrian trajectory prediction in presence of vehicles that can be applied for unstructured environments. This paper also investigates specific considerations for pedestrian-vehicle interaction (compared with pedestrian-pedestrian interaction) and reviews how different variables such as prediction uncertainties and behavioural differences are accounted for in the previously proposed prediction models. PRISMA guidelines were followed. Articles that did not consider vehicle and pedestrian interactions or actual trajectories, and articles that only focused on road crossing were excluded. A total of 1260 unique peer-reviewed articles from ACM Digital Library, IEEE Xplore, and Scopus databases were identified in the search. 64 articles were included in the final review as they met the inclusion and exclusion criteria. An overview of datasets containing trajectory data of both pedestrians and vehicles used by the reviewed papers has been provided. Research gaps and directions for future work, such as having more effective definition of interacting agents in deep learning methods and the need for gathering more datasets of mixed traffic in unstructured environments are discussed.","versions":[{"version":"v1","created":"Fri, 11 Aug 2023 23:58:51 GMT"}],"update_date":"2023-08-15","authors_parsed":[["Golchoubian","Mahsa"],["Ghafurian","Moojan"],["Dautenhahn","Kerstin"],["Azad","Nasser Lashgarian"]],"application_domain":"Transportation and Intelligent Mobility","prompt":"Please help me summarize the research status in the field of pedestrian trajectory prediction in unstructured environments with human-vehicle interactions prior to August 2023."}
{"arxiv_id":"2308.15985","submitter":"Jianwu Fang","authors":"Jianwu Fang, iahuan Qiao, Jianru Xue, and Zhengguo Li","title":"Vision-Based Traffic Accident Detection and Anticipation: A Survey","comments":"accepted in IEEE Transactions on Circuits and Systems for Video\n  Technology; 16 pages, 155 references","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Traffic accident detection and anticipation is an obstinate road safety problem and painstaking efforts have been devoted. With the rapid growth of video data, Vision-based Traffic Accident Detection and Anticipation (named Vision-TAD and Vision-TAA) become the last one-mile problem for safe driving and surveillance safety. However, the long-tailed, unbalanced, highly dynamic, complex, and uncertain properties of traffic accidents form the Out-of-Distribution (OOD) feature for Vision-TAD and Vision-TAA. Current AI development may focus on these OOD but important problems. What has been done for Vision-TAD and Vision-TAA? What direction we should focus on in the future for this problem? A comprehensive survey is important. We present the first survey on Vision-TAD in the deep learning era and the first-ever survey for Vision-TAA. The pros and cons of each research prototype are discussed in detail during the investigation. In addition, we also provide a critical review of 31 publicly available benchmarks and related evaluation metrics. Through this survey, we want to spawn new insights and open possible trends for Vision-TAD and Vision-TAA tasks.","versions":[{"version":"v1","created":"Wed, 30 Aug 2023 12:13:41 GMT"}],"update_date":"2023-08-31","authors_parsed":[["Fang","Jianwu"],["Qiao","iahuan"],["Xue","Jianru"],["Li","Zhengguo"]],"application_domain":"Transportation and Intelligent Mobility","prompt":"Please help me research the field of vision-based traffic accident detection and prediction, requiring that references can only be made to papers published before August 2023."}
{"arxiv_id":"2402.10079","submitter":"Hamed Haghighi Mr","authors":"Hamed Haghighi, Xiaomeng Wang, Hao Jing, and Mehrdad Dianati","title":"Data-driven Camera and Lidar Simulation Models for Autonomous Driving: A Review from Generative Models to Volume Renderers","comments":"To be published in IEEE Transactions on Intelligent Vehicles","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.GR cs.LG cs.RO","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Perception sensors, particularly camera and Lidar, are key elements of Autonomous Driving Systems (ADS) that enable them to comprehend their surroundings to informed driving and control decisions. Therefore, developing realistic simulation models for these sensors is essential for conducting effective simulation-based testing of ADS. Moreover, the rise of deep learning-based perception models has increased the utility of sensor simulation models for synthesising diverse training datasets. The traditional sensor simulation models rely on computationally expensive physics-based algorithms, specifically in complex systems such as ADS. Hence, the current potential resides in data-driven approaches, fuelled by the exceptional performance of deep generative models in capturing high-dimensional data distribution and volume renderers in accurately representing scenes. This paper reviews the current state-of-the-art data-driven camera and Lidar simulation models and their evaluation methods. It explores a spectrum of models from the novel perspective of generative models and volume renderers. Generative models are discussed in terms of their input-output types, while volume renderers are categorised based on their input encoding. Finally, the paper illustrates commonly used evaluation techniques for assessing sensor simulation models and highlights the existing research gaps in the area.","versions":[{"version":"v1","created":"Mon, 29 Jan 2024 16:56:17 GMT"},{"version":"v2","created":"Fri, 21 Mar 2025 14:13:38 GMT"}],"update_date":"2025-03-24","authors_parsed":[["Haghighi","Hamed"],["Wang","Xiaomeng"],["Jing","Hao"],["Dianati","Mehrdad"]],"application_domain":"Transportation and Intelligent Mobility","prompt":"Please help me research the current state of studies on data-driven camera and LiDAR simulation models in the field of autonomous driving, ensuring that only papers published before March 2025 are referenced."}
{"arxiv_id":"2108.09522","submitter":"Yiming Zhao","authors":"Yiming Zhao, Xiao Zhang, Xinming Huang","title":"A Technical Survey and Evaluation of Traditional Point Cloud Clustering Methods for LiDAR Panoptic Segmentation","comments":"1. A hybrid SOTA solution. 2. Accept by ICCV2021 Workshop on\n  Traditional Computer Vision in the Age of Deep Learning. 3. Code:\n  https:\/\/github.com\/placeforyiming\/ICCVW21-LiDAR-Panoptic-Segmentation-TradiCV-Survey-of-Point-Cloud-Cluster","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.RO","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"LiDAR panoptic segmentation is a newly proposed technical task for autonomous driving. In contrast to popular end-to-end deep learning solutions, we propose a hybrid method with an existing semantic segmentation network to extract semantic information and a traditional LiDAR point cloud cluster algorithm to split each instance object. We argue geometry-based traditional clustering algorithms are worth being considered by showing a state-of-the-art performance among all published end-to-end deep learning solutions on the panoptic segmentation leaderboard of the SemanticKITTI dataset. To our best knowledge, we are the first to attempt the point cloud panoptic segmentation with clustering algorithms. Therefore, instead of working on new models, we give a comprehensive technical survey in this paper by implementing four typical cluster methods and report their performances on the benchmark. Those four cluster methods are the most representative ones with real-time running speed. They are implemented with C++ in this paper and then wrapped as a python function for seamless integration with the existing deep learning frameworks. We release our code for peer researchers who might be interested in this problem.","versions":[{"version":"v1","created":"Sat, 21 Aug 2021 14:59:02 GMT"}],"update_date":"2021-08-24","authors_parsed":[["Zhao","Yiming"],["Zhang","Xiao"],["Huang","Xinming"]],"application_domain":"Transportation and Intelligent Mobility","prompt":"Please write a technical survey report on panoramic segmentation of LiDAR point clouds. The specific research area is 3D point cloud understanding in autonomous driving scenarios. My research direction is to explore a hybrid technical approach that decouples semantic segmentation and instance segmentation: first, using state-of-the-art deep learning networks for per-point semantic classification; second, for points identified as belonging to the \"things\" category, leveraging traditional, non-deep-learning, geometry-based clustering algorithms for instance segmentation. I aim to survey and compare different types of traditional clustering algorithms, including but not limited to:\n\n1. Clustering methods based on Euclidean distance;\n2. Supervoxel clustering methods;\n3. Fast clustering algorithms based on range images (e.g., variants of connected component labeling algorithms).\n\nPlease include the following constraints in the survey:\n1. Reference only papers published before August 2021.\n2. Focus on papers published in top-tier English-language conferences or journals in computer vision and robotics (such as CVPR, ICCV, IROS, ICRA).\n3. Give priority to algorithms that have been evaluated on public datasets (such as the SemanticKITTI panoramic segmentation benchmark) and demonstrate potential for real-time processing at millisecond-level speeds."}
{"arxiv_id":"2108.09091","submitter":"Renhe Jiang","authors":"Renhe Jiang, Du Yin, Zhaonan Wang, Yizhuo Wang, Jiewen Deng, Hangchen Liu, Zekun Cai, Jinliang Deng, Xuan Song, Ryosuke Shibasaki","title":"DL-Traff: Survey and Benchmark of Deep Learning Models for Urban Traffic Prediction","comments":"This paper has been accepted by CIKM 2021 Resource Track","journal-ref":null,"doi":"10.1145\/3459637.3482000","report-no":null,"categories":"cs.LG","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Nowadays, with the rapid development of IoT (Internet of Things) and CPS (Cyber-Physical Systems) technologies, big spatiotemporal data are being generated from mobile phones, car navigation systems, and traffic sensors. By leveraging state-of-the-art deep learning technologies on such data, urban traffic prediction has drawn a lot of attention in AI and Intelligent Transportation System community. The problem can be uniformly modeled with a 3D tensor (T, N, C), where T denotes the total time steps, N denotes the size of the spatial domain (i.e., mesh-grids or graph-nodes), and C denotes the channels of information. According to the specific modeling strategy, the state-of-the-art deep learning models can be divided into three categories: grid-based, graph-based, and multivariate time-series models. In this study, we first synthetically review the deep traffic models as well as the widely used datasets, then build a standard benchmark to comprehensively evaluate their performances with the same settings and metrics. Our study named DL-Traff is implemented with two most popular deep learning frameworks, i.e., TensorFlow and PyTorch, which is already publicly available as two GitHub repositories https:\/\/github.com\/deepkashiwa20\/DL-Traff-Grid and https:\/\/github.com\/deepkashiwa20\/DL-Traff-Graph. With DL-Traff, we hope to deliver a useful resource to researchers who are interested in spatiotemporal data analysis.","versions":[{"version":"v1","created":"Fri, 20 Aug 2021 10:08:26 GMT"}],"update_date":"2021-08-23","authors_parsed":[["Jiang","Renhe"],["Yin","Du"],["Wang","Zhaonan"],["Wang","Yizhuo"],["Deng","Jiewen"],["Liu","Hangchen"],["Cai","Zekun"],["Deng","Jinliang"],["Song","Xuan"],["Shibasaki","Ryosuke"]],"application_domain":"Transportation and Intelligent Mobility","prompt":"I hope you can help me research the field of urban traffic prediction. My research focuses on spatiotemporal data prediction based on deep learning, specifically on how models capture spatial and temporal dependencies in traffic data. Please pay special attention to two types of methods: Grid-based models and Graph-based models. Introduce how they respectively use Convolutional Neural Networks (CNN) and Graph Neural Networks (GNN) to handle spatial correlations and how they incorporate structures like Recurrent Neural Networks (RNN) to manage temporal dependencies. Please note that all referenced papers must have been published before August 2021."}
{"arxiv_id":"2006.00648","submitter":"Mahdi Elhousni","authors":"Mahdi Elhousni and Xinming Huang","title":"A Survey on 3D LiDAR Localization for Autonomous Vehicles","comments":"Accepted by IV2020","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"LiDAR sensors are becoming one of the most essential sensors in achieving full autonomy for self driving cars. LiDARs are able to produce rich, dense and precise spatial data, which can tremendously help in localizing and tracking a moving vehicle. In this paper, we review the latest finding in 3D LiDAR localization for autonomous driving cars, and analyse the results obtained by each method, in an effort to guide the research community towards the path that seems to be the most promising.","versions":[{"version":"v1","created":"Mon, 1 Jun 2020 00:19:35 GMT"},{"version":"v2","created":"Sat, 21 Nov 2020 17:07:12 GMT"}],"update_date":"2020-11-24","authors_parsed":[["Elhousni","Mahdi"],["Huang","Xinming"]],"application_domain":"Transportation and Intelligent Mobility","prompt":"I am conducting a literature review on 3D LiDAR localization technology for autonomous vehicles. I hope you can summarize and analyze the major research directions and methods in this field, particularly methods based on 3D point cloud registration, methods based on 3D features, and emerging methods based on deep learning. Please ensure that all the referenced literature is published before November 2020."}
{"arxiv_id":"2204.07974","submitter":"Daniel Bogdoll","authors":"Daniel Bogdoll, Maximilian Nitsche, J. Marius Z\\\"ollner","title":"Anomaly Detection in Autonomous Driving: A Survey","comments":"Daniel Bogdoll and Maximilian Nitsche contributed equally. Accepted\n  for publication at CVPR 2022 WAD workshop","journal-ref":null,"doi":"10.1109\/CVPRW56347.2022.00495","report-no":null,"categories":"cs.RO","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Nowadays, there are outstanding strides towards a future with autonomous vehicles on our roads. While the perception of autonomous vehicles performs well under closed-set conditions, they still struggle to handle the unexpected. This survey provides an extensive overview of anomaly detection techniques based on camera, lidar, radar, multimodal and abstract object level data. We provide a systematization including detection approach, corner case level, ability for an online application, and further attributes. We outline the state-of-the-art and point out current research gaps.","versions":[{"version":"v1","created":"Sun, 17 Apr 2022 10:48:25 GMT"}],"update_date":"2022-09-29","authors_parsed":[["Bogdoll","Daniel"],["Nitsche","Maximilian"],["Z\u00f6llner","J. Marius"]],"application_domain":"Transportation and Intelligent Mobility","prompt":"I need a detailed literature review on anomaly detection for autonomous driving. My specific research areas include:  \n1. **Sensor Modalities**: Methods for anomaly detection based on cameras, Lidar, Radar, and multi-modal sensors.  \n2. **Types of Detection Methods**: A systematic review of various technical approaches, especially deep learning-based methods, such as reconstruction, prediction, generative models, confidence scores, and feature extraction.  \n3. **Types of Anomalies**: Coverage of different anomaly levels, such as object-single-point anomalies and scene-contextual anomalies.  \n\nAdditionally, please adhere to the following constraints:  \n- All referenced papers must have been published before April 2022.  \n- Focus on top-tier conferences and journals in the fields of computer vision and robotics, such as CVPR, ICCV, ECCV, IROS, and ICRA.  \n- The cited papers should primarily be in English."}
{"arxiv_id":"2302.10588","submitter":"Xingyu Zhao","authors":"Yi Qi, Yi Dong, Siddartha Khastgir, Paul Jennings, Xingyu Zhao, Xiaowei Huang","title":"STPA for Learning-Enabled Systems: A Survey and A New Practice","comments":"Accepted by the 26th IEEE Int. Conf. on Intelligent Transportation\n  Systems (ITSC'23), 8 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Systems Theoretic Process Analysis (STPA) is a systematic approach for hazard analysis that has been used across many industrial sectors including transportation, energy, and defense. The unstoppable trend of using Machine Learning (ML) in safety-critical systems has led to the pressing need of extending STPA to Learning-Enabled Systems (LESs). Although works have been carried out on various example LESs, without a systematic review, it is unclear how effective and generalisable the extended STPA methods are, and whether further improvements can be made. To this end, we present a systematic survey of 31 papers, summarising them from five perspectives (attributes of concern, objects under study, modifications, derivatives and processes being modelled). Furthermore, we identify room for improvement and accordingly introduce DeepSTPA, which enhances STPA from two aspects that are missing from the state-of-the-practice: (i) Control loop structures are explicitly extended to identify hazards from the data-driven development process spanning the ML lifecycle; (ii) Fine-grained functionalities are modelled at the layer-wise levels of ML models to detect root causes. We demonstrate and compare DeepSTPA and STPA through a case study on an autonomous emergency braking system.","versions":[{"version":"v1","created":"Tue, 21 Feb 2023 10:43:51 GMT"},{"version":"v2","created":"Mon, 17 Jul 2023 15:56:59 GMT"}],"update_date":"2023-07-18","authors_parsed":[["Qi","Yi"],["Dong","Yi"],["Khastgir","Siddartha"],["Jennings","Paul"],["Zhao","Xingyu"],["Huang","Xiaowei"]],"application_domain":"Transportation and Intelligent Mobility","prompt":"Please help me research the application and extension of \"System-Theoretic Process Analysis (STPA)\" in the academic field of \"Learning-Enabled Systems (LESs)\"."}
{"arxiv_id":"2408.14199","submitter":"Jianye Xu","authors":"Armin Mokhtarian, Jianye Xu, Patrick Scheffe, Maximilian Kloock, Simon Sch\\\"afer, Heeseung Bang, Viet-Anh Le, Sangeet Ulhas, Johannes Betz, Sean Wilson, Spring Berman, Liam Paull, Amanda Prorok, Bassam Alrifaee","title":"A Survey on Small-Scale Testbeds for Connected and Automated Vehicles and Robot Swarms","comments":"16 pages, 11 figures, 1 table. This work was accepted by the IEEE\n  Robotics & Automation Magazine","journal-ref":null,"doi":"10.13140\/RG.2.2.16176.74248\/1","report-no":null,"categories":"cs.RO cs.MA","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Connected and automated vehicles and robot swarms hold transformative potential for enhancing safety, efficiency, and sustainability in the transportation and manufacturing sectors. Extensive testing and validation of these technologies is crucial for their deployment in the real world. While simulations are essential for initial testing, they often have limitations in capturing the complex dynamics of real-world interactions. This limitation underscores the importance of small-scale testbeds. These testbeds provide a realistic, cost-effective, and controlled environment for testing and validating algorithms, acting as an essential intermediary between simulation and full-scale experiments. This work serves to facilitate researchers' efforts in identifying existing small-scale testbeds suitable for their experiments and provide insights for those who want to build their own. In addition, it delivers a comprehensive survey of the current landscape of these testbeds. We derive 62 characteristics of testbeds based on the well-known sense-plan-act paradigm and offer an online table comparing 23 small-scale testbeds based on these characteristics. The online table is hosted on our designated public webpage https:\/\/bassamlab.github.io\/testbeds-survey, and we invite testbed creators and developers to contribute to it. We closely examine nine testbeds in this paper, demonstrating how the derived characteristics can be used to present testbeds. Furthermore, we discuss three ongoing challenges concerning small-scale testbeds that we identified, i.e., small-scale to full-scale transition, sustainability, and power and resource management.","versions":[{"version":"v1","created":"Mon, 26 Aug 2024 11:54:27 GMT"},{"version":"v2","created":"Thu, 21 Nov 2024 07:38:12 GMT"}],"update_date":"2024-11-22","authors_parsed":[["Mokhtarian","Armin"],["Xu","Jianye"],["Scheffe","Patrick"],["Kloock","Maximilian"],["Sch\u00e4fer","Simon"],["Bang","Heeseung"],["Le","Viet-Anh"],["Ulhas","Sangeet"],["Betz","Johannes"],["Wilson","Sean"],["Berman","Spring"],["Paull","Liam"],["Prorok","Amanda"],["Alrifaee","Bassam"]],"application_domain":"Transportation and Intelligent Mobility","prompt":"I need a detailed review of small test platforms for Connected Autonomous Vehicles (CAVs) and Robotic Swarms (RSs). This review should focus on the design, architecture, capabilities, and limitations of these test platforms, specifically how they support research directions such as multi-agent planning and control, human-robot interaction, computer vision, and swarm behavior. Please analyze how the research adopts the \"sense-plan-act\" paradigm to extract features and make comparisons among different test platforms (e.g., F1TENTH, Duckietown, Robotarium, etc.). Additionally, I expect the report to cover the challenges faced in this field, such as the transition from small-scale to full-scale deployment, platform sustainability, as well as power consumption and resource management. Ensure that all cited papers are published before November 2024. When selecting papers, prioritize English-language publications from top-tier conferences and journals, such as ICRA, IROS, IV, CDC, IEEE Robotics and Automation Letters, and IEEE Transactions on Intelligent Vehicles. Furthermore, pay special attention to contributions from leading research institutions in robotics and autonomous driving from countries like Germany, the United States, Canada, and the United Kingdom."}
{"arxiv_id":"2407.03993","submitter":"Yongjie Wang","authors":"Yongjie Wang, Xiaoqi Qiu, Yu Yue, Xu Guo, Zhiwei Zeng, Yuhong Feng, Zhiqi Shen","title":"A Survey on Natural Language Counterfactual Generation","comments":"Accepted by EMNLP 2024 Findings","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Natural language counterfactual generation aims to minimally modify a given text such that the modified text will be classified into a different class. The generated counterfactuals provide insight into the reasoning behind a model's predictions by highlighting which words significantly influence the outcomes. Additionally, they can be used to detect model fairness issues and augment the training data to enhance the model's robustness. A substantial amount of research has been conducted to generate counterfactuals for various NLP tasks, employing different models and methodologies. With the rapid growth of studies in this field, a systematic review is crucial to guide future researchers and developers. To bridge this gap, this survey provides a comprehensive overview of textual counterfactual generation methods, particularly those based on Large Language Models. We propose a new taxonomy that systematically categorizes the generation methods into four groups and summarizes the metrics for evaluating the generation quality. Finally, we discuss ongoing research challenges and outline promising directions for future work.","versions":[{"version":"v1","created":"Thu, 4 Jul 2024 15:13:59 GMT"},{"version":"v2","created":"Sat, 5 Oct 2024 09:39:11 GMT"}],"update_date":"2024-10-08","authors_parsed":[["Wang","Yongjie"],["Qiu","Xiaoqi"],["Yue","Yu"],["Guo","Xu"],["Zeng","Zhiwei"],["Feng","Yuhong"],["Shen","Zhiqi"]],"application_domain":"Artificial Intelligence and Data Intelligence","prompt":"I need a survey on the field of Natural Language Counterfactual Generation. The goal of this field is to alter model predictions by minimally modifying the text, which serves purposes such as model interpretability, fairness analysis, and robustness improvement. I hope the survey systematically reviews the methods in this field, particularly covering the evolution from traditional approaches to recent methods based on large language models (LLMs). It should also classify and summarize these methods, analyzing their advantages and disadvantages. Please note that only papers published before October 2024 can be referenced and cited in the writing."}
{"arxiv_id":"2209.10342","submitter":"Mikko Lauri","authors":"Mikko Lauri, David Hsu, Joni Pajarinen","title":"Partially Observable Markov Decision Processes in Robotics: A Survey","comments":"20 pages, 10 figures. Author version of paper. Accepted for\n  publication in IEEE Transactions on Robotics","journal-ref":null,"doi":"10.1109\/TRO.2022.3200138","report-no":null,"categories":"cs.RO cs.AI cs.SY eess.SY","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Noisy sensing, imperfect control, and environment changes are defining characteristics of many real-world robot tasks. The partially observable Markov decision process (POMDP) provides a principled mathematical framework for modeling and solving robot decision and control tasks under uncertainty. Over the last decade, it has seen many successful applications, spanning localization and navigation, search and tracking, autonomous driving, multi-robot systems, manipulation, and human-robot interaction. This survey aims to bridge the gap between the development of POMDP models and algorithms at one end and application to diverse robot decision tasks at the other. It analyzes the characteristics of these tasks and connects them with the mathematical and algorithmic properties of the POMDP framework for effective modeling and solution. For practitioners, the survey provides some of the key task characteristics in deciding when and how to apply POMDPs to robot tasks successfully. For POMDP algorithm designers, the survey provides new insights into the unique challenges of applying POMDPs to robot systems and points to promising new directions for further research.","versions":[{"version":"v1","created":"Wed, 21 Sep 2022 13:24:20 GMT"}],"update_date":"2022-09-22","authors_parsed":[["Lauri","Mikko"],["Hsu","David"],["Pajarinen","Joni"]],"application_domain":"Artificial Intelligence and Data Intelligence","prompt":"I need you to write a detailed literature review on \"The Applications of Partially Observable Markov Decision Processes (POMDPs) in Robotics\". Please strictly adhere to the following requirements:\n1. **Time Range**: All referenced research findings must have been published before September 2022.\n2. **Research Domain**: The core of the review is the application of POMDPs in robotics, specifically covering at least the following four subfields: autonomous driving, robotic manipulation and grasping, human-robot interaction, and multi-robot collaboration.\n3. **Research Content**: For each subfield, explain its key sources of uncertainty and challenges, and analyze how POMDPs have been applied to model and address these issues. Focus should be placed on mainstream POMDP-solving algorithms, such as sampling- and search-based online algorithms (e.g., POMCP, DESPOT) and point-based value iteration offline algorithms, along with their specific application cases in these domains.\n4. **Literature Source Restrictions**: Priority should be given to referencing top-tier conferences and journals in robotics and artificial intelligence, such as ICRA, IROS, RSS, AAAI, IJCAI, and IEEE Transactions on Robotics.\n5. **Language**: Mainly refer to English literature."}
{"arxiv_id":"2004.05937","submitter":"Lin Wang","authors":"Lin Wang and Kuk-Jin Yoon","title":"Knowledge Distillation and Student-Teacher Learning for Visual Intelligence: A Review and New Outlooks","comments":"Accepted to IEEE Transactions on Pattern Analysis and Machine\n  Intelligence(TPAMI),2021. Some references are updated in this version","journal-ref":"IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2021","doi":"10.1109\/TPAMI.2021.3055564","report-no":"https:\/\/ieeexplore.ieee.org\/document\/9340578","categories":"cs.CV cs.AI cs.LG","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Deep neural models in recent years have been successful in almost every field, including extremely complex problem statements. However, these models are huge in size, with millions (and even billions) of parameters, thus demanding more heavy computation power and failing to be deployed on edge devices. Besides, the performance boost is highly dependent on redundant labeled data. To achieve faster speeds and to handle the problems caused by the lack of data, knowledge distillation (KD) has been proposed to transfer information learned from one model to another. KD is often characterized by the so-called `Student-Teacher' (S-T) learning framework and has been broadly applied in model compression and knowledge transfer. This paper is about KD and S-T learning, which are being actively studied in recent years. First, we aim to provide explanations of what KD is and how\/why it works. Then, we provide a comprehensive survey on the recent progress of KD methods together with S-T frameworks typically for vision tasks. In general, we consider some fundamental questions that have been driving this research area and thoroughly generalize the research progress and technical details. Additionally, we systematically analyze the research status of KD in vision applications. Finally, we discuss the potentials and open challenges of existing methods and prospect the future directions of KD and S-T learning.","versions":[{"version":"v1","created":"Mon, 13 Apr 2020 13:45:38 GMT"},{"version":"v2","created":"Wed, 15 Apr 2020 06:53:08 GMT"},{"version":"v3","created":"Mon, 4 May 2020 01:27:02 GMT"},{"version":"v4","created":"Sun, 11 Oct 2020 13:33:33 GMT"},{"version":"v5","created":"Wed, 6 Jan 2021 08:16:08 GMT"},{"version":"v6","created":"Mon, 25 Jan 2021 12:37:46 GMT"},{"version":"v7","created":"Thu, 17 Jun 2021 07:17:50 GMT"}],"update_date":"2021-06-18","authors_parsed":[["Wang","Lin"],["Yoon","Kuk-Jin"]],"application_domain":"Artificial Intelligence and Data Intelligence","prompt":"I am researching the application of Knowledge Distillation and Student-Teacher Learning in the field of visual intelligence within deep learning. I aim to understand the core concepts, main motivations (such as model compression and knowledge transfer), and various technical classifications in this domain. Please focus on summarizing and analyzing methods based on different types of knowledge (e.g., logits-based distillation and feature-based distillation from intermediate layers) and examining the developments and characteristics of different teacher-student frameworks (such as single\/multi-teacher, online distillation, and self-distillation). Ensure that all referenced papers were published before June 2021."}
{"arxiv_id":"2102.07193","submitter":"Vignesh Prasad","authors":"Vignesh Prasad, Ruth Stock-Homburg, Jan Peters","title":"Human-Robot Handshaking: A Review","comments":"Pre-print version. Accepted for publication in the International\n  Journal of Social Robotics","journal-ref":null,"doi":"10.1007\/s12369-021-00763-z","report-no":null,"categories":"cs.RO cs.HC","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"For some years now, the use of social, anthropomorphic robots in various situations has been on the rise. These are robots developed to interact with humans and are equipped with corresponding extremities. They already support human users in various industries, such as retail, gastronomy, hotels, education and healthcare. During such Human-Robot Interaction (HRI) scenarios, physical touch plays a central role in the various applications of social robots as interactive non-verbal behaviour is a key factor in making the interaction more natural. Shaking hands is a simple, natural interaction used commonly in many social contexts and is seen as a symbol of greeting, farewell and congratulations. In this paper, we take a look at the existing state of Human-Robot Handshaking research, categorise the works based on their focus areas, draw out the major findings of these areas while analysing their pitfalls. We mainly see that some form of synchronisation exists during the different phases of the interaction. In addition to this, we also find that additional factors like gaze, voice facial expressions etc. can affect the perception of a robotic handshake and that internal factors like personality and mood can affect the way in which handshaking behaviours are executed by humans. Based on the findings and insights, we finally discuss possible ways forward for research on such physically interactive behaviours.","versions":[{"version":"v1","created":"Sun, 14 Feb 2021 16:46:24 GMT"}],"update_date":"2021-03-23","authors_parsed":[["Prasad","Vignesh"],["Stock-Homburg","Ruth"],["Peters","Jan"]],"application_domain":"Artificial Intelligence and Data Intelligence","prompt":"I need a detailed literature review on \"Human-Robot Handshaking.\" Please focus on English academic papers published before February 2021, particularly those presented at top conferences or related journals such as HRI, IROS, ICRA, and RO-MAN. The review should cover the following aspects: 1) Decomposition and modeling of handshake behaviors: Summarize how the studies divide handshakes into different stages (e.g., approach, grasp, shake) and the modeling and control methods used for each stage, such as learning-based methods (e.g., imitation learning, reinforcement learning) and model-based methods (e.g., Central Pattern Generators (CPGs), impedance control). 2) Physical and social factors of interaction: Analyze how physical factors (e.g., force feedback, robot hand design, stiffness control) and social factors (e.g., gaze, voice, social context, user personality) discussed in the papers influence handshake quality and user perception. 3) Evaluation methods: Summarize experimental paradigms and evaluation metrics used to measure the \"humanness\" or \"naturalness\" of handshakes, such as the Turing test, Godspeed scales, etc."}
{"arxiv_id":"2408.02085","submitter":"Yulei Qin","authors":"Yulei Qin, Yuncheng Yang, Pengcheng Guo, Gang Li, Hang Shao, Yuchen Shi, Zihan Xu, Yun Gu, Ke Li, Xing Sun","title":"Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data Assessment and Selection for Instruction Tuning of Language Models","comments":"Accepted to TMLR with Survey Certificate, review, survey, 37 pages, 5\n  figures, 4 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.CL eess.SP","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Instruction tuning plays a critical role in aligning large language models (LLMs) with human preference. Despite the vast amount of open instruction datasets, naively training a LLM on all existing instructions may not be optimal and practical. To pinpoint the most beneficial datapoints, data assessment and selection methods have been proposed in the fields of natural language processing (NLP) and deep learning. However, under the context of instruction tuning, there still exists a gap in knowledge on what kind of data evaluation metrics can be employed and how they can be integrated into the selection mechanism. To bridge this gap, we present a comprehensive review on existing literature of data assessment and selection especially for instruction tuning of LLMs. We systematically categorize all applicable methods into quality-based, diversity-based, and importance-based ones where a unified, fine-grained taxonomy is structured. For each category, representative methods are elaborated to describe the landscape of relevant research. In addition, comparison between the latest methods is conducted on their officially reported results to provide in-depth discussions on their limitations. Finally, we summarize the open challenges and propose the promosing avenues for future studies. All related contents are available at https:\/\/github.com\/yuleiqin\/fantastic-data-engineering.","versions":[{"version":"v1","created":"Sun, 4 Aug 2024 16:50:07 GMT"},{"version":"v2","created":"Tue, 6 Aug 2024 03:19:25 GMT"},{"version":"v3","created":"Wed, 7 Aug 2024 06:04:31 GMT"},{"version":"v4","created":"Fri, 29 Nov 2024 10:10:43 GMT"},{"version":"v5","created":"Sun, 29 Dec 2024 04:41:32 GMT"}],"update_date":"2024-12-31","authors_parsed":[["Qin","Yulei"],["Yang","Yuncheng"],["Guo","Pengcheng"],["Li","Gang"],["Shao","Hang"],["Shi","Yuchen"],["Xu","Zihan"],["Gu","Yun"],["Li","Ke"],["Sun","Xing"]],"application_domain":"Artificial Intelligence and Data Intelligence","prompt":"I need an academic survey on data evaluation and selection in the instruction fine-tuning of large language models. The survey should focus on how to extract high-quality, highly diverse, and valuable data subsets from massive instruction data to enhance model performance and training efficiency. Please systematically summarize the methodologies in this field, especially the representative techniques that perform selection based on the three dimensions of data quality, diversity, and importance. Ensure that all referenced papers are published before December 2024."}
{"arxiv_id":"2407.08356","submitter":"Tomasz Kryjak","authors":"Tomasz Kryjak","title":"Event-based vision on FPGAs -- a survey","comments":"Accepted for the 2024 27th Euromicro Conference on Digital System\n  Design (DSD)","journal-ref":null,"doi":"10.1109\/DSD64264.2024.00078","report-no":null,"categories":"cs.CV","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"In recent years there has been a growing interest in event cameras, i.e. vision sensors that record changes in illumination independently for each pixel. This type of operation ensures that acquisition is possible in very adverse lighting conditions, both in low light and high dynamic range, and reduces average power consumption. In addition, the independent operation of each pixel results in low latency, which is desirable for robotic solutions. Nowadays, Field Programmable Gate Arrays (FPGAs), along with general-purpose processors (GPPs\/CPUs) and programmable graphics processing units (GPUs), are popular architectures for implementing and accelerating computing tasks. In particular, their usefulness in the embedded vision domain has been repeatedly demonstrated over the past 30 years, where they have enabled fast data processing (even in real-time) and energy efficiency. Hence, the combination of event cameras and reconfigurable devices seems to be a good solution, especially in the context of energy-efficient real-time embedded systems. This paper gives an overview of the most important works, where FPGAs have been used in different contexts to process event data. It covers applications in the following areas: filtering, stereovision, optical flow, acceleration of AI-based algorithms (including spiking neural networks) for object classification, detection and tracking, and applications in robotics and inspection systems. Current trends and challenges for such systems are also discussed.","versions":[{"version":"v1","created":"Thu, 11 Jul 2024 10:07:44 GMT"}],"update_date":"2025-03-11","authors_parsed":[["Kryjak","Tomasz"]],"application_domain":"Artificial Intelligence and Data Intelligence","prompt":"I need a detailed academic survey report on the implementation of event camera data processing on FPGA.  \nSpecific research domain: Utilizing reconfigurable hardware platforms (FPGA, SoC FPGA) for processing and accelerating data generated by event cameras (also known as DVS or neuromorphic cameras).  \nResearch directions:  \n1. Event data preprocessing, particularly hardware implementations of noise filtering algorithms.  \n2. Classical computer vision tasks, such as optical flow estimation and stereo vision (depth estimation).  \n3. AI-based object detection, classification, and tracking, including implementations of both \"classical\" algorithms and AI methods.  \nFocus methodologies:  \n1. Approaches that convert event data into pseudo-images (event frames) for further processing.  \n2. Direct event data stream processing approaches, especially those based on spiking neural networks (SNN).  \n3. AI models for event data, such as convolutional neural networks (CNN) or graph neural networks (GNN), aimed at hardware acceleration.  \nConstraints:  \n- Only consider papers published before July 2024.  \n- Focus chiefly on English-language papers from top-tier computer vision and robotics conferences such as CVPR, ICCV, ECCV, IROS, and ICRA.  \n- If feasible, reference major research institutions active in this domain, such as the University of Seville, ETH Zurich, etc."}
{"arxiv_id":"2204.10365","submitter":"Anoop K","authors":"Anoop K., Manjary P. Gangan, Deepak P., Lajish V. L","title":"Towards an Enhanced Understanding of Bias in Pre-trained Neural Language Models: A Survey with Special Emphasis on Affective Bias","comments":"Accepted at ICDSE 2021","journal-ref":null,"doi":"10.1007\/978-981-19-4453-6_2","report-no":null,"categories":"cs.CL cs.AI","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"The remarkable progress in Natural Language Processing (NLP) brought about by deep learning, particularly with the recent advent of large pre-trained neural language models, is brought into scrutiny as several studies began to discuss and report potential biases in NLP applications. Bias in NLP is found to originate from latent historical biases encoded by humans into textual data which gets perpetuated or even amplified by NLP algorithm. We present a survey to comprehend bias in large pre-trained language models, analyze the stages at which they occur in these models, and various ways in which these biases could be quantified and mitigated. Considering wide applicability of textual affective computing based downstream tasks in real-world systems such as business, healthcare, education, etc., we give a special emphasis on investigating bias in the context of affect (emotion) i.e., Affective Bias, in large pre-trained language models. We present a summary of various bias evaluation corpora that help to aid future research and discuss challenges in the research on bias in pre-trained language models. We believe that our attempt to draw a comprehensive view of bias in pre-trained language models, and especially the exploration of affective bias will be highly beneficial to researchers interested in this evolving field.","versions":[{"version":"v1","created":"Thu, 21 Apr 2022 18:51:19 GMT"}],"update_date":"2023-01-25","authors_parsed":[["K.","Anoop"],["Gangan","Manjary P."],["P.","Deepak"],["L","Lajish V."]],"application_domain":"Artificial Intelligence and Data Intelligence","prompt":"I need a comprehensive literature review on the issue of bias in pre-trained language models (PLMs). The specific requirements are as follows:  \n1. **Research Domain and Direction**: Provide a thorough review of bias problems in pre-trained models, covering the sources of bias (e.g., training data, model algorithms), types of bias (e.g., gender, racial, religious, occupational bias, as well as intersectional bias), and strategies for bias identification, quantification, and mitigation.  \n2. **Special Focus**: Pay special attention to the subfield of \"Affective Bias,\" which refers to how emotions or sentiments are unfairly associated with specific social groups and how this impacts downstream tasks (e.g., sentiment analysis).  \n3. **Methodological Focus**: For bias quantification, spotlight methods based on word embedding association tests (e.g., WEAT, SEAT). For bias mitigation, focus on techniques like data augmentation (e.g., counterfactual data augmentation), representation debiasing, and algorithmic debiasing methods (e.g., loss function modification, adversarial training).  \n4. **Constraints**:  \n    * Mainly focus on Transformer-based PLMs, such as BERT, the GPT series, RoBERTa, XLNet, etc.  \n    * Prioritize papers from top-tier NLP conferences, such as ACL, EMNLP, NAACL, and AAAI.  \n    * Primarily focus on English-language papers.  \n\nEnsure that all referenced sources were published no later than April 2022."}
{"arxiv_id":"2404.05264","submitter":"Yuxin Cao","authors":"Yihe Fan, Yuxin Cao, Ziyu Zhao, Ziyao Liu, Shaofeng Li","title":"Unbridled Icarus: A Survey of the Potential Perils of Image Inputs in Multimodal Large Language Model Security","comments":"8 pages, 1 figure. Accepted to 2024 IEEE International Conference on\n  Systems, Man, and Cybernetics","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.CV","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Multimodal Large Language Models (MLLMs) demonstrate remarkable capabilities that increasingly influence various aspects of our daily lives, constantly defining the new boundary of Artificial General Intelligence (AGI). Image modalities, enriched with profound semantic information and a more continuous mathematical nature compared to other modalities, greatly enhance the functionalities of MLLMs when integrated. However, this integration serves as a double-edged sword, providing attackers with expansive vulnerabilities to exploit for highly covert and harmful attacks. The pursuit of reliable AI systems like powerful MLLMs has emerged as a pivotal area of contemporary research. In this paper, we endeavor to demostrate the multifaceted risks associated with the incorporation of image modalities into MLLMs. Initially, we delineate the foundational components and training processes of MLLMs. Subsequently, we construct a threat model, outlining the security vulnerabilities intrinsic to MLLMs. Moreover, we analyze and summarize existing scholarly discourses on MLLMs' attack and defense mechanisms, culminating in suggestions for the future research on MLLM security. Through this comprehensive analysis, we aim to deepen the academic understanding of MLLM security challenges and propel forward the development of trustworthy MLLM systems.","versions":[{"version":"v1","created":"Mon, 8 Apr 2024 07:54:18 GMT"},{"version":"v2","created":"Sun, 11 Aug 2024 11:39:54 GMT"}],"update_date":"2024-08-13","authors_parsed":[["Fan","Yihe"],["Cao","Yuxin"],["Zhao","Ziyu"],["Liu","Ziyao"],["Li","Shaofeng"]],"application_domain":"Information and Communication Technology (ICT)","prompt":"I want to research the safety domain of Multimodal Large Language Models (MLLM), specifically focusing on the security risks introduced by image modality input. Please help me organize current mainstream attack methods, such as adversarial perturbations targeting images, jailbreaks, prompt injections, and data poisoning, as well as existing defense techniques, including training-time defenses and inference-time defenses. When writing, please ensure that all referenced papers are published before August 2024."}
{"arxiv_id":"2310.12986","submitter":"Hannes Fassold","authors":"Hannes Fassold","title":"A survey of manifold learning and its applications for multimedia","comments":"Accepted for ICVSP 2023 conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.MM cs.AI","license":"http:\/\/creativecommons.org\/licenses\/by-sa\/4.0\/","abstract":"Manifold learning is an emerging research domain of machine learning. In this work, we give an introduction into manifold learning and how it is employed for important application fields in multimedia.","versions":[{"version":"v1","created":"Fri, 8 Sep 2023 07:16:45 GMT"}],"update_date":"2023-10-23","authors_parsed":[["Fassold","Hannes"]],"application_domain":"Information and Communication Technology (ICT)","prompt":"Please help me research studies related to manifold learning and its applications in the multimedia field published before September 2023."}
{"arxiv_id":"2206.04149","submitter":"Armin Danesh Pazho","authors":"Armin Danesh Pazho, Ghazal Alinezhad Noghre, Arnab A Purkayastha, Jagannadh Vempati, Otto Martin, and Hamed Tabkhi","title":"A Survey of Graph-based Deep Learning for Anomaly Detection in Distributed Systems","comments":"The first two authors (A. Danesh Pazho and G. Alinezhad Noghre) have\n  equal contribution. The article is accepted by IEEE Transactions on Knowledge\n  and Data Engineering","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Anomaly detection is a crucial task in complex distributed systems. A thorough understanding of the requirements and challenges of anomaly detection is pivotal to the security of such systems, especially for real-world deployment. While there are many works and application domains that deal with this problem, few have attempted to provide an in-depth look at such systems. In this survey, we explore the potentials of graph-based algorithms to identify anomalies in distributed systems. These systems can be heterogeneous or homogeneous, which can result in distinct requirements. One of our objectives is to provide an in-depth look at graph-based approaches to conceptually analyze their capability to handle real-world challenges such as heterogeneity and dynamic structure. This study gives an overview of the State-of-the-Art (SotA) research articles in the field and compare and contrast their characteristics. To facilitate a more comprehensive understanding, we present three systems with varying abstractions as use cases. We examine the specific challenges involved in anomaly detection within such systems. Subsequently, we elucidate the efficacy of graphs in such systems and explicate their advantages. We then delve into the SotA methods and highlight their strength and weaknesses, pointing out the areas for possible improvements and future works.","versions":[{"version":"v1","created":"Wed, 8 Jun 2022 20:19:28 GMT"},{"version":"v2","created":"Thu, 1 Jun 2023 21:27:49 GMT"}],"update_date":"2023-06-05","authors_parsed":[["Pazho","Armin Danesh"],["Noghre","Ghazal Alinezhad"],["Purkayastha","Arnab A"],["Vempati","Jagannadh"],["Martin","Otto"],["Tabkhi","Hamed"]],"application_domain":"Information and Communication Technology (ICT)","prompt":"I need you to help me complete the literature survey and write an academic review. This review focuses on the application of graph deep learning for anomaly detection in distributed systems. In the survey, please emphasize sorting and analyzing advanced methods capable of handling heterogeneous and dynamic graphs, such as graph autoencoders, graph contrastive learning, and graph transformers. The review should summarize how existing techniques address real-world challenges in anomaly detection for distributed systems (e.g., data sparsity, lack of labels) and compare the advantages and disadvantages of different methods. Most importantly, all referenced literature must have been published before June 2023."}
{"arxiv_id":"2103.05292","submitter":"Yue Liu","authors":"Yue Liu, Chakkrit Tantithamthavorn, Li Li and Yepang Liu","title":"Deep Learning for Android Malware Defenses: a Systematic Literature Review","comments":"Accepted by ACM Computing Surveys","journal-ref":null,"doi":"10.1145\/3544968","report-no":null,"categories":"cs.CR cs.LG cs.SE","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Malicious applications (particularly those targeting the Android platform) pose a serious threat to developers and end-users. Numerous research efforts have been devoted to developing effective approaches to defend against Android malware. However, given the explosive growth of Android malware and the continuous advancement of malicious evasion technologies like obfuscation and reflection, Android malware defense approaches based on manual rules or traditional machine learning may not be effective. In recent years, a dominant research field called deep learning (DL), which provides a powerful feature abstraction ability, has demonstrated a compelling and promising performance in a variety of areas, like natural language processing and computer vision. To this end, employing deep learning techniques to thwart Android malware attacks has recently garnered considerable research attention. Yet, no systematic literature review focusing on deep learning approaches for Android Malware defenses exists. In this paper, we conducted a systematic literature review to search and analyze how deep learning approaches have been applied in the context of malware defenses in the Android environment. As a result, a total of 132 studies covering the period 2014-2021 were identified. Our investigation reveals that, while the majority of these sources mainly consider DL-based on Android malware detection, 53 primary studies (40.1 percent) design defense approaches based on other scenarios. This review also discusses research trends, research focuses, challenges, and future research directions in DL-based Android malware defenses.","versions":[{"version":"v1","created":"Tue, 9 Mar 2021 08:33:08 GMT"},{"version":"v2","created":"Tue, 25 Jan 2022 02:49:37 GMT"},{"version":"v3","created":"Tue, 9 Aug 2022 07:25:10 GMT"}],"update_date":"2022-08-10","authors_parsed":[["Liu","Yue"],["Tantithamthavorn","Chakkrit"],["Li","Li"],["Liu","Yepang"]],"application_domain":"Information and Communication Technology (ICT)","prompt":"Please help me research academic studies on using deep learning techniques for Android malware defense published before August 2022."}
{"arxiv_id":"2406.06852","submitter":"Shuai Zhao","authors":"Shuai Zhao, Meihuizi Jia, Zhongliang Guo, Leilei Gan, Xiaoyu Xu, Xiaobao Wu, Jie Fu, Yichao Feng, Fengjun Pan, Luu Anh Tuan","title":"A Survey of Recent Backdoor Attacks and Defenses in Large Language Models","comments":"Accepted in TMLR","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.AI cs.CL","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Large Language Models (LLMs), which bridge the gap between human language understanding and complex problem-solving, achieve state-of-the-art performance on several NLP tasks, particularly in few-shot and zero-shot settings. Despite the demonstrable efficacy of LLMs, due to constraints on computational resources, users have to engage with open-source language models or outsource the entire training process to third-party platforms. However, research has demonstrated that language models are susceptible to potential security vulnerabilities, particularly in backdoor attacks. Backdoor attacks are designed to introduce targeted vulnerabilities into language models by poisoning training samples or model weights, allowing attackers to manipulate model responses through malicious triggers. While existing surveys on backdoor attacks provide a comprehensive overview, they lack an in-depth examination of backdoor attacks specifically targeting LLMs. To bridge this gap and grasp the latest trends in the field, this paper presents a novel perspective on backdoor attacks for LLMs by focusing on fine-tuning methods. Specifically, we systematically classify backdoor attacks into three categories: full-parameter fine-tuning, parameter-efficient fine-tuning, and no fine-tuning Based on insights from a substantial review, we also discuss crucial issues for future research on backdoor attacks, such as further exploring attack algorithms that do not require fine-tuning, or developing more covert attack algorithms.","versions":[{"version":"v1","created":"Mon, 10 Jun 2024 23:54:21 GMT"},{"version":"v2","created":"Thu, 13 Jun 2024 08:52:44 GMT"},{"version":"v3","created":"Fri, 19 Jul 2024 08:50:24 GMT"},{"version":"v4","created":"Thu, 12 Sep 2024 00:27:06 GMT"},{"version":"v5","created":"Sat, 4 Jan 2025 13:39:47 GMT"}],"update_date":"2025-01-07","authors_parsed":[["Zhao","Shuai"],["Jia","Meihuizi"],["Guo","Zhongliang"],["Gan","Leilei"],["Xu","Xiaoyu"],["Wu","Xiaobao"],["Fu","Jie"],["Feng","Yichao"],["Pan","Fengjun"],["Tuan","Luu Anh"]],"application_domain":"Artificial Intelligence and Data Intelligence","prompt":"I need a comprehensive literature review on the security of large language models (LLMs), focusing on the topic of backdoor attacks and defenses, with all cited references published prior to January 2025. The specific requirements are as follows:\n\n1.  **Research Area**: Backdoor attacks and defenses in large language models.\n2.  **Research Focus**: Systematically review and analyze backdoor attack techniques based on various deployment methods, particularly following these categories:\n    *   Attacks based on full-parameter fine-tuning.\n    *   Attacks based on parameter-efficient fine-tuning (PEFT), such as methods like LoRA and prompt-tuning.\n    *   Attacks without fine-tuning, for example, attacks performed through in-context learning, instruction poisoning, or chain-of-thought.\n    Additionally, please summarize the defense methods against the above attacks, including strategies based on sample detection and model correction.\n3.  **Constraints**:\n    *   Please prioritize top conference or journal papers from the fields of natural language processing (NLP) and AI security, such as ACL, EMNLP, NAACL, ICLR, NeurIPS, USENIX Security, and IEEE S&P.\n    *   The referenced papers should predominantly be in English.\n    *   Consider relevant studies from institutions like Nanyang Technological University, Shanghai AI Lab, and Beijing Institute of Technology where appropriate."}
{"arxiv_id":"2109.12843","submitter":"Chen Gao","authors":"Chen Gao, Yu Zheng, Nian Li, Yinfeng Li, Yingrong Qin, Jinghua Piao, Yuhan Quan, Jianxin Chang, Depeng Jin, Xiangnan He, Yong Li","title":"A Survey of Graph Neural Networks for Recommender Systems: Challenges, Methods, and Directions","comments":"accepted by ACM Transactions on Recommender Systems","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Recommender system is one of the most important information services on today's Internet. Recently, graph neural networks have become the new state-of-the-art approach to recommender systems. In this survey, we conduct a comprehensive review of the literature on graph neural network-based recommender systems. We first introduce the background and the history of the development of both recommender systems and graph neural networks. For recommender systems, in general, there are four aspects for categorizing existing works: stage, scenario, objective, and application. For graph neural networks, the existing methods consist of two categories, spectral models and spatial ones. We then discuss the motivation of applying graph neural networks into recommender systems, mainly consisting of the high-order connectivity, the structural property of data, and the enhanced supervision signal. We then systematically analyze the challenges in graph construction, embedding propagation\/aggregation, model optimization, and computation efficiency. Afterward and primarily, we provide a comprehensive overview of a multitude of existing works of graph neural network-based recommender systems, following the taxonomy above. Finally, we raise discussions on the open problems and promising future directions in this area. We summarize the representative papers along with their code repositories in \\url{https:\/\/github.com\/tsinghua-fib-lab\/GNN-Recommender-Systems}.","versions":[{"version":"v1","created":"Mon, 27 Sep 2021 07:22:10 GMT"},{"version":"v2","created":"Wed, 31 Aug 2022 03:49:23 GMT"},{"version":"v3","created":"Thu, 12 Jan 2023 06:57:03 GMT"}],"update_date":"2023-01-13","authors_parsed":[["Gao","Chen"],["Zheng","Yu"],["Li","Nian"],["Li","Yinfeng"],["Qin","Yingrong"],["Piao","Jinghua"],["Quan","Yuhan"],["Chang","Jianxin"],["Jin","Depeng"],["He","Xiangnan"],["Li","Yong"]],"application_domain":"Information and Communication Technology (ICT)","prompt":"Please write an academic review on the application of graph neural networks in recommendation systems, referencing only papers published before January 2023. This review should systematically summarize the research progress in this field, covering the use of graph neural networks in various recommendation scenarios (e.g., social recommendation, sequential recommendation) and different recommendation stages (e.g., matching, ranking). Additionally, please focus on analyzing the advantages and disadvantages of various methods, particularly their contributions to addressing key challenges in recommendation systems, such as graph construction, information propagation, and model optimization."}
{"arxiv_id":"2302.00058","submitter":"Thi Kieu Khanh Ho","authors":"Thi Kieu Khanh Ho, Ali Karami, Narges Armanfard","title":"Graph Anomaly Detection in Time Series: A Survey","comments":"Accepted to IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (IEEE TPAMI)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"With the recent advances in technology, a wide range of systems continue to collect a large amount of data over time and thus generate time series. Time-Series Anomaly Detection (TSAD) is an important task in various time-series applications such as e-commerce, cybersecurity, vehicle maintenance, and healthcare monitoring. However, this task is very challenging as it requires considering both the intra-variable dependency (relationships within a variable over time) and the inter-variable dependency (relationships between multiple variables) existing in time-series data. Recent graph-based approaches have made impressive progress in tackling the challenges of this field. In this survey, we conduct a comprehensive and up-to-date review of TSAD using graphs, referred to as G-TSAD. First, we explore the significant potential of graph representation for time-series data and and its contributions to facilitating anomaly detection. Then, we review state-of-the-art graph anomaly detection techniques, mostly leveraging deep learning architectures, in the context of time series. For each method, we discuss its strengths, limitations, and the specific applications where it excels. Finally, we address both the technical and application challenges currently facing the field, and suggest potential future directions for advancing research and improving practical outcomes.","versions":[{"version":"v1","created":"Tue, 31 Jan 2023 19:48:01 GMT"},{"version":"v2","created":"Thu, 8 Jun 2023 16:44:12 GMT"},{"version":"v3","created":"Sat, 17 Feb 2024 01:12:46 GMT"},{"version":"v4","created":"Sun, 28 Apr 2024 18:43:33 GMT"},{"version":"v5","created":"Thu, 27 Mar 2025 15:47:29 GMT"},{"version":"v6","created":"Tue, 29 Apr 2025 21:36:11 GMT"}],"update_date":"2025-05-01","authors_parsed":[["Ho","Thi Kieu Khanh"],["Karami","Ali"],["Armanfard","Narges"]],"application_domain":"Information and Communication Technology (ICT)","prompt":"I am conducting research in the field of time-series anomaly detection, particularly focusing on methods that utilize graph structures to model complex inter-variable and intra-variable dependencies in the data. I hope you can help me review the research progress in this direction, with an emphasis on graph-based time-series anomaly detection (G-TSAD) methods based on deep learning, such as various algorithms using autoencoders (AE), generative adversarial networks (GAN), predictive models, or self-supervised learning. Please ensure that all referenced papers were published before April 2025."}
{"arxiv_id":"2106.16125","submitter":"Sicheng Zhao","authors":"Sicheng Zhao, Xingxu Yao, Jufeng Yang, Guoli Jia, Guiguang Ding, Tat-Seng Chua, Bj\\\"orn W. Schuller, Kurt Keutzer","title":"Affective Image Content Analysis: Two Decades Review and New Perspectives","comments":"Accepted by IEEE TPAMI","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.MM","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Images can convey rich semantics and induce various emotions in viewers. Recently, with the rapid advancement of emotional intelligence and the explosive growth of visual data, extensive research efforts have been dedicated to affective image content analysis (AICA). In this survey, we will comprehensively review the development of AICA in the recent two decades, especially focusing on the state-of-the-art methods with respect to three main challenges -- the affective gap, perception subjectivity, and label noise and absence. We begin with an introduction to the key emotion representation models that have been widely employed in AICA and description of available datasets for performing evaluation with quantitative comparison of label noise and dataset bias. We then summarize and compare the representative approaches on (1) emotion feature extraction, including both handcrafted and deep features, (2) learning methods on dominant emotion recognition, personalized emotion prediction, emotion distribution learning, and learning from noisy data or few labels, and (3) AICA based applications. Finally, we discuss some challenges and promising research directions in the future, such as image content and context understanding, group emotion clustering, and viewer-image interaction.","versions":[{"version":"v1","created":"Wed, 30 Jun 2021 15:20:56 GMT"}],"update_date":"2021-07-01","authors_parsed":[["Zhao","Sicheng"],["Yao","Xingxu"],["Yang","Jufeng"],["Jia","Guoli"],["Ding","Guiguang"],["Chua","Tat-Seng"],["Schuller","Bj\u00f6rn W."],["Keutzer","Kurt"]],"application_domain":"Information and Communication Technology (ICT)","prompt":"I need a detailed academic research report on the field of Affective Image Content Analysis (AICA). The report should systematically review the development of this field over the past two decades, with a focus on methods proposed to address the three core challenges of \"affective gap,\" \"perceptual subjectivity,\" and \"label noise and missing labels.\" The specific requirements are as follows:\n1. Provide a detailed account of the evolution of affective features, including the transition from handcrafted features such as Gabor filters and principles-of-art to deep features based on Convolutional Neural Networks (CNNs).\n2. Categorically summarize mainstream learning methods, including dominant emotion recognition, personalized emotion prediction, emotion distribution learning, and advanced techniques for addressing label deficiencies such as domain adaptation, few-shot\/zero-shot learning, etc.\n3. Constraints: The research should primarily focus on English papers published in top-tier conferences and journals in the fields of computer vision and multimedia, such as CVPR, ICCV, ACM MM, AAAI, IEEE TPAMI, and IEEE TAFFC. All referenced papers must have been published before June 2021."}
{"arxiv_id":"2307.08739","submitter":"Nicole Yunger Halpern","authors":"Jos\\'e Antonio Mar\\'in Guzm\\'an and Paul Erker and Simone Gasparinetti and Marcus Huber and Nicole Yunger Halpern","title":"Key Issues Review: Useful autonomous quantum machines","comments":"Close to published version. Corrected minor typos","journal-ref":"Rep. Prog. Phys. 87, 12 (2024)","doi":"10.1088\/1361-6633\/ad8803","report-no":null,"categories":"quant-ph cond-mat.stat-mech physics.bio-ph physics.chem-ph","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Controlled quantum machines have matured significantly. A natural next step is to increasingly grant them autonomy, freeing them from time-dependent external control. For example, autonomy could pare down the classical control wires that heat and decohere quantum circuits; and an autonomous quantum refrigerator recently reset a superconducting qubit to near its ground state, as is necessary before a computation. Which fundamental conditions are necessary for realizing useful autonomous quantum machines? Inspired by recent quantum thermodynamics and chemistry, we posit conditions analogous to DiVincenzo's criteria for quantum computing. Furthermore, we illustrate the criteria with multiple autonomous quantum machines (refrigerators, circuits, clocks, etc.) and multiple candidate platforms (neutral atoms, molecules, superconducting qubits, etc.). Our criteria are intended to foment and guide the development of useful autonomous quantum machines.","versions":[{"version":"v1","created":"Mon, 17 Jul 2023 18:00:02 GMT"},{"version":"v2","created":"Wed, 11 Sep 2024 23:13:49 GMT"},{"version":"v3","created":"Sun, 08 Jun 2025 23:29:47 GMT"}],"update_date":"2025-06-10","authors_parsed":[["Guzm\u00e1n","Jos\u00e9 Antonio Mar\u00edn"],["Erker","Paul"],["Gasparinetti","Simone"],["Huber","Marcus"],["Halpern","Nicole Yunger"]],"application_domain":"Information and Communication Technology (ICT)","prompt":"I need a detailed literature review on \"Useful Autonomous Quantum Machines.\" My research focuses on understanding the fundamental criteria, key challenges, and solutions required to transition from theoretical prototypes to practical tools. Please address the following aspects:\n1. **Fundamental Definitions and Criteria**: Elaborate on the set of criteria necessary for constructing practical autonomous quantum machines, such as useful energy extraction, interactions between components, timing mechanisms, adequate purity maintenance, and the trade-offs between input and output.\n2. **Key Device Types**: Analyze several typical autonomous quantum machines, including autonomous quantum heat engines (e.g., refrigerators), autonomous quantum clocks, and autonomous quantum circuits. Provide a review of their functioning, theoretical models, and the latest experimental advancements.\n3. **Physical Implementation Platforms**: Examine and compare the potential, progress, and challenges of various physical platforms (e.g., superconducting qubits, trapped ions, neutral atoms, molecules, quantum dots) in the realization of these machines.\n\nPlease adhere to the following constraints:\n- **Cutoff Date**: Your review **must only** rely on academic papers published **before June 2025**.\n- **Paper Language**: Focus **primarily on English-language** papers.\n- **Target Journals**: Place special emphasis on studies published in **Physical Review Letters, Physical Review X, Nature, Nature Communications, Science, Science Advances**, and other top-tier journals.\n- **Institutions of Interest**: Pay particular attention to research conducted by **National Institute of Standards and Technology (NIST), University of Maryland, Vienna University of Technology (TU Wien)**."}
{"arxiv_id":"2410.08918","submitter":"Isaac Johnson","authors":"Isaac Johnson, Lucie-Aim\\'ee Kaffee and Miriam Redi","title":"Wikimedia data for AI: a review of Wikimedia datasets for NLP tasks and AI-assisted editing","comments":"Accepted to NLP for Wikipedia Workshop at EMNLP '24","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CY","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Wikimedia content is used extensively by the AI community and within the language modeling community in particular. In this paper, we provide a review of the different ways in which Wikimedia data is curated to use in NLP tasks across pre-training, post-training, and model evaluations. We point to opportunities for greater use of Wikimedia content but also identify ways in which the language modeling community could better center the needs of Wikimedia editors. In particular, we call for incorporating additional sources of Wikimedia data, a greater focus on benchmarks for LLMs that encode Wikimedia principles, and greater multilingualism in Wikimedia-derived datasets.","versions":[{"version":"v1","created":"Fri, 11 Oct 2024 15:46:09 GMT"}],"update_date":"2024-10-14","authors_parsed":[["Johnson","Isaac"],["Kaffee","Lucie-Aim\u00e9e"],["Redi","Miriam"]],"application_domain":"Information and Communication Technology (ICT)","prompt":"I am conducting an in-depth study on how artificial intelligence empowers Wikimedia communities. My goal is to comprehensively understand the current technological landscape, challenges, and opportunities of utilizing natural language processing (NLP) and large language models (LLM) to assist Wikimedia editing tasks. Specifically, I hope to explore literature covering the following aspects:\n1. **Data construction and pretraining**: Investigating how various forms of raw data from Wikimedia projects (not limited to Wikipedia articles but also including talk pages, Wikisource, etc.) are processed and utilized to build datasets for model pretraining.\n2. **Model fine-tuning for editing tasks**: Focusing on the application of fine-tuned pretrained models for specific editing assistant tasks, such as vandalism detection, citation recommendation, NPOV (Neutral Point of View) violation detection, edit summary generation, and even article creation from scratch.\n3. **Model evaluation and alignment**: Concentrating on the benchmarks used for evaluating model performance, particularly those methods that assess whether the model adheres to Wikimedia's core content policies, such as \"Verifiability,\" \"Neutral Point of View,\" and \"No Original Research.\" \n\nTo make the research more targeted, please pay additional attention to the following constraints:\n* **Conference\/Journal**: Priority should be given to papers published in top natural language processing conferences, such as ACL, EMNLP, and NAACL.\n* **Paper Language**: Primarily focus on papers written in English, but also include studies on multilingual support if available.\n\nAll referenced papers must be publicly available before **October 2024**."}
{"arxiv_id":"2302.05017","submitter":"Bingnan Wang","authors":"Bingnan Wang, Fanjiang Xu and Quan Zheng","title":"A survey on facial image deblurring","comments":"Accepted to computational visual media","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"When a facial image is blurred, it significantly affects high-level vision tasks such as face recognition. The purpose of facial image deblurring is to recover a clear image from a blurry input image, which can improve the recognition accuracy, etc. However, general deblurring methods do not perform well on facial images. Therefore, some face deblurring methods have been proposed to improve performance by adding semantic or structural information as specific priors according to the characteristics of the facial images. In this paper, we survey and summarize recently published methods for facial image deblurring, most of which are based on deep learning. First, we provide a brief introduction to the modeling of image blurring. Next, we summarize face deblurring methods into two categories: model-based methods and deep learning-based methods. Furthermore, we summarize the datasets, loss functions, and performance evaluation metrics commonly used in the neural network training process. We show the performance of classical methods on these datasets and metrics and provide a brief discussion on the differences between model-based and learning-based methods. Finally, we discuss the current challenges and possible future research directions.","versions":[{"version":"v1","created":"Fri, 10 Feb 2023 02:24:56 GMT"},{"version":"v2","created":"Thu, 16 Mar 2023 11:03:09 GMT"}],"update_date":"2023-03-17","authors_parsed":[["Wang","Bingnan"],["Xu","Fanjiang"],["Zheng","Quan"]],"application_domain":"Public Safety and Social Governance","prompt":"Please help me research the field of facial image deblurring, and only refer to papers published before March 2023."}
{"arxiv_id":"2108.09646","submitter":"Mohammad Masudur Rahman","authors":"Mohammad Masudur Rahman and Chanchal K. Roy","title":"A Systematic Review of Automated Query Reformulations in Source Code Search","comments":"81 pages, accepted at TOSEM","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE cs.IR cs.LG cs.NE","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Fixing software bugs and adding new features are two of the major maintenance tasks. Software bugs and features are reported as change requests. Developers consult these requests and often choose a few keywords from them as an ad hoc query. Then they execute the query with a search engine to find the exact locations within software code that need to be changed. Unfortunately, even experienced developers often fail to choose appropriate queries, which leads to costly trials and errors during a code search. Over the years, many studies attempt to reformulate the ad hoc queries from developers to support them. In this systematic literature review, we carefully select 70 primary studies on query reformulations from 2,970 candidate studies, perform an in-depth qualitative analysis (e.g., Grounded Theory), and then answer seven research questions with major findings. First, to date, eight major methodologies (e.g., term weighting, term co-occurrence analysis, thesaurus lookup) have been adopted to reformulate queries. Second, the existing studies suffer from several major limitations (e.g., lack of generalizability, vocabulary mismatch problem, subjective bias) that might prevent their wide adoption. Finally, we discuss the best practices and future opportunities to advance the state of research in search query reformulations.","versions":[{"version":"v1","created":"Sun, 22 Aug 2021 05:47:10 GMT"},{"version":"v2","created":"Thu, 8 Jun 2023 22:10:08 GMT"}],"update_date":"2023-06-12","authors_parsed":[["Rahman","Mohammad Masudur"],["Roy","Chanchal K."]],"application_domain":"Information and Communication Technology (ICT)","prompt":"I need a detailed academic survey report on Automated Query Reformulation in source code search.  \nSpecific research domain: Source code search, including local code search (e.g., concept location, bug localization, feature location) as well as Internet-scale code search.  \nResearch focuses:  \n1. Key methodologies for query reformulation: Please systematically organize and classify the existing techniques for query reformulation, such as term weighting-based methods (e.g., TF-IDF) and relevance feedback methods; extracting semantic relationships using dependency graphs, word co-occurrence, and dictionaries (e.g., WordNet); advanced techniques based on machine learning (e.g., deep learning, word embeddings) and genetic algorithms; as well as mining software repositories (e.g., GitHub, Stack Overflow) for API recommendation.  \n2. Evaluation methods and challenges: Analyze the commonly used evaluation metrics for these techniques (e.g., Hit@K, MAP, MRR), datasets, and summarize the common challenges they face in real-world applications (e.g., noise introduction, lack of generalization, evaluation bias).  \n3. Comparative analysis: Compare and contrast local code search with Internet-scale code search in terms of query reformulation methodologies, objectives, and challenges.  \nConstraints:  \n1. Focus on papers published in top-tier conferences and journals in the software engineering domain, such as ICSE, ASE, FSE, ICSME, TSE, TOSEM.  \n2. Papers of interest are primarily in English.  \n3. Please note that all your analyses and references must be based on literature published no later than June 2023."}
{"arxiv_id":"2402.05617","submitter":"Elena Senger","authors":"Elena Senger, Mike Zhang, Rob van der Goot, Barbara Plank","title":"Deep Learning-based Computational Job Market Analysis: A Survey on Skill Extraction and Classification from Job Postings","comments":"Published at NLP4HR 2024 (EACL Workshop)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Recent years have brought significant advances to Natural Language Processing (NLP), which enabled fast progress in the field of computational job market analysis. Core tasks in this application domain are skill extraction and classification from job postings. Because of its quick growth and its interdisciplinary nature, there is no exhaustive assessment of this emerging field. This survey aims to fill this gap by providing a comprehensive overview of deep learning methodologies, datasets, and terminologies specific to NLP-driven skill extraction and classification. Our comprehensive cataloging of publicly available datasets addresses the lack of consolidated information on dataset creation and characteristics. Finally, the focus on terminology addresses the current lack of consistent definitions for important concepts, such as hard and soft skills, and terms relating to skill extraction and classification.","versions":[{"version":"v1","created":"Thu, 8 Feb 2024 12:20:28 GMT"}],"update_date":"2024-02-09","authors_parsed":[["Senger","Elena"],["Zhang","Mike"],["van der Goot","Rob"],["Plank","Barbara"]],"application_domain":"Public Safety and Social Governance","prompt":"Please research the academic field of extracting and classifying skills from job postings using deep learning methods, referring only to papers published before February 2024."}
{"arxiv_id":"2106.02533","submitter":"Weiwei Jiang","authors":"Weiwei Jiang","title":"Graph-based Deep Learning for Communication Networks: A Survey","comments":"Accepted by Elsevier Computer Communications. Github link:\n  https:\/\/github.com\/jwwthu\/GNN-Communication-Networks","journal-ref":"Computer Communications, 2021","doi":"10.1016\/j.comcom.2021.12.015","report-no":null,"categories":"cs.NI cs.LG","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Communication networks are important infrastructures in contemporary society. There are still many challenges that are not fully solved and new solutions are proposed continuously in this active research area. In recent years, to model the network topology, graph-based deep learning has achieved the state-of-the-art performance in a series of problems in communication networks. In this survey, we review the rapidly growing body of research using different graph-based deep learning models, e.g. graph convolutional and graph attention networks, in various problems from different types of communication networks, e.g. wireless networks, wired networks, and software defined networks. We also present a well-organized list of the problem and solution for each study and identify future research directions. To the best of our knowledge, this paper is the first survey that focuses on the application of graph-based deep learning methods in communication networks involving both wired and wireless scenarios. To track the follow-up research, a public GitHub repository is created, where the relevant papers will be updated continuously.","versions":[{"version":"v1","created":"Fri, 4 Jun 2021 14:59:10 GMT"},{"version":"v2","created":"Wed, 22 Dec 2021 02:28:48 GMT"}],"update_date":"2022-01-03","authors_parsed":[["Jiang","Weiwei"]],"application_domain":"Information and Communication Technology (ICT)","prompt":"I need a detailed academic research report on the application of graph deep learning in the field of communication networks. The specific research areas include but are not limited to wireless networks (e.g., cellular networks, the Internet of Things), wired networks (e.g., data center networks, backbone networks), and software-defined networks (SDN). The research directions should focus on key problems such as routing optimization, traffic prediction, resource allocation, network slicing, virtual network embedding (VNE), and service function chaining (SFC). At the methodological level, please review the specific applications and performance of various graph neural network models (such as GCN, GAT, MPNN, GraphSAGE, etc.) in solving the above-mentioned problems. As a constraint, this research must only refer to and cite papers written before [December 2021], with an emphasis on English papers published in top-tier conferences\/journals such as ACM SIGCOMM, IEEE INFOCOM, and IEEE Journal on Selected Areas in Communications."}
{"arxiv_id":"2202.06481","submitter":"Jiafei Duan","authors":"Jiafei Duan, Arijit Dasgupta, Jason Fischer, Cheston Tan","title":"A Survey on Machine Learning Approaches for Modelling Intuitive Physics","comments":"Paper accepted at IJCAI 2022 (Survey Track)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Research in cognitive science has provided extensive evidence of human cognitive ability in performing physical reasoning of objects from noisy perceptual inputs. Such a cognitive ability is commonly known as intuitive physics. With advancements in deep learning, there is an increasing interest in building intelligent systems that are capable of performing physical reasoning from a given scene for the purpose of building better AI systems. As a result, many contemporary approaches in modelling intuitive physics for machine cognition have been inspired by literature from cognitive science. Despite the wide range of work in physical reasoning for machine cognition, there is a scarcity of reviews that organize and group these deep learning approaches. Especially at the intersection of intuitive physics and artificial intelligence, there is a need to make sense of the diverse range of ideas and approaches. Therefore, this paper presents a comprehensive survey of recent advances and techniques in intuitive physics-inspired deep learning approaches for physical reasoning. The survey will first categorize existing deep learning approaches into three facets of physical reasoning before organizing them into three general technical approaches and propose six categorical tasks of the field. Finally, we highlight the challenges of the current field and present some future research directions.","versions":[{"version":"v1","created":"Mon, 14 Feb 2022 04:44:44 GMT"},{"version":"v2","created":"Wed, 27 Apr 2022 15:47:07 GMT"},{"version":"v3","created":"Thu, 28 Apr 2022 02:47:47 GMT"}],"update_date":"2022-04-29","authors_parsed":[["Duan","Jiafei"],["Dasgupta","Arijit"],["Fischer","Jason"],["Tan","Cheston"]],"application_domain":"Artificial Intelligence and Data Intelligence","prompt":"I need a detailed academic survey report on \"Modeling Intuitive Physics Using Machine Learning Methods.\" The report should systematically review the research in this field. The specific requirements are as follows:  \n1. **Research Domain and Direction**: The core focus is to explore how deep learning models can simulate human intuitive physics capabilities. The survey should be organized by different facets of physical reasoning, specifically including prediction, inference, and causal reasoning.  \n2. **Focus on Methodologies**: Please analyze and summarize the three main technical approaches in this domain, namely methods based on inverse rendering, inverse physics, and inverse dynamics.  \n3. **Core Tasks**: The report should cover discussions on mainstream evaluation tasks, such as predicting object interaction outcomes (PIO), physical property inference (PPI), and violation-of-expectation (VoE) event detection.  \n4. **Constraints**:  \n   * **Cutoff Date**: All referenced papers must have been published before **April 2022**.  \n   * **Language of Papers**: The focus should primarily be on English-language literature.  \n   * **Conferences\/Journals**: Priority should be given to works published in top-tier conferences (e.g., NeurIPS, ICLR, CVPR, ECCV) and journals."}
{"arxiv_id":"2202.00126","submitter":"Sarah Masud","authors":"Tanmay Garg, Sarah Masud, Tharun Suresh, Tanmoy Chakraborty","title":"Handling Bias in Toxic Speech Detection: A Survey","comments":"Accepted in ACM Computing Surveys, 30 pages, 5 figures, 7 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SI cs.CY cs.LG","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Detecting online toxicity has always been a challenge due to its inherent subjectivity. Factors such as the context, geography, socio-political climate, and background of the producers and consumers of the posts play a crucial role in determining if the content can be flagged as toxic. Adoption of automated toxicity detection models in production can thus lead to a sidelining of the various groups they aim to help in the first place. It has piqued researchers' interest in examining unintended biases and their mitigation. Due to the nascent and multi-faceted nature of the work, complete literature is chaotic in its terminologies, techniques, and findings. In this paper, we put together a systematic study of the limitations and challenges of existing methods for mitigating bias in toxicity detection. We look closely at proposed methods for evaluating and mitigating bias in toxic speech detection. To examine the limitations of existing methods, we also conduct a case study to introduce the concept of bias shift due to knowledge-based bias mitigation. The survey concludes with an overview of the critical challenges, research gaps, and future directions. While reducing toxicity on online platforms continues to be an active area of research, a systematic study of various biases and their mitigation strategies will help the research community produce robust and fair models.","versions":[{"version":"v1","created":"Wed, 26 Jan 2022 10:38:36 GMT"},{"version":"v2","created":"Wed, 2 Feb 2022 10:29:23 GMT"},{"version":"v3","created":"Sun, 15 Jan 2023 14:51:55 GMT"}],"update_date":"2023-01-18","authors_parsed":[["Garg","Tanmay"],["Masud","Sarah"],["Suresh","Tharun"],["Chakraborty","Tanmoy"]],"application_domain":"Public Safety and Social Governance","prompt":"Please help me investigate the academic field of bias mitigation in the detection of harmful online speech, restricting references to papers published before January 2023."}
{"arxiv_id":"2405.10347","submitter":"Yang Liu","authors":"Jing Liu, Yang Liu, Jieyu Lin, Jielin Li, Liang Cao, Peng Sun, Bo Hu, Liang Song, Azzedine Boukerche, Victor C.M. Leung","title":"Networking Systems for Video Anomaly Detection: A Tutorial and Survey","comments":"Accepted to ACM Computing Surveys. For more information and\n  supplementary material, please visit https:\/\/github.com\/fdjingliu\/NSVAD","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.CY","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"The increasing utilization of surveillance cameras in smart cities, coupled with the surge of online video applications, has heightened concerns regarding public security and privacy protection, which propelled automated Video Anomaly Detection (VAD) into a fundamental research task within the Artificial Intelligence (AI) community. With the advancements in deep learning and edge computing, VAD has made significant progress and advances synergized with emerging applications in smart cities and video internet, which has moved beyond the conventional research scope of algorithm engineering to deployable Networking Systems for VAD (NSVAD), a practical hotspot for intersection exploration in the AI, IoVT, and computing fields. In this article, we delineate the foundational assumptions, learning frameworks, and applicable scenarios of various deep learning-driven VAD routes, offering an exhaustive tutorial for novices in NSVAD. In addition, this article elucidates core concepts by reviewing recent advances and typical solutions and aggregating available research resources accessible at https:\/\/github.com\/fdjingliu\/NSVAD. Lastly, this article projects future development trends and discusses how the integration of AI and computing technologies can address existing research challenges and promote open opportunities, serving as an insightful guide for prospective researchers and engineers.","versions":[{"version":"v1","created":"Thu, 16 May 2024 02:00:44 GMT"},{"version":"v2","created":"Fri, 15 Nov 2024 04:44:40 GMT"},{"version":"v3","created":"Wed, 26 Mar 2025 16:44:38 GMT"},{"version":"v4","created":"Thu, 3 Apr 2025 05:41:14 GMT"}],"update_date":"2025-04-04","authors_parsed":[["Liu","Jing"],["Liu","Yang"],["Lin","Jieyu"],["Li","Jielin"],["Cao","Liang"],["Sun","Peng"],["Hu","Bo"],["Song","Liang"],["Boukerche","Azzedine"],["Leung","Victor C. M."]],"application_domain":"Public Safety and Social Governance","prompt":"I require a comprehensive literature review on \"Networking Systems for Video Anomaly Detection\" (NSVAD). Please focus your investigation and analysis on the following aspects:  \n1. **Research Domain and Paradigm**: Systematically review the definitions, key components (e.g., hardware layer, system layer, algorithm layer, and application layer), and research paradigms of NSVAD.  \n2. **Core Technical Approaches**: Provide a detailed comparative analysis of three mainstream deep-learning-based approaches: Unsupervised Video Anomaly Detection (UVAD), Weakly Supervised Video Anomaly Detection (WsVAD), and Fully Unsupervised Video Anomaly Detection (FuVAD). Explain their fundamental assumptions, learning frameworks, representative models, and applicable scenarios.  \n3. **Emerging Research Tasks**: Highlight and introduce emerging research directions such as Open-Set Video Anomaly Detection (OSVAD), Open-Vocabulary Video Anomaly Detection (OVVAD), and Multi-Modal Video Anomaly Detection.  \n\n**Constraints**:  \n* **Publication Deadline**: All cited studies must have been publicly available before April 2025.  \n* **Focused Conferences\/Journals**: Primarily reference top-tier conference papers in fields like computer vision (e.g., CVPR, ICCV, ECCV), artificial intelligence (e.g., AAAI, IJCAI), and data mining (e.g., KDD).  \n* **Language**: Focus mainly on English-language literature."}
{"arxiv_id":"2105.01605","submitter":"Xiaojun Chang","authors":"Xiangtan Lin and Pengzhen Ren and Yun Xiao and Xiaojun Chang and Alex Hauptmann","title":"Person Search Challenges and Solutions: A Survey","comments":"8 pages; Accepted by IJCAI 2021 Survey Track","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Person search has drawn increasing attention due to its real-world applications and research significance. Person search aims to find a probe person in a gallery of scene images with a wide range of applications, such as criminals search, multicamera tracking, missing person search, etc. Early person search works focused on image-based person search, which uses person image as the search query. Text-based person search is another major person search category that uses free-form natural language as the search query. Person search is challenging, and corresponding solutions are diverse and complex. Therefore, systematic surveys on this topic are essential. This paper surveyed the recent works on image-based and text-based person search from the perspective of challenges and solutions. Specifically, we provide a brief analysis of highly influential person search methods considering the three significant challenges: the discriminative person features, the query-person gap, and the detection-identification inconsistency. We summarise and compare evaluation results. Finally, we discuss open issues and some promising future research directions.","versions":[{"version":"v1","created":"Sat, 1 May 2021 11:10:20 GMT"}],"update_date":"2021-05-05","authors_parsed":[["Lin","Xiangtan"],["Ren","Pengzhen"],["Xiao","Yun"],["Chang","Xiaojun"],["Hauptmann","Alex"]],"application_domain":"Public Safety and Social Governance","prompt":"Please write a detailed academic survey on the field of person search, covering the two subfields of image-based and text-based person search. The survey should deeply analyze how different methods address the three core challenges in this domain: 1) learning discriminative deep feature representations; 2) bridging the gap between the query and target person using methods such as deep metric learning; and 3) mitigating inconsistencies between detection and identification tasks through methods like identity-driven detection. During the survey, priority should be given to English papers published in top-tier computer vision conferences or journals (e.g., CVPR, ECCV, AAAI). Most importantly, all cited research results must have been published on or before May 2021."}
{"arxiv_id":"2307.11556","submitter":"Aron Schnakenbeck","authors":"Robin Mro{\\ss}, Aron Schnakenbeck, Marcus V\\\"olker, Alexander Fay, Stefan Kowalewski","title":"Unambiguous Interpretation of IEC 60848 GRAFCET based on a Literature Review","comments":"\\c{opyright} 2023 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting\/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works","journal-ref":"2023 IEEE 28th International Conference on Emerging Technologies\n  and Factory Automation (ETFA)","doi":"10.1109\/ETFA54631.2023.10275504","report-no":null,"categories":"eess.SY cs.SY","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"IEC 60848 GRAFCET is a standardized, graphical specification language for control functions. Because of the semiformal nature of IEC 60848, the details of specifications created with GRAFCET can be interpreted in different ways, possibly leading to faulty implementations. These ambiguities have been partially addressed in existing literature, but solved in different manners. Based on a literature review, this work aims at providing an overview of existing interpretations and, based on that, proposes a comprehensive interpretation algorithm for IEC 60848, which takes all relevant ambiguities from the literature review into account.","versions":[{"version":"v1","created":"Fri, 21 Jul 2023 13:05:12 GMT"},{"version":"v2","created":"Mon, 1 Jul 2024 08:04:43 GMT"}],"update_date":"2024-07-02","authors_parsed":[["Mro\u00df","Robin"],["Schnakenbeck","Aron"],["V\u00f6lker","Marcus"],["Fay","Alexander"],["Kowalewski","Stefan"]],"application_domain":"Manufacturing and Smart Manufacturing","prompt":"Please help me research the semantic ambiguities within the IEC 60848 GRAFCET standard and the methods for their interpretation, ensuring that references are limited to papers published before July 2024."}
{"arxiv_id":"2408.01934","submitter":"Tiet Nguyen Khoi Nguyen","authors":"Khoi Nguyen Tiet Nguyen, Wenyu Zhang, Kangkang Lu, Yuhuan Wu, Xingjian Zheng, Hui Li Tan, Liangli Zhen","title":"A Survey and Evaluation of Adversarial Attacks for Object Detection","comments":"Accepted for publication in the IEEE Transactions on Neural Networks\n  and Learning Systems (TNNLS)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Deep learning models achieve remarkable accuracy in computer vision tasks, yet remain vulnerable to adversarial examples--carefully crafted perturbations to input images that can deceive these models into making confident but incorrect predictions. This vulnerability pose significant risks in high-stakes applications such as autonomous vehicles, security surveillance, and safety-critical inspection systems. While the existing literature extensively covers adversarial attacks in image classification, comprehensive analyses of such attacks on object detection systems remain limited. This paper presents a novel taxonomic framework for categorizing adversarial attacks specific to object detection architectures, synthesizes existing robustness metrics, and provides a comprehensive empirical evaluation of state-of-the-art attack methodologies on popular object detection models, including both traditional detectors and modern detectors with vision-language pretraining. Through rigorous analysis of open-source attack implementations and their effectiveness across diverse detection architectures, we derive key insights into attack characteristics. Furthermore, we delineate critical research gaps and emerging challenges to guide future investigations in securing object detection systems against adversarial threats. Our findings establish a foundation for developing more robust detection models while highlighting the urgent need for standardized evaluation protocols in this rapidly evolving domain.","versions":[{"version":"v1","created":"Sun, 4 Aug 2024 05:22:08 GMT"},{"version":"v2","created":"Tue, 6 Aug 2024 02:39:46 GMT"},{"version":"v3","created":"Thu, 3 Apr 2025 10:40:36 GMT"},{"version":"v4","created":"Mon, 7 Apr 2025 04:17:39 GMT"},{"version":"v5","created":"Thu, 17 Apr 2025 15:52:09 GMT"}],"update_date":"2025-04-18","authors_parsed":[["Nguyen","Khoi Nguyen Tiet"],["Zhang","Wenyu"],["Lu","Kangkang"],["Wu","Yuhuan"],["Zheng","Xingjian"],["Tan","Hui Li"],["Zhen","Liangli"]],"application_domain":"Public Safety and Social Governance","prompt":"I need a literature review on adversarial attacks in the field of object detection. This review should systematically summarize the current state of research in this area, covering the classification of mainstream attack methods (such as white-box, black-box, and physical attacks), strategies for attacking different components of object detectors, and the common metrics used to evaluate attack effectiveness. Please ensure that only papers published before April 2025 are referenced and cited."}
{"arxiv_id":"2103.04673","submitter":"Ahmed Alharbi","authors":"Ahmed Alharbi, Hai Dong, Xun Yi, Zahir Tari and Ibrahim Khalil","title":"Social Media Identity Deception Detection: A Survey","comments":"Accepted for publication in ACM Computing Surveys","journal-ref":"ACM Computing Surveys (CSUR), 54(3), 1-35 (2021)","doi":"10.1145\/3446372","report-no":null,"categories":"cs.CR cs.SI","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Social media have been growing rapidly and become essential elements of many people's lives. Meanwhile, social media have also come to be a popular source for identity deception. Many social media identity deception cases have arisen over the past few years. Recent studies have been conducted to prevent and detect identity deception. This survey analyses various identity deception attacks, which can be categorized into fake profile, identity theft and identity cloning. This survey provides a detailed review of social media identity deception detection techniques. It also identifies primary research challenges and issues in the existing detection techniques. This article is expected to benefit both researchers and social media providers.","versions":[{"version":"v1","created":"Mon, 8 Mar 2021 11:19:40 GMT"},{"version":"v2","created":"Thu, 22 Apr 2021 13:45:08 GMT"}],"update_date":"2021-04-23","authors_parsed":[["Alharbi","Ahmed"],["Dong","Hai"],["Yi","Xun"],["Tari","Zahir"],["Khalil","Ibrahim"]],"application_domain":"Public Safety and Social Governance","prompt":"I need a detailed academic research report on social media identity fraud detection. The research should focus on detecting identity fraud attacks on social media platforms and specifically cover detection techniques for the following types of attacks: 1) Fake Profiles, including Sybil attacks, Sockpuppet accounts, and Social Botnets; 2) Identity Theft; 3) Identity Cloning. In terms of detection methods, please prioritize analysis and comparison of techniques based on Graph-based, Machine Learning-based, and Behavior-based approaches. Ensure that all referenced research works were published prior to April 2021, with priority given to English papers published in top-tier conferences in the fields of computer security or data mining (e.g., ACM CCS, NDSS, WWW)."}
{"arxiv_id":"2408.00516","submitter":"Alexandru Vasilache","authors":"Alexandru Vasilache, Sven Nitzsche, Daniel Floegel, Tobias Schuermann, Stefan von Dosky, Thomas Bierweiler, Marvin Mu{\\ss}ler, Florian K\\\"alber, Soeren Hohmann, Juergen Becker","title":"Low-Power Vibration-Based Predictive Maintenance for Industry 4.0 using Neural Networks: A Survey","comments":"The final version will be published at the ECML-PKDD 2024 joint\n  post-workshop proceeding in Springer Communications in Computer and\n  Information Science","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"The advancements in smart sensors for Industry 4.0 offer ample opportunities for low-powered predictive maintenance and condition monitoring. However, traditional approaches in this field rely on processing in the cloud, which incurs high costs in energy and storage. This paper investigates the potential of neural networks for low-power on-device computation of vibration sensor data for predictive maintenance. We review the literature on Spiking Neural Networks (SNNs) and Artificial Neuronal Networks (ANNs) for vibration-based predictive maintenance by analyzing datasets, data preprocessing, network architectures, and hardware implementations. Our findings suggest that no satisfactory standard benchmark dataset exists for evaluating neural networks in predictive maintenance tasks. Furthermore frequency domain transformations are commonly employed for preprocessing. SNNs mainly use shallow feed forward architectures, whereas ANNs explore a wider range of models and deeper networks. Finally, we highlight the need for future research on hardware implementations of neural networks for low-power predictive maintenance applications and the development of a standardized benchmark dataset.","versions":[{"version":"v1","created":"Thu, 1 Aug 2024 12:46:37 GMT"}],"update_date":"2024-08-02","authors_parsed":[["Vasilache","Alexandru"],["Nitzsche","Sven"],["Floegel","Daniel"],["Schuermann","Tobias"],["von Dosky","Stefan"],["Bierweiler","Thomas"],["Mu\u00dfler","Marvin"],["K\u00e4lber","Florian"],["Hohmann","Soeren"],["Becker","Juergen"]],"application_domain":"Manufacturing and Smart Manufacturing","prompt":"Please help me investigate the academic research in the field of low-power, vibration-based predictive maintenance using neural networks under the background of Industry 4.0, with the requirement that only papers published before August 2024 may be referenced."}
{"arxiv_id":"2112.01942","submitter":"Markku Suomalainen","authors":"Markku Suomalainen, Yiannis Karayiannidis and Ville Kyrki","title":"A Survey of Robot Manipulation in Contact","comments":"Accepted for publication in Robotics and Autonomous Systems","journal-ref":"Robotics and Autonomous Systems, Volume 156, 2022, 104224, ISSN\n  0921-8890,","doi":"10.1016\/j.robot.2022.104224","report-no":null,"categories":"cs.RO","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"In this survey, we present the current status on robots performing manipulation tasks that require varying contact with the environment, such that the robot must either implicitly or explicitly control the contact force with the environment to complete the task. Robots can perform more and more manipulation tasks that are still done by humans, and there is a growing number of publications on the topics of 1) performing tasks that always require contact and 2) mitigating uncertainty by leveraging the environment in tasks that, under perfect information, could be performed without contact. The recent trends have seen robots perform tasks earlier left for humans, such as massage, and in the classical tasks, such as peg-in-hole, there is a more efficient generalization to other similar tasks, better error tolerance, and faster planning or learning of the tasks. Thus, in this survey we cover the current stage of robots performing such tasks, starting from surveying all the different in-contact tasks robots can perform, observing how these tasks are controlled and represented, and finally presenting the learning and planning of the skills required to complete these tasks.","versions":[{"version":"v1","created":"Fri, 3 Dec 2021 14:40:47 GMT"},{"version":"v2","created":"Mon, 9 May 2022 09:56:18 GMT"},{"version":"v3","created":"Mon, 25 Jul 2022 20:35:27 GMT"}],"update_date":"2022-08-16","authors_parsed":[["Suomalainen","Markku"],["Karayiannidis","Yiannis"],["Kyrki","Ville"]],"application_domain":"Manufacturing and Smart Manufacturing","prompt":"Please help me research the field of contact-rich manipulation in robotics, but make sure to only reference papers published before July 2022."}
{"arxiv_id":"2403.00669","submitter":"Emmanuel Yangue","authors":"Amirul Islam Saimon, Emmanuel Yangue, Xiaowei Yue, Zhenyu James Kong, Chenang Liu","title":"Advancing Additive Manufacturing through Deep Learning: A Comprehensive Review of Current Progress and Future Challenges","comments":"55 pages, 7 figures, 10 Tables, Published in IISE Transactions","journal-ref":"IISE Transactions, 1-44, 2024","doi":"10.1080\/24725854.2024.2443592","report-no":null,"categories":"cs.LG","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"This paper presents the first comprehensive literature review of deep learning (DL) applications in additive manufacturing (AM). It addresses the need for a thorough analysis in this rapidly growing yet scattered field, aiming to bring together existing knowledge and encourage further development. Our research questions cover three major areas of AM: (i) design for AM, (ii) AM modeling, and (iii) monitoring and control in AM. We use a step-by-step approach following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines to select papers from Scopus and Web of Science databases, aligning with our research questions. We include only those papers that implement DL across seven major AM categories - binder jetting, directed energy deposition, material extrusion, material jetting, powder bed fusion, sheet lamination, and vat photopolymerization. Our analysis reveals a trend towards using deep generative models, such as generative adversarial networks, for generative design in AM. It also highlights an increasing effort to incorporate process physics into DL models to improve AM process modeling and reduce data requirements. Additionally, there is growing interest in using 3D point cloud data for AM process monitoring, alongside traditional 1D and 2D formats. Finally, this paper summarizes the current challenges and recommends some of the promising opportunities in this domain for further investigation with a special focus on (i) generalizing DL models for a wide range of geometry types, (ii) managing uncertainties both in AM data and DL models, (iii) overcoming limited, imbalanced, and noisy AM data issues by incorporating deep generative models, and (iv) unveiling the potential of interpretable DL for AM.","versions":[{"version":"v1","created":"Fri, 1 Mar 2024 17:01:47 GMT"},{"version":"v2","created":"Mon, 23 Dec 2024 19:05:16 GMT"}],"update_date":"2024-12-25","authors_parsed":[["Saimon","Amirul Islam"],["Yangue","Emmanuel"],["Yue","Xiaowei"],["Kong","Zhenyu James"],["Liu","Chenang"]],"application_domain":"Manufacturing and Smart Manufacturing","prompt":"I need a literature review on the application of deep learning in the field of additive manufacturing. The research should primarily cover three aspects: design for additive manufacturing (DfAM), such as topology optimization and geometric deviation compensation; additive manufacturing process modeling, including thermal behavior modeling and process-structure-property (PSP) relationship prediction; and monitoring and control of the additive manufacturing process, such as defect detection and process control based on images, sensor signals, or point cloud data. Particular attention should be given to the application of deep learning methods such as generative adversarial networks (GANs), physics-informed neural networks (PINNs), and recurrent neural networks (RNNs). Please note that you must only refer to papers published before December 2024 for writing."}
{"arxiv_id":"2309.13744","submitter":"Hao Wang","authors":"Hao Wang, Omkar Salunkhe, Walter Quadrini, Dan L\\\"amkull, Fredrik Ore, M\\'elanie Despeisse, Luca Fumagalli, Johan Stahre, Bj\\\"orn Johansson","title":"A Systematic Literature Review of Computer Vision Applications in Robotized Wire Harness Assembly","comments":"This paper has been published in Advanced Engineering Informatics.\n  Please refer to the published version","journal-ref":null,"doi":"10.1016\/j.aei.2024.102596","report-no":null,"categories":"cs.CV cs.AI cs.RO","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"This article provides a systematic literature review of computer vision applications in robotized wire harness assembly.","versions":[{"version":"v1","created":"Sun, 24 Sep 2023 20:28:01 GMT"},{"version":"v2","created":"Wed, 1 Nov 2023 20:10:24 GMT"},{"version":"v3","created":"Tue, 21 May 2024 18:19:00 GMT"}],"update_date":"2024-05-24","authors_parsed":[["Wang","Hao"],["Salunkhe","Omkar"],["Quadrini","Walter"],["L\u00e4mkull","Dan"],["Ore","Fredrik"],["Despeisse","M\u00e9lanie"],["Fumagalli","Luca"],["Stahre","Johan"],["Johansson","Bj\u00f6rn"]],"application_domain":"Manufacturing and Smart Manufacturing","prompt":"I am conducting research on the application of computer vision in robotic harness assembly for automotive production lines and require a detailed literature review. My research focuses on robotic harness assembly in the context of final automobile assembly processes, specifically aiming to address the perception and manipulation challenges associated with flexible harnesses using computer vision technologies. In terms of research orientation, please prioritize studies related to the application of vision systems for the identification, localization, pose estimation, and deformation tracking of harness components (e.g., connectors, clips, cables, harness bundles). Please perform a comparative analysis of the advantages and limitations of traditional image processing methods (e.g., feature point-based approaches, template matching, fiducial markers) versus modern deep learning techniques (e.g., CNNs, object detection, instance segmentation). Additionally, explore the differences and development trends in the application of 2D vision versus 3D vision technologies (e.g., RGB-D cameras, point cloud processing) in this particular context. For the literature selection, prioritize references from top-tier conferences and journals in robotics and automation (e.g., ICRA, IROS, CASE, IEEE Transactions on Automation Science and Engineering, Robotics and Computer-Integrated Manufacturing). The language of the papers should be restricted to English, with a preference for works authored by institutions such as Chalmers University of Technology, Technical University of Munich, Osaka University, or research groups with collaborations with automotive companies like Volvo or Scania. Lastly, the review should address the challenges faced when implementing these techniques in real-life industrial production, such as ensuring robustness, achieving real-time performance (cycle time), and enabling human-robot collaboration (HRC). Please ensure all analyses and citations are drawn exclusively from papers published no later than May 2024."}
{"arxiv_id":"2210.06858","submitter":"Jonas Fritzsch","authors":"Jonas Fritzsch, Justus Bogner, Markus Haug, Ana Cristina Franco da Silva, Carolin Rubner, Matthias Saft, Horst Sauer, Stefan Wagner","title":"Adopting Microservices and DevOps in the Cyber-Physical Systems Domain: A Rapid Review and Case Study","comments":"10 pages, 8 figures, accepted for publication at \"Software: Practice\n  and Experience - Wiley Online Library\"","journal-ref":null,"doi":"10.1002\/spe.3169","report-no":null,"categories":"cs.SE","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"The domain of cyber-physical systems (CPS) has recently seen strong growth, e.g., due to the rise of the Internet of Things (IoT) in industrial domains, commonly referred to as \"Industry 4.0\". However, CPS challenges like the strong hardware focus can impact modern software development practices, especially in the context of modernizing legacy systems. While microservices and DevOps have been widely studied for enterprise applications, there is insufficient coverage for the CPS domain. Our goal is therefore to analyze the peculiarities of such systems regarding challenges and practices for using and migrating towards microservices and DevOps. We conducted a rapid review based on 146 scientific papers, and subsequently validated our findings in an interview-based case study with 9 CPS professionals in different business units at Siemens AG. The combined results picture the specifics of microservices and DevOps in the CPS domain. While several differences were revealed that may require adapted methods, many challenges and practices are shared with typical enterprise applications. Our study supports CPS researchers and practitioners with a summary of challenges, practices to address them, and research opportunities.","versions":[{"version":"v1","created":"Thu, 13 Oct 2022 09:18:45 GMT"}],"update_date":"2022-11-22","authors_parsed":[["Fritzsch","Jonas"],["Bogner","Justus"],["Haug","Markus"],["da Silva","Ana Cristina Franco"],["Rubner","Carolin"],["Saft","Matthias"],["Sauer","Horst"],["Wagner","Stefan"]],"application_domain":"Manufacturing and Smart Manufacturing","prompt":"Please help me research academic studies on the adoption of microservices and DevOps in the field of Cyber-Physical Systems (CPS) prior to October 2022."}
{"arxiv_id":"2207.14394","submitter":"Josiah Walker","authors":"Josiah Walker, Nakul Bajaj, Braden L. Crimmins, and J. Alex Halderman","title":"Logic and Accuracy Testing: A Fifty-State Review","comments":"27 pages, 4 figures, to be published in E-Vote-ID: Seventh\n  International Joint Conference on Electronic Voting","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CY","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Pre-election logic and accuracy (L&A) testing is a process in which election officials validate the behavior of voting equipment by casting a known set of test ballots and confirming the expected results. Ideally, such testing can serve to detect certain forms of human error or fraud and help bolster voter confidence. We present the first detailed analysis of L&A testing practices across the United States. We find that while all states require L&A testing before every election, their implementations vary dramatically in scope, transparency, and rigorousness. We summarize each state's requirements and score them according to uniform criteria. We also highlight best practices and flag opportunities for improvement, in hopes of encouraging broader adoption of more effective L&A processes.","versions":[{"version":"v1","created":"Thu, 28 Jul 2022 22:21:37 GMT"},{"version":"v2","created":"Mon, 1 Aug 2022 15:53:35 GMT"}],"update_date":"2022-08-02","authors_parsed":[["Walker","Josiah"],["Bajaj","Nakul"],["Crimmins","Braden L."],["Halderman","J. Alex"]],"application_domain":"Public Safety and Social Governance","prompt":"I need a detailed literature review on the \"Logic and Accuracy (L&A) Testing\" of electronic voting systems in the United States. The core of the research is to evaluate and compare the policies and procedures for L&A testing implemented by different U.S. states to verify voting equipment prior to elections. The review should thoroughly explore the following aspects: 1) the objectives of L&A testing, such as detecting equipment malfunctions, misconfigurations, and preventing specific types of fraud; 2) differences in testing procedures across jurisdictions, particularly among U.S. states, including the scope, rigor, and transparency of the tests; and 3) specific methodologies for evaluating L&A testing effectiveness, such as whether all devices and ballot styles are tested, whether the testing process is public, whether it can detect ballot option shifts, whether it verifies multi-ballot limits, and whether non-deterministic or randomized testing is utilized to enhance security.\n\nRestrictions are as follows:\n1. Cutoff Date: All cited literature must have been published on or before August 2022.\n2. Paper Language: Focus primarily on English-language literature.\n3. Publishing Institutions: Pay special attention to work published by institutions with outstanding research in election security, such as the University of Michigan.\n4. Conferences\/Journals: Prioritize papers presented at top-tier security and electronic voting conferences, such as USENIX Security and USENIX EVT\/E-Vote-ID."}
{"arxiv_id":"2311.06993","submitter":"Sizhe Ma","authors":"Sizhe Ma, Katherine A. Flanigan, Mario Berg\\'es","title":"State-of-the-art review and synthesis: A requirement-based roadmap for standardized predictive maintenance automation using digital twin technologies","comments":"This paper has been accepted for publication in Advanced Engineering\n  Informatics (2024)","journal-ref":null,"doi":"10.1016\/j.aei.2024.102800","report-no":null,"categories":"cs.AI cs.SY eess.SY","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Recent digital advances have popularized predictive maintenance (PMx), offering enhanced efficiency, automation, accuracy, cost savings, and independence in maintenance processes. Yet, PMx continues to face numerous limitations such as poor explainability, sample inefficiency of data-driven methods, complexity of physics-based methods, and limited generalizability and scalability of knowledge-based methods. This paper proposes leveraging Digital Twins (DTs) to address these challenges and enable automated PMx adoption on a larger scale. While DTs have the potential to be transformative, they have not yet reached the maturity needed to bridge these gaps in a standardized manner. Without a standard definition guiding this evolution, the transformation lacks a solid foundation for development. This paper provides a requirement-based roadmap to support standardized PMx automation using DT technologies. Our systematic approach comprises two primary stages. First, we methodically identify the Informational Requirements (IRs) and Functional Requirements (FRs) for PMx, which serve as a foundation from which any unified framework must emerge. Our approach to defining and using IRs and FRs as the backbone of any PMx DT is supported by the proven success of these requirements as blueprints in other areas, such as product development in the software industry. Second, we conduct a thorough literature review across various fields to assess how these IRs and FRs are currently being applied within DTs, enabling us to identify specific areas where further research is needed to support the progress and maturation of requirement-based PMx DTs.","versions":[{"version":"v1","created":"Mon, 13 Nov 2023 00:16:25 GMT"},{"version":"v2","created":"Tue, 10 Sep 2024 15:20:25 GMT"}],"update_date":"2024-09-11","authors_parsed":[["Ma","Sizhe"],["Flanigan","Katherine A."],["Berg\u00e9s","Mario"]],"application_domain":"Manufacturing and Smart Manufacturing","prompt":"I need your assistance in completing an academic research study on the application of digital twin technology to achieve predictive maintenance automation. This study requires a systematic review of the current state of research in this field, with a focus on the information and functional requirements that support predictive maintenance tasks, such as fault detection, health assessment, and lifetime prediction. Please investigate how existing digital twin applications fulfill these requirements, especially those leveraging data-driven, physics-based, or hybrid modeling approaches. Finally, identify the critical gaps in current studies and suggest future research directions. Please note that all referenced literature must have been published before September 2024."}
{"arxiv_id":"2303.14133","submitter":"Junhao Dong","authors":"Junhao Dong, Junxi Chen, Xiaohua Xie, Jianhuang Lai, and Hao Chen","title":"Survey on Adversarial Attack and Defense for Medical Image Analysis: Methods and Challenges","comments":"Accepted by ACM Computing Surveys (CSUR) (DOI:\n  https:\/\/doi.org\/10.1145\/3702638)","journal-ref":null,"doi":"10.1145\/3702638","report-no":null,"categories":"eess.IV cs.CR cs.CV","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Deep learning techniques have achieved superior performance in computer-aided medical image analysis, yet they are still vulnerable to imperceptible adversarial attacks, resulting in potential misdiagnosis in clinical practice. Oppositely, recent years have also witnessed remarkable progress in defense against these tailored adversarial examples in deep medical diagnosis systems. In this exposition, we present a comprehensive survey on recent advances in adversarial attacks and defenses for medical image analysis with a systematic taxonomy in terms of the application scenario. We also provide a unified framework for different types of adversarial attack and defense methods in the context of medical image analysis. For a fair comparison, we establish a new benchmark for adversarially robust medical diagnosis models obtained by adversarial training under various scenarios. To the best of our knowledge, this is the first survey paper that provides a thorough evaluation of adversarially robust medical diagnosis models. By analyzing qualitative and quantitative results, we conclude this survey with a detailed discussion of current challenges for adversarial attack and defense in medical image analysis systems to shed light on future research directions. Code is available on \\href{https:\/\/github.com\/tomvii\/Adv_MIA}{\\color{red}{GitHub}}.","versions":[{"version":"v1","created":"Fri, 24 Mar 2023 16:38:58 GMT"},{"version":"v2","created":"Mon, 4 Nov 2024 02:59:25 GMT"}],"update_date":"2024-11-05","authors_parsed":[["Dong","Junhao"],["Chen","Junxi"],["Xie","Xiaohua"],["Lai","Jianhuang"],["Chen","Hao"]],"application_domain":"Healthcare and Biomedicine","prompt":"Please help me research adversarial attacks and defense methods in the field of medical image analysis, and ensure that all referenced papers are published before November 2024."}
{"arxiv_id":"2405.13082","submitter":"Haocong Rao","authors":"Haocong Rao, Minlin Zeng, Xuejiao Zhao, Chunyan Miao","title":"A Survey of Artificial Intelligence in Gait-Based Neurodegenerative Disease Diagnosis","comments":"Accepted by Neurocomputing journal. Article: 57 pages, citing 290\n  papers. Appendix: 30 pages. A up-to-date resource (papers, data, etc.) of\n  this survey (AI4NDD) is provided at\n  https:\/\/github.com\/minlinzeng\/AI4NDD-Survey","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CV","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Recent years have witnessed an increasing global population affected by neurodegenerative diseases (NDs), which traditionally require extensive healthcare resources and human effort for medical diagnosis and monitoring. As a crucial disease-related motor symptom, human gait can be exploited to characterize different NDs. The current advances in artificial intelligence (AI) models enable automatic gait analysis for NDs identification and classification, opening a new avenue to facilitate faster and more cost-effective diagnosis of NDs. In this paper, we provide a comprehensive survey on recent progress of machine learning and deep learning based AI techniques applied to diagnosis of five typical NDs through gait. We provide an overview of the process of AI-assisted NDs diagnosis, and present a systematic taxonomy of existing gait data and AI models. Meanwhile, a novel quality evaluation criterion is proposed to quantitatively assess the quality of existing studies. Through an extensive review and analysis of 169 studies, we present recent technical advancements, discuss existing challenges, potential solutions, and future directions in this field. Finally, we envision the prospective utilization of 3D skeleton data for human gait representation and the development of more efficient AI models for NDs diagnosis.","versions":[{"version":"v1","created":"Tue, 21 May 2024 06:44:40 GMT"},{"version":"v2","created":"Thu, 18 Jul 2024 09:12:08 GMT"},{"version":"v3","created":"Thu, 12 Dec 2024 13:02:17 GMT"},{"version":"v4","created":"Mon, 16 Dec 2024 04:44:47 GMT"},{"version":"v5","created":"Thu, 6 Feb 2025 13:34:48 GMT"}],"update_date":"2025-02-07","authors_parsed":[["Rao","Haocong"],["Zeng","Minlin"],["Zhao","Xuejiao"],["Miao","Chunyan"]],"application_domain":"Healthcare and Biomedicine","prompt":"I need an academic survey on the use of artificial intelligence for gait-assisted diagnosis of neurodegenerative diseases. This survey should systematically review the research field, focusing on how machine learning and deep learning models are utilized to diagnose various neurodegenerative diseases such as Parkinson's disease and Alzheimer's disease by analyzing patients' gait data. Special attention should be paid to the types of AI methods employed, including traditional approaches like Support Vector Machines (SVM) and Random Forests, as well as more modern techniques like Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Graph Neural Networks (GCN). Please ensure that all references and cited papers were published before February 2025."}
{"arxiv_id":"2406.17804","submitter":"Hongyan Kai","authors":"Wanyu Bian, Panfeng Li, Mengyao Zheng, Chihang Wang, Anying Li, Ying Li, Haowei Ni, Zixuan Zeng","title":"A Review of Electromagnetic Elimination Methods for low-field portable MRI scanner","comments":"Accepted by 2024 5th International Conference on Machine Learning and\n  Computer Application","journal-ref":"Proceedings of the 2024 5th International Conference on Machine\n  Learning and Computer Application (ICMLCA), 2024, pp. 614-618","doi":"10.1109\/ICMLCA63499.2024.10753737","report-no":null,"categories":"physics.med-ph cs.AI cs.CV cs.LG eess.IV","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"This paper analyzes conventional and deep learning methods for eliminating electromagnetic interference (EMI) in MRI systems. We compare traditional analytical and adaptive techniques with advanced deep learning approaches. Key strengths and limitations of each method are highlighted. Recent advancements in active EMI elimination, such as external EMI receiver coils, are discussed alongside deep learning methods, which show superior EMI suppression by leveraging neural networks trained on MRI data. While deep learning improves EMI elimination and diagnostic capabilities, it introduces security and safety concerns, particularly in commercial applications. A balanced approach, integrating conventional reliability with deep learning's advanced capabilities, is proposed for more effective EMI suppression in MRI systems.","versions":[{"version":"v1","created":"Sat, 22 Jun 2024 15:24:33 GMT"},{"version":"v2","created":"Mon, 14 Oct 2024 03:09:16 GMT"},{"version":"v3","created":"Wed, 13 Nov 2024 09:50:48 GMT"}],"update_date":"2024-11-25","authors_parsed":[["Bian","Wanyu"],["Li","Panfeng"],["Zheng","Mengyao"],["Wang","Chihang"],["Li","Anying"],["Li","Ying"],["Ni","Haowei"],["Zeng","Zixuan"]],"application_domain":"Healthcare and Biomedicine","prompt":"Please help me investigate academic papers published before November 2024 on electromagnetic interference elimination methods for low-field portable MRI."}
{"arxiv_id":"2204.10325","submitter":"Chinmoy Deka","authors":"Chinmoy Deka, Abhishek Shrivastava, Ajish K. Abraham, Saurabh Nautiyal, Praveen Chauhan","title":"AI-Based Automated Speech Therapy Tools for persons with Speech Sound Disorders: A Systematic Literature Review","comments":"This article has been accepted for publication in Speech, Language\n  and Hearing, published by Taylor & Francis","journal-ref":null,"doi":"10.21203\/rs.3.rs-1517404\/v1","report-no":null,"categories":"cs.HC cs.AI","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"This paper presents a systematic literature review of published studies on AI-based automated speech therapy tools for persons with speech sound disorders (SSD). The COVID-19 pandemic has initiated the requirement for automated speech therapy tools for persons with SSD making speech therapy accessible and affordable. However, there are no guidelines for designing such automated tools and their required degree of automation compared to human experts. In this systematic review, we followed the PRISMA framework to address four research questions: 1) what types of SSD do AI-based automated speech therapy tools address, 2) what is the level of autonomy achieved by such tools, 3) what are the different modes of intervention, and 4) how effective are such tools in comparison with human experts. An extensive search was conducted on digital libraries to find research papers relevant to our study from 2007 to 2022. The results show that AI-based automated speech therapy tools for persons with SSD are increasingly gaining attention among researchers. Articulation disorders were the most frequently addressed SSD based on the reviewed papers. Further, our analysis shows that most researchers proposed fully automated tools without considering the role of other stakeholders. Our review indicates that mobile-based and gamified applications were the most frequent mode of intervention. The results further show that only a few studies compared the effectiveness of such tools compared to expert Speech-Language Pathologists (SLP). Our paper presents the state-of-the-art in the field, contributes significant insights based on the research questions, and provides suggestions for future research directions.","versions":[{"version":"v1","created":"Thu, 21 Apr 2022 13:02:41 GMT"},{"version":"v2","created":"Thu, 18 Apr 2024 20:42:41 GMT"}],"update_date":"2024-04-22","authors_parsed":[["Deka","Chinmoy"],["Shrivastava","Abhishek"],["Abraham","Ajish K."],["Nautiyal","Saurabh"],["Chauhan","Praveen"]],"application_domain":"Healthcare and Biomedicine","prompt":"Please help me research the field of \"artificial intelligence-based automated speech therapy tools applied to speech disorders,\" ensuring that all reference materials are published before April 2024."}
{"arxiv_id":"2304.11218","submitter":"Luca Nannini","authors":"Luca Nannini, Agathe Balayn, Adam Leon Smith","title":"Explainability in AI Policies: A Critical Review of Communications, Reports, Regulations, and Standards in the EU, US, and UK","comments":"Submission draft accepted for ACM FAccT 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CY cs.AI","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Public attention towards explainability of artificial intelligence (AI) systems has been rising in recent years to offer methodologies for human oversight. This has translated into the proliferation of research outputs, such as from Explainable AI, to enhance transparency and control for system debugging and monitoring, and intelligibility of system process and output for user services. Yet, such outputs are difficult to adopt on a practical level due to a lack of a common regulatory baseline, and the contextual nature of explanations. Governmental policies are now attempting to tackle such exigence, however it remains unclear to what extent published communications, regulations, and standards adopt an informed perspective to support research, industry, and civil interests. In this study, we perform the first thematic and gap analysis of this plethora of policies and standards on explainability in the EU, US, and UK. Through a rigorous survey of policy documents, we first contribute an overview of governmental regulatory trajectories within AI explainability and its sociotechnical impacts. We find that policies are often informed by coarse notions and requirements for explanations. This might be due to the willingness to conciliate explanations foremost as a risk management tool for AI oversight, but also due to the lack of a consensus on what constitutes a valid algorithmic explanation, and how feasible the implementation and deployment of such explanations are across stakeholders of an organization. Informed by AI explainability research, we conduct a gap analysis of existing policies, leading us to formulate a set of recommendations on how to address explainability in regulations for AI systems, especially discussing the definition, feasibility, and usability of explanations, as well as allocating accountability to explanation providers.","versions":[{"version":"v1","created":"Thu, 20 Apr 2023 07:53:07 GMT"}],"update_date":"2023-04-25","authors_parsed":[["Nannini","Luca"],["Balayn","Agathe"],["Smith","Adam Leon"]],"application_domain":"Public Safety and Social Governance","prompt":"I require a comprehensive academic investigation into the policies and regulations regarding the explainability of Artificial Intelligence (AI). Specifically, I aim to systematically review and critically analyze official communications, policy reports, laws, regulations, and industry standards related to AI explainability, as issued by governments or relevant institutions within the European Union, United States, and United Kingdom. The core focus of this investigation is to conduct thematic and gap analyses to identify how current policies and regulations define, require, and adopt explainability, while comparing these aspects with the current state of academic research in areas such as algorithms, human-computer interaction (HCI), and AI ethics. I am particularly interested in how policies address issues related to the definition, feasibility, usability of explainability, and the allocation of accountability.\n\nTo ensure the accuracy of this investigation, please adhere to the following guidelines:\n1. **Cut-off Date**: All cited references and policy documents must have been published before April 2023.\n2. **Language of Papers**: Focus primarily on English-language academic papers.\n3. **Target Conferences\/Journals**: Emphasize top-tier conferences in AI, HCI, and ethics, such as FAccT (ACM Conference on Fairness, Accountability, and Transparency), CHI (ACM Conference on Human Factors in Computing Systems), and AAAI.\n4. **Target Institutions**: When analyzing policies and standards, pay special attention to reports and guidelines issued by organizations such as the U.S. National Institute of Standards and Technology (NIST), the UK Information Commissioner's Office (ICO), the Alan Turing Institute, and the European Union High-Level Expert Group on Artificial Intelligence (HLEG)."}
{"arxiv_id":"2312.06445","submitter":"Trevor Exley","authors":"Trevor Exley, Emilly Hays, Daniel Johnson, Arian Moridani, Ramya Motati, Amir Jafari","title":"Towards a Unified Naming Scheme for Thermo-Active Soft Actuators: A Review of Materials, Working Principles, and Applications","comments":"16 pages, 10 figures, accepted to Robotics Reports","journal-ref":null,"doi":"10.1089\/rorep.2023.0023","report-no":null,"categories":"cs.RO","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Soft robotics is a rapidly growing field that spans the fields of chemistry, materials science, and engineering. Due to the diverse background of the field, there have been contrasting naming schemes such as 'intelligent', 'smart' and 'adaptive' materials which add vagueness to the broad innovation among literature. Therefore, a clear, functional and descriptive naming scheme is proposed in which a previously vague name -- Soft Material for Soft Actuators -- can remain clear and concise -- Phase-Change Elastomers for Artificial Muscles. By synthesizing the working principle, material, and application into a naming scheme, the searchability of soft robotics can be enhanced and applied to other fields. The field of thermo-active soft actuators spans multiple domains and requires added clarity. Thermo-active actuators have potential for a variety of applications spanning virtual reality haptics to assistive devices. This review offers a comprehensive guide to selecting the type of thermo-active actuator when one has an application in mind. Additionally, it discusses future directions and improvements that are necessary for implementation.","versions":[{"version":"v1","created":"Mon, 11 Dec 2023 15:25:52 GMT"}],"update_date":"2024-01-22","authors_parsed":[["Exley","Trevor"],["Hays","Emilly"],["Johnson","Daniel"],["Moridani","Arian"],["Motati","Ramya"],["Jafari","Amir"]],"application_domain":"Healthcare and Biomedicine","prompt":"I am conducting a literature review on thermally active soft actuators. Please help me summarize the current state of research in this field, focusing on core materials (such as shape memory polymers, liquid crystal elastomers, phase change materials, etc.) and their working principles (such as shape memory effect, phase change-induced volume expansion, Joule heating effect, etc.). Additionally, organize their performance in applications like artificial muscles and rehabilitation devices. During the investigation, please ensure that all referenced literature must have been published before December 2023."}
{"arxiv_id":"2108.11986","submitter":"Maximilian Ernst Tschuchnig","authors":"Maximilian E. Tschuchnig and Michael Gadermayr","title":"Anomaly Detection in Medical Imaging -- A Mini Review","comments":"Accepted and presented at iDSC2021 edit: During work on this\n  publication Maximilian Ernst Tschuchnig was affiliated with Salzburg\n  University of Applied Sciences and University of Salzburg","journal-ref":"international Data Science Conference 2021","doi":"10.1007\/978-3-658-36295-9_5","report-no":null,"categories":"eess.IV cs.CV cs.LG","license":"http:\/\/creativecommons.org\/licenses\/by-sa\/4.0\/","abstract":"The increasing digitization of medical imaging enables machine learning based improvements in detecting, visualizing and segmenting lesions, easing the workload for medical experts. However, supervised machine learning requires reliable labelled data, which is is often difficult or impossible to collect or at least time consuming and thereby costly. Therefore methods requiring only partly labeled data (semi-supervised) or no labeling at all (unsupervised methods) have been applied more regularly. Anomaly detection is one possible methodology that is able to leverage semi-supervised and unsupervised methods to handle medical imaging tasks like classification and segmentation. This paper uses a semi-exhaustive literature review of relevant anomaly detection papers in medical imaging to cluster into applications, highlight important results, establish lessons learned and give further advice on how to approach anomaly detection in medical imaging. The qualitative analysis is based on google scholar and 4 different search terms, resulting in 120 different analysed papers. The main results showed that the current research is mostly motivated by reducing the need for labelled data. Also, the successful and substantial amount of research in the brain MRI domain shows the potential for applications in further domains like OCT and chest X-ray.","versions":[{"version":"v1","created":"Wed, 25 Aug 2021 11:45:40 GMT"},{"version":"v2","created":"Mon, 2 Dec 2024 14:25:58 GMT"}],"update_date":"2024-12-03","authors_parsed":[["Tschuchnig","Maximilian E."],["Gadermayr","Michael"]],"application_domain":"Healthcare and Biomedicine","prompt":"I am researching anomaly detection in medical imaging, with a primary focus on unsupervised and semi-supervised learning methods aimed at reducing reliance on large amounts of labeled data. Please help me review the research progress in this direction, particularly techniques based on reconstruction or deviation, such as autoencoders (AEs), generative adversarial networks (GANs), and their variants. Also, please include applications of some classic one-class classification methods (e.g., OC-SVM). Ensure that all the papers you reference were published before December 2024."}
{"arxiv_id":"2101.01665","submitter":"Rana Mostafa AbdElMohsen AbdElMolla","authors":"Reem Abdel-Salam, Rana Mostafa and Mayada Hadhood","title":"Human Activity Recognition using Wearable Sensors: Review, Challenges, Evaluation Benchmark","comments":"Accepted at 2ND International Workshop on Deep Learning for Human\n  Activity Recognition, Held in conjunction with IJCAI-PRICAI 2020, January\n  2021, Japan and published at Springer Communications in Computer and\n  Information Science (CCIS) proceedings","journal-ref":"CCIS. 1370(2021) 1-15","doi":"10.1007\/978-981-16-0575-8_1","report-no":null,"categories":"cs.CV","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Recognizing human activity plays a significant role in the advancements of human-interaction applications in healthcare, personal fitness, and smart devices. Many papers presented various techniques for human activity representation that resulted in distinguishable progress. In this study, we conduct an extensive literature review on recent, top-performing techniques in human activity recognition based on wearable sensors. Due to the lack of standardized evaluation and to assess and ensure a fair comparison between the state-of-the-art techniques, we applied a standardized evaluation benchmark on the state-of-the-art techniques using six publicly available data-sets: MHealth, USCHAD, UTD-MHAD, WISDM, WHARF, and OPPORTUNITY. Also, we propose an experimental, improved approach that is a hybrid of enhanced handcrafted features and a neural network architecture which outperformed top-performing techniques with the same standardized evaluation benchmark applied concerning MHealth, USCHAD, UTD-MHAD data-sets.","versions":[{"version":"v1","created":"Tue, 5 Jan 2021 17:33:04 GMT"},{"version":"v2","created":"Wed, 6 Jan 2021 09:19:21 GMT"}],"update_date":"2023-11-22","authors_parsed":[["Abdel-Salam","Reem"],["Mostafa","Rana"],["Hadhood","Mayada"]],"application_domain":"Healthcare and Biomedicine","prompt":"I want to investigate research on human activity recognition (HAR) using wearable sensors such as accelerometers and gyroscopes. Please focus on papers published before January 2021 and review the mainstream methods in this field, including approaches based on handcrafted feature extraction and traditional machine learning classifiers, as well as deep learning-based methods, especially techniques for processing sensor time-series data using convolutional neural networks (CNN), long short-term memory networks (LSTM), and hybrid models combining CNN and LSTM."}
{"arxiv_id":"2206.05498","submitter":"Athanasios Vlontzos","authors":"Athanasios Vlontzos, Daniel Rueckert, Bernhard Kainz","title":"A Review of Causality for Learning Algorithms in Medical Image Analysis","comments":"Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA)\n  https:\/\/www.melba-journal.org\/papers\/2022:028.html\". ; Paper ID: 2022:028","journal-ref":"Machine.Learning.for.Biomedical.Imaging. 1 (2022)","doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.GL","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Medical image analysis is a vibrant research area that offers doctors and medical practitioners invaluable insight and the ability to accurately diagnose and monitor disease. Machine learning provides an additional boost for this area. However, machine learning for medical image analysis is particularly vulnerable to natural biases like domain shifts that affect algorithmic performance and robustness. In this paper we analyze machine learning for medical image analysis within the framework of Technology Readiness Levels and review how causal analysis methods can fill a gap when creating robust and adaptable medical image analysis algorithms. We review methods using causality in medical imaging AI\/ML and find that causal analysis has the potential to mitigate critical problems for clinical translation but that uptake and clinical downstream research has been limited so far.","versions":[{"version":"v1","created":"Sat, 11 Jun 2022 11:04:13 GMT"},{"version":"v2","created":"Sat, 26 Nov 2022 10:25:19 GMT"}],"update_date":"2022-11-29","authors_parsed":[["Vlontzos","Athanasios"],["Rueckert","Daniel"],["Kainz","Bernhard"]],"application_domain":"Healthcare and Biomedicine","prompt":"I need a comprehensive literature review on the topic of causality in the application of machine learning algorithms for medical image analysis. My main focus is on how methods like causal inference and causal discovery can enhance the robustness, fairness, and explainability of models when addressing challenges such as domain shift, selection bias, and spurious correlations. Please emphasize the following aspects:\n1. Causal methods to address out-of-distribution (OOD) generalization and domain adaptation problems.\n2. Techniques based on causal relationships to generate counterfactual medical images and their applications.\n3. Research utilizing causal analysis to improve algorithmic fairness, safety, and explainability.\nReferences should primarily be in English, especially papers published in top-tier conferences and journals such as MICCAI, ISBI, and IPMI. You may consider research outputs from institutions like Imperial College London. Importantly, your response must strictly reference papers published before November 2022."}
{"arxiv_id":"2401.07915","submitter":"Avishai Sintov","authors":"Abraham Itzhak Weinberg, Alon Shirizly, Osher Azulay and Avishai Sintov","title":"Survey of Learning-based Approaches for Robotic In-Hand Manipulation","comments":"Accepted to Frontiers in Robotics and AI","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Human dexterity is an invaluable capability for precise manipulation of objects in complex tasks. The capability of robots to similarly grasp and perform in-hand manipulation of objects is critical for their use in the ever changing human environment, and for their ability to replace manpower. In recent decades, significant effort has been put in order to enable in-hand manipulation capabilities to robotic systems. Initial robotic manipulators followed carefully programmed paths, while later attempts provided a solution based on analytical modeling of motion and contact. However, these have failed to provide practical solutions due to inability to cope with complex environments and uncertainties. Therefore, the effort has shifted to learning-based approaches where data is collected from the real world or through a simulation, during repeated attempts to complete various tasks. The vast majority of learning approaches focused on learning data-based models that describe the system to some extent or Reinforcement Learning (RL). RL, in particular, has seen growing interest due to the remarkable ability to generate solutions to problems with minimal human guidance. In this survey paper, we track the developments of learning approaches for in-hand manipulations and, explore the challenges and opportunities. This survey is designed both as an introduction for novices in the field with a glossary of terms as well as a guide of novel advances for advanced practitioners.","versions":[{"version":"v1","created":"Mon, 15 Jan 2024 19:07:37 GMT"},{"version":"v2","created":"Thu, 24 Oct 2024 16:14:21 GMT"}],"update_date":"2024-10-25","authors_parsed":[["Weinberg","Abraham Itzhak"],["Shirizly","Alon"],["Azulay","Osher"],["Sintov","Avishai"]],"application_domain":"Manufacturing and Smart Manufacturing","prompt":"I'm conducting research in the field of robotic in-hand manipulation. I would like you to provide a review of the development in this area, with a focus on three main technical approaches: Model-driven Learning, Reinforcement Learning, and Imitation Learning. In your review, please discuss how these methods address specific challenges in dexterous hand manipulation, such as object pose estimation, dynamics modeling, and policy learning. Note that you may only reference and cite academic papers published before October 2024."}
{"arxiv_id":"2412.06157","submitter":"Li Bai","authors":"Li Bai, Haibo Hu, Qingqing Ye, Haoyang Li, Leixia Wang, Jianliang Xu","title":"Membership Inference Attacks and Defenses in Federated Learning: A Survey","comments":"To be published in ACM Computing Surveys","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Federated learning is a decentralized machine learning approach where clients train models locally and share model updates to develop a global model. This enables low-resource devices to collaboratively build a high-quality model without requiring direct access to the raw training data. However, despite only sharing model updates, federated learning still faces several privacy vulnerabilities. One of the key threats is membership inference attacks, which target clients' privacy by determining whether a specific example is part of the training set. These attacks can compromise sensitive information in real-world applications, such as medical diagnoses within a healthcare system. Although there has been extensive research on membership inference attacks, a comprehensive and up-to-date survey specifically focused on it within federated learning is still absent. To fill this gap, we categorize and summarize membership inference attacks and their corresponding defense strategies based on their characteristics in this setting. We introduce a unique taxonomy of existing attack research and provide a systematic overview of various countermeasures. For these studies, we thoroughly analyze the strengths and weaknesses of different approaches. Finally, we identify and discuss key future research directions for readers interested in advancing the field.","versions":[{"version":"v1","created":"Mon, 9 Dec 2024 02:39:58 GMT"}],"update_date":"2024-12-10","authors_parsed":[["Bai","Li"],["Hu","Haibo"],["Ye","Qingqing"],["Li","Haoyang"],["Wang","Leixia"],["Xu","Jianliang"]],"application_domain":"Healthcare and Biomedicine","prompt":"I need a literature review on Membership Inference Attacks and defense techniques in Federated Learning. This review should systematically summarize the current state of research in this field, including but not limited to the categorization of mainstream attack methods (e.g., attacks based on model updates, trend-based attacks, etc.) and corresponding defense strategies (e.g., partial sharing, secure aggregation, noise perturbation, anomaly detection, etc.). Please provide a detailed analysis of the principles, advantages, and disadvantages of each type of attack and defense technology, and ensure that all cited research outcomes were published before December 2024."}
{"arxiv_id":"2310.11011","submitter":"Aneesh Komanduri","authors":"Aneesh Komanduri, Xintao Wu, Yongkai Wu, Feng Chen","title":"From Identifiable Causal Representations to Controllable Counterfactual Generation: A Survey on Causal Generative Modeling","comments":"Published in Transactions on Machine Learning Research (TMLR)\n  (05\/2024); 72 pages, 27 figures, 4 tables","journal-ref":"Transactions on Machine Learning Research, 2024","doi":null,"report-no":null,"categories":"cs.LG cs.AI stat.ML","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Deep generative models have shown tremendous capability in data density estimation and data generation from finite samples. While these models have shown impressive performance by learning correlations among features in the data, some fundamental shortcomings are their lack of explainability, tendency to induce spurious correlations, and poor out-of-distribution extrapolation. To remedy such challenges, recent work has proposed a shift toward causal generative models. Causal models offer several beneficial properties to deep generative models, such as distribution shift robustness, fairness, and interpretability. Structural causal models (SCMs) describe data-generating processes and model complex causal relationships and mechanisms among variables in a system. Thus, SCMs can naturally be combined with deep generative models. We provide a technical survey on causal generative modeling categorized into causal representation learning and controllable counterfactual generation methods. We focus on fundamental theory, methodology, drawbacks, datasets, and metrics. Then, we cover applications of causal generative models in fairness, privacy, out-of-distribution generalization, precision medicine, and biological sciences. Lastly, we discuss open problems and fruitful research directions for future work in the field.","versions":[{"version":"v1","created":"Tue, 17 Oct 2023 05:45:32 GMT"},{"version":"v2","created":"Thu, 23 May 2024 16:59:29 GMT"}],"update_date":"2024-05-24","authors_parsed":[["Komanduri","Aneesh"],["Wu","Xintao"],["Wu","Yongkai"],["Chen","Feng"]],"application_domain":"Healthcare and Biomedicine","prompt":"I need a scholarly review on causal generative models. This review should primarily focus on two major directions: Identifiable Causal Representation Learning (CRL) and Controllable Counterfactual Generation (CCG). For CRL, please investigate how to learn semantically meaningful latent variables with causal relationships and their causal structures from high-dimensional data, especially methods that leverage data from different levels (observational, interventional, counterfactual) of Pearl's Causal Hierarchy. For CCG, please focus on how to model known causal variables to achieve controllable sample generation. The review should cover representative methods based on various generative models such as VAE, GAN, flow models, and diffusion models. Please ensure that all referenced literature is published before May 2024."}
{"arxiv_id":"2401.16386","submitter":"Da-Wei Zhou","authors":"Da-Wei Zhou, Hai-Long Sun, Jingyi Ning, Han-Jia Ye, De-Chuan Zhan","title":"Continual Learning with Pre-Trained Models: A Survey","comments":"Accepted to IJCAI 2024. Code is available at:\n  https:\/\/github.com\/sun-hailong\/LAMDA-PILOT","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CV","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Nowadays, real-world applications often face streaming data, which requires the learning system to absorb new knowledge as data evolves. Continual Learning (CL) aims to achieve this goal and meanwhile overcome the catastrophic forgetting of former knowledge when learning new ones. Typical CL methods build the model from scratch to grow with incoming data. However, the advent of the pre-trained model (PTM) era has sparked immense research interest, particularly in leveraging PTMs' robust representational capabilities. This paper presents a comprehensive survey of the latest advancements in PTM-based CL. We categorize existing methodologies into three distinct groups, providing a comparative analysis of their similarities, differences, and respective advantages and disadvantages. Additionally, we offer an empirical study contrasting various state-of-the-art methods to highlight concerns regarding fairness in comparisons. The source code to reproduce these evaluations is available at: https:\/\/github.com\/sun-hailong\/LAMDA-PILOT","versions":[{"version":"v1","created":"Mon, 29 Jan 2024 18:27:52 GMT"},{"version":"v2","created":"Tue, 23 Apr 2024 10:44:01 GMT"}],"update_date":"2024-04-24","authors_parsed":[["Zhou","Da-Wei"],["Sun","Hai-Long"],["Ning","Jingyi"],["Ye","Han-Jia"],["Zhan","De-Chuan"]],"application_domain":"Basic Research and Scientific Exploration","prompt":"I hope to research the field of Continual Learning (CL) based on Pre-trained Models (PTMs). Specifically, I aim to understand how the academic community utilizes large-scale pre-trained models (e.g., Vision Transformers) to address the problem of catastrophic forgetting in incremental learning. Please focus on the mainstream methodological branches in recent years, such as prompt-based methods, representation-based methods, and model mixture-based methods, and summarize their approaches along with their strengths and weaknesses. Ensure that all referenced papers are published before April 2024."}
{"arxiv_id":"2108.04344","submitter":"Ashad Kabir","authors":"Aishwarza Panday, Muhammad Ashad Kabir, Nihad Karim Chowdhury","title":"A Survey of Machine Learning Techniques for Detecting and Diagnosing COVID-19 from Imaging","comments":"23 pages, 6 figures, accepted in Quantitative Biology","journal-ref":"Quantitative Biology, 2021","doi":null,"report-no":null,"categories":"cs.CV cs.LG eess.IV","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Due to the limited availability and high cost of the reverse transcription-polymerase chain reaction (RT-PCR) test, many studies have proposed machine learning techniques for detecting COVID-19 from medical imaging. The purpose of this study is to systematically review, assess, and synthesize research articles that have used different machine learning techniques to detect and diagnose COVID-19 from chest X-ray and CT scan images. A structured literature search was conducted in the relevant bibliographic databases to ensure that the survey solely centered on reproducible and high-quality research. We selected papers based on our inclusion criteria. In this survey, we reviewed $98$ articles that fulfilled our inclusion criteria. We have surveyed a complete pipeline of chest imaging analysis techniques related to COVID-19, including data collection, pre-processing, feature extraction, classification, and visualization. We have considered CT scans and X-rays as both are widely used to describe the latest developments in medical imaging to detect COVID-19. This survey provides researchers with valuable insights into different machine learning techniques and their performance in the detection and diagnosis of COVID-19 from chest imaging. At the end, the challenges and limitations in detecting COVID-19 using machine learning techniques and the future direction of research are discussed.","versions":[{"version":"v1","created":"Sun, 25 Jul 2021 12:26:57 GMT"}],"update_date":"2021-08-11","authors_parsed":[["Panday","Aishwarza"],["Kabir","Muhammad Ashad"],["Chowdhury","Nihad Karim"]],"application_domain":"Healthcare and Biomedicine","prompt":"Please help me research the academic field of using machine learning and deep learning techniques for COVID-19 assisted diagnosis prior to July 2021. The primary research focus is on detecting and diagnosing COVID-19 through the analysis of chest X-rays and CT scan images. Emphasis should be placed on the datasets used in the papers, data preprocessing methods, feature extraction techniques (such as various CNN architectures), classification models, and visualization methods for explaining model decisions (such as Grad-CAM)."}
{"arxiv_id":"2007.08199","submitter":"Hwanjun Song","authors":"Hwanjun Song, Minseok Kim, Dongmin Park, Yooju Shin, Jae-Gil Lee","title":"Learning from Noisy Labels with Deep Neural Networks: A Survey","comments":"Final version published in TNNLS Journal (2022 March)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CV stat.ML","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Deep learning has achieved remarkable success in numerous domains with help from large amounts of big data. However, the quality of data labels is a concern because of the lack of high-quality labels in many real-world scenarios. As noisy labels severely degrade the generalization performance of deep neural networks, learning from noisy labels (robust training) is becoming an important task in modern deep learning applications. In this survey, we first describe the problem of learning with label noise from a supervised learning perspective. Next, we provide a comprehensive review of 62 state-of-the-art robust training methods, all of which are categorized into five groups according to their methodological difference, followed by a systematic comparison of six properties used to evaluate their superiority. Subsequently, we perform an in-depth analysis of noise rate estimation and summarize the typically used evaluation methodology, including public noisy datasets and evaluation metrics. Finally, we present several promising research directions that can serve as a guideline for future studies. All the contents will be available at https:\/\/github.com\/songhwanjun\/Awesome-Noisy-Labels.","versions":[{"version":"v1","created":"Thu, 16 Jul 2020 09:23:13 GMT"},{"version":"v2","created":"Tue, 21 Jul 2020 14:09:46 GMT"},{"version":"v3","created":"Wed, 28 Oct 2020 03:38:50 GMT"},{"version":"v4","created":"Mon, 5 Apr 2021 04:43:20 GMT"},{"version":"v5","created":"Tue, 8 Jun 2021 11:32:13 GMT"},{"version":"v6","created":"Wed, 10 Nov 2021 15:42:28 GMT"},{"version":"v7","created":"Thu, 10 Mar 2022 01:51:43 GMT"}],"update_date":"2022-03-11","authors_parsed":[["Song","Hwanjun"],["Kim","Minseok"],["Park","Dongmin"],["Shin","Yooju"],["Lee","Jae-Gil"]],"application_domain":"Basic Research and Scientific Exploration","prompt":"I am studying the issue of learning from noisy labels in deep learning. I hope you can help me summarize the mainstream approaches proposed in the academic community to mitigate the negative impact of label noise on the generalization performance of models during training, especially in classification tasks. Please focus on, but not be limited to, the following types of methods: robust loss function design, strategies for loss adjustment through sample filtering or reweighting, and approaches that leverage semi-supervised ideas to handle noisy samples. All the content you write must only reference papers published before March 2022."}
{"arxiv_id":"2301.07499","submitter":"Yuanbo Wang","authors":"Yuanbo Wang, Unaiza Ahsan, Hanyan Li, Matthew Hagen","title":"A Comprehensive Review of Modern Object Segmentation Approaches","comments":"173 pages, 49 figures, published in Foundations and Trends in\n  Computer Graphics and Vision on 10\/4\/22. Authors retain copyright","journal-ref":"Foundations and Trends in Computer Graphics and Vision: Vol. 13:\n  No. 2-3, pp 111-283","doi":"10.1561\/0600000097","report-no":null,"categories":"cs.CV","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Image segmentation is the task of associating pixels in an image with their respective object class labels. It has a wide range of applications in many industries including healthcare, transportation, robotics, fashion, home improvement, and tourism. Many deep learning-based approaches have been developed for image-level object recognition and pixel-level scene understanding-with the latter requiring a much denser annotation of scenes with a large set of objects. Extensions of image segmentation tasks include 3D and video segmentation, where units of voxels, point clouds, and video frames are classified into different objects. We use \"Object Segmentation\" to refer to the union of these segmentation tasks. In this monograph, we investigate both traditional and modern object segmentation approaches, comparing their strengths, weaknesses, and utilities. We examine in detail the wide range of deep learning-based segmentation techniques developed in recent years, provide a review of the widely used datasets and evaluation metrics, and discuss potential future research directions.","versions":[{"version":"v1","created":"Fri, 13 Jan 2023 19:35:46 GMT"}],"update_date":"2023-01-19","authors_parsed":[["Wang","Yuanbo"],["Ahsan","Unaiza"],["Li","Hanyan"],["Hagen","Matthew"]],"application_domain":"Basic Research and Scientific Exploration","prompt":"Please help me research the field of computer vision regarding modern deep learning-based approaches to object segmentation, with the requirement to reference only papers published before January 2023."}
{"arxiv_id":"2406.11373","submitter":"Giuseppe Gaetano Luciano Dr","authors":"Giuseppe Gaetano Luciano","title":"Kaniadakis entropy in extreme gravitational and cosmological environments: a review on the state-of-the-art and future prospects","comments":"Accepted for publication in EPJB, Topical Collection \"New Trends in\n  Statistical Physics of Complex Systems: Theoretical and Experimental\n  Approaches\"","journal-ref":"Eur.Phys.J.B 97 (2024) 6, 80","doi":"10.1140\/epjb\/s10051-024-00730-3","report-no":null,"categories":"astro-ph.CO gr-qc hep-th","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Kaniadakis ($\\kappa$-deformed) statistics is being widely used for describing relativistic systems with non-extensive behavior and\/or interactions. It is built upon a one-parameter generalization of the classical Boltzmann-Gibbs-Shannon entropy, possessing the latter as a particular sub-case. Recently, Kaniadakis model has been adapted to accommodate the complexities of systems under the influence of gravity. The ensuing framework exhibits a rich phenomenology that allows for a deeper understanding of the most extreme conditions of the Universe. Here we present the state-of-the-art of $\\kappa$-statistics, discussing its virtues and drawbacks at different energy scales. Special focus is dedicated to gravitational and cosmological implications, including effects on the expanding Universe in dark energy scenarios. This review highlights the versatility of Kaniadakis paradigm, demonstrating its broad application across various fields and setting the stage for further advancements in statistical modeling and theoretical physics.","versions":[{"version":"v1","created":"Mon, 17 Jun 2024 09:51:27 GMT"}],"update_date":"2025-03-25","authors_parsed":[["Luciano","Giuseppe Gaetano"]],"application_domain":"Basic Research and Scientific Exploration","prompt":"I need to conduct an in-depth literature review for an academic paper on the application of Kaniadakis entropy (\u03ba-entropy) in gravity and cosmology. Please provide me with a comprehensive literature survey strictly based on publications available before **June 2024**:\n\n1.  **Research Field**: Kaniadakis statistical mechanics, regarded as a relativistic generalization of the standard Boltzmann-Gibbs statistics.\n\n2.  **Core Research Directions**:\n    *   **Black Hole Thermodynamics**: Investigate how Kaniadakis entropy modifies the black hole entropy-area relation, impacts phase transitions (e.g., Van der Waals-like P-V critical behaviors), heat capacity, and thermodynamic stability.\n    *   **Holographic Dark Energy Models**: Study holographic dark energy models (KHDE) constructed using Kaniadakis entropy, particularly the modified expression for energy density and the use of these models to interpret the accelerated expansion of the universe.\n    *   **Modified Friedmann Cosmology**: Analyze corrections to the Friedmann equations derived from Kaniadakis entropy, their applicability in resolving major cosmological tensions (e.g., Hubble tension and \u03c38 tension), and their potential to address issues such as baryogenesis and the origin of high-energy neutrinos.\n    *   **Early Universe**: Examine the influence of Kaniadakis entropy on inflation models, particularly slow-roll inflation and the evolution of primordial perturbation growth.\n\n3.  **Constraints**:\n    *   **Sources of Literature**: Focus on high-impact journals in physics and astronomy, such as *Physical Review D*, *European Physical Journal C*, *Physics Letters B*, *Journal of High Energy Physics (JHEP)*, and *Monthly Notices of the Royal Astronomical Society (MNRAS)*.\n    *   **Language**: Primarily consider English-language publications.\n    *   **Deadline**: All referenced findings must be published before **June 2024**."}
{"arxiv_id":"2304.05482","submitter":"Mahdi S. Hosseini Dr.","authors":"Mahdi S. Hosseini, Babak Ehteshami Bejnordi, Vincent Quoc-Huy Trinh, Danial Hasan, Xingwen Li, Taehyo Kim, Haochen Zhang, Theodore Wu, Kajanan Chinniah, Sina Maghsoudlou, Ryan Zhang, Stephen Yang, Jiadai Zhu, Lyndon Chan, Samir Khaki, Andrei Buin, Fatemeh Chaji, Ala Salehi, Bich Ngoc Nguyen, Dimitris Samaras and Konstantinos N. Plataniotis","title":"Computational Pathology: A Survey Review and The Way Forward","comments":"Accepted in Elsevier Journal of Pathology Informatics (JPI) 2024","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.CV","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Computational Pathology CPath is an interdisciplinary science that augments developments of computational approaches to analyze and model medical histopathology images. The main objective for CPath is to develop infrastructure and workflows of digital diagnostics as an assistive CAD system for clinical pathology, facilitating transformational changes in the diagnosis and treatment of cancer that are mainly address by CPath tools. With evergrowing developments in deep learning and computer vision algorithms, and the ease of the data flow from digital pathology, currently CPath is witnessing a paradigm shift. Despite the sheer volume of engineering and scientific works being introduced for cancer image analysis, there is still a considerable gap of adopting and integrating these algorithms in clinical practice. This raises a significant question regarding the direction and trends that are undertaken in CPath. In this article we provide a comprehensive review of more than 800 papers to address the challenges faced in problem design all-the-way to the application and implementation viewpoints. We have catalogued each paper into a model-card by examining the key works and challenges faced to layout the current landscape in CPath. We hope this helps the community to locate relevant works and facilitate understanding of the field's future directions. In a nutshell, we oversee the CPath developments in cycle of stages which are required to be cohesively linked together to address the challenges associated with such multidisciplinary science. We overview this cycle from different perspectives of data-centric, model-centric, and application-centric problems. We finally sketch remaining challenges and provide directions for future technical developments and clinical integration of CPath (https:\/\/github.com\/AtlasAnalyticsLab\/CPath_Survey).","versions":[{"version":"v1","created":"Tue, 11 Apr 2023 20:28:33 GMT"},{"version":"v2","created":"Mon, 22 Jan 2024 01:48:29 GMT"},{"version":"v3","created":"Sat, 27 Jan 2024 21:27:51 GMT"}],"update_date":"2024-01-30","authors_parsed":[["Hosseini","Mahdi S."],["Bejnordi","Babak Ehteshami"],["Trinh","Vincent Quoc-Huy"],["Hasan","Danial"],["Li","Xingwen"],["Kim","Taehyo"],["Zhang","Haochen"],["Wu","Theodore"],["Chinniah","Kajanan"],["Maghsoudlou","Sina"],["Zhang","Ryan"],["Yang","Stephen"],["Zhu","Jiadai"],["Chan","Lyndon"],["Khaki","Samir"],["Buin","Andrei"],["Chaji","Fatemeh"],["Salehi","Ala"],["Nguyen","Bich Ngoc"],["Samaras","Dimitris"],["Plataniotis","Konstantinos N."]],"application_domain":"Healthcare and Biomedicine","prompt":"Please provide me with a comprehensive academic research report on the field of Computational Pathology, with specific requirements as follows:\n\n- **Research Field and Focus**: I am interested in how computational methods, particularly deep learning and computer vision techniques, are applied to analyze and model histopathological images (such as WSI) to aid in cancer diagnosis (e.g., tumor detection, grading), prognosis analysis, and treatment response prediction. The research content should systematically cover the entire workflow, from data (e.g., dataset construction, annotation methods) to models (e.g., model architectures, learning paradigms) to applications (e.g., clinical validation, emerging trends).\n- **Methodologies of Interest**: Please focus on various deep learning models, including but not limited to Convolutional Neural Networks (CNNs), Graph Neural Networks (GNNs), Transformer models, Multiple Instance Learning (MIL), and the use of self-supervised and weakly supervised learning methods in Computational Pathology. Additionally, discuss the role of generative models (e.g., GANs, diffusion models) in tasks such as data augmentation or virtual staining.\n\n**Constraints**:\n1. **Literature Cut-off Date**: All referenced papers must be published **before January 2024**.\n2. **Preferred Conferences\/Journals**: Please prioritize papers from top conferences and journals, such as CVPR, MICCAI, Nature Medicine, IEEE Transactions on Medical Imaging (T-MI), and Medical Image Analysis (MedIA).\n3. **Language of Papers**: Focus primarily on English academic papers.\n4. **Published Institutions**: Emphasize research outcomes from leading academic institutions (e.g., Stanford University, University of Toronto) and notable corporate AI labs (e.g., Google AI, Qualcomm AI Research)."}
{"arxiv_id":"2203.17005","submitter":"Jiale Guo","authors":"Ziyao Liu, Jiale Guo, Wenzhuo Yang, Jiani Fan, Kwok-Yan Lam, Jun Zhao","title":"Privacy-Preserving Aggregation in Federated Learning: A Survey","comments":"20 pages, 10 figures. Accepted by IEEE Transactions on Big Data","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Over the recent years, with the increasing adoption of Federated Learning (FL) algorithms and growing concerns over personal data privacy, Privacy-Preserving Federated Learning (PPFL) has attracted tremendous attention from both academia and industry. Practical PPFL typically allows multiple participants to individually train their machine learning models, which are then aggregated to construct a global model in a privacy-preserving manner. As such, Privacy-Preserving Aggregation (PPAgg) as the key protocol in PPFL has received substantial research interest. This survey aims to fill the gap between a large number of studies on PPFL, where PPAgg is adopted to provide a privacy guarantee, and the lack of a comprehensive survey on the PPAgg protocols applied in FL systems. In this survey, we review the PPAgg protocols proposed to address privacy and security issues in FL systems. The focus is placed on the construction of PPAgg protocols with an extensive analysis of the advantages and disadvantages of these selected PPAgg protocols and solutions. Additionally, we discuss the open-source FL frameworks that support PPAgg. Finally, we highlight important challenges and future research directions for applying PPAgg to FL systems and the combination of PPAgg with other technologies for further security improvement.","versions":[{"version":"v1","created":"Thu, 31 Mar 2022 12:58:57 GMT"},{"version":"v2","created":"Wed, 13 Jul 2022 08:12:25 GMT"}],"update_date":"2022-07-14","authors_parsed":[["Liu","Ziyao"],["Guo","Jiale"],["Yang","Wenzhuo"],["Fan","Jiani"],["Lam","Kwok-Yan"],["Zhao","Jun"]],"application_domain":"Basic Research and Scientific Exploration","prompt":"Please help me research privacy-preserving model aggregation protocols in federated learning, with the requirement to refer only to papers published before July 2022."}
{"arxiv_id":"2101.01507","submitter":"Hai Lan","authors":"Hai Lan, Zhifeng Bao, Yuwei Peng","title":"A Survey on Advancing the DBMS Query Optimizer: Cardinality Estimation, Cost Model, and Plan Enumeration","comments":"This paper was accepted by Data Science and Engineering (DSEJ) in\n  Dec, 2020","journal-ref":null,"doi":"10.1007\/s41019-020-00149-7","report-no":null,"categories":"cs.DB cs.AI","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Query optimizer is at the heart of the database systems. Cost-based optimizer studied in this paper is adopted in almost all current database systems. A cost-based optimizer introduces a plan enumeration algorithm to find a (sub)plan, and then uses a cost model to obtain the cost of that plan, and selects the plan with the lowest cost. In the cost model, cardinality, the number of tuples through an operator, plays a crucial role. Due to the inaccuracy in cardinality estimation, errors in cost model, and the huge plan space, the optimizer cannot find the optimal execution plan for a complex query in a reasonable time. In this paper, we first deeply study the causes behind the limitations above. Next, we review the techniques used to improve the quality of the three key components in the cost-based optimizer, cardinality estimation, cost model, and plan enumeration. We also provide our insights on the future directions for each of the above aspects.","versions":[{"version":"v1","created":"Tue, 5 Jan 2021 13:47:45 GMT"}],"update_date":"2021-01-06","authors_parsed":[["Lan","Hai"],["Bao","Zhifeng"],["Peng","Yuwei"]],"application_domain":"Basic Research and Scientific Exploration","prompt":"Please help me research academic literature on advancements in database query optimizer technology, and ensure that all referenced papers were published before January 2021."}
{"arxiv_id":"2003.00653","submitter":"Wei Jin","authors":"Wei Jin, Yaxin Li, Han Xu, Yiqi Wang, Shuiwang Ji, Charu Aggarwal and Jiliang Tang","title":"Adversarial Attacks and Defenses on Graphs: A Review, A Tool and Empirical Studies","comments":"Accepted by SIGKDD Explorations","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CR stat.ML","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Deep neural networks (DNNs) have achieved significant performance in various tasks. However, recent studies have shown that DNNs can be easily fooled by small perturbation on the input, called adversarial attacks. As the extensions of DNNs to graphs, Graph Neural Networks (GNNs) have been demonstrated to inherit this vulnerability. Adversary can mislead GNNs to give wrong predictions by modifying the graph structure such as manipulating a few edges. This vulnerability has arisen tremendous concerns for adapting GNNs in safety-critical applications and has attracted increasing research attention in recent years. Thus, it is necessary and timely to provide a comprehensive overview of existing graph adversarial attacks and the countermeasures. In this survey, we categorize existing attacks and defenses, and review the corresponding state-of-the-art methods. Furthermore, we have developed a repository with representative algorithms (https:\/\/github.com\/DSE-MSU\/DeepRobust\/tree\/master\/deeprobust\/graph). The repository enables us to conduct empirical studies to deepen our understandings on attacks and defenses on graphs.","versions":[{"version":"v1","created":"Mon, 2 Mar 2020 04:32:38 GMT"},{"version":"v2","created":"Tue, 3 Mar 2020 18:31:56 GMT"},{"version":"v3","created":"Sat, 12 Dec 2020 17:21:00 GMT"}],"update_date":"2020-12-15","authors_parsed":[["Jin","Wei"],["Li","Yaxin"],["Xu","Han"],["Wang","Yiqi"],["Ji","Shuiwang"],["Aggarwal","Charu"],["Tang","Jiliang"]],"application_domain":"Basic Research and Scientific Exploration","prompt":"I need a comprehensive literature review on adversarial attacks and defenses in graph neural networks (GNNs). The specific research directions include:  \n1) Attack methods: Systematic categorization and review of attack algorithms targeting mainstream GNN models such as GCN and GAT, covering white-box, gray-box, and black-box settings, as well as poisoning and evasion attack scenarios, with an analysis of perturbation techniques applied to graph structures and node features.  \n2) Defense strategies: Thorough examination of existing defense techniques, including but not limited to adversarial training, certifiable robustness, graph purification (e.g., methods based on SVD or Jaccard similarity), and defense models utilizing attention mechanisms.  \nIn the writing process, please adhere to the following constraints:  \n- All cited references must have been published before December 2020.  \n- Emphasis should be placed on English papers published in top-tier conferences such as KDD, NeurIPS, ICML, and WWW.  \n- Relevant studies from institutions such as Michigan State University and Texas A&M University can be appropriately highlighted.  \nPlease note that you must only reference papers published prior to December 2020."}
{"arxiv_id":"2404.00929","submitter":"Ling Hu","authors":"Yuemei Xu, Ling Hu, Jiayi Zhao, Zihan Qiu, Kexin XU, Yuqi Ye, Hanwen Gu","title":"A Survey on Multilingual Large Language Models: Corpora, Alignment, and Bias","comments":"The article has been accepted by Frontiers of Computer Science (FCS),\n  with the DOI: {10.1007\/s11704-024-40579-4}","journal-ref":null,"doi":"10.1007\/s11704-024-40579-4","report-no":null,"categories":"cs.CL cs.AI","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Based on the foundation of Large Language Models (LLMs), Multilingual LLMs (MLLMs) have been developed to address the challenges faced in multilingual natural language processing, hoping to achieve knowledge transfer from high-resource languages to low-resource languages. However, significant limitations and challenges still exist, such as language imbalance, multilingual alignment, and inherent bias. In this paper, we aim to provide a comprehensive analysis of MLLMs, delving deeply into discussions surrounding these critical issues. First of all, we start by presenting an overview of MLLMs, covering their evolutions, key techniques, and multilingual capacities. Secondly, we explore the multilingual training corpora of MLLMs and the multilingual datasets oriented for downstream tasks that are crucial to enhance the cross-lingual capability of MLLMs. Thirdly, we survey the state-of-the-art studies of multilingual representations and investigate whether the current MLLMs can learn a universal language representation. Fourthly, we discuss bias on MLLMs, including its categories, evaluation metrics, and debiasing techniques. Finally, we discuss existing challenges and point out promising research directions of MLLMs.","versions":[{"version":"v1","created":"Mon, 1 Apr 2024 05:13:56 GMT"},{"version":"v2","created":"Thu, 6 Jun 2024 16:04:15 GMT"},{"version":"v3","created":"Mon, 9 Dec 2024 14:30:11 GMT"}],"update_date":"2024-12-10","authors_parsed":[["Xu","Yuemei"],["Hu","Ling"],["Zhao","Jiayi"],["Qiu","Zihan"],["XU","Kexin"],["Ye","Yuqi"],["Gu","Hanwen"]],"application_domain":"Basic Research and Scientific Exploration","prompt":"I want to investigate the field of multilingual large language models (MLLMs). Please focus on the key challenges in this field, particularly the construction and imbalance issues of multilingual training corpora, technical methods for cross-linguistic representation alignment, as well as various biases present in the models (such as linguistic bias and social bias) and their debiasing techniques. Make sure that all the references you cite were published before December 2024."}
{"arxiv_id":"2304.11534","submitter":"Kunze Wang","authors":"Kunze Wang, Yihao Ding, Soyeon Caren Han","title":"Graph Neural Networks for Text Classification: A Survey","comments":"28 pages, published in Artificial Intelligence Review","journal-ref":null,"doi":"10.1007\/s10462-024-10808-0","report-no":null,"categories":"cs.CL","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Text Classification is the most essential and fundamental problem in Natural Language Processing. While numerous recent text classification models applied the sequential deep learning technique, graph neural network-based models can directly deal with complex structured text data and exploit global information. Many real text classification applications can be naturally cast into a graph, which captures words, documents, and corpus global features. In this survey, we bring the coverage of methods up to 2023, including corpus-level and document-level graph neural networks. We discuss each of these methods in detail, dealing with the graph construction mechanisms and the graph-based learning process. As well as the technological survey, we look at issues behind and future directions addressed in text classification using graph neural networks. We also cover datasets, evaluation metrics, and experiment design and present a summary of published performance on the publicly available benchmarks. Note that we present a comprehensive comparison between different techniques and identify the pros and cons of various evaluation metrics in this survey.","versions":[{"version":"v1","created":"Sun, 23 Apr 2023 04:21:50 GMT"},{"version":"v2","created":"Thu, 27 Apr 2023 13:42:25 GMT"},{"version":"v3","created":"Fri, 5 Jul 2024 12:06:26 GMT"}],"update_date":"2024-07-08","authors_parsed":[["Wang","Kunze"],["Ding","Yihao"],["Han","Soyeon Caren"]],"application_domain":"Basic Research and Scientific Exploration","prompt":"I need a detailed academic research report on using Graph Neural Networks (GNN) for text classification. The report should systematically review advancements in this field, with a focus on the following aspects:\n1. **Core Methodology**: Provide a detailed explanation and comparison of two main approaches: corpus-level GNNs and document-level GNNs. For each method, thoroughly analyze graph construction strategies (e.g., defining nodes and edges using PMI, TF-IDF, etc.), representation methods for nodes and edges, and graph learning algorithms (e.g., GCN, GAT, etc.).\n2. **Key Model Analysis**: List and analyze representative models, such as TextGCN, SGC, BertGCN (corpus-level), and Text-Level-GNN, TextING (document-level).\n3. **Evaluation and Challenges**: Summarize commonly used benchmark datasets in this field (e.g., 20NG, R8, MR) and evaluation metrics (e.g., Accuracy, F1-score), and discuss major challenges faced by current research, such as scalability, computational costs, and integration with pre-trained language models.\n**Restrictions**:\n- Only refer to and cite papers published **before July 2024**.\n- Focus on English literature published in top conferences\/journals in natural language processing and artificial intelligence (e.g., ACL, EMNLP, NAACL, AAAI, WWW, ICLR)."}
{"arxiv_id":"2406.07494","submitter":"Frederic Kirstein","authors":"Frederic Kirstein, Jan Philip Wahle, Bela Gipp, Terry Ruas","title":"CADS: A Systematic Literature Review on the Challenges of Abstractive Dialogue Summarization","comments":"Published in the Journal of Artificial Intelligence Research (JAIR)\n  (https:\/\/www.jair.org\/index.php\/jair\/article\/view\/16674)","journal-ref":"Journal of Artificial Intelligence Research (JAIR), Vol. 82, 2025","doi":"10.1613\/jair.1.16674","report-no":null,"categories":"cs.CL cs.AI","license":"http:\/\/creativecommons.org\/licenses\/by-sa\/4.0\/","abstract":"Abstractive dialogue summarization is the task of distilling conversations into informative and concise summaries. Although reviews have been conducted on this topic, there is a lack of comprehensive work detailing the challenges of dialogue summarization, unifying the differing understanding of the task, and aligning proposed techniques, datasets, and evaluation metrics with the challenges. This article summarizes the research on Transformer-based abstractive summarization for English dialogues by systematically reviewing 1262 unique research papers published between 2019 and 2024, relying on the Semantic Scholar and DBLP databases. We cover the main challenges present in dialog summarization (i.e., language, structure, comprehension, speaker, salience, and factuality) and link them to corresponding techniques such as graph-based approaches, additional training tasks, and planning strategies, which typically overly rely on BART-based encoder-decoder models. We find that while some challenges, like language, have seen considerable progress, mainly due to training methods, others, such as comprehension, factuality, and salience, remain difficult and hold significant research opportunities. We investigate how these approaches are typically assessed, covering the datasets for the subdomains of dialogue (e.g., meeting, medical), the established automatic metrics and human evaluation approaches for assessing scores and annotator agreement. We observe that only a few datasets span across all subdomains. The ROUGE metric is the most used, while human evaluation is frequently reported without sufficient detail on inner-annotator agreement and annotation guidelines. Additionally, we discuss the possible implications of the recently explored large language models and conclude that despite a potential shift in relevance and difficulty, our described challenge taxonomy remains relevant.","versions":[{"version":"v1","created":"Tue, 11 Jun 2024 17:30:22 GMT"},{"version":"v2","created":"Wed, 12 Jun 2024 10:47:09 GMT"},{"version":"v3","created":"Wed, 23 Apr 2025 18:00:46 GMT"}],"update_date":"2025-04-25","authors_parsed":[["Kirstein","Frederic"],["Wahle","Jan Philip"],["Gipp","Bela"],["Ruas","Terry"]],"application_domain":"Basic Research and Scientific Exploration","prompt":"I need a literature review in the field of abstractive dialogue summarization. This review should focus on Transformer-based models since 2019. Please thoroughly analyze the core challenges in this area (such as linguistic characteristics, dialogue structure, factuality, etc.) and summarize the main technical approaches proposed to address these challenges, commonly used benchmark datasets, and mainstream evaluation metrics (such as ROUGE and human evaluation). Ensure that all cited references are published no later than April 2025."}
{"arxiv_id":"2011.12063","submitter":"Cheng-Hao Lin","authors":"Tzu-hsien Huang, Jheng-hao Lin, Chien-yu Huang, Hung-yi Lee","title":"How Far Are We from Robust Voice Conversion: A Survey","comments":"Accepted by SLT 2021","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.SD","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Voice conversion technologies have been greatly improved in recent years with the help of deep learning, but their capabilities of producing natural sounding utterances in different conditions remain unclear. In this paper, we gave a thorough study of the robustness of known VC models. We also modified these models, such as the replacement of speaker embeddings, to further improve their performances. We found that the sampling rate and audio duration greatly influence voice conversion. All the VC models suffer from unseen data, but AdaIN-VC is relatively more robust. Also, the speaker embedding jointly trained is more suitable for voice conversion than those trained on speaker identification.","versions":[{"version":"v1","created":"Tue, 24 Nov 2020 12:34:36 GMT"},{"version":"v2","created":"Wed, 2 Dec 2020 08:45:23 GMT"},{"version":"v3","created":"Mon, 3 May 2021 08:32:25 GMT"}],"update_date":"2021-05-04","authors_parsed":[["Huang","Tzu-hsien"],["Lin","Jheng-hao"],["Huang","Chien-yu"],["Lee","Hung-yi"]],"application_domain":"Culture, Media and Digital Content","prompt":"Please help me investigate the research progress on the robustness of Voice Conversion (VC) models prior to May 2021."}
{"arxiv_id":"2103.07853","submitter":"Hongsheng Hu","authors":"Hongsheng Hu and Zoran Salcic and Lichao Sun and Gillian Dobbie and Philip S. Yu and Xuyun Zhang","title":"Membership Inference Attacks on Machine Learning: A Survey","comments":"Accepted by ACM Computing Surveys","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CR","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Machine learning (ML) models have been widely applied to various applications, including image classification, text generation, audio recognition, and graph data analysis. However, recent studies have shown that ML models are vulnerable to membership inference attacks (MIAs), which aim to infer whether a data record was used to train a target model or not. MIAs on ML models can directly lead to a privacy breach. For example, via identifying the fact that a clinical record that has been used to train a model associated with a certain disease, an attacker can infer that the owner of the clinical record has the disease with a high chance. In recent years, MIAs have been shown to be effective on various ML models, e.g., classification models and generative models. Meanwhile, many defense methods have been proposed to mitigate MIAs. Although MIAs on ML models form a newly emerging and rapidly growing research area, there has been no systematic survey on this topic yet. In this paper, we conduct the first comprehensive survey on membership inference attacks and defenses. We provide the taxonomies for both attacks and defenses, based on their characterizations, and discuss their pros and cons. Based on the limitations and gaps identified in this survey, we point out several promising future research directions to inspire the researchers who wish to follow this area. This survey not only serves as a reference for the research community but also provides a clear description for researchers outside this research domain. To further help the researchers, we have created an online resource repository, which we will keep updated with future relevant work. Interested readers can find the repository at https:\/\/github.com\/HongshengHu\/membership-inference-machine-learning-literature.","versions":[{"version":"v1","created":"Sun, 14 Mar 2021 06:10:47 GMT"},{"version":"v2","created":"Wed, 17 Mar 2021 03:21:35 GMT"},{"version":"v3","created":"Sun, 7 Nov 2021 10:13:31 GMT"},{"version":"v4","created":"Thu, 3 Feb 2022 04:29:23 GMT"}],"update_date":"2022-02-04","authors_parsed":[["Hu","Hongsheng"],["Salcic","Zoran"],["Sun","Lichao"],["Dobbie","Gillian"],["Yu","Philip S."],["Zhang","Xuyun"]],"application_domain":"Basic Research and Scientific Exploration","prompt":"I need a detailed academic review on Membership Inference Attacks (MIAs) in machine learning. This review should cover the following aspects: Firstly, systematically organize the taxonomy of MIAs, including categorizations based on the target model (e.g., classification models, generative models, embedding models), attacker knowledge (e.g., black-box and white-box attacks), and attack methods (e.g., classifier-based attacks, metric-based attacks); Secondly, provide a detailed introduction to main defense techniques against MIAs, such as confidence score masking, regularization methods, knowledge distillation, and differential privacy; Finally, explore the reasons why MIAs are effective, especially their connection to model overfitting. When drafting this review, there are several strict constraints: 1. All cited literature must have been publicly available before February 2022. 2. Please primarily reference English academic papers. 3. Focus on relevant works published in top-tier security conferences (such as IEEE S&P, ACM CCS, USENIX Security, NDSS) and machine learning conferences (such as ICML, NeurIPS)."}
{"arxiv_id":"2402.07181","submitter":"Ben Fei","authors":"Ben Fei, Jingyi Xu, Rui Zhang, Qingyuan Zhou, Weidong Yang, Ying He","title":"3D Gaussian as a New Era: A Survey","comments":"Accepted at IEEE TVCG 2024, Please refer to:\n  https:\/\/ieeexplore.ieee.org\/document\/10521791","journal-ref":null,"doi":"10.1109\/TVCG.2024.3397828","report-no":null,"categories":"cs.CV cs.GR","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"3D Gaussian Splatting (3D-GS) has emerged as a significant advancement in the field of Computer Graphics, offering explicit scene representation and novel view synthesis without the reliance on neural networks, such as Neural Radiance Fields (NeRF). This technique has found diverse applications in areas such as robotics, urban mapping, autonomous navigation, and virtual reality\/augmented reality, just name a few. Given the growing popularity and expanding research in 3D Gaussian Splatting, this paper presents a comprehensive survey of relevant papers from the past year. We organize the survey into taxonomies based on characteristics and applications, providing an introduction to the theoretical underpinnings of 3D Gaussian Splatting. Our goal through this survey is to acquaint new researchers with 3D Gaussian Splatting, serve as a valuable reference for seminal works in the field, and inspire future research directions, as discussed in our concluding section.","versions":[{"version":"v1","created":"Sun, 11 Feb 2024 12:33:08 GMT"},{"version":"v2","created":"Wed, 10 Jul 2024 02:48:08 GMT"}],"update_date":"2024-07-11","authors_parsed":[["Fei","Ben"],["Xu","Jingyi"],["Zhang","Rui"],["Zhou","Qingyuan"],["Yang","Weidong"],["He","Ying"]],"application_domain":"Culture, Media and Digital Content","prompt":"I need a detailed technical investigation report on 3D Gaussian Splatting. Please focus on the research advancements of this technology in the following areas: 1) Representation optimization: including improving efficiency, photorealism, reducing costs, and physical dynamics simulation; 2) 3D reconstruction: methods for reconstructing both static and dynamic scenes; 3) Scene editing and generation: text\/image-guided editing and 4D content generation; 4) Downstream applications: applications in SLAM, 3D perception, and virtual human\/digital human modeling. Please prioritize referencing English papers published in top computer vision and graphics conferences such as CVPR, ICCV, ECCV, and SIGGRAPH (ACM TOG). Most importantly, all cited references must be published before July 2024."}
{"arxiv_id":"2401.09252","submitter":"Thiago L. T. da Silveira","authors":"Thiago Lopes Trugillo da Silveira, Paulo Gamarra Lessa Pinto, Jeffri Erwin Murrugarra Llerena, Claudio Rosito Jung","title":"3D Scene Geometry Estimation from 360$^\\circ$ Imagery: A Survey","comments":"Published in ACM Computing Surveys","journal-ref":"ACM Comput. Surv. 55, 4, Article 68, 2023","doi":"10.1145\/3519021","report-no":null,"categories":"cs.CV cs.AI cs.GR cs.LG","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"This paper provides a comprehensive survey on pioneer and state-of-the-art 3D scene geometry estimation methodologies based on single, two, or multiple images captured under the omnidirectional optics. We first revisit the basic concepts of the spherical camera model, and review the most common acquisition technologies and representation formats suitable for omnidirectional (also called 360$^\\circ$, spherical or panoramic) images and videos. We then survey monocular layout and depth inference approaches, highlighting the recent advances in learning-based solutions suited for spherical data. The classical stereo matching is then revised on the spherical domain, where methodologies for detecting and describing sparse and dense features become crucial. The stereo matching concepts are then extrapolated for multiple view camera setups, categorizing them among light fields, multi-view stereo, and structure from motion (or visual simultaneous localization and mapping). We also compile and discuss commonly adopted datasets and figures of merit indicated for each purpose and list recent results for completeness. We conclude this paper by pointing out current and future trends.","versions":[{"version":"v1","created":"Wed, 17 Jan 2024 14:57:27 GMT"}],"update_date":"2024-01-18","authors_parsed":[["da Silveira","Thiago Lopes Trugillo"],["Pinto","Paulo Gamarra Lessa"],["Llerena","Jeffri Erwin Murrugarra"],["Jung","Claudio Rosito"]],"application_domain":"Culture, Media and Digital Content","prompt":"Please help me research the academic field of 3D scene geometry reconstruction based on 360-degree panoramic images, ensuring that only papers published before January 2024 are referenced."}
{"arxiv_id":"2209.00099","submitter":"Marcos Vin\\'icius Treviso","authors":"Marcos Treviso, Ji-Ung Lee, Tianchu Ji, Betty van Aken, Qingqing Cao, Manuel R. Ciosici, Michael Hassid, Kenneth Heafield, Sara Hooker, Colin Raffel, Pedro H. Martins, Andr\\'e F. T. Martins, Jessica Zosa Forde, Peter Milder, Edwin Simpson, Noam Slonim, Jesse Dodge, Emma Strubell, Niranjan Balasubramanian, Leon Derczynski, Iryna Gurevych, Roy Schwartz","title":"Efficient Methods for Natural Language Processing: A Survey","comments":"Accepted at TACL, pre publication version","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Recent work in natural language processing (NLP) has yielded appealing results from scaling model parameters and training data; however, using only scale to improve performance means that resource consumption also grows. Such resources include data, time, storage, or energy, all of which are naturally limited and unevenly distributed. This motivates research into efficient methods that require fewer resources to achieve similar results. This survey synthesizes and relates current methods and findings in efficient NLP. We aim to provide both guidance for conducting NLP under limited resources, and point towards promising research directions for developing more efficient methods.","versions":[{"version":"v1","created":"Wed, 31 Aug 2022 20:32:35 GMT"},{"version":"v2","created":"Fri, 24 Mar 2023 19:49:14 GMT"}],"update_date":"2023-03-28","authors_parsed":[["Treviso","Marcos"],["Lee","Ji-Ung"],["Ji","Tianchu"],["van Aken","Betty"],["Cao","Qingqing"],["Ciosici","Manuel R."],["Hassid","Michael"],["Heafield","Kenneth"],["Hooker","Sara"],["Raffel","Colin"],["Martins","Pedro H."],["Martins","Andr\u00e9 F. T."],["Forde","Jessica Zosa"],["Milder","Peter"],["Simpson","Edwin"],["Slonim","Noam"],["Dodge","Jesse"],["Strubell","Emma"],["Balasubramanian","Niranjan"],["Derczynski","Leon"],["Gurevych","Iryna"],["Schwartz","Roy"]],"application_domain":"Basic Research and Scientific Exploration","prompt":"I am conducting an in-depth literature review on efficient natural language processing (Efficient NLP), and I seek your assistance in completing it. My research objective is to systematically organize and summarize various approaches proposed to improve model efficiency and reduce computational and storage resource consumption. Please focus on the following specific directions: 1) Model compression methods, including pruning, knowledge distillation, and quantization; 2) Parameter-efficient fine-tuning techniques, such as Adapters, LoRA, and Prefix-Tuning; 3) Efficient model architectures, especially sparse models (e.g., Mixture-of-Experts) and efficient attention mechanisms. When collecting materials, please adhere to the following restrictions: all referenced papers must have been published before March 2023, with priority given to those published in top-tier conferences such as ACL, EMNLP, ICLR, and NeurIPS in English. If possible, please also pay special attention to research findings from institutions such as the Allen Institute for AI, Cohere, and IBM Research."}
{"arxiv_id":"2212.04634","submitter":"Yuxin Wang","authors":"Yuxin Wang, Jieru Lin, Zhiwei Yu, Wei Hu, B\\\"orje F. Karlsson","title":"Open-world Story Generation with Structured Knowledge Enhancement: A Comprehensive Survey","comments":"Accepted in Neurocomputing","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Storytelling and narrative are fundamental to human experience, intertwined with our social and cultural engagement. As such, researchers have long attempted to create systems that can generate stories automatically. In recent years, powered by deep learning and massive data resources, automatic story generation has shown significant advances. However, considerable challenges, like the need for global coherence in generated stories, still hamper generative models from reaching the same storytelling ability as human narrators. To tackle these challenges, many studies seek to inject structured knowledge into the generation process, which is referred to as structured knowledge-enhanced story generation. Incorporating external knowledge can enhance the logical coherence among story events, achieve better knowledge grounding, and alleviate over-generalization and repetition problems in stories. This survey provides the latest and comprehensive review of this research field: (i) we present a systematic taxonomy regarding how existing methods integrate structured knowledge into story generation; (ii) we summarize involved story corpora, structured knowledge datasets, and evaluation metrics; (iii) we give multidimensional insights into the challenges of knowledge-enhanced story generation and cast light on promising directions for future study.","versions":[{"version":"v1","created":"Fri, 9 Dec 2022 02:19:07 GMT"},{"version":"v2","created":"Fri, 24 Mar 2023 13:20:05 GMT"},{"version":"v3","created":"Tue, 12 Sep 2023 17:38:30 GMT"}],"update_date":"2023-09-13","authors_parsed":[["Wang","Yuxin"],["Lin","Jieru"],["Yu","Zhiwei"],["Hu","Wei"],["Karlsson","B\u00f6rje F."]],"application_domain":"Culture, Media and Digital Content","prompt":"I hope you write a review on leveraging structured knowledge to enhance open-world story generation. This review should focus on how external structured knowledge (such as ConceptNet, ATOMIC, and other knowledge graphs) can be integrated into story generation models to improve the logical coherence, consistency, and knowledge richness of generated stories. Please emphasize the analysis and organization of major existing technical approaches, such as methods that transform knowledge into text and methods that encode knowledge as vector representations to guide the generation process. Ensure that all cited research findings were published no later than September 2023."}
{"arxiv_id":"2110.06901","submitter":"Lucas Mourot","authors":"L. Mourot, L. Hoyet, F. Le Clerc, Fran\\c{c}ois Schnitzler (2) and Pierre Hellier (2) ((1) Inria, Univ Rennes, CNRS, IRISA, (2) InterDigital, Inc)","title":"A Survey on Deep Learning for Skeleton-Based Human Animation","comments":"32 pages, 10 figures, 4 tables, published in Computer Graphics Forum\n  (CGF)","journal-ref":null,"doi":"10.1111\/cgf.14426","report-no":null,"categories":"cs.GR","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Human character animation is often critical in entertainment content production, including video games, virtual reality or fiction films. To this end, deep neural networks drive most recent advances through deep learning and deep reinforcement learning. In this article, we propose a comprehensive survey on the state-of-the-art approaches based on either deep learning or deep reinforcement learning in skeleton-based human character animation. First, we introduce motion data representations, most common human motion datasets and how basic deep models can be enhanced to foster learning of spatial and temporal patterns in motion data. Second, we cover state-of-the-art approaches divided into three large families of applications in human animation pipelines: motion synthesis, character control and motion editing. Finally, we discuss the limitations of the current state-of-the-art methods based on deep learning and\/or deep reinforcement learning in skeletal human character animation and possible directions of future research to alleviate current limitations and meet animators' needs.","versions":[{"version":"v1","created":"Wed, 13 Oct 2021 17:29:50 GMT"},{"version":"v2","created":"Tue, 23 Nov 2021 08:44:41 GMT"}],"update_date":"2021-11-24","authors_parsed":[["Mourot","L."],["Hoyet","L."],["Clerc","F. Le"],["Schnitzler","Fran\u00e7ois"],["Hellier","Pierre"]],"application_domain":"Culture, Media and Digital Content","prompt":"Please help me research academic studies on skeleton-based human animation generation and control using deep learning before November 2021."}
{"arxiv_id":"2405.20716","submitter":"Kaustubh Rajwade","authors":"Kaustubh Rajwade and Joeri van Leeuwen","title":"A Needle in a Cosmic Haystack: A Review of FRB Search Techniques","comments":"17 pages, 7 figures, published in the special issue of the Universe\n  journal (Guest editor: Maura Pilia)","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.HE astro-ph.IM","license":"http:\/\/creativecommons.org\/publicdomain\/zero\/1.0\/","abstract":"Ephemeral Fast Radio Bursts (FRBs) must be powered by some of the most energetic processes in the Universe. That makes them highly interesting in their own right and as precise probes for estimating cosmological parameters. This field thus poses a unique challenge: FRBs must be detected promptly and immediately localised and studied based only on that single millisecond-duration flash. The problem is that the burst occurrence is highly unpredictable and that their distance strongly suppresses their brightness. Since the discovery of FRBs in single-dish archival data in 2007, detection software has evolved tremendously. Pipelines now detect bursts in real-time within a matter of seconds, operate on interferometers, buffer high-time and frequency resolution data, and issue real-time alerts to other observatories for rapid multi-wavelength follow-up. In this paper, we review the components that comprise a FRB search software pipeline, we discuss the proven techniques that were adopted from pulsar searches, we highlight newer, more efficient techniques for detecting FRBs, and we conclude by discussing the proposed novel future methodologies that may power the search for FRBs in the era of big data astronomy.","versions":[{"version":"v1","created":"Fri, 31 May 2024 09:12:55 GMT"}],"update_date":"2024-06-03","authors_parsed":[["Rajwade","Kaustubh"],["van Leeuwen","Joeri"]],"application_domain":"Basic Research and Scientific Exploration","prompt":"Please write a detailed literature review on fast radio burst (FRB) search techniques and algorithms, referencing only papers published before May 2024. The review should systematically outline the entire workflow of FRB search, with the following specific requirements: 1. **Research Area**: Real-time detection and data processing of fast radio bursts (FRB). 2. **Research Focus**: Conduct in-depth analysis of the evolution and advantages\/disadvantages of key techniques, including radio frequency interference (RFI) suppression (e.g., IQRM, Z-dot filtering), dispersion delay removal (e.g., FDMT, semi-coherent\/coherent dispersion removal), matched filtering, and final candidate automatic classification using machine learning (e.g., CNN). 3. **Scope of References**: Prefer citing English-language papers published in leading astronomy journals such as Nature, MNRAS, and ApJ, and consider research results from teams involved in radio telescope projects such as CHIME, Apertif, and Parkes."}
{"arxiv_id":"2205.08977","submitter":"Qinqin Tang","authors":"Qinqin Tang, F. Richard Yu, Renchao Xie, Azzedine Boukerche, Tao Huang, Yunjie Liu","title":"Internet of Intelligence: A Survey on the Enabling Technologies, Applications, and Challenges","comments":"This article has been accepted for publication in a future issue of\n  IEEE Communications Surveys & Tutorials","journal-ref":"IEEE Communications Surveys & Tutorials,2022","doi":"10.1109\/COMST.2022.3175453","report-no":null,"categories":"cs.NI","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"The Internet of intelligence is conceived as an emerging networking paradigm, which will make intelligence as easy to obtain as information. This paper provides an overview of the Internet of intelligence, focusing on motivations, architecture, enabling technologies, applications, and existing challenges. This can provide a good foundation for those who are interested to gain insights into the concept of the Internet of intelligence and the key enablers of this emerging networking paradigm. Specifically, this paper starts by investigating the evolution of networking paradigms and artificial intelligence (AI), based on which we present the motivations of the Internet of intelligence by demonstrating that networking needs intelligence and intelligence needs networking. We then present the layered architecture to characterize the Internet of intelligence systems and discuss the enabling technologies of each layer. Moreover, we discuss the critical applications and their integration with the Internet of intelligence paradigm. Finally, some technical challenges and open issues are summarized to fully exploit the benefits of the Internet of intelligence.","versions":[{"version":"v1","created":"Wed, 18 May 2022 15:00:29 GMT"}],"update_date":"2022-05-19","authors_parsed":[["Tang","Qinqin"],["Yu","F. Richard"],["Xie","Renchao"],["Boukerche","Azzedine"],["Huang","Tao"],["Liu","Yunjie"]],"application_domain":"Basic Research and Scientific Exploration","prompt":"Please write a comprehensive academic review on the \"Internet of Intelligence.\" The specific requirements are as follows: 1. **Research Area**: Focus on the emerging networking paradigm of the \"Internet of Intelligence\" and explore how it represents the next stage in the evolution of the Internet of Information, enabling ubiquitous acquisition and sharing of intelligence. 2. **Research Content**: The review should cover the motivations behind the Internet of Intelligence, its layered architecture, the key enabling technologies at each layer (e.g., 6G, edge computing, software-defined networking, information-centric networking, artificial intelligence, blockchain, digital twin, etc.), typical applications in fields such as smart transportation, intelligent industry, and smart healthcare, as well as the technical challenges and open research questions it faces. 3. **Constraints**: The writing must exclusively reference academic papers publicly published **on or before May 2022**. Particular attention should be given to **English-language** literature published in top journals and conferences, such as **IEEE Communications Surveys & Tutorials, IEEE Network, and IEEE Wireless Communications**."}
{"arxiv_id":"2308.04603","submitter":"Xin Zhong","authors":"Xin Zhong, Arjon Das, Fahad Alrasheedi, Abdullah Tanvir","title":"A Brief Yet In-Depth Survey of Deep Learning-Based Image Watermarking","comments":"This paper was accepted for publication by the MDPI Applied Sciences\n  journal","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.MM cs.CR cs.LG","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"This paper presents a comprehensive survey on deep learning-based image watermarking, a technique that entails the invisible embedding and extraction of watermarks within a cover image, aiming to offer a seamless blend of robustness and adaptability. We navigate the complex landscape of this interdisciplinary domain, linking historical foundations, current innovations, and prospective developments. Unlike existing literature, our study concentrates exclusively on image watermarking with deep learning, delivering an in-depth, yet brief analysis enriched by three fundamental contributions. First, we introduce a refined categorization, segmenting the field into Embedder-Extractor, Deep Networks as a Feature Transformation, and Hybrid Methods. This taxonomy, inspired by the varied roles of deep learning across studies, is designed to infuse clarity, offering readers technical insights and directional guidance. Second, our exploration dives into representative methodologies, encapsulating the diverse research directions and inherent challenges within each category to provide a consolidated perspective. Lastly, we venture beyond established boundaries to outline emerging frontiers, offering a detailed insight into prospective research avenues.","versions":[{"version":"v1","created":"Tue, 8 Aug 2023 22:06:14 GMT"},{"version":"v2","created":"Mon, 2 Oct 2023 17:43:23 GMT"},{"version":"v3","created":"Sun, 29 Oct 2023 14:52:32 GMT"}],"update_date":"2023-10-31","authors_parsed":[["Zhong","Xin"],["Das","Arjon"],["Alrasheedi","Fahad"],["Tanvir","Abdullah"]],"application_domain":"Culture, Media and Digital Content","prompt":"I am conducting a literature review on the application of deep learning in the field of image digital watermarking. My research focuses on exploring how deep learning models can be utilized to embed and extract watermarks, aiming to improve the robustness and imperceptibility of watermarks. I am particularly interested in several mainstream technical paradigms, including end-to-end jointly trained encoder-decoder architectures, methods that use deep networks as feature transformation tools, and hybrid approaches that combine traditional algorithms with deep learning. Please summarize the current state of research in this field and ensure that all referenced literature is published before October 2023."}
{"arxiv_id":"2203.01923","submitter":"Yating Tian","authors":"Yating Tian, Hongwen Zhang, Yebin Liu, Limin Wang","title":"Recovering 3D Human Mesh from Monocular Images: A Survey","comments":"Published in IEEE TPAMI, Survey on monocular 3D human mesh recovery,\n  Project page: https:\/\/github.com\/tinatiansjz\/hmr-survey","journal-ref":null,"doi":"10.1109\/TPAMI.2023.3298850","report-no":null,"categories":"cs.CV cs.GR","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Estimating human pose and shape from monocular images is a long-standing problem in computer vision. Since the release of statistical body models, 3D human mesh recovery has been drawing broader attention. With the same goal of obtaining well-aligned and physically plausible mesh results, two paradigms have been developed to overcome challenges in the 2D-to-3D lifting process: i) an optimization-based paradigm, where different data terms and regularization terms are exploited as optimization objectives; and ii) a regression-based paradigm, where deep learning techniques are embraced to solve the problem in an end-to-end fashion. Meanwhile, continuous efforts are devoted to improving the quality of 3D mesh labels for a wide range of datasets. Though remarkable progress has been achieved in the past decade, the task is still challenging due to flexible body motions, diverse appearances, complex environments, and insufficient in-the-wild annotations. To the best of our knowledge, this is the first survey that focuses on the task of monocular 3D human mesh recovery. We start with the introduction of body models and then elaborate recovery frameworks and training objectives by providing in-depth analyses of their strengths and weaknesses. We also summarize datasets, evaluation metrics, and benchmark results. Open issues and future directions are discussed in the end, hoping to motivate researchers and facilitate their research in this area. A regularly updated project page can be found at https:\/\/github.com\/tinatiansjz\/hmr-survey.","versions":[{"version":"v1","created":"Thu, 3 Mar 2022 18:56:08 GMT"},{"version":"v2","created":"Tue, 8 Mar 2022 12:42:52 GMT"},{"version":"v3","created":"Sat, 10 Jun 2023 10:10:36 GMT"},{"version":"v4","created":"Mon, 24 Jul 2023 06:59:56 GMT"},{"version":"v5","created":"Fri, 25 Aug 2023 07:30:32 GMT"},{"version":"v6","created":"Tue, 2 Jan 2024 15:38:20 GMT"}],"update_date":"2024-01-03","authors_parsed":[["Tian","Yating"],["Zhang","Hongwen"],["Liu","Yebin"],["Wang","Limin"]],"application_domain":"Culture, Media and Digital Content","prompt":"Please help me research the academic field of \"recovering 3D human meshes from monocular images,\" and only refer to papers published before January 2024."}
{"arxiv_id":"2112.12284","submitter":"Linwei Zhu","authors":"Yun Zhang, Linwei Zhu, Gangyi Jiang, Sam Kwong and C.-C.Jay Kuo","title":"A Survey on Perceptually Optimized Video Coding","comments":"36 pages, 12 figures, 6 tables, accepted by ACM Computing Surveys","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.MM eess.IV","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"To provide users with more realistic visual experiences, videos are developing in the trends of Ultra High Definition (UHD), High Frame Rate (HFR), High Dynamic Range (HDR), Wide Color Gammut (WCG) and high clarity. However, the data amount of videos increases exponentially, which requires high efficiency video compression for storage and network transmission. Perceptually optimized video coding aims to maximize compression efficiency by exploiting visual redundancies. In this paper, we present a broad and systematic survey on perceptually optimized video coding. Firstly, we present problem formulation and framework of the perceptually optimized video coding, which includes visual perception modelling, visual quality assessment and perceptual video coding optimization. Secondly, recent advances on visual factors, computational perceptual models and quality assessment models are presented. Thirdly, we review perceptual video coding optimizations from four key aspects, including perceptually optimized bit allocation, rate-distortion optimization, transform and quantization, filtering and enhancement. In each part, problem formulation, working flow, recent advances, advantages and challenges are presented. Fourthly, perceptual coding performances of the latest coding standards and tools are experimentally analyzed. Finally, challenging issues and future opportunities are identified.","versions":[{"version":"v1","created":"Thu, 23 Dec 2021 00:19:16 GMT"},{"version":"v2","created":"Wed, 16 Nov 2022 02:28:27 GMT"}],"update_date":"2022-11-17","authors_parsed":[["Zhang","Yun"],["Zhu","Linwei"],["Jiang","Gangyi"],["Kwong","Sam"],["Kuo","C. -C. Jay"]],"application_domain":"Culture, Media and Digital Content","prompt":"Please help me research the field of Perceptual Video Coding, ensuring that all referenced papers must have been published before November 2022."}
{"arxiv_id":"2204.08461","submitter":"James Brock","authors":"James Brock, Zahraa S. Abdallah","title":"Investigating Temporal Convolutional Neural Networks for Satellite Image Time Series Classification: A survey","comments":"24 pages (not inc. 6 pages for appendices and references), 8 figures,\n  15 tables. Submitted for publishing","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Satellite Image Time Series (SITS) of the Earth's surface provide detailed land cover maps, with their quality in the spatial and temporal dimensions consistently improving. These image time series are integral for developing systems that aim to produce accurate, up-to-date land cover maps of the Earth's surface. Applications are wide-ranging, with notable examples including ecosystem mapping, vegetation process monitoring and anthropogenic land-use change tracking. Recently proposed methods for SITS classification have demonstrated respectable merit, but these methods tend to lack native mechanisms that exploit the temporal dimension of the data; commonly resulting in extensive data pre-processing contributing to prohibitively long training times. To overcome these shortcomings, Temporal CNNs have recently been employed for SITS classification tasks with encouraging results. This paper seeks to survey this method against a plethora of other contemporary methods for SITS classification to validate the existing findings in recent literature. Comprehensive experiments are carried out on two benchmark SITS datasets with the results demonstrating that Temporal CNNs display a superior performance to the comparative benchmark algorithms across both studied datasets, achieving accuracies of 95.0\\% and 87.3\\% respectively. Investigations into the Temporal CNN architecture also highlighted the non-trivial task of optimising the model for a new dataset.","versions":[{"version":"v1","created":"Wed, 13 Apr 2022 14:08:14 GMT"},{"version":"v2","created":"Thu, 20 Apr 2023 13:58:18 GMT"}],"update_date":"2023-04-21","authors_parsed":[["Brock","James"],["Abdallah","Zahraa S."]],"application_domain":"Energy and Environmental Sustainability","prompt":"I need you to research the field of Satellite Image Time Series (SITS) classification for me. My research focuses on land cover mapping, and I would like you to specifically concentrate on deep learning methods that effectively utilize the temporal dimension of data, such as Temporal Convolutional Neural Networks (Temporal CNNs), Recurrent Neural Networks (RNNs), and Transformers. Please summarize the advantages and disadvantages of these methods and compare their performance on benchmark datasets. Note that you can only refer to and cite papers published before April 2023."}
{"arxiv_id":"2411.15583","submitter":"Yawen Zhang","authors":"Yawen Zhang, Han Zhou, Zhoumingju Jiang, Zilu Tang, Tao Luo, Qinyuan Lei","title":"Exploring Viewing Modalities in Cinematic Virtual Reality: A Systematic Review and Meta-Analysis of Challenges in Evaluating User Experience","comments":"29 pages, recommend for acceptance by CSCW","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.HC","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Cinematic Virtual Reality (CVR) is a narrative-driven VR experience that uses head-mounted displays with a 360-degree field of view. Previous research has explored different viewing modalities to enhance viewers' CVR experience. This study conducted a systematic review and meta-analysis focusing on how different viewing modalities, including intervened rotation, avatar assistance, guidance cues, and perspective shifting, influence the CVR experience. The study has screened 3444 papers (between 01\/01\/2013 and 17\/06\/2023) and selected 45 for systematic review, 13 of which also for meta-analysis. We conducted separate random-effects meta-analysis and applied Robust Variance Estimation to examine CVR viewing modalities and user experience outcomes. Evidence from experiments was synthesized as differences between standardized mean differences (SMDs) of user experience of control group (\"Swivel-Chair\" CVR) and experiment groups. To our surprise, we found inconsistencies in the effect sizes across different studies, even with the same viewing modalities. Moreover, in these studies, terms such as \"presence,\" \"immersion,\" and \"narrative engagement\" were often used interchangeably. Their irregular use of questionnaires, overreliance on self-developed questionnaires, and incomplete data reporting may have led to unrigorous evaluations of CVR experiences. This study contributes to Human-Computer Interaction (HCI) research by identifying gaps in CVR research, emphasizing the need for standardization of terminologies and methodologies to enhance the reliability and comparability of future CVR research.","versions":[{"version":"v1","created":"Sat, 23 Nov 2024 15:12:16 GMT"}],"update_date":"2024-11-26","authors_parsed":[["Zhang","Yawen"],["Zhou","Han"],["Jiang","Zhoumingju"],["Tang","Zilu"],["Luo","Tao"],["Lei","Qinyuan"]],"application_domain":"Culture, Media and Digital Content","prompt":"I am conducting a study in the field of Cinematic Virtual Reality (CVR) and require a detailed literature review. The core focus of the research is to systematically analyze and summarize how different viewing modalities affect user experience. Please emphasize the following types of viewing modalities: 1) guidance cues, including implicit\/explicit and intra-narrative\/extra-narrative cues; 2) intervened rotation, such as forced or assisted rotation; 3) avatar assistance; and 4) perspective shifting. Additionally, pay attention to the key metrics and methods used in these studies to assess user experience, such as presence, immersion, narrative engagement, and motion sickness, and explore the challenges and limitations of existing evaluation methods (e.g., questionnaires). When gathering literature, prioritize top-tier conference papers in the fields of Human-Computer Interaction (HCI) and Virtual Reality (VR), such as ACM CHI and IEEE VR. All referenced papers must be in English and published before November 2024."}
{"arxiv_id":"2212.13693","submitter":"Yifan Zhao","authors":"Yifan Zhao, Jia Li, Yonghong Tian","title":"Parsing Objects at a Finer Granularity: A Survey","comments":"Survey for fine-grained part segmentation and object recognition;\n  Accepted by Machine Intelligence Research (MIR, 2024)","journal-ref":null,"doi":"10.1007\/s11633-022-1404-6","report-no":null,"categories":"cs.CV","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Fine-grained visual parsing, including fine-grained part segmentation and fine-grained object recognition, has attracted considerable critical attention due to its importance in many real-world applications, e.g., agriculture, remote sensing, and space technologies. Predominant research efforts tackle these fine-grained sub-tasks following different paradigms, while the inherent relations between these tasks are neglected. Moreover, given most of the research remains fragmented, we conduct an in-depth study of the advanced work from a new perspective of learning the part relationship. In this perspective, we first consolidate recent research and benchmark syntheses with new taxonomies. Based on this consolidation, we revisit the universal challenges in fine-grained part segmentation and recognition tasks and propose new solutions by part relationship learning for these important challenges. Furthermore, we conclude several promising lines of research in fine-grained visual parsing for future research.","versions":[{"version":"v1","created":"Wed, 28 Dec 2022 04:20:10 GMT"}],"update_date":"2024-02-23","authors_parsed":[["Zhao","Yifan"],["Li","Jia"],["Tian","Yonghong"]],"application_domain":"Energy and Environmental Sustainability","prompt":"Please help me compile a literature review on the field of fine-grained visual analysis, referring only to papers published before December 2022. This review should focus on two representative tasks: fine-grained object recognition and semantic part segmentation. I hope the review will deeply explore the intrinsic connections between these two tasks, particularly methods that address challenges in fine-grained tasks through \"part relationship learning.\" Additionally, please summarize the main challenges, commonly used benchmark datasets, and mainstream technical strategies in this field."}
{"arxiv_id":"2408.16202","submitter":"Chenhui Cui","authors":"Qi Dong, Rubing Huang, Chenhui Cui, Dave Towey, Ling Zhou, Jinyu Tian, Jianzhou Wang","title":"Short-Term Electricity-Load Forecasting by Deep Learning: A Comprehensive Survey","comments":"To be published in Engineering Applications of Artificial Intelligence","journal-ref":null,"doi":"10.1016\/j.engappai.2025.110980","report-no":null,"categories":"cs.LG cs.AI","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Short-Term Electricity-Load Forecasting (STELF) refers to the prediction of the immediate demand (in the next few hours to several days) for the power system. Various external factors, such as weather changes and the emergence of new electricity consumption scenarios, can impact electricity demand, causing load data to fluctuate and become non-linear, which increases the complexity and difficulty of STELF. In the past decade, deep learning has been applied to STELF, modeling and predicting electricity demand with high accuracy, and contributing significantly to the development of STELF. This paper provides a comprehensive survey on deep-learning-based STELF over the past ten years. It examines the entire forecasting process, including data pre-processing, feature extraction, deep-learning modeling and optimization, and results evaluation. This paper also identifies some research challenges and potential research directions to be further investigated in future work.","versions":[{"version":"v1","created":"Thu, 29 Aug 2024 01:47:09 GMT"},{"version":"v2","created":"Sun, 18 May 2025 06:46:52 GMT"}],"update_date":"2025-05-20","authors_parsed":[["Dong","Qi"],["Huang","Rubing"],["Cui","Chenhui"],["Towey","Dave"],["Zhou","Ling"],["Tian","Jinyu"],["Wang","Jianzhou"]],"application_domain":"Energy and Environmental Sustainability","prompt":"Please help me research studies on short-term power load forecasting using deep learning published before May 2025."}
{"arxiv_id":"2305.08493","submitter":"Mohamad Elzohbi","authors":"Mohamad Elzohbi, Richard Zhao","title":"Creative Data Generation: A Review Focusing on Text and Poetry","comments":"10 pages, 2 figures, accepted for the International Conference on\n  Computational Creativity 2023 (ICCC'23)","journal-ref":"Proceedings of 14th International Conference on Computational\n  Creativity (ICCC), Waterloo, Canada, June, 2023, p29-38","doi":null,"report-no":null,"categories":"cs.CL","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"The rapid advancement in machine learning has led to a surge in automatic data generation, making it increasingly challenging to differentiate between naturally or human-generated data and machine-generated data. Despite these advancements, the generation of creative data remains a challenge. This paper aims to investigate and comprehend the essence of creativity, both in general and within the context of natural language generation. We review various approaches to creative writing devices and tasks, with a specific focus on the generation of poetry. We aim to shed light on the challenges and opportunities in the field of creative data generation.","versions":[{"version":"v1","created":"Mon, 15 May 2023 09:50:15 GMT"},{"version":"v2","created":"Mon, 26 Jun 2023 03:50:55 GMT"}],"update_date":"2024-10-22","authors_parsed":[["Elzohbi","Mohamad"],["Zhao","Richard"]],"application_domain":"Culture, Media and Digital Content","prompt":"I need a comprehensive literature review on the field of Creative Natural Language Generation, with all referenced papers published no later than June 2023. \n\nThe primary research focus should be on poetry generation, delving deeply into its technological evolution. This includes early rule-based and template-based approaches, heuristic methods such as evolutionary algorithms, mid-stage statistical methods, and modern deep learning approaches. For the deep learning section, please elaborate on various models based on RNN, Reinforcement Learning (RL), and Transformer architectures (e.g., GPT, BART), detailing their principles and applications.\n\nIn addition to poetry generation, please also cover other related creative text generation tasks, such as the automatic generation of rhetorical devices like metaphor, simile, and pun. \n\nWhen selecting references, prioritize English-language literature, focusing on work published in leading natural language processing and artificial intelligence conferences (e.g., ACL, EMNLP, NAACL, AAAI) as well as on the arXiv preprint platform."}
{"arxiv_id":"2206.13188","submitter":"Yi Wang","authors":"Yi Wang, Conrad M Albrecht, Nassim Ait Ali Braham, Lichao Mou, Xiao Xiang Zhu","title":"Self-supervised Learning in Remote Sensing: A Review","comments":"Accepted by IEEE Geoscience and Remote Sensing Magazine. 32 pages, 22\n  content pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"In deep learning research, self-supervised learning (SSL) has received great attention triggering interest within both the computer vision and remote sensing communities. While there has been a big success in computer vision, most of the potential of SSL in the domain of earth observation remains locked. In this paper, we provide an introduction to, and a review of the concepts and latest developments in SSL for computer vision in the context of remote sensing. Further, we provide a preliminary benchmark of modern SSL algorithms on popular remote sensing datasets, verifying the potential of SSL in remote sensing and providing an extended study on data augmentations. Finally, we identify a list of promising directions of future research in SSL for earth observation (SSL4EO) to pave the way for fruitful interaction of both domains.","versions":[{"version":"v1","created":"Mon, 27 Jun 2022 11:04:47 GMT"},{"version":"v2","created":"Fri, 2 Sep 2022 08:48:34 GMT"}],"update_date":"2022-09-05","authors_parsed":[["Wang","Yi"],["Albrecht","Conrad M"],["Braham","Nassim Ait Ali"],["Mou","Lichao"],["Zhu","Xiao Xiang"]],"application_domain":"Energy and Environmental Sustainability","prompt":"I want to research self-supervised learning in the field of remote sensing image analysis before September 2022. Please focus on mainstream branches of self-supervised learning methods, such as generative methods (e.g., autoencoders, GANs), predictive methods (e.g., designing proxy tasks using context), and contrastive learning methods (e.g., MoCo, SimCLR), and summarize their applications on different remote sensing data (e.g., multispectral, hyperspectral, SAR)."}
{"arxiv_id":"2111.04006","submitter":"Gengchen Mai","authors":"Gengchen Mai, Krzysztof Janowicz, Yingjie Hu, Song Gao, Bo Yan, Rui Zhu, Ling Cai, Ni Lao","title":"A Review of Location Encoding for GeoAI: Methods and Applications","comments":"32 Pages, 5 Figures, Accepted to International Journal of\n  Geographical Information Science, 2021","journal-ref":"International Journal of Geographical Information Science, 2021","doi":"10.1080\/13658816.2021.2004602","report-no":null,"categories":"cs.LG","license":"http:\/\/creativecommons.org\/publicdomain\/zero\/1.0\/","abstract":"A common need for artificial intelligence models in the broader geoscience is to represent and encode various types of spatial data, such as points (e.g., points of interest), polylines (e.g., trajectories), polygons (e.g., administrative regions), graphs (e.g., transportation networks), or rasters (e.g., remote sensing images), in a hidden embedding space so that they can be readily incorporated into deep learning models. One fundamental step is to encode a single point location into an embedding space, such that this embedding is learning-friendly for downstream machine learning models such as support vector machines and neural networks. We call this process location encoding. However, there lacks a systematic review on the concept of location encoding, its potential applications, and key challenges that need to be addressed. This paper aims to fill this gap. We first provide a formal definition of location encoding, and discuss the necessity of location encoding for GeoAI research from a machine learning perspective. Next, we provide a comprehensive survey and discussion about the current landscape of location encoding research. We classify location encoding models into different categories based on their inputs and encoding methods, and compare them based on whether they are parametric, multi-scale, distance preserving, and direction aware. We demonstrate that existing location encoding models can be unified under a shared formulation framework. We also discuss the application of location encoding for different types of spatial data. Finally, we point out several challenges in location encoding research that need to be solved in the future.","versions":[{"version":"v1","created":"Sun, 7 Nov 2021 05:25:49 GMT"},{"version":"v2","created":"Thu, 10 Mar 2022 19:16:25 GMT"}],"update_date":"2022-03-14","authors_parsed":[["Mai","Gengchen"],["Janowicz","Krzysztof"],["Hu","Yingjie"],["Gao","Song"],["Yan","Bo"],["Zhu","Rui"],["Cai","Ling"],["Lao","Ni"]],"application_domain":"Energy and Environmental Sustainability","prompt":"Please assist me in researching \"Location Encoding\" techniques in the field of Geospatial Artificial Intelligence (GeoAI), requiring all referenced papers to have been published before March 2022."}
{"arxiv_id":"2210.01272","submitter":"Brandon Victor","authors":"Brandon Victor, Zhen He, Aiden Nibali","title":"A systematic review of the use of Deep Learning in Satellite Imagery for Agriculture","comments":"23 pages, 5 figures and 10 tables in main paper. Final version, as\n  submitted and accepted at JSTARS","journal-ref":"IEEE Journal of Selected Topics in Applied Earth Observations and\n  Remote Sensing Volume 18 2024 Pages 2297-2316","doi":"10.1109\/JSTARS.2024.3501216","report-no":null,"categories":"cs.CV cs.LG eess.IV","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Agricultural research is essential for increasing food production to meet the requirements of an increasing population in the coming decades. Recently, satellite technology has been improving rapidly and deep learning has seen much success in generic computer vision tasks and many application areas which presents an important opportunity to improve analysis of agricultural land. Here we present a systematic review of 150 studies to find the current uses of deep learning on satellite imagery for agricultural research. Although we identify 5 categories of agricultural monitoring tasks, the majority of the research interest is in crop segmentation and yield prediction. We found that, when used, modern deep learning methods consistently outperformed traditional machine learning across most tasks; the only exception was that Long Short-Term Memory (LSTM) Recurrent Neural Networks did not consistently outperform Random Forests (RF) for yield prediction. The reviewed studies have largely adopted methodologies from generic computer vision, except for one major omission: benchmark datasets are not utilised to evaluate models across studies, making it difficult to compare results. Additionally, some studies have specifically utilised the extra spectral resolution available in satellite imagery, but other divergent properties of satellite images - such as the hugely different scales of spatial patterns - are not being taken advantage of in the reviewed studies.","versions":[{"version":"v1","created":"Mon, 3 Oct 2022 23:44:38 GMT"},{"version":"v2","created":"Fri, 15 Dec 2023 04:58:36 GMT"},{"version":"v3","created":"Tue, 14 Jan 2025 01:34:10 GMT"}],"update_date":"2025-01-15","authors_parsed":[["Victor","Brandon"],["He","Zhen"],["Nibali","Aiden"]],"application_domain":"Energy and Environmental Sustainability","prompt":"Please help me write a scholarly review on the application of deep learning for processing satellite imagery in the agricultural domain, with the requirement that only papers published before January 2025 can be referenced."}
{"arxiv_id":"2010.00661","submitter":"Md Hasan Shahriar","authors":"Nur Imtiazul Haque, Md Hasan Shahriar, Md Golam Dastgir, Anjan Debnath, Imtiaz Parvez, Arif Sarwat, Mohammad Ashiqur Rahman","title":"Machine Learning in Generation, Detection, and Mitigation of Cyberattacks in Smart Grid: A Survey","comments":"6 pages, 4 figures, accepted in 2020 North American Power Symposium\n  (NAPS)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.LG cs.SY eess.SP eess.SY stat.ML","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Smart grid (SG) is a complex cyber-physical system that utilizes modern cyber and physical equipment to run at an optimal operating point. Cyberattacks are the principal threats confronting the usage and advancement of the state-of-the-art systems. The advancement of SG has added a wide range of technologies, equipment, and tools to make the system more reliable, efficient, and cost-effective. Despite attaining these goals, the threat space for the adversarial attacks has also been expanded because of the extensive implementation of the cyber networks. Due to the promising computational and reasoning capability, machine learning (ML) is being used to exploit and defend the cyberattacks in SG by the attackers and system operators, respectively. In this paper, we perform a comprehensive summary of cyberattacks generation, detection, and mitigation schemes by reviewing state-of-the-art research in the SG domain. Additionally, we have summarized the current research in a structured way using tabular format. We also present the shortcomings of the existing works and possible future research direction based on our investigation.","versions":[{"version":"v1","created":"Tue, 1 Sep 2020 05:16:51 GMT"}],"update_date":"2020-10-05","authors_parsed":[["Haque","Nur Imtiazul"],["Shahriar","Md Hasan"],["Dastgir","Md Golam"],["Debnath","Anjan"],["Parvez","Imtiaz"],["Sarwat","Arif"],["Rahman","Mohammad Ashiqur"]],"application_domain":"Energy and Environmental Sustainability","prompt":"Please help me research studies conducted before September 2020 on the application of machine learning techniques for attack generation, detection, and mitigation in the domain of smart grid cybersecurity."}
{"arxiv_id":"2206.03237","submitter":"Fabian Stiehle","authors":"Fabian Stiehle and Ingo Weber","title":"Blockchain for Business Process Enactment: A Taxonomy and Systematic Literature Review","comments":"Preprint, Accepted at BPM 2022, Blockchain Forum","journal-ref":"Business Process Management: Blockchain, Robotic Process\n  Automation, and Central and Eastern Europe Forum. BPM 2022. Lecture Notes in\n  Business Information Processing, vol 459. Springer, Cham","doi":"10.1007\/978-3-031-16168-1_1","report-no":null,"categories":"cs.SE","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Blockchain has been proposed to facilitate the enactment of interorganisational business processes. For such processes, blockchain can guarantee the enforcement of rules and the integrity of execution traces - without the need for a centralised trusted party. However, the enactment of interorganisational processes pose manifold challenges. In this work, we ask what answers the research field offers in response to those challenges. To do so, we conduct a systematic literature review (SLR). As our guiding question, we investigate the guarantees and capabilities of blockchain-based enactment approaches. Based on resulting empirical evidence, we develop a taxonomy for blockchain-based enactment. We find that a wide range of approaches support traceability and correctness; however, research focusing on flexibility and scalability remains nascent. For all challenges, we point towards future research opportunities.","versions":[{"version":"v1","created":"Tue, 7 Jun 2022 12:38:15 GMT"},{"version":"v2","created":"Fri, 15 Jul 2022 14:51:42 GMT"}],"update_date":"2022-11-15","authors_parsed":[["Stiehle","Fabian"],["Weber","Ingo"]],"application_domain":"Finance and Business Services","prompt":"Please help me research academic studies before July 2022 on using blockchain technology to support business process execution."}
{"arxiv_id":"2207.10457","submitter":"Leonidas Droukas","authors":"Leonidas Droukas, Zoe Doulgeri, Nikolaos L. Tsakiridis, Dimitra Triantafyllou, Ioannis Kleitsiotis, Ioannis Mariolis, Dimitrios Giakoumis, Dimitrios Tzovaras, Dimitrios Kateris and Dionysis Bochtis","title":"A Survey of Robotic Harvesting Systems and Enabling Technologies","comments":"55 pages, 4 figures. Accepted for publication in Journal of\n  Intelligent & Robotic Systems","journal-ref":"Journal of Intelligent & Robotic Systems volume 107, Article\n  number: 21 (2023)","doi":"10.1007\/s10846-022-01793-z","report-no":null,"categories":"cs.RO","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"This paper presents a comprehensive review of ground agricultural robotic systems and applications with special focus on harvesting that span research and commercial products and results, as well as their enabling technologies. The majority of literature concerns the development of crop detection, field navigation via vision and their related challenges. Health monitoring, yield estimation, water status inspection, seed planting and weed removal are frequently encountered tasks. Regarding robotic harvesting, apples, strawberries, tomatoes and sweet peppers are mainly the crops considered in publications, research projects and commercial products. The reported harvesting agricultural robotic solutions, typically consist of a mobile platform, a single robotic arm\/manipulator and various navigation\/vision systems. This paper reviews reported development of specific functionalities and hardware, typically required by an operating agricultural robot harvester; they include (a) vision systems, (b) motion planning\/navigation methodologies (for the robotic platform and\/or arm), (c) Human-Robot-Interaction (HRI) strategies with 3D visualization, (d) system operation planning & grasping strategies and (e) robotic end-effector\/gripper design. Clearly, automated agriculture and specifically autonomous harvesting via robotic systems is a research area that remains wide open, offering several challenges where new contributions can be made.","versions":[{"version":"v1","created":"Thu, 21 Jul 2022 12:56:17 GMT"},{"version":"v2","created":"Fri, 22 Jul 2022 11:22:14 GMT"},{"version":"v3","created":"Wed, 1 Feb 2023 16:22:44 GMT"}],"update_date":"2023-02-02","authors_parsed":[["Droukas","Leonidas"],["Doulgeri","Zoe"],["Tsakiridis","Nikolaos L."],["Triantafyllou","Dimitra"],["Kleitsiotis","Ioannis"],["Mariolis","Ioannis"],["Giakoumis","Dimitrios"],["Tzovaras","Dimitrios"],["Kateris","Dimitrios"],["Bochtis","Dionysis"]],"application_domain":"Energy and Environmental Sustainability","prompt":"I am conducting an in-depth literature review on ground agricultural robot harvesting systems. My research focuses on: 1) Integrated robotic harvesting systems, specifically targeting high-value crops such as apples, strawberries, bell peppers, and grapes. Please examine system architectures (e.g., single-arm, dual-arm collaboration), performance metrics (e.g., harvesting success rate, single-fruit picking time), and application scenarios (e.g., greenhouses, orchards). 2) Key enabling technologies, with a particular focus on: a. Vision perception technologies based on deep learning (e.g., CNN, YOLO, Mask-RCNN) for fruit detection, localization, and maturity evaluation in complex environments with occlusions and varying lighting conditions; b. Motion planning and visual servo control of robotic arms, as well as end-effectors designed for different crops; c. Autonomous navigation and SLAM techniques suitable for unstructured agricultural environments. During the review, please prioritize top conferences and journals at the intersection of robotics and agriculture, such as ICRA, IROS, Journal of Field Robotics, Computers and Electronics in Agriculture, and focus on research published mainly in English. Most importantly, all cited literature must be published before February 2023."}
{"arxiv_id":"2306.05817","submitter":"Jianghao Lin","authors":"Jianghao Lin, Xinyi Dai, Yunjia Xi, Weiwen Liu, Bo Chen, Hao Zhang, Yong Liu, Chuhan Wu, Xiangyang Li, Chenxu Zhu, Huifeng Guo, Yong Yu, Ruiming Tang, Weinan Zhang","title":"How Can Recommender Systems Benefit from Large Language Models: A Survey","comments":"Accepted by ACM Transactions on Information Systems (TOIS); Look-up\n  table in appendix","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cs.AI","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"With the rapid development of online services, recommender systems (RS) have become increasingly indispensable for mitigating information overload. Despite remarkable progress, conventional recommendation models (CRM) still have some limitations, e.g., lacking open-world knowledge, and difficulties in comprehending users' underlying preferences and motivations. Meanwhile, large language models (LLM) have shown impressive general intelligence and human-like capabilities, which mainly stem from their extensive open-world knowledge, reasoning ability, as well as their comprehension of human culture and society. Consequently, the emergence of LLM is inspiring the design of recommender systems and pointing out a promising research direction, i.e., whether we can incorporate LLM and benefit from their knowledge and capabilities to compensate for the limitations of CRM. In this paper, we conduct a comprehensive survey on this research direction from the perspective of the whole pipeline in real-world recommender systems. Specifically, we summarize existing works from two orthogonal aspects: where and how to adapt LLM to RS. For the WHERE question, we discuss the roles that LLM could play in different stages of the recommendation pipeline, i.e., feature engineering, feature encoder, scoring\/ranking function, user interaction, and pipeline controller. For the HOW question, we investigate the training and inference strategies, resulting in two fine-grained taxonomy criteria, i.e., whether to tune LLM or not, and whether to involve conventional recommendation models for inference. Then, we highlight key challenges in adapting LLM to RS from three aspects, i.e., efficiency, effectiveness, and ethics. Finally, we summarize the survey and discuss the future prospects. We actively maintain a GitHub repository for papers and other related resources: https:\/\/github.com\/CHIANGEL\/Awesome-LLM-for-RecSys\/.","versions":[{"version":"v1","created":"Fri, 9 Jun 2023 11:31:50 GMT"},{"version":"v2","created":"Mon, 12 Jun 2023 04:11:14 GMT"},{"version":"v3","created":"Tue, 27 Jun 2023 06:03:57 GMT"},{"version":"v4","created":"Wed, 28 Jun 2023 01:59:11 GMT"},{"version":"v5","created":"Fri, 2 Feb 2024 12:11:44 GMT"},{"version":"v6","created":"Tue, 9 Jul 2024 13:17:52 GMT"}],"update_date":"2024-07-10","authors_parsed":[["Lin","Jianghao"],["Dai","Xinyi"],["Xi","Yunjia"],["Liu","Weiwen"],["Chen","Bo"],["Zhang","Hao"],["Liu","Yong"],["Wu","Chuhan"],["Li","Xiangyang"],["Zhu","Chenxu"],["Guo","Huifeng"],["Yu","Yong"],["Tang","Ruiming"],["Zhang","Weinan"]],"application_domain":"Finance and Business Services","prompt":"Certainly! Here's the translation:\n\nPlease help me research the application of large language models in the field of recommendation systems, and ensure that all referenced papers were published before July 2024."}
{"arxiv_id":"2407.15186","submitter":"Liang Shi","authors":"Liang Shi, Zhengju Tang, Nan Zhang, Xiaotong Zhang, Zhi Yang","title":"A Survey on Employing Large Language Models for Text-to-SQL Tasks","comments":"Accepted by ACM Computing Surveys (CSUR)","journal-ref":null,"doi":"10.1145\/3737873.","report-no":null,"categories":"cs.CL","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"With the development of the Large Language Models (LLMs), a large range of LLM-based Text-to-SQL(Text2SQL) methods have emerged. This survey provides a comprehensive review of LLM-based Text2SQL studies. We first enumerate classic benchmarks and evaluation metrics. For the two mainstream methods, prompt engineering and finetuning, we introduce a comprehensive taxonomy and offer practical insights into each subcategory. We present an overall analysis of the above methods and various models evaluated on well-known datasets and extract some characteristics. Finally, we discuss the challenges and future directions in this field.","versions":[{"version":"v1","created":"Sun, 21 Jul 2024 14:48:23 GMT"},{"version":"v2","created":"Sun, 11 Aug 2024 13:54:21 GMT"},{"version":"v3","created":"Mon, 09 Sep 2024 06:17:21 GMT"},{"version":"v4","created":"Thu, 07 Nov 2024 03:26:58 GMT"},{"version":"v5","created":"Tue, 03 Jun 2025 14:40:01 GMT"}],"update_date":"2025-06-04","authors_parsed":[["Shi","Liang"],["Tang","Zhengju"],["Zhang","Nan"],["Zhang","Xiaotong"],["Yang","Zhi"]],"application_domain":"Finance and Business Services","prompt":"I need a scholarly review of the academic research on the application of large language models in the Text-to-SQL domain. This review should systematically outline the state-of-the-art in this field, with a focus on two major technical approaches: prompt engineering and model fine-tuning. For prompt engineering, it should explore how techniques such as in-context learning and chain-of-thought can enhance model performance. For model fine-tuning, it should concentrate on how to effectively optimize open-source large models for specific domains or tasks. Please ensure that all referenced research findings are published before June 2025."}
{"arxiv_id":"2207.07483","submitter":"Aleksandr Petrov","authors":"Aleksandr Petrov and Craig Macdonald","title":"A Systematic Review and Replicability Study of BERT4Rec for Sequential Recommendation","comments":"This paper is accepted at the Reproducibility track of the ACM RecSys\n  '22 conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cs.AI cs.LG","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"BERT4Rec is an effective model for sequential recommendation based on the Transformer architecture. In the original publication, BERT4Rec claimed superiority over other available sequential recommendation approaches (e.g. SASRec), and it is now frequently being used as a state-of-the art baseline for sequential recommendations. However, not all subsequent publications confirmed this result and proposed other models that were shown to outperform BERT4Rec in effectiveness. In this paper we systematically review all publications that compare BERT4Rec with another popular Transformer-based model, namely SASRec, and show that BERT4Rec results are not consistent within these publications. To understand the reasons behind this inconsistency, we analyse the available implementations of BERT4Rec and show that we fail to reproduce results of the original BERT4Rec publication when using their default configuration parameters. However, we are able to replicate the reported results with the original code if training for a much longer amount of time (up to 30x) compared to the default configuration. We also propose our own implementation of BERT4Rec based on the Hugging Face Transformers library, which we demonstrate replicates the originally reported results on 3 out 4 datasets, while requiring up to 95% less training time to converge. Overall, from our systematic review and detailed experiments, we conclude that BERT4Rec does indeed exhibit state-of-the-art effectiveness for sequential recommendation, but only when trained for a sufficient amount of time. Additionally, we show that our implementation can further benefit from adapting other Transformer architectures that are available in the Hugging Face Transformers library (e.g. using disentangled attention, as provided by DeBERTa, or larger hidden layer size cf. ALBERT).","versions":[{"version":"v1","created":"Fri, 15 Jul 2022 14:09:04 GMT"}],"update_date":"2022-07-18","authors_parsed":[["Petrov","Aleksandr"],["Macdonald","Craig"]],"application_domain":"Finance and Business Services","prompt":"Please help me investigate the current research status and reproducibility issues of Transformer-based models, represented by BERT4Rec, in the field of sequential recommendation, and ensure that all referenced papers were published before July 2022."}
{"arxiv_id":"2011.13534","submitter":"Nishant Subramani","authors":"Nishant Subramani and Alexandre Matton and Malcolm Greaves and Adrian Lam","title":"A Survey of Deep Learning Approaches for OCR and Document Understanding","comments":"Accepted to the ML-RSA Workshop at NeurIPS2020. 15 pages (10 +\n  References)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.CV cs.IR cs.LG","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Documents are a core part of many businesses in many fields such as law, finance, and technology among others. Automatic understanding of documents such as invoices, contracts, and resumes is lucrative, opening up many new avenues of business. The fields of natural language processing and computer vision have seen tremendous progress through the development of deep learning such that these methods have started to become infused in contemporary document understanding systems. In this survey paper, we review different techniques for document understanding for documents written in English and consolidate methodologies present in literature to act as a jumping-off point for researchers exploring this area.","versions":[{"version":"v1","created":"Fri, 27 Nov 2020 03:05:59 GMT"},{"version":"v2","created":"Thu, 4 Feb 2021 23:48:39 GMT"}],"update_date":"2021-02-08","authors_parsed":[["Subramani","Nishant"],["Matton","Alexandre"],["Greaves","Malcolm"],["Lam","Adrian"]],"application_domain":"Finance and Business Services","prompt":"Please help me research the application of deep learning in the field of document understanding, and only refer to papers published on or before February 2021."}
{"arxiv_id":"2010.06479","submitter":"Yvan Lucas","authors":"Yvan Lucas, Johannes Jurgovsky","title":"Credit card fraud detection using machine learning: A survey","comments":"To be published","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"Credit card fraud has emerged as major problem in the electronic payment sector. In this survey, we study data-driven credit card fraud detection particularities and several machine learning methods to address each of its intricate challenges with the goal to identify fraudulent transactions that have been issued illegitimately on behalf of the rightful card owner. In particular, we first characterize a typical credit card detection task: the dataset and its attributes, the metric choice along with some methods to handle such unbalanced datasets. These questions are the entry point of every credit card fraud detection problem. Then we focus on dataset shift (sometimes called concept drift), which refers to the fact that the underlying distribution generating the dataset evolves over times: For example, card holders may change their buying habits over seasons and fraudsters may adapt their strategies. This phenomenon may hinder the usage of machine learning methods for real world datasets such as credit card transactions datasets. Afterwards we highlights different approaches used in order to capture the sequential properties of credit card transactions. These approaches range from feature engineering techniques (transactions aggregations for example) to proper sequence modeling methods such as recurrent neural networks (LSTM) or graphical models (hidden markov models).","versions":[{"version":"v1","created":"Tue, 13 Oct 2020 15:35:32 GMT"}],"update_date":"2020-10-14","authors_parsed":[["Lucas","Yvan"],["Jurgovsky","Johannes"]],"application_domain":"Finance and Business Services","prompt":"Please help me research the advancements in the field of using machine learning for credit card fraud detection, with the requirement that only papers published before October 2020 may be referenced."}
{"arxiv_id":"2107.08827","submitter":"Gustav Sourek","authors":"Matej Uhr\\'in, Gustav \\v{S}ourek, Ond\\v{r}ej Hub\\'a\\v{c}ek, Filip \\v{Z}elezn\\'y","title":"Optimal sports betting strategies in practice: an experimental review","comments":"Accepted to IMA Journal of Management Mathematics where it, however,\n  appeared with swapped names and surnames - putting the correct version here\n  for reference","journal-ref":"IMA Journal of Management Mathematics (2021) 00","doi":"10.1093\/imaman\/dpaa029","report-no":null,"categories":"q-fin.PM cs.CE q-fin.RM","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"We investigate the most popular approaches to the problem of sports betting investment based on modern portfolio theory and the Kelly criterion. We define the problem setting, the formal investment strategies, and review their common modifications used in practice. The underlying purpose of the reviewed modifications is to mitigate the additional risk stemming from the unrealistic mathematical assumptions of the formal strategies. We test the resulting methods using a unified evaluation protocol for three sports: horse racing, basketball and soccer. The results show the practical necessity of the additional risk-control methods and demonstrate their individual benefits. Particularly, we show that an adaptive variant of the popular ``fractional Kelly'' method is a very suitable choice across a wide range of settings.","versions":[{"version":"v1","created":"Thu, 15 Jul 2021 15:09:47 GMT"}],"update_date":"2021-07-20","authors_parsed":[["Uhr\u00edn","Matej"],["\u0160ourek","Gustav"],["Hub\u00e1\u010dek","Ond\u0159ej"],["\u017delezn\u00fd","Filip"]],"application_domain":"Finance and Business Services","prompt":"I am conducting research on sports betting investment strategies and request a literature review. My focus is not on predictive models for match outcomes but rather on fund management and optimizing betting portfolios. I hope the review can cover two mainstream theoretical approaches: the Kelly Criterion and Modern Portfolio Theory. Specifically, I am particularly interested in how these theories have been adapted in practice to address real-world uncertainties (e.g., inability to know the true probabilities of match outcomes), such as fractional Kelly, drawdown constraints, and other risk management methods. Please ensure that all referenced literature was published before July 2021."}
{"arxiv_id":"2111.00358","submitter":"Saumitra Mishra","authors":"Saumitra Mishra, Sanghamitra Dutta, Jason Long, Daniele Magazzeni","title":"A Survey on the Robustness of Feature Importance and Counterfactual Explanations","comments":"4 pages plus references. Accepted at the workshop on Explainable AI\n  in Finance (XAI-FIN21). Camera-ready version. V2: Added more references and\n  expanded robust explanations for counterfactuals","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http:\/\/arxiv.org\/licenses\/nonexclusive-distrib\/1.0\/","abstract":"There exist several methods that aim to address the crucial task of understanding the behaviour of AI\/ML models. Arguably, the most popular among them are local explanations that focus on investigating model behaviour for individual instances. Several methods have been proposed for local analysis, but relatively lesser effort has gone into understanding if the explanations are robust and accurately reflect the behaviour of underlying models. In this work, we present a survey of the works that analysed the robustness of two classes of local explanations (feature importance and counterfactual explanations) that are popularly used in analysing AI\/ML models in finance. The survey aims to unify existing definitions of robustness, introduces a taxonomy to classify different robustness approaches, and discusses some interesting results. Finally, the survey introduces some pointers about extending current robustness analysis approaches so as to identify reliable explainability methods.","versions":[{"version":"v1","created":"Sat, 30 Oct 2021 22:48:04 GMT"},{"version":"v2","created":"Tue, 3 Jan 2023 14:53:00 GMT"}],"update_date":"2023-01-04","authors_parsed":[["Mishra","Saumitra"],["Dutta","Sanghamitra"],["Long","Jason"],["Magazzeni","Daniele"]],"application_domain":"Finance and Business Services","prompt":"Please help me investigate the robustness of local explanation methods in Explainable Artificial Intelligence (XAI), based on papers published before January 2023."}
{"arxiv_id":"2311.10723","submitter":"Yinheng Li","authors":"Yinheng Li, Shaofei Wang, Han Ding, Hang Chen","title":"Large Language Models in Finance: A Survey","comments":"Accepted by 4th ACM International Conference on AI in Finance\n  (ICAIF-23) https:\/\/ai-finance.org","journal-ref":null,"doi":null,"report-no":null,"categories":"q-fin.GN cs.AI cs.CL","license":"http:\/\/creativecommons.org\/licenses\/by\/4.0\/","abstract":"Recent advances in large language models (LLMs) have opened new possibilities for artificial intelligence applications in finance. In this paper, we provide a practical survey focused on two key aspects of utilizing LLMs for financial tasks: existing solutions and guidance for adoption. First, we review current approaches employing LLMs in finance, including leveraging pretrained models via zero-shot or few-shot learning, fine-tuning on domain-specific data, and training custom LLMs from scratch. We summarize key models and evaluate their performance improvements on financial natural language processing tasks. Second, we propose a decision framework to guide financial professionals in selecting the appropriate LLM solution based on their use case constraints around data, compute, and performance needs. The framework provides a pathway from lightweight experimentation to heavy investment in customized LLMs. Lastly, we discuss limitations and challenges around leveraging LLMs in financial applications. Overall, this survey aims to synthesize the state-of-the-art and provide a roadmap for responsibly applying LLMs to advance financial AI.","versions":[{"version":"v1","created":"Thu, 28 Sep 2023 06:04:04 GMT"},{"version":"v2","created":"Mon, 8 Jul 2024 22:13:09 GMT"}],"update_date":"2024-07-10","authors_parsed":[["Li","Yinheng"],["Wang","Shaofei"],["Ding","Han"],["Chen","Hang"]],"application_domain":"Finance and Business Services","prompt":"I am researching the application of large language models (LLMs) in the financial domain. Please summarize how the academic and industrial communities have applied LLMs to financial tasks, such as financial sentiment analysis, news summarization, quantitative trading, etc., before July 2024. I am particularly interested in several mainstream technical approaches: directly using pre-trained models for zero-shot or few-shot learning, fine-tuning on financial datasets, and training specialized large-scale financial models from scratch. Please conduct a review based on these directions and reference only papers published before July 2024."}
